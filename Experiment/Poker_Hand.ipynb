{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Poker_Hand.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ig8-7jK-U9-J",
        "1aiNz4-SeCZ7",
        "yMBdAnKneyUn"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_10Yt3B6qVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb94195-bd2d-4b50-990e-45bb34b9664a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thesis'...\n",
            "remote: Enumerating objects: 234, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 234 (delta 22), reused 18 (delta 7), pack-reused 181\u001b[K\n",
            "Receiving objects: 100% (234/234), 11.15 MiB | 16.82 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lehoangphuongnhi/Thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Thesis"
      ],
      "metadata": {
        "id": "xmbISPEC8wCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1972d38d-9db1-4b9b-f267-866dd0414d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Thesis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!make start-gpu\n",
        "!pip install wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbhJyurf8zMS",
        "outputId": "b51f5ef8-06f1-4a94-ea26-509a939775b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "make: *** No rule to make target 'start-gpu'.  Stop.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=0b993bd2bd066354a917f951732878e48f954933d638cf741202f4fe94d634a5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
      ],
      "metadata": {
        "id": "_bzKGhHcEM9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Code.tab_model import TabNetClassifier\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "import os\n",
        "import wget\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import gzip\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4nQBRF9k81SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Poker Hand dataset"
      ],
      "metadata": {
        "id": "VMXAs2uIPjKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-training-true.data\"\n",
        "dataset_name = 'poker-hand-train'\n",
        "out = Path(os.getcwd()+'/data/'+dataset_name+'.csv')"
      ],
      "metadata": {
        "id": "U31IIAVGCBz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out.parent.mkdir(parents=True, exist_ok=True)\n",
        "if out.exists():\n",
        "    print(\"File already exists.\")\n",
        "else:\n",
        "    print(\"Downloading file...\")\n",
        "    wget.download(url, out.as_posix())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7keYn3OtCQnE",
        "outputId": "64898e58-0d00-4eb0-fa85-4760debc9bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url_1 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/poker/poker-hand-testing.data\"\n",
        "dataset_name_1 = 'poker-hand-test'\n",
        "out_1 = Path(os.getcwd()+'/data/'+dataset_name_1+'.csv')"
      ],
      "metadata": {
        "id": "Tg5l5HPlLOP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_1.parent.mkdir(parents=True, exist_ok=True)\n",
        "if out_1.exists():\n",
        "    print(\"File already exists.\")\n",
        "else:\n",
        "    print(\"Downloading file...\")\n",
        "    wget.download(url_1, out_1.as_posix())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um5OCLntLPWl",
        "outputId": "69c2d435-6881-4816-fc32-e159d1514776"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load data and split"
      ],
      "metadata": {
        "id": "aAQcfYfzUBmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_columns = ['S1', 'C1','S2', 'C2','S3', 'C3','S4', 'C4','S5', 'C5','Poker Hand']"
      ],
      "metadata": {
        "id": "UzR69pIMhvkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(out, header = None, names = feature_columns)"
      ],
      "metadata": {
        "id": "junAlYrzLRMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(out_1, header = None, names = feature_columns)"
      ],
      "metadata": {
        "id": "KmREwOMNK1Vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_total = len(train)\n",
        "\n",
        "train_indices, valid_indices = train_test_split(\n",
        "    range(n_total), test_size=0.1, random_state=0)"
      ],
      "metadata": {
        "id": "JSnCfZ9vT9Dq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple preprocessing"
      ],
      "metadata": {
        "id": "ig8-7jK-U9-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nunique = train.nunique()\n",
        "types = train.dtypes\n",
        "\n",
        "categorical_columns = []\n",
        "categorical_dims =  {}\n",
        "for col in train.columns:\n",
        "        print(col, train[col].nunique())\n",
        "        l_enc = LabelEncoder()\n",
        "        train[col] = train[col].fillna(\"VV_likely\")\n",
        "        train[col] = l_enc.fit_transform(train[col].values)\n",
        "        categorical_columns.append(col)\n",
        "        categorical_dims[col] = len(l_enc.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCHn_i3nLXOk",
        "outputId": "f064b21b-345c-4aa6-b8eb-8c1d23b5c61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S1 4\n",
            "C1 13\n",
            "S2 4\n",
            "C2 13\n",
            "S3 4\n",
            "C3 13\n",
            "S4 4\n",
            "C4 13\n",
            "S5 4\n",
            "C5 13\n",
            "Poker Hand 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in test.columns:\n",
        "        print(col, test[col].nunique())\n",
        "        l_enc = LabelEncoder()\n",
        "        test[col] = test[col].fillna(\"VV_likely\")\n",
        "        test[col] = l_enc.fit_transform(test[col].values)\n",
        "        #categorical_columns.append(col)\n",
        "        #categorical_dims[col] = len(l_enc.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhUqgIe_pubJ",
        "outputId": "59abae7a-2b9f-4742-b100-b1ffee50aa83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S1 4\n",
            "C1 13\n",
            "S2 4\n",
            "C2 13\n",
            "S3 4\n",
            "C3 13\n",
            "S4 4\n",
            "C4 13\n",
            "S5 4\n",
            "C5 13\n",
            "Poker Hand 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = 'Poker Hand'"
      ],
      "metadata": {
        "id": "Id3mqwtsA8vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [ col for col in train.columns if col not in [target]] \n",
        "\n",
        "cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
        "\n",
        "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]"
      ],
      "metadata": {
        "id": "HHk_FWhvLvWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmDzAdkZgjtJ",
        "outputId": "3d225066-9ce2-4798-aa3a-dbefc22ce4fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['S1', 'C1', 'S2', 'C2', 'S3', 'C3', 'S4', 'C4', 'S5', 'C5']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_idxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abl2EQrBgid6",
        "outputId": "10bc0948-e3e9-4d90-d562-4c829fd98a41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_dims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcX5LWZrw9_s",
        "outputId": "dda73c8a-3395-4033-f495-733c66519adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 13, 4, 13, 4, 13, 4, 13, 4, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "im = pd.DataFrame()"
      ],
      "metadata": {
        "id": "dyfx74yzkqy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im = train['Poker Hand'].value_counts()"
      ],
      "metadata": {
        "id": "DmumI3_IauRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "im"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqYUULMHku0W",
        "outputId": "9c4ef301-9a7b-4dcf-cb3b-9eb9552cad81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    12493\n",
              "1    10599\n",
              "2     1206\n",
              "3      513\n",
              "4       93\n",
              "5       54\n",
              "6       36\n",
              "7        6\n",
              "9        5\n",
              "8        5\n",
              "Name: Poker Hand, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "plt.bar(im.index, im.values)\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "R0XJdUOXkZ4P",
        "outputId": "a6b5d4f0-4a3b-4db0-d570-6c84a0530be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = train['Poker Hand'].groupby(train['Poker Hand']).size()\n",
        "fig = plt.figure(figsize = (10, 7))\n",
        "ax = fig.add_axes([0.5,0.5,.8,.8])\n",
        "ax.set_title('Label')\n",
        "ax.set_yscale('log')\n",
        "ax.set_xticks([0,1,2,3,4,5,6,7,8,9])\n",
        "for val in range(len(y)):\n",
        "    ax.annotate(str(y[val]), xy = (val, y[val]), xytext = (val-.4, y[val]))\n",
        "    ax.bar(val,y[val])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "bOCMaL9LWEMC",
        "outputId": "52bdaf57-7fe5-4545-80f6-09a892e659b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmgAAAHCCAYAAABbgDVcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3df5TVdb3v8ecbBlREBxQnbAYdbogDjDLqJN57Oph2IChRMU+JnJs/UNKTHrOu5jnejmSp6LJ7raXpwiS855DmDxQhLtIqFL1XJUAxCEwKFfw1qDEpWgF+7h8zzQUFDzAbvp/Z83ysxWr2Z3/33q/PMscX38/3+9mRUkKSJEn56FJ0AEmSJG3NgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuapE4pIh6JiPP29GslaUdY0CR1eBHxQkT8XdE5JKlULGiSJEmZsaBJKksR0TsiZkfEuoj4Q+vPNR847BMRsTAi/hgRMyPigC1ef1xE/N+IWB8RSyPi03t2BpI6MwuapHLVBfgxcChwCPAecPMHjvkycC5wMLAJ+AFARFQDPwO+CxwA/Dfg/og4aI8kl9TpWdAklaWU0psppftTSu+mlN4GrgGO/8Bh/5ZSWpZS2gB8C/hiRHQF/gGYk1Kak1J6P6X0c2AR8Lk9OglJnVZF0QEkaXeIiB7A/wRGAb1bh/eLiK4ppc2tj9ds8ZIXgW5AH1rOuv19RIzZ4vluwPzdm1qSWljQJJWrbwCHA8NSSq9FRAPwNBBbHNNvi58PATYCb9BS3P4tpXT+ngorSVtyiVNSuegWEXv/9Q8tZ83eA9a3Xvx/1TZe8w8RMbj1bNvVwH2tZ9f+HRgTEZ+NiK6t7/npbdxkIEm7hQVNUrmYQ0sh++ufXsA+tJwRexKYu43X/BswDXgN2Bv4J4CU0hrgFOBfgHW0nFG7DH9nStpDIqVUdAZJkiRtwb8NSpIkZcaCJkmSlBkLmiRJUmYsaJIkSZmxoEmSJGUmi41q+/Tpk2pra4uOIUmStMcsXrz4jZTSNr/jN4uCVltby6JFi4qOIUmStMdExIvbe84lTkmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzHS6gnbuuedSVVVFfX1929hll11GXV0dRx55JGPHjmX9+vVbveall16iZ8+e3HjjjW1j3//+96mvr2fIkCHcdNNNbePf+ta3OPLII2loaGDkyJG88soru39SkiSprHS6gnb22Wczd+7crcZGjBjBsmXLePbZZxk4cCDXXXfdVs9//etfZ/To0W2Ply1bxu23387ChQtZunQps2fPZtWqVUBL2Xv22Wd55plnOOmkk7j66qt3/6QkSVJZ6XQFbfjw4RxwwAFbjY0cOZKKipavJT3uuONYu3Zt23MPPvgg/fv3Z8iQIW1jK1asYNiwYfTo0YOKigqOP/54ZsyYAcD+++/fdtyGDRuIiN05HUmSVIY6XUH7j0ydOrXtbNk777zD9ddfz1VXXbXVMfX19Tz22GO8+eabvPvuu8yZM4c1a9a0PX/llVfSr18/pk+f7hk0SZK00yxoW7jmmmuoqKhg/PjxAEyaNIlLL72Unj17bnXcoEGD+OY3v8nIkSMZNWoUDQ0NdO3adav3WbNmDePHj+fmm2/eo3OQJEkdnwWt1bRp05g9ezbTp09vW5Z86qmnuPzyy6mtreWmm27i2muvbStcEyZMYPHixSxYsIDevXszcODAD73n+PHjuf/++/foPCRJUsdXUXSAHMydO5cbbriBRx99lB49erSNP/bYY20/T5o0iZ49e3LRRRcB0NTURFVVFS+99BIzZszgySefBOD555/nsMMOA2DmzJnU1dXtwZlIkqRyECmlojPQ2NiYFi1atNs/p/aKn7HuoRv480u/ZvN7f6Rrj15Ufmo8f3zyXtLmjXTZZz8A9vr44Rz42Yu2eu36x6cT3fahcthpALw2/XLef+9t6NKV3ieexz61DQCse+BaNr61FqILFfsfxAGf/SoV+/XZ6awvTP78Th1/7rnnMnv2bKqqqli2bBkAb731Fl/60pd44YUXqK2t5Z577qF379488sgjnHLKKfTv3x+A0047jX/9138FWrYPuf3220kpcf755/O1r30NgKVLl3LBBRfwzjvvUFtby/Tp07e6IUKSJO2ciFicUmrc5nOdraB1FDtb0BYsWEDPnj358pe/3FbQLr/8cg444ACuuOIKJk+ezB/+8Aeuv/56HnnkEW688UZmz5691XssW7aMM844g4ULF9K9e3dGjRrFbbfdxoABA/jkJz/JjTfeyPHHH8/UqVNZvXo13/nOd0o2X0mSOpuPKmheg1YmtrV9yMyZMznrrLMAOOuss3jwwQc/8j0+avuQ3/72twwfPhxo2TfOa+skSdp9LGhl7PXXX+fggw8GoG/fvrz++uttzz3xxBMMHTqU0aNHs3z5cuCjtw8ZMmQIM2fOBODee+/dalsRSZJUWha0TiIi2u5OPfroo3nxxRdZunQpF198Maeeeirw0duHTJ06lR/+8Iccc8wxvP3223Tv3r2wuUiSVO4saGXsYx/7GK+++ioAr776KlVVVUDLtx38dW+3z33uc2zcuJE33ngD2P72IXV1dcybN4/Fixczbtw4PvGJTxQwI0mSOgcLWhk7+eSTufPOOwG48847OeWUUwB47bXX+OvNIQsXLuT999/nwAMPBFq2DwHatg8588wztxp///33+e53v8sFF1ywR+ciSVJnslv2QYuIfYFHgUkppdn/0fFqv3HjxvHII4/wxhtvUFNTw7e//W2uuOIKvvjFL3LHHXdw6KGHcs899wBw3333ceutt1JRUcE+++zD3Xff3bb8+YUvfIE333yTbt26ccstt9CrVy8A7rrrLm655RagZVuOc845p5iJSpLUCezQNhsRMRU4CWhKKdVvMT4K+D7QFfhRSmly6/jVwDvAb3akoLnNxoft1DYbkyp3X5BSmtRcdAJJkrJRim02pgGjPvCmXYFbgNHAYGBcRAyOiBHAb4CmXU4sSZLUie3QEmdKaUFE1H5g+FhgVUrp9wARcTdwCtAT2JeW0vZeRMxJKb3/wfeMiInARIBDDjlkV/NLkiSVnfZcg1YNbLkZ1lpgWErpIoCIOBt4Y1vlDCClNAWYAi1LnO3IIUmSVFZ225elp5Sm7a73liRJKmft2WbjZaDfFo9rWsckSZLUDu0paL8CDouI/hHRHTgDeKg0sSRJkjqvHSpoEXEX8ARweESsjYgJKaVNwEXAw8AK4J6U0vKd+fCIGBMRU5qb3X5BkiTpr3b0Ls5x2xmfA8zZ1Q9PKc0CZjU2Np6/q+8hSZJUbvyqJ0mSpMxY0CRJkjJjQZMkScqMBU2SJCkzhRY07+KUJEn6sEILWkppVkppYmVlZZExJEmSsuISpyRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZ7+KUJEnKjHdxSpIkZcYlTkmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMuM2GJElSZtxmQ5IkKTMucUqSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZtyoVpIkKTNuVCtJkpQZlzglSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMz4TQKSJEmZ8ZsEJEmSMuMSpyRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlJlCC1pEjImIKc3NzUXGkCRJykqhBS2lNCulNLGysrLIGJIkSVlxiVOSJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpM4UWtIgYExFTmpubi4whSZKUlUILWkppVkppYmVlZZExJEmSsuISpyRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlBkLmiRJUmYsaJIkSZmxoClb5557LlVVVdTX17eNXXbZZdTV1XHkkUcyduxY1q9f3/bcddddx4ABAzj88MN5+OGH28bXr1/P6aefTl1dHYMGDeKJJ57Yo/OQJGlnWdCUrbPPPpu5c+duNTZixAiWLVvGs88+y8CBA7nuuusA+M1vfsPdd9/N8uXLmTt3Lv/4j//I5s2bAbjkkksYNWoUK1euZOnSpQwaNGiPz0WSpJ1hQVO2hg8fzgEHHLDV2MiRI6moqADguOOOY+3atQDMnDmTM844g7322ov+/fszYMAAFi5cSHNzMwsWLGDChAkAdO/enV69eu3ZiUiStJMsaOqwpk6dyujRowF4+eWX6devX9tzNTU1vPzyy6xevZqDDjqIc845h6OOOorzzjuPDRs2FBVZkqQdYkFTh3TNNddQUVHB+PHjP/K4TZs2sWTJEi688EKefvpp9t13XyZPnryHUkqStGssaOpwpk2bxuzZs5k+fToRAUB1dTVr1qxpO2bt2rVUV1dTU1NDTU0Nw4YNA+D0009nyZIlheSWJGlHWdDUocydO5cbbriBhx56iB49erSNn3zyydx99938+c9/ZvXq1Tz//PMce+yx9O3bl379+vHcc88B8Itf/ILBgwcXFV+SpB1SUXQAaVuOuPMI1ty6hg0rN7DpnU10O6AbVadW8cbP3uD9Te9zyDGHALDPJ/ah+uxqAJoGNLFfv/2IrsHBZx5Mw783APDeiPdoGNVA2pToflB3as6rYe6dc7f72Tvr12f9umTvJUkSWNCUsX4X9vvQ2AHHH7CNI1tUnVxF1clVHxrf59B9GDBpQEmzSZK0O7nEKUmSlBkLmiRJUmYsaJIkSZmxoEmSJGWm5AUtIgZFxG0RcV9EXFjq95ckSSp3O1TQImJqRDRFxLIPjI+KiOciYlVEXAGQUlqRUroA+CLwN6WPLEmSVN529AzaNGDUlgMR0RW4BRgNDAbGRcTg1udOBn4GzClZUkmSpE5ihwpaSmkB8NYHho8FVqWUfp9S+gtwN3BK6/EPpZRGA9v9osSImBgRiyJi0bp163YtvSRJUhlqz0a11cCaLR6vBYZFxKeB04C9+IgzaCmlKcAUgMbGxtSOHJIkSWWl5N8kkFJ6BHik1O8rSZLUWbTnLs6XgS2/i6emdUySJEnt0J6C9ivgsIjoHxHdgTOAh0oTS5IkqfPa0W027gKeAA6PiLURMSGltAm4CHgYWAHck1JavjMfHhFjImJKc3PzzuaWJEkqWzt0DVpKadx2xufQjq00UkqzgFmNjY3n7+p7SJIklRu/6kmSJCkzFjRJkqTMWNAkSZIyY0GTJEnKTKEFzbs4JUmSPqzQgpZSmpVSmlhZWVlkDEmSpKy4xClJkpQZC5okSVJmLGiSJEmZsaBJkiRlxrs4JUmSMuNdnJIkSZlxiVOSJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpM26zIe1htbW1HHHEETQ0NNDY2AjAvffey5AhQ+jSpQuLFi1qO3bhwoU0NDTQ0NDA0KFDeeCBB4qKLUnagyqK/PCU0ixgVmNj4/lF5pD2tPnz59OnT5+2x/X19cyYMYOvfOUrWx1XX1/PokWLqKio4NVXX2Xo0KGMGTOGiopC/9WVJO1m/paXMjBo0KBtjvfo0aPt5z/96U9ExJ6KJEkqkNegSXtYRDBy5EiOOeYYpkyZ8h8e/9RTTzFkyBCOOOIIbrvtNs+eSVIn4G96aQ97/PHHqa6upqmpiREjRlBXV8fw4cO3e/ywYcNYvnw5K1as4KyzzmL06NHsvffeezCxJGlP8wyatIdVV1cDUFVVxdixY1m4cOEOvW7QoEH07NmTZcuW7c54kqQMWNCkPWjDhg28/fbbbT/PmzeP+vr67R6/evVqNm3aBMCLL77IypUrqa2t3RNRJUkFcolT2oNef/11xo4dC8CmTZs488wzGTVqFA888AAXX3wx69at4/Of/zwNDQ08/PDDPP7440yePJlu3brRpUsXfvjDH25196ckqTxFSqnoDDQ2NqYt937aXWqv+Nlu/4xSeWHy53f84EmVuy9IKU3a8f3ujrjziN0YpLR+fdavd/jYFXXbvlszN4NWrig6giSVvYhYnFJq3NZzblQrSZKUmUILWkppVkppYmVlBzkDJEmStAd4k4AkSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlBm/SUCSJCkzfpOAJElSZlzilCRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMlNoQYuIMRExpbm5ucgYkiRJWSm0oKWUZqWUJlZWVhYZQ5IkKSsucUqSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlBkLmiRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlptCCFhFjImJKc3NzkTEkSZKyUmhBSynNSilNrKysLDKGJElSVlzilCRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEkl8f3vf5/6+nqGDBnCTTfdBMC3vvUtjjzySBoaGhg5ciSvvPJKwSklqWPYLQUtIk6NiNsj4qcRMXJ3fIakfCxbtozbb7+dhQsXsnTpUmbPns2qVau47LLLePbZZ3nmmWc46aSTuPrqq4uOKkkdwg4XtIiYGhFNEbHsA+OjIuK5iFgVEVcApJQeTCmdD1wAfKm0kSXlZsWKFQwbNowePXpQUVHB8ccfz4wZM9h///3bjtmwYQMRUWBKSeo4duYM2jRg1JYDEdEVuAUYDQwGxkXE4C0O+e+tz0sqY/X19Tz22GO8+eabvPvuu8yZM4c1a9YAcOWVV9KvXz+mT5/uGTRJ2kE7XNBSSguAtz4wfCywKqX0+5TSX4C7gVOixfXA/04pLdnW+0XExIhYFBGL1q1bt6v5JWVg0KBBfPOb32TkyJGMGjWKhoYGunbtCsA111zDmjVrGD9+PDfffHPBSSWpY2jvNWjVwJotHq9tHbsY+Dvg9Ii4YFsvTClNSSk1ppQaDzrooHbGkFS0CRMmsHjxYhYsWEDv3r0ZOHDgVs+PHz+e+++/v6B0ktSxVOyON00p/QD4we54b0l5ampqoqqqipdeeokZM2bw5JNP8vzzz3PYYYcBMHPmTOrq6gpOKUkdQ3sL2stAvy0e17SOSepkvvCFL/Dmm2/SrVs3brnlFnr16sWECRN47rnn6NKlC4ceeii33XZb0TElqUNob0H7FXBYRPSnpZidAZzZ7lSSOoxbLvglAGcM+Xbb2Mp7YeW9v+TEg77KiVtcwfDgd54DntvDCf+/r952YmGfLUk7Y2e22bgLeAI4PCLWRsSElNIm4CLgYWAFcE9KaflOvOeYiJjS3Ny8s7klSZLK1g6fQUspjdvO+Bxgzq58eEppFjCrsbHx/F15vSRJUjnyq54kSZIyY0GTJEnKjAVNkiQpMxY0SZKkzBRa0LyLU5Ik6cMKLWgppVkppYmVlZVFxpAkScqKS5ySJEmZsaBJkiRlxoImSZKUGQuaJElSZryLU5IkKTPexSlJkpQZlzglSZIyY0GTJEnKjAVNkiQpMxY0SdqO2tpajjjiCBoaGmhsbNzque9973tEBG+88UZB6SSVs4qiA0hSzubPn0+fPn22GluzZg3z5s3jkEMOKSiVpHLnNhuStJMuvfRSbrjhBiKi6CiSypTbbEjSdkQEI0eO5JhjjmHKlCkAzJw5k+rqaoYOHVpwOknlzCVOSdqOxx9/nOrqapqamhgxYgR1dXVce+21zJs3r+hoksqcNwlI0nZUV1cDUFVVxdixY3n00UdZvXo1Q4cOpba2lrVr13L00Ufz2muvFZxUUrmxoEnSNmzYsIG333677ed58+bxyU9+kqamJl544QVeeOEFampqWLJkCX379i04raRy4xKnJH3A9750Em++8y7T/s8iAN5PiaMO+TjLf3wzy398c9txf1zXxA/PO5N99+peVFS+8dPZhX22pN3HgiZJ23Bgzx5847PDP/KYK086cQ+lkdTZuMQpSZKUGQuaJElSZtyoVpIkKTNuVCtJkpQZlzglSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZI6kT/96U8ce+yxDB06lCFDhnDVVVcBkFLiyiuvZODAgQwaNIgf/OAHBSeVOje/i1OSOpG99tqLX/7yl/Ts2ZONGzfyqU99itGjR7NixQrWrFnDypUr6dKlC01NTUVHlTq1QgtaRIwBxgwYMKDIGJLUaUQEPXv2BGDjxo1s3LiRiODWW2/lJz/5CV26tCysVFVVFRlT6vT8JgFJ6mQ2b95MQ0MDVVVVjBgxgmHDhvG73/2On/70pzQ2NjJ69Gief/75omNKnZrXoElSJ9O1a1eeeeYZ1q5dy8KFC1m2bBl//vOf2XvvvVm0aBHnn38+5557btExpU7NgiZJnVSvXr044YQTmDt3LjU1NZx22mkAjB07lmeffbbgdFLnZkGTpE5k3bp1rF+/HoD33nuPn//859TV1XHqqacyf/58AB599FEGDhxYZEyp0/MuTknqJNZe8Rgrmn7HpT+7ls1pM++nxJi6E2h4vJL+fxrOP13zHW745nfZt3sPrvvsN1h7xWOFZa2Z/LeFfbaUAwuaJHUig6o+wdxz7vjQeOXe+3Hn399QQCJJ2+ISpyRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlptCCFhFjImJKc3NzkTEkSZKyUmhBSynNSilNrKysLDKGJElSVlzilCRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScpMoQUtIsZExJTm5uYiY0iSJGWl0IKWUpqVUppYWVlZZAxJkqSsuMQpSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlBkLmiRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZixokiRJmbGgSZIkZcaCJkmSlBkLmiRJUmYsaJIkSZmxoEmSJGXGgiZJkpQZC5okSVJmLGiSJEmZsaBJkiRlxoImSZKUGQuaJElSZkpe0CLiP0XEHRFxX6nfW5IkqTPYoYIWEVMjoikiln1gfFREPBcRqyLiCoCU0u9TShN2R1hJkqTOYEfPoE0DRm05EBFdgVuA0cBgYFxEDC5pOkmSpE5ohwpaSmkB8NYHho8FVrWeMfsLcDdwSonzSZIkdTrtuQatGlizxeO1QHVEHBgRtwFHRcQ/b+/FETExIhZFxKJ169a1I4YkSVJ5qSj1G6aU3gQu2IHjpgBTABobG1Opc0iSJHVU7TmD9jLQb4vHNa1jkiRJaof2FLRfAYdFRP+I6A6cATxUmliSJEmd145us3EX8ARweESsjYgJKaVNwEXAw8AK4J6U0vLdF1WSJKlz2KFr0FJK47YzPgeYs6sfHhFjgDEDBgzY1beQJEkqO4V+1VNKaVZKaWJlZWWRMSRJkrLid3FKkiRlxoImSZKUGQuaJElSZgotaBExJiKmNDc3FxlDkiQpK94kIEmSlBmXOCVJkjJjQZMkScqMBU2SJCkzFjRJkqTMWNAkSZIy4zYbkqQOb/369Zx++unU1dUxaNAgnnjiiaIjSe3iNhuSpA7vkksuYdSoUaxcuZKlS5cyaNCgoiNJ7VJRdABJktqjubmZBQsWMG3aNAC6d+9O9+7diw0ltZPXoEmSOrTVq1dz0EEHcc4553DUUUdx3nnnsWHDhqJjSe1iQZMkdWibNm1iyZIlXHjhhTz99NPsu+++TJ48uehYUrtY0CRJHVpNTQ01NTUMGzYMgNNPP50lS5YUnEpqHwuaJKlD69u3L/369eO5554D4Be/+AWDBw8uOJXUPoXeJBARY4AxAwYMKDKGJKmDmjRpEgBDhgzhhBNOYPPmzfTu3ZtTTjml7blc5JZHeSu0oKWUZgGzGhsbzy8yhySpY+vbty8TJ04sOkZJ1dbWst9++9G1a1cqKipYtGhR0ZFKolznVWpusyFJUqbmz59Pnz59io5RcuU6r1LyGjRJkqTMWNAkScpQRDBy5EiOOeYYpkyZUnSckinXeZWaS5ySJGXo8ccfp7q6mqamJkaMGEFdXR3Dhw8vOla7leu8Ss0zaJIkZai6uhqAqqoqxo4dy8KFCwtOVBrlOq9Ss6BJkpSZDRs28Pbbb7f9PG/ePOrr6wtO1X7lOq/dwX3QJEnKzIwHBjHpqtcB2Lw5ceJnetKt+1f5xS8LDvYBnznxdzt8bN/5z7DplbU0/+vXAUibN7P3Z0Zz9l59Yf4zuyviLnnthIaiI7gPmiRJufn4x7sx5faaomOUXMXHazjwR/cUHaNDcIlTkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMxY0CRJkjJjQZMkScqMBU2SJCkzhRa0iBgTEVOam5uLjCFJkpSVQgtaSmlWSmliZWVlkTEkSZKy4hKnJElSZixokiRJmbGgSd5Kt1AAAAUmSURBVJIkZcaCJkmSlBkLmiRJUmYsaJIkSZmJlFLRGYiIdcCLRedohz7AG0WHKDHn1HGU47zKcU5QnvMqxzlBec7LOeXn0JTSQdt6IouC1tFFxKKUUmPROUrJOXUc5TivcpwTlOe8ynFOUJ7zck4di0uckiRJmbGgSZIkZcaCVhpTig6wGzinjqMc51WOc4LynFc5zgnKc17OqQPxGjRJkqTMeAZNkiQpMxa0doiIURHxXESsiogris5TChExNSKaImJZ0VlKJSL6RcT8iPhNRCyPiEuKzlQKEbF3RCyMiKWt8/p20ZlKJSK6RsTTETG76CylEBEvRMSvI+KZiFhUdJ5SiYheEXFfRKyMiBUR8Z+LztQeEXF46z+jv/75Y0R8rehcpRARl7b+nlgWEXdFxN5FZ2qviLikdT7Ly+Wf05Zc4txFEdEV+C0wAlgL/AoYl1L6TaHB2ikihgPvAP8rpVRfdJ5SiIiDgYNTSksiYj9gMXBqGfyzCmDflNI7EdENeBy4JKX0ZMHR2i0ivg40AvunlE4qOk97RcQLQGNKqSPv1/QhEXEn8FhK6UcR0R3okVJaX3SuUmj9Hf8yMCyl1JH36SQiqmn5/TA4pfReRNwDzEkpTSs22a6LiHrgbuBY4C/AXOCClNKqQoOVkGfQdt2xwKqU0u9TSn+h5f8opxScqd1SSguAt4rOUUoppVdTSktaf34bWAFUF5uq/VKLd1ofdmv90+H/xhURNcDngR8VnUXbFxGVwHDgDoCU0l/KpZy1+gzwu45ezrZQAewTERVAD+CVgvO01yDgqZTSuymlTcCjwGkFZyopC9quqwbWbPF4LWXwH/1yFxG1wFHAU8UmKY3WpcBngCbg5ymlcpjXTcDlwPtFBymhBMyLiMURMbHoMCXSH1gH/Lh1OfpHEbFv0aFK6AzgrqJDlEJK6WXgRuAl4FWgOaU0r9hU7bYM+NuIODAiegCfA/oVnKmkLGjqNCKiJ3A/8LWU0h+LzlMKKaXNKaUGoAY4tvW0f4cVEScBTSmlxUVnKbFPpZSOBkYDX229lKCjqwCOBm5NKR0FbADK5Vrc7sDJwL1FZymFiOhNywpPf+DjwL4R8Q/FpmqflNIK4HpgHi3Lm88AmwsNVWIWtF33Mlu39ZrWMWWo9Rqt+4HpKaUZRecptdalpfnAqKKztNPfACe3XrN1N3BiRPx7sZHar/UMBimlJuABWi6R6OjWAmu3OGt7Hy2FrRyMBpaklF4vOkiJ/B2wOqW0LqW0EZgB/JeCM7VbSumOlNIxKaXhwB9ouS68bFjQdt2vgMMion/r37bOAB4qOJO2ofVi+juAFSml/1F0nlKJiIMiolfrz/vQcsPKymJTtU9K6Z9TSjUppVpa/p36ZUqpQ/9NPyL2bb05hdYlwJG0LM90aCml14A1EXF469BngA59480WxlEmy5utXgKOi4gerb8PP0PLtbgdWkRUtf7vIbRcf/aTYhOVVkXRATqqlNKmiLgIeBjoCkxNKS0vOFa7RcRdwKeBPhGxFrgqpXRHsana7W+A/wr8uvV6LYB/SSnNKTBTKRwM3Nl6t1kX4J6UUllsS1FmPgY80PLfRSqAn6SU5hYbqWQuBqa3/iX198A5Bedpt9YSPQL4StFZSiWl9FRE3AcsATYBT1MeO/DfHxEHAhuBr5bZTSpusyFJkpQblzglSZIyY0GTJEnKjAVNkiQpMxY0SZKkzFjQJEmSMmNBkyRJyowFTZIkKTMWNEmSpMz8Pw/fuepfVDrHAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "1aiNz4-SeCZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train[features].values[train_indices]\n",
        "y_train = train[target].values[train_indices]\n",
        "\n",
        "X_valid = train[features].values[valid_indices]\n",
        "y_valid = train[target].values[valid_indices]\n",
        "\n",
        "X_test = test[features].values\n",
        "y_test = test[target].values"
      ],
      "metadata": {
        "id": "tfhPYcJieA44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    n_d=128, n_a=128, n_steps=4,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=[3,12,3,12,3,12,3,12,3,12],\n",
        "    gamma=1.5, n_ind=2, n_shared=2,\n",
        "    lambda_sparse=1e-6, momentum=0.05, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 80},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98-YcI5IEtDC",
        "outputId": "dfcaf9da-3edb-42c6-db5d-0ac7bb60fd6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name = ['train', 'val'],\n",
        "    max_epochs=800, patience=100,\n",
        "    batch_size=4096, vbs=1024 #, augmentations=aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03bd826e-d011-4319-98ad-f4eb81904824",
        "id": "26kKpe6Hbilq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 2.26043 | train_accuracy: 0.43947 | val_accuracy: 0.42863 |  0:00:00s\n",
            "epoch 1  | loss: 1.34992 | train_accuracy: 0.47403 | val_accuracy: 0.45822 |  0:00:01s\n",
            "epoch 2  | loss: 1.18359 | train_accuracy: 0.48007 | val_accuracy: 0.46941 |  0:00:01s\n",
            "epoch 3  | loss: 1.13228 | train_accuracy: 0.48127 | val_accuracy: 0.47341 |  0:00:02s\n",
            "epoch 4  | loss: 1.09489 | train_accuracy: 0.48327 | val_accuracy: 0.47061 |  0:00:03s\n",
            "epoch 5  | loss: 1.05795 | train_accuracy: 0.48105 | val_accuracy: 0.46821 |  0:00:03s\n",
            "epoch 6  | loss: 1.02709 | train_accuracy: 0.48932 | val_accuracy: 0.47661 |  0:00:04s\n",
            "epoch 7  | loss: 1.01778 | train_accuracy: 0.49798 | val_accuracy: 0.4918  |  0:00:04s\n",
            "epoch 8  | loss: 1.0102  | train_accuracy: 0.49727 | val_accuracy: 0.47621 |  0:00:05s\n",
            "epoch 9  | loss: 0.99654 | train_accuracy: 0.49762 | val_accuracy: 0.46661 |  0:00:05s\n",
            "epoch 10 | loss: 0.99403 | train_accuracy: 0.50144 | val_accuracy: 0.47221 |  0:00:06s\n",
            "epoch 11 | loss: 0.99362 | train_accuracy: 0.50118 | val_accuracy: 0.47781 |  0:00:07s\n",
            "epoch 12 | loss: 0.9837  | train_accuracy: 0.51304 | val_accuracy: 0.48061 |  0:00:07s\n",
            "epoch 13 | loss: 0.97472 | train_accuracy: 0.52068 | val_accuracy: 0.4922  |  0:00:08s\n",
            "epoch 14 | loss: 0.97141 | train_accuracy: 0.52077 | val_accuracy: 0.507   |  0:00:08s\n",
            "epoch 15 | loss: 0.97606 | train_accuracy: 0.52823 | val_accuracy: 0.5034  |  0:00:09s\n",
            "epoch 16 | loss: 0.97198 | train_accuracy: 0.52486 | val_accuracy: 0.4966  |  0:00:09s\n",
            "epoch 17 | loss: 0.96291 | train_accuracy: 0.52646 | val_accuracy: 0.503   |  0:00:10s\n",
            "epoch 18 | loss: 0.96491 | train_accuracy: 0.52632 | val_accuracy: 0.5086  |  0:00:11s\n",
            "epoch 19 | loss: 0.95856 | train_accuracy: 0.52606 | val_accuracy: 0.51419 |  0:00:11s\n",
            "epoch 20 | loss: 0.958   | train_accuracy: 0.52801 | val_accuracy: 0.5034  |  0:00:12s\n",
            "epoch 21 | loss: 0.96141 | train_accuracy: 0.5325  | val_accuracy: 0.4958  |  0:00:12s\n",
            "epoch 22 | loss: 0.9536  | train_accuracy: 0.53152 | val_accuracy: 0.5038  |  0:00:13s\n",
            "epoch 23 | loss: 0.95317 | train_accuracy: 0.54116 | val_accuracy: 0.5002  |  0:00:14s\n",
            "epoch 24 | loss: 0.94793 | train_accuracy: 0.53587 | val_accuracy: 0.5098  |  0:00:14s\n",
            "epoch 25 | loss: 0.94938 | train_accuracy: 0.53903 | val_accuracy: 0.5074  |  0:00:15s\n",
            "epoch 26 | loss: 0.94445 | train_accuracy: 0.54249 | val_accuracy: 0.51619 |  0:00:15s\n",
            "epoch 27 | loss: 0.945   | train_accuracy: 0.54027 | val_accuracy: 0.5102  |  0:00:16s\n",
            "epoch 28 | loss: 0.9418  | train_accuracy: 0.54449 | val_accuracy: 0.4962  |  0:00:16s\n",
            "epoch 29 | loss: 0.94317 | train_accuracy: 0.54756 | val_accuracy: 0.5018  |  0:00:17s\n",
            "epoch 30 | loss: 0.94132 | train_accuracy: 0.54805 | val_accuracy: 0.499   |  0:00:18s\n",
            "epoch 31 | loss: 0.93714 | train_accuracy: 0.5484  | val_accuracy: 0.5014  |  0:00:18s\n",
            "epoch 32 | loss: 0.93442 | train_accuracy: 0.55173 | val_accuracy: 0.5058  |  0:00:19s\n",
            "epoch 33 | loss: 0.93812 | train_accuracy: 0.55196 | val_accuracy: 0.5066  |  0:00:19s\n",
            "epoch 34 | loss: 0.94195 | train_accuracy: 0.54854 | val_accuracy: 0.5078  |  0:00:20s\n",
            "epoch 35 | loss: 0.94056 | train_accuracy: 0.54543 | val_accuracy: 0.4942  |  0:00:20s\n",
            "epoch 36 | loss: 0.94078 | train_accuracy: 0.54969 | val_accuracy: 0.5038  |  0:00:21s\n",
            "epoch 37 | loss: 0.93738 | train_accuracy: 0.54849 | val_accuracy: 0.5074  |  0:00:22s\n",
            "epoch 38 | loss: 0.93802 | train_accuracy: 0.55302 | val_accuracy: 0.5042  |  0:00:22s\n",
            "epoch 39 | loss: 0.93241 | train_accuracy: 0.5564  | val_accuracy: 0.5014  |  0:00:23s\n",
            "epoch 40 | loss: 0.92975 | train_accuracy: 0.5564  | val_accuracy: 0.5086  |  0:00:23s\n",
            "epoch 41 | loss: 0.92753 | train_accuracy: 0.55245 | val_accuracy: 0.4922  |  0:00:24s\n",
            "epoch 42 | loss: 0.93051 | train_accuracy: 0.55556 | val_accuracy: 0.4982  |  0:00:24s\n",
            "epoch 43 | loss: 0.92034 | train_accuracy: 0.55986 | val_accuracy: 0.4974  |  0:00:25s\n",
            "epoch 44 | loss: 0.92424 | train_accuracy: 0.56    | val_accuracy: 0.51619 |  0:00:26s\n",
            "epoch 45 | loss: 0.92379 | train_accuracy: 0.55978 | val_accuracy: 0.4978  |  0:00:26s\n",
            "epoch 46 | loss: 0.92033 | train_accuracy: 0.56897 | val_accuracy: 0.51979 |  0:00:27s\n",
            "epoch 47 | loss: 0.91828 | train_accuracy: 0.56511 | val_accuracy: 0.4898  |  0:00:27s\n",
            "epoch 48 | loss: 0.91476 | train_accuracy: 0.5636  | val_accuracy: 0.4946  |  0:00:28s\n",
            "epoch 49 | loss: 0.92072 | train_accuracy: 0.56377 | val_accuracy: 0.48021 |  0:00:29s\n",
            "epoch 50 | loss: 0.9146  | train_accuracy: 0.56404 | val_accuracy: 0.4966  |  0:00:29s\n",
            "epoch 51 | loss: 0.91075 | train_accuracy: 0.56289 | val_accuracy: 0.497   |  0:00:30s\n",
            "epoch 52 | loss: 0.91191 | train_accuracy: 0.566   | val_accuracy: 0.5018  |  0:00:30s\n",
            "epoch 53 | loss: 0.91654 | train_accuracy: 0.56084 | val_accuracy: 0.51499 |  0:00:31s\n",
            "epoch 54 | loss: 0.91815 | train_accuracy: 0.54942 | val_accuracy: 0.48461 |  0:00:31s\n",
            "epoch 55 | loss: 0.91907 | train_accuracy: 0.5664  | val_accuracy: 0.5062  |  0:00:32s\n",
            "epoch 56 | loss: 0.91828 | train_accuracy: 0.56098 | val_accuracy: 0.5018  |  0:00:33s\n",
            "epoch 57 | loss: 0.91753 | train_accuracy: 0.56577 | val_accuracy: 0.5022  |  0:00:33s\n",
            "epoch 58 | loss: 0.91168 | train_accuracy: 0.56546 | val_accuracy: 0.4906  |  0:00:34s\n",
            "epoch 59 | loss: 0.91561 | train_accuracy: 0.56946 | val_accuracy: 0.4942  |  0:00:34s\n",
            "epoch 60 | loss: 0.91019 | train_accuracy: 0.56808 | val_accuracy: 0.5026  |  0:00:35s\n",
            "epoch 61 | loss: 0.91367 | train_accuracy: 0.56582 | val_accuracy: 0.4986  |  0:00:35s\n",
            "epoch 62 | loss: 0.91323 | train_accuracy: 0.56266 | val_accuracy: 0.5082  |  0:00:36s\n",
            "epoch 63 | loss: 0.91574 | train_accuracy: 0.5632  | val_accuracy: 0.51659 |  0:00:37s\n",
            "epoch 64 | loss: 0.92064 | train_accuracy: 0.56462 | val_accuracy: 0.5118  |  0:00:37s\n",
            "epoch 65 | loss: 0.91223 | train_accuracy: 0.56182 | val_accuracy: 0.5094  |  0:00:38s\n",
            "epoch 66 | loss: 0.91077 | train_accuracy: 0.56249 | val_accuracy: 0.4942  |  0:00:38s\n",
            "epoch 67 | loss: 0.9146  | train_accuracy: 0.5664  | val_accuracy: 0.4958  |  0:00:39s\n",
            "epoch 68 | loss: 0.91595 | train_accuracy: 0.56808 | val_accuracy: 0.5066  |  0:00:39s\n",
            "epoch 69 | loss: 0.90853 | train_accuracy: 0.57319 | val_accuracy: 0.51819 |  0:00:40s\n",
            "epoch 70 | loss: 0.9036  | train_accuracy: 0.57515 | val_accuracy: 0.51299 |  0:00:41s\n",
            "epoch 71 | loss: 0.90354 | train_accuracy: 0.57248 | val_accuracy: 0.51939 |  0:00:41s\n",
            "epoch 72 | loss: 0.90231 | train_accuracy: 0.5723  | val_accuracy: 0.52619 |  0:00:42s\n",
            "epoch 73 | loss: 0.90565 | train_accuracy: 0.57275 | val_accuracy: 0.51659 |  0:00:42s\n",
            "epoch 74 | loss: 0.90274 | train_accuracy: 0.5723  | val_accuracy: 0.51339 |  0:00:43s\n",
            "epoch 75 | loss: 0.89784 | train_accuracy: 0.57119 | val_accuracy: 0.5122  |  0:00:43s\n",
            "epoch 76 | loss: 0.90299 | train_accuracy: 0.57466 | val_accuracy: 0.51819 |  0:00:44s\n",
            "epoch 77 | loss: 0.89868 | train_accuracy: 0.57715 | val_accuracy: 0.51899 |  0:00:45s\n",
            "epoch 78 | loss: 0.896   | train_accuracy: 0.57102 | val_accuracy: 0.505   |  0:00:45s\n",
            "epoch 79 | loss: 0.9026  | train_accuracy: 0.57128 | val_accuracy: 0.5114  |  0:00:46s\n",
            "epoch 80 | loss: 0.90206 | train_accuracy: 0.57417 | val_accuracy: 0.51859 |  0:00:46s\n",
            "epoch 81 | loss: 0.89794 | train_accuracy: 0.57173 | val_accuracy: 0.52019 |  0:00:47s\n",
            "epoch 82 | loss: 0.90028 | train_accuracy: 0.57128 | val_accuracy: 0.5046  |  0:00:47s\n",
            "epoch 83 | loss: 0.89891 | train_accuracy: 0.56999 | val_accuracy: 0.51579 |  0:00:48s\n",
            "epoch 84 | loss: 0.89855 | train_accuracy: 0.57306 | val_accuracy: 0.501   |  0:00:49s\n",
            "epoch 85 | loss: 0.90014 | train_accuracy: 0.56848 | val_accuracy: 0.4962  |  0:00:49s\n",
            "epoch 86 | loss: 0.90409 | train_accuracy: 0.56324 | val_accuracy: 0.4958  |  0:00:50s\n",
            "epoch 87 | loss: 0.90206 | train_accuracy: 0.56426 | val_accuracy: 0.4938  |  0:00:50s\n",
            "epoch 88 | loss: 0.9003  | train_accuracy: 0.57275 | val_accuracy: 0.5006  |  0:00:51s\n",
            "epoch 89 | loss: 0.89366 | train_accuracy: 0.57906 | val_accuracy: 0.52059 |  0:00:51s\n",
            "epoch 90 | loss: 0.89285 | train_accuracy: 0.57777 | val_accuracy: 0.52019 |  0:00:52s\n",
            "epoch 91 | loss: 0.89573 | train_accuracy: 0.5775  | val_accuracy: 0.53339 |  0:00:52s\n",
            "epoch 92 | loss: 0.89212 | train_accuracy: 0.57417 | val_accuracy: 0.52499 |  0:00:53s\n",
            "epoch 93 | loss: 0.89128 | train_accuracy: 0.57884 | val_accuracy: 0.53619 |  0:00:54s\n",
            "epoch 94 | loss: 0.89122 | train_accuracy: 0.58252 | val_accuracy: 0.52259 |  0:00:54s\n",
            "epoch 95 | loss: 0.88336 | train_accuracy: 0.58243 | val_accuracy: 0.53139 |  0:00:55s\n",
            "epoch 96 | loss: 0.884   | train_accuracy: 0.58239 | val_accuracy: 0.51299 |  0:00:55s\n",
            "epoch 97 | loss: 0.89028 | train_accuracy: 0.5779  | val_accuracy: 0.51939 |  0:00:56s\n",
            "epoch 98 | loss: 0.89097 | train_accuracy: 0.5807  | val_accuracy: 0.52179 |  0:00:57s\n",
            "epoch 99 | loss: 0.88991 | train_accuracy: 0.58221 | val_accuracy: 0.51499 |  0:00:57s\n",
            "epoch 100| loss: 0.88758 | train_accuracy: 0.58381 | val_accuracy: 0.52699 |  0:00:58s\n",
            "epoch 101| loss: 0.88364 | train_accuracy: 0.58679 | val_accuracy: 0.53539 |  0:00:58s\n",
            "epoch 102| loss: 0.87685 | train_accuracy: 0.58594 | val_accuracy: 0.52819 |  0:00:59s\n",
            "epoch 103| loss: 0.87778 | train_accuracy: 0.58452 | val_accuracy: 0.52739 |  0:00:59s\n",
            "epoch 104| loss: 0.88123 | train_accuracy: 0.5847  | val_accuracy: 0.53499 |  0:01:00s\n",
            "epoch 105| loss: 0.88044 | train_accuracy: 0.58537 | val_accuracy: 0.53379 |  0:01:01s\n",
            "epoch 106| loss: 0.8818  | train_accuracy: 0.58537 | val_accuracy: 0.53579 |  0:01:01s\n",
            "epoch 107| loss: 0.881   | train_accuracy: 0.58501 | val_accuracy: 0.53259 |  0:01:02s\n",
            "epoch 108| loss: 0.88241 | train_accuracy: 0.58452 | val_accuracy: 0.51779 |  0:01:02s\n",
            "epoch 109| loss: 0.88269 | train_accuracy: 0.58328 | val_accuracy: 0.52139 |  0:01:03s\n",
            "epoch 110| loss: 0.88334 | train_accuracy: 0.58012 | val_accuracy: 0.52179 |  0:01:03s\n",
            "epoch 111| loss: 0.88395 | train_accuracy: 0.5807  | val_accuracy: 0.52539 |  0:01:04s\n",
            "epoch 112| loss: 0.88844 | train_accuracy: 0.58874 | val_accuracy: 0.53858 |  0:01:05s\n",
            "epoch 113| loss: 0.88461 | train_accuracy: 0.58159 | val_accuracy: 0.53539 |  0:01:05s\n",
            "epoch 114| loss: 0.88289 | train_accuracy: 0.5819  | val_accuracy: 0.52539 |  0:01:06s\n",
            "epoch 115| loss: 0.88903 | train_accuracy: 0.57604 | val_accuracy: 0.51739 |  0:01:06s\n",
            "epoch 116| loss: 0.90122 | train_accuracy: 0.57364 | val_accuracy: 0.51899 |  0:01:07s\n",
            "epoch 117| loss: 0.90178 | train_accuracy: 0.57337 | val_accuracy: 0.53539 |  0:01:07s\n",
            "epoch 118| loss: 0.8977  | train_accuracy: 0.5775  | val_accuracy: 0.53259 |  0:01:08s\n",
            "epoch 119| loss: 0.90264 | train_accuracy: 0.57826 | val_accuracy: 0.53139 |  0:01:09s\n",
            "epoch 120| loss: 0.90172 | train_accuracy: 0.5735  | val_accuracy: 0.54098 |  0:01:09s\n",
            "epoch 121| loss: 0.91112 | train_accuracy: 0.57413 | val_accuracy: 0.53778 |  0:01:10s\n",
            "epoch 122| loss: 0.9105  | train_accuracy: 0.57297 | val_accuracy: 0.53099 |  0:01:10s\n",
            "epoch 123| loss: 0.90668 | train_accuracy: 0.5739  | val_accuracy: 0.53579 |  0:01:11s\n",
            "epoch 124| loss: 0.90232 | train_accuracy: 0.57692 | val_accuracy: 0.53539 |  0:01:11s\n",
            "epoch 125| loss: 0.89838 | train_accuracy: 0.57879 | val_accuracy: 0.53579 |  0:01:12s\n",
            "epoch 126| loss: 0.89298 | train_accuracy: 0.5775  | val_accuracy: 0.53739 |  0:01:13s\n",
            "epoch 127| loss: 0.89748 | train_accuracy: 0.57897 | val_accuracy: 0.51699 |  0:01:13s\n",
            "epoch 128| loss: 0.89574 | train_accuracy: 0.57368 | val_accuracy: 0.52939 |  0:01:14s\n",
            "epoch 129| loss: 0.89822 | train_accuracy: 0.57684 | val_accuracy: 0.52179 |  0:01:14s\n",
            "epoch 130| loss: 0.89315 | train_accuracy: 0.58354 | val_accuracy: 0.52619 |  0:01:15s\n",
            "epoch 131| loss: 0.89188 | train_accuracy: 0.58279 | val_accuracy: 0.54218 |  0:01:15s\n",
            "epoch 132| loss: 0.88825 | train_accuracy: 0.58492 | val_accuracy: 0.54298 |  0:01:16s\n",
            "epoch 133| loss: 0.88319 | train_accuracy: 0.58816 | val_accuracy: 0.54418 |  0:01:17s\n",
            "epoch 134| loss: 0.88172 | train_accuracy: 0.59443 | val_accuracy: 0.53659 |  0:01:17s\n",
            "epoch 135| loss: 0.87837 | train_accuracy: 0.59363 | val_accuracy: 0.52939 |  0:01:18s\n",
            "epoch 136| loss: 0.87334 | train_accuracy: 0.59376 | val_accuracy: 0.53299 |  0:01:18s\n",
            "epoch 137| loss: 0.87147 | train_accuracy: 0.59398 | val_accuracy: 0.53499 |  0:01:19s\n",
            "epoch 138| loss: 0.86981 | train_accuracy: 0.59332 | val_accuracy: 0.54218 |  0:01:20s\n",
            "epoch 139| loss: 0.86683 | train_accuracy: 0.59598 | val_accuracy: 0.54818 |  0:01:20s\n",
            "epoch 140| loss: 0.86685 | train_accuracy: 0.59239 | val_accuracy: 0.54258 |  0:01:21s\n",
            "epoch 141| loss: 0.87485 | train_accuracy: 0.59052 | val_accuracy: 0.53778 |  0:01:21s\n",
            "epoch 142| loss: 0.87319 | train_accuracy: 0.59243 | val_accuracy: 0.53219 |  0:01:22s\n",
            "epoch 143| loss: 0.87552 | train_accuracy: 0.59047 | val_accuracy: 0.54338 |  0:01:22s\n",
            "epoch 144| loss: 0.87493 | train_accuracy: 0.59372 | val_accuracy: 0.54418 |  0:01:23s\n",
            "epoch 145| loss: 0.86793 | train_accuracy: 0.59678 | val_accuracy: 0.53739 |  0:01:24s\n",
            "epoch 146| loss: 0.86371 | train_accuracy: 0.60007 | val_accuracy: 0.53858 |  0:01:24s\n",
            "epoch 147| loss: 0.86204 | train_accuracy: 0.6002  | val_accuracy: 0.53259 |  0:01:25s\n",
            "epoch 148| loss: 0.86226 | train_accuracy: 0.59887 | val_accuracy: 0.53619 |  0:01:25s\n",
            "epoch 149| loss: 0.8585  | train_accuracy: 0.60269 | val_accuracy: 0.54658 |  0:01:26s\n",
            "epoch 150| loss: 0.85365 | train_accuracy: 0.6042  | val_accuracy: 0.54018 |  0:01:26s\n",
            "epoch 151| loss: 0.85893 | train_accuracy: 0.60385 | val_accuracy: 0.53978 |  0:01:27s\n",
            "epoch 152| loss: 0.86347 | train_accuracy: 0.59607 | val_accuracy: 0.52539 |  0:01:28s\n",
            "epoch 153| loss: 0.8644  | train_accuracy: 0.59452 | val_accuracy: 0.53898 |  0:01:28s\n",
            "epoch 154| loss: 0.86848 | train_accuracy: 0.59199 | val_accuracy: 0.54618 |  0:01:29s\n",
            "epoch 155| loss: 0.86934 | train_accuracy: 0.59207 | val_accuracy: 0.54698 |  0:01:29s\n",
            "epoch 156| loss: 0.86301 | train_accuracy: 0.59629 | val_accuracy: 0.53858 |  0:01:30s\n",
            "epoch 157| loss: 0.85776 | train_accuracy: 0.6014  | val_accuracy: 0.53818 |  0:01:30s\n",
            "epoch 158| loss: 0.85366 | train_accuracy: 0.60163 | val_accuracy: 0.54058 |  0:01:31s\n",
            "epoch 159| loss: 0.85402 | train_accuracy: 0.60229 | val_accuracy: 0.55058 |  0:01:32s\n",
            "epoch 160| loss: 0.85246 | train_accuracy: 0.6042  | val_accuracy: 0.54178 |  0:01:32s\n",
            "epoch 161| loss: 0.85295 | train_accuracy: 0.60442 | val_accuracy: 0.54738 |  0:01:33s\n",
            "epoch 162| loss: 0.84952 | train_accuracy: 0.60762 | val_accuracy: 0.54698 |  0:01:33s\n",
            "epoch 163| loss: 0.84719 | train_accuracy: 0.60709 | val_accuracy: 0.54698 |  0:01:34s\n",
            "epoch 164| loss: 0.84534 | train_accuracy: 0.60625 | val_accuracy: 0.53659 |  0:01:34s\n",
            "epoch 165| loss: 0.84382 | train_accuracy: 0.61487 | val_accuracy: 0.54818 |  0:01:35s\n",
            "epoch 166| loss: 0.83766 | train_accuracy: 0.61393 | val_accuracy: 0.55138 |  0:01:36s\n",
            "epoch 167| loss: 0.83338 | train_accuracy: 0.61553 | val_accuracy: 0.55218 |  0:01:36s\n",
            "epoch 168| loss: 0.8323  | train_accuracy: 0.61775 | val_accuracy: 0.55698 |  0:01:37s\n",
            "epoch 169| loss: 0.83335 | train_accuracy: 0.61824 | val_accuracy: 0.55178 |  0:01:37s\n",
            "epoch 170| loss: 0.82943 | train_accuracy: 0.61917 | val_accuracy: 0.54138 |  0:01:38s\n",
            "epoch 171| loss: 0.83552 | train_accuracy: 0.62051 | val_accuracy: 0.53898 |  0:01:38s\n",
            "epoch 172| loss: 0.83334 | train_accuracy: 0.61686 | val_accuracy: 0.54538 |  0:01:39s\n",
            "epoch 173| loss: 0.83601 | train_accuracy: 0.61713 | val_accuracy: 0.56058 |  0:01:40s\n",
            "epoch 174| loss: 0.83468 | train_accuracy: 0.61811 | val_accuracy: 0.56417 |  0:01:40s\n",
            "epoch 175| loss: 0.83515 | train_accuracy: 0.61766 | val_accuracy: 0.56777 |  0:01:41s\n",
            "epoch 176| loss: 0.83288 | train_accuracy: 0.62002 | val_accuracy: 0.57017 |  0:01:41s\n",
            "epoch 177| loss: 0.82703 | train_accuracy: 0.61824 | val_accuracy: 0.56377 |  0:01:42s\n",
            "epoch 178| loss: 0.82665 | train_accuracy: 0.61593 | val_accuracy: 0.56737 |  0:01:43s\n",
            "epoch 179| loss: 0.82357 | train_accuracy: 0.62255 | val_accuracy: 0.55898 |  0:01:43s\n",
            "epoch 180| loss: 0.82647 | train_accuracy: 0.62526 | val_accuracy: 0.55898 |  0:01:44s\n",
            "epoch 181| loss: 0.8263  | train_accuracy: 0.6281  | val_accuracy: 0.55898 |  0:01:44s\n",
            "epoch 182| loss: 0.82128 | train_accuracy: 0.62677 | val_accuracy: 0.56897 |  0:01:45s\n",
            "epoch 183| loss: 0.82121 | train_accuracy: 0.621   | val_accuracy: 0.56937 |  0:01:45s\n",
            "epoch 184| loss: 0.8281  | train_accuracy: 0.6194  | val_accuracy: 0.56657 |  0:01:46s\n",
            "epoch 185| loss: 0.82803 | train_accuracy: 0.62055 | val_accuracy: 0.57057 |  0:01:47s\n",
            "epoch 186| loss: 0.83271 | train_accuracy: 0.61713 | val_accuracy: 0.55818 |  0:01:47s\n",
            "epoch 187| loss: 0.83178 | train_accuracy: 0.61855 | val_accuracy: 0.56777 |  0:01:48s\n",
            "epoch 188| loss: 0.82579 | train_accuracy: 0.62175 | val_accuracy: 0.56337 |  0:01:48s\n",
            "epoch 189| loss: 0.82626 | train_accuracy: 0.62135 | val_accuracy: 0.55138 |  0:01:49s\n",
            "epoch 190| loss: 0.83117 | train_accuracy: 0.62357 | val_accuracy: 0.56257 |  0:01:50s\n",
            "epoch 191| loss: 0.82123 | train_accuracy: 0.62113 | val_accuracy: 0.56777 |  0:01:50s\n",
            "epoch 192| loss: 0.81769 | train_accuracy: 0.62668 | val_accuracy: 0.57577 |  0:01:51s\n",
            "epoch 193| loss: 0.8154  | train_accuracy: 0.62913 | val_accuracy: 0.56218 |  0:01:51s\n",
            "epoch 194| loss: 0.81536 | train_accuracy: 0.6321  | val_accuracy: 0.55778 |  0:01:52s\n",
            "epoch 195| loss: 0.82212 | train_accuracy: 0.63019 | val_accuracy: 0.56058 |  0:01:52s\n",
            "epoch 196| loss: 0.81643 | train_accuracy: 0.63184 | val_accuracy: 0.55018 |  0:01:53s\n",
            "epoch 197| loss: 0.80789 | train_accuracy: 0.63619 | val_accuracy: 0.56297 |  0:01:54s\n",
            "epoch 198| loss: 0.81482 | train_accuracy: 0.63126 | val_accuracy: 0.56697 |  0:01:54s\n",
            "epoch 199| loss: 0.82357 | train_accuracy: 0.62482 | val_accuracy: 0.55978 |  0:01:55s\n",
            "epoch 200| loss: 0.82314 | train_accuracy: 0.62624 | val_accuracy: 0.57177 |  0:01:55s\n",
            "epoch 201| loss: 0.82573 | train_accuracy: 0.62504 | val_accuracy: 0.57857 |  0:01:56s\n",
            "epoch 202| loss: 0.82217 | train_accuracy: 0.63059 | val_accuracy: 0.57937 |  0:01:56s\n",
            "epoch 203| loss: 0.81704 | train_accuracy: 0.62708 | val_accuracy: 0.58577 |  0:01:57s\n",
            "epoch 204| loss: 0.80889 | train_accuracy: 0.63459 | val_accuracy: 0.59216 |  0:01:58s\n",
            "epoch 205| loss: 0.80594 | train_accuracy: 0.63766 | val_accuracy: 0.57897 |  0:01:58s\n",
            "epoch 206| loss: 0.80106 | train_accuracy: 0.63992 | val_accuracy: 0.57897 |  0:01:59s\n",
            "epoch 207| loss: 0.80003 | train_accuracy: 0.63739 | val_accuracy: 0.57257 |  0:01:59s\n",
            "epoch 208| loss: 0.80515 | train_accuracy: 0.63646 | val_accuracy: 0.57857 |  0:02:00s\n",
            "epoch 209| loss: 0.79634 | train_accuracy: 0.64619 | val_accuracy: 0.59016 |  0:02:00s\n",
            "epoch 210| loss: 0.79552 | train_accuracy: 0.65107 | val_accuracy: 0.59976 |  0:02:01s\n",
            "epoch 211| loss: 0.7852  | train_accuracy: 0.64721 | val_accuracy: 0.59816 |  0:02:02s\n",
            "epoch 212| loss: 0.78598 | train_accuracy: 0.65103 | val_accuracy: 0.60736 |  0:02:02s\n",
            "epoch 213| loss: 0.78801 | train_accuracy: 0.65472 | val_accuracy: 0.58936 |  0:02:03s\n",
            "epoch 214| loss: 0.78115 | train_accuracy: 0.65209 | val_accuracy: 0.58896 |  0:02:03s\n",
            "epoch 215| loss: 0.78207 | train_accuracy: 0.65805 | val_accuracy: 0.58776 |  0:02:04s\n",
            "epoch 216| loss: 0.78058 | train_accuracy: 0.65982 | val_accuracy: 0.60496 |  0:02:04s\n",
            "epoch 217| loss: 0.77757 | train_accuracy: 0.66253 | val_accuracy: 0.59656 |  0:02:05s\n",
            "epoch 218| loss: 0.77539 | train_accuracy: 0.66591 | val_accuracy: 0.60656 |  0:02:06s\n",
            "epoch 219| loss: 0.77256 | train_accuracy: 0.66062 | val_accuracy: 0.61016 |  0:02:06s\n",
            "epoch 220| loss: 0.76995 | train_accuracy: 0.66138 | val_accuracy: 0.61935 |  0:02:07s\n",
            "epoch 221| loss: 0.76938 | train_accuracy: 0.66622 | val_accuracy: 0.62095 |  0:02:07s\n",
            "epoch 222| loss: 0.76276 | train_accuracy: 0.66907 | val_accuracy: 0.61375 |  0:02:08s\n",
            "epoch 223| loss: 0.76018 | train_accuracy: 0.67062 | val_accuracy: 0.60976 |  0:02:08s\n",
            "epoch 224| loss: 0.75594 | train_accuracy: 0.67138 | val_accuracy: 0.61255 |  0:02:09s\n",
            "epoch 225| loss: 0.75386 | train_accuracy: 0.67115 | val_accuracy: 0.61575 |  0:02:10s\n",
            "epoch 226| loss: 0.75076 | train_accuracy: 0.67622 | val_accuracy: 0.62135 |  0:02:10s\n",
            "epoch 227| loss: 0.74615 | train_accuracy: 0.67422 | val_accuracy: 0.62415 |  0:02:11s\n",
            "epoch 228| loss: 0.74155 | train_accuracy: 0.6784  | val_accuracy: 0.63175 |  0:02:11s\n",
            "epoch 229| loss: 0.74562 | train_accuracy: 0.67511 | val_accuracy: 0.61655 |  0:02:12s\n",
            "epoch 230| loss: 0.76051 | train_accuracy: 0.66413 | val_accuracy: 0.61735 |  0:02:12s\n",
            "epoch 231| loss: 0.76941 | train_accuracy: 0.66054 | val_accuracy: 0.60936 |  0:02:13s\n",
            "epoch 232| loss: 0.76252 | train_accuracy: 0.67031 | val_accuracy: 0.60856 |  0:02:13s\n",
            "epoch 233| loss: 0.7528  | train_accuracy: 0.67462 | val_accuracy: 0.62215 |  0:02:14s\n",
            "epoch 234| loss: 0.75403 | train_accuracy: 0.6736  | val_accuracy: 0.61335 |  0:02:15s\n",
            "epoch 235| loss: 0.75502 | train_accuracy: 0.67555 | val_accuracy: 0.62215 |  0:02:15s\n",
            "epoch 236| loss: 0.74533 | train_accuracy: 0.67835 | val_accuracy: 0.62735 |  0:02:16s\n",
            "epoch 237| loss: 0.73897 | train_accuracy: 0.68075 | val_accuracy: 0.62495 |  0:02:16s\n",
            "epoch 238| loss: 0.73977 | train_accuracy: 0.68413 | val_accuracy: 0.62535 |  0:02:17s\n",
            "epoch 239| loss: 0.73479 | train_accuracy: 0.68466 | val_accuracy: 0.62895 |  0:02:18s\n",
            "epoch 240| loss: 0.73939 | train_accuracy: 0.67866 | val_accuracy: 0.63055 |  0:02:18s\n",
            "epoch 241| loss: 0.74343 | train_accuracy: 0.67777 | val_accuracy: 0.63055 |  0:02:19s\n",
            "epoch 242| loss: 0.74741 | train_accuracy: 0.67995 | val_accuracy: 0.63854 |  0:02:19s\n",
            "epoch 243| loss: 0.74704 | train_accuracy: 0.68177 | val_accuracy: 0.61655 |  0:02:20s\n",
            "epoch 244| loss: 0.74028 | train_accuracy: 0.67888 | val_accuracy: 0.62055 |  0:02:20s\n",
            "epoch 245| loss: 0.7384  | train_accuracy: 0.68693 | val_accuracy: 0.62975 |  0:02:21s\n",
            "epoch 246| loss: 0.73545 | train_accuracy: 0.68675 | val_accuracy: 0.62655 |  0:02:22s\n",
            "epoch 247| loss: 0.7349  | train_accuracy: 0.68266 | val_accuracy: 0.63974 |  0:02:22s\n",
            "epoch 248| loss: 0.74047 | train_accuracy: 0.68484 | val_accuracy: 0.63774 |  0:02:23s\n",
            "epoch 249| loss: 0.73414 | train_accuracy: 0.68755 | val_accuracy: 0.64094 |  0:02:23s\n",
            "epoch 250| loss: 0.73192 | train_accuracy: 0.69039 | val_accuracy: 0.63295 |  0:02:24s\n",
            "epoch 251| loss: 0.72621 | train_accuracy: 0.69519 | val_accuracy: 0.64254 |  0:02:24s\n",
            "epoch 252| loss: 0.7145  | train_accuracy: 0.6955  | val_accuracy: 0.64694 |  0:02:25s\n",
            "epoch 253| loss: 0.70856 | train_accuracy: 0.70061 | val_accuracy: 0.64654 |  0:02:26s\n",
            "epoch 254| loss: 0.70351 | train_accuracy: 0.70136 | val_accuracy: 0.63535 |  0:02:26s\n",
            "epoch 255| loss: 0.70328 | train_accuracy: 0.70541 | val_accuracy: 0.64454 |  0:02:27s\n",
            "epoch 256| loss: 0.69153 | train_accuracy: 0.70612 | val_accuracy: 0.64574 |  0:02:27s\n",
            "epoch 257| loss: 0.69248 | train_accuracy: 0.70972 | val_accuracy: 0.63615 |  0:02:28s\n",
            "epoch 258| loss: 0.6947  | train_accuracy: 0.70678 | val_accuracy: 0.63934 |  0:02:28s\n",
            "epoch 259| loss: 0.69794 | train_accuracy: 0.70781 | val_accuracy: 0.64574 |  0:02:29s\n",
            "epoch 260| loss: 0.69452 | train_accuracy: 0.70954 | val_accuracy: 0.64934 |  0:02:29s\n",
            "epoch 261| loss: 0.69307 | train_accuracy: 0.70518 | val_accuracy: 0.64934 |  0:02:30s\n",
            "epoch 262| loss: 0.7106  | train_accuracy: 0.70709 | val_accuracy: 0.64694 |  0:02:31s\n",
            "epoch 263| loss: 0.70138 | train_accuracy: 0.70883 | val_accuracy: 0.64934 |  0:02:31s\n",
            "epoch 264| loss: 0.69759 | train_accuracy: 0.71269 | val_accuracy: 0.65814 |  0:02:32s\n",
            "epoch 265| loss: 0.69241 | train_accuracy: 0.71558 | val_accuracy: 0.65694 |  0:02:32s\n",
            "epoch 266| loss: 0.69022 | train_accuracy: 0.7146  | val_accuracy: 0.66773 |  0:02:33s\n",
            "epoch 267| loss: 0.68641 | train_accuracy: 0.71611 | val_accuracy: 0.66134 |  0:02:34s\n",
            "epoch 268| loss: 0.67993 | train_accuracy: 0.71971 | val_accuracy: 0.67173 |  0:02:34s\n",
            "epoch 269| loss: 0.67779 | train_accuracy: 0.7194  | val_accuracy: 0.66933 |  0:02:35s\n",
            "epoch 270| loss: 0.67992 | train_accuracy: 0.71709 | val_accuracy: 0.66493 |  0:02:35s\n",
            "epoch 271| loss: 0.68235 | train_accuracy: 0.72171 | val_accuracy: 0.67453 |  0:02:36s\n",
            "epoch 272| loss: 0.68005 | train_accuracy: 0.71731 | val_accuracy: 0.66413 |  0:02:36s\n",
            "epoch 273| loss: 0.67819 | train_accuracy: 0.71705 | val_accuracy: 0.66293 |  0:02:37s\n",
            "epoch 274| loss: 0.68703 | train_accuracy: 0.7158  | val_accuracy: 0.65334 |  0:02:38s\n",
            "epoch 275| loss: 0.68341 | train_accuracy: 0.71616 | val_accuracy: 0.64854 |  0:02:38s\n",
            "epoch 276| loss: 0.68405 | train_accuracy: 0.71434 | val_accuracy: 0.65494 |  0:02:39s\n",
            "epoch 277| loss: 0.68233 | train_accuracy: 0.71651 | val_accuracy: 0.64614 |  0:02:39s\n",
            "epoch 278| loss: 0.6757  | train_accuracy: 0.72127 | val_accuracy: 0.65374 |  0:02:40s\n",
            "epoch 279| loss: 0.66807 | train_accuracy: 0.72371 | val_accuracy: 0.66094 |  0:02:40s\n",
            "epoch 280| loss: 0.66573 | train_accuracy: 0.72438 | val_accuracy: 0.66373 |  0:02:41s\n",
            "epoch 281| loss: 0.65818 | train_accuracy: 0.73055 | val_accuracy: 0.65974 |  0:02:42s\n",
            "epoch 282| loss: 0.64709 | train_accuracy: 0.73415 | val_accuracy: 0.66333 |  0:02:42s\n",
            "epoch 283| loss: 0.64475 | train_accuracy: 0.73655 | val_accuracy: 0.66493 |  0:02:43s\n",
            "epoch 284| loss: 0.63741 | train_accuracy: 0.74184 | val_accuracy: 0.66693 |  0:02:43s\n",
            "epoch 285| loss: 0.63203 | train_accuracy: 0.74086 | val_accuracy: 0.67533 |  0:02:44s\n",
            "epoch 286| loss: 0.63576 | train_accuracy: 0.7449  | val_accuracy: 0.67933 |  0:02:45s\n",
            "epoch 287| loss: 0.63147 | train_accuracy: 0.7489  | val_accuracy: 0.68213 |  0:02:45s\n",
            "epoch 288| loss: 0.62344 | train_accuracy: 0.74863 | val_accuracy: 0.67133 |  0:02:46s\n",
            "epoch 289| loss: 0.61867 | train_accuracy: 0.74757 | val_accuracy: 0.67373 |  0:02:46s\n",
            "epoch 290| loss: 0.61961 | train_accuracy: 0.75188 | val_accuracy: 0.68013 |  0:02:47s\n",
            "epoch 291| loss: 0.6191  | train_accuracy: 0.75205 | val_accuracy: 0.68493 |  0:02:48s\n",
            "epoch 292| loss: 0.61408 | train_accuracy: 0.75063 | val_accuracy: 0.68453 |  0:02:48s\n",
            "epoch 293| loss: 0.617   | train_accuracy: 0.75112 | val_accuracy: 0.68812 |  0:02:49s\n",
            "epoch 294| loss: 0.61739 | train_accuracy: 0.75419 | val_accuracy: 0.67973 |  0:02:49s\n",
            "epoch 295| loss: 0.61281 | train_accuracy: 0.75516 | val_accuracy: 0.67613 |  0:02:50s\n",
            "epoch 296| loss: 0.60998 | train_accuracy: 0.75672 | val_accuracy: 0.67573 |  0:02:50s\n",
            "epoch 297| loss: 0.60554 | train_accuracy: 0.75832 | val_accuracy: 0.68733 |  0:02:51s\n",
            "epoch 298| loss: 0.601   | train_accuracy: 0.76165 | val_accuracy: 0.69612 |  0:02:52s\n",
            "epoch 299| loss: 0.59648 | train_accuracy: 0.76503 | val_accuracy: 0.69852 |  0:02:52s\n",
            "epoch 300| loss: 0.59116 | train_accuracy: 0.76858 | val_accuracy: 0.69212 |  0:02:53s\n",
            "epoch 301| loss: 0.58201 | train_accuracy: 0.77071 | val_accuracy: 0.69212 |  0:02:53s\n",
            "epoch 302| loss: 0.58682 | train_accuracy: 0.76858 | val_accuracy: 0.69212 |  0:02:54s\n",
            "epoch 303| loss: 0.59176 | train_accuracy: 0.76805 | val_accuracy: 0.69052 |  0:02:54s\n",
            "epoch 304| loss: 0.59656 | train_accuracy: 0.766   | val_accuracy: 0.69172 |  0:02:55s\n",
            "epoch 305| loss: 0.5949  | train_accuracy: 0.77    | val_accuracy: 0.69252 |  0:02:56s\n",
            "epoch 306| loss: 0.6063  | train_accuracy: 0.75392 | val_accuracy: 0.68812 |  0:02:56s\n",
            "epoch 307| loss: 0.62953 | train_accuracy: 0.74361 | val_accuracy: 0.67533 |  0:02:57s\n",
            "epoch 308| loss: 0.65877 | train_accuracy: 0.73024 | val_accuracy: 0.66973 |  0:02:57s\n",
            "epoch 309| loss: 0.66025 | train_accuracy: 0.73251 | val_accuracy: 0.68373 |  0:02:58s\n",
            "epoch 310| loss: 0.64837 | train_accuracy: 0.74015 | val_accuracy: 0.68693 |  0:02:58s\n",
            "epoch 311| loss: 0.65521 | train_accuracy: 0.73988 | val_accuracy: 0.68733 |  0:02:59s\n",
            "epoch 312| loss: 0.64877 | train_accuracy: 0.74215 | val_accuracy: 0.69652 |  0:03:00s\n",
            "epoch 313| loss: 0.64019 | train_accuracy: 0.74184 | val_accuracy: 0.70332 |  0:03:00s\n",
            "epoch 314| loss: 0.6418  | train_accuracy: 0.74623 | val_accuracy: 0.70012 |  0:03:01s\n",
            "epoch 315| loss: 0.62988 | train_accuracy: 0.75201 | val_accuracy: 0.70292 |  0:03:01s\n",
            "epoch 316| loss: 0.6146  | train_accuracy: 0.75628 | val_accuracy: 0.70452 |  0:03:02s\n",
            "epoch 317| loss: 0.60853 | train_accuracy: 0.75796 | val_accuracy: 0.71291 |  0:03:02s\n",
            "epoch 318| loss: 0.60156 | train_accuracy: 0.75921 | val_accuracy: 0.71731 |  0:03:03s\n",
            "epoch 319| loss: 0.60178 | train_accuracy: 0.76281 | val_accuracy: 0.72491 |  0:03:04s\n",
            "epoch 320| loss: 0.59699 | train_accuracy: 0.76667 | val_accuracy: 0.72291 |  0:03:04s\n",
            "epoch 321| loss: 0.58726 | train_accuracy: 0.7736  | val_accuracy: 0.73491 |  0:03:05s\n",
            "epoch 322| loss: 0.57841 | train_accuracy: 0.7788  | val_accuracy: 0.73371 |  0:03:05s\n",
            "epoch 323| loss: 0.56293 | train_accuracy: 0.78075 | val_accuracy: 0.73531 |  0:03:06s\n",
            "epoch 324| loss: 0.56443 | train_accuracy: 0.78364 | val_accuracy: 0.72971 |  0:03:06s\n",
            "epoch 325| loss: 0.55376 | train_accuracy: 0.78484 | val_accuracy: 0.73531 |  0:03:07s\n",
            "epoch 326| loss: 0.55755 | train_accuracy: 0.79039 | val_accuracy: 0.73051 |  0:03:08s\n",
            "epoch 327| loss: 0.55454 | train_accuracy: 0.78902 | val_accuracy: 0.73491 |  0:03:08s\n",
            "epoch 328| loss: 0.54948 | train_accuracy: 0.79701 | val_accuracy: 0.7393  |  0:03:09s\n",
            "epoch 329| loss: 0.53662 | train_accuracy: 0.79848 | val_accuracy: 0.7385  |  0:03:09s\n",
            "epoch 330| loss: 0.52999 | train_accuracy: 0.80221 | val_accuracy: 0.73731 |  0:03:10s\n",
            "epoch 331| loss: 0.52319 | train_accuracy: 0.80315 | val_accuracy: 0.7441  |  0:03:10s\n",
            "epoch 332| loss: 0.51739 | train_accuracy: 0.80892 | val_accuracy: 0.7469  |  0:03:11s\n",
            "epoch 333| loss: 0.51419 | train_accuracy: 0.80959 | val_accuracy: 0.7453  |  0:03:12s\n",
            "epoch 334| loss: 0.50533 | train_accuracy: 0.81025 | val_accuracy: 0.7409  |  0:03:12s\n",
            "epoch 335| loss: 0.50317 | train_accuracy: 0.81141 | val_accuracy: 0.7517  |  0:03:13s\n",
            "epoch 336| loss: 0.50232 | train_accuracy: 0.81043 | val_accuracy: 0.7445  |  0:03:13s\n",
            "epoch 337| loss: 0.50746 | train_accuracy: 0.81243 | val_accuracy: 0.7541  |  0:03:14s\n",
            "epoch 338| loss: 0.50899 | train_accuracy: 0.81456 | val_accuracy: 0.7609  |  0:03:15s\n",
            "epoch 339| loss: 0.50492 | train_accuracy: 0.81332 | val_accuracy: 0.7593  |  0:03:15s\n",
            "epoch 340| loss: 0.50863 | train_accuracy: 0.80968 | val_accuracy: 0.7589  |  0:03:16s\n",
            "epoch 341| loss: 0.52115 | train_accuracy: 0.80466 | val_accuracy: 0.7457  |  0:03:16s\n",
            "epoch 342| loss: 0.52434 | train_accuracy: 0.8011  | val_accuracy: 0.7501  |  0:03:17s\n",
            "epoch 343| loss: 0.5302  | train_accuracy: 0.79999 | val_accuracy: 0.7425  |  0:03:17s\n",
            "epoch 344| loss: 0.52741 | train_accuracy: 0.80417 | val_accuracy: 0.7445  |  0:03:18s\n",
            "epoch 345| loss: 0.51734 | train_accuracy: 0.8075  | val_accuracy: 0.7589  |  0:03:19s\n",
            "epoch 346| loss: 0.53466 | train_accuracy: 0.80737 | val_accuracy: 0.7513  |  0:03:19s\n",
            "epoch 347| loss: 0.52325 | train_accuracy: 0.81345 | val_accuracy: 0.7569  |  0:03:20s\n",
            "epoch 348| loss: 0.51055 | train_accuracy: 0.80843 | val_accuracy: 0.7557  |  0:03:20s\n",
            "epoch 349| loss: 0.51933 | train_accuracy: 0.8079  | val_accuracy: 0.7477  |  0:03:21s\n",
            "epoch 350| loss: 0.51937 | train_accuracy: 0.80865 | val_accuracy: 0.7605  |  0:03:21s\n",
            "epoch 351| loss: 0.51198 | train_accuracy: 0.81403 | val_accuracy: 0.7621  |  0:03:22s\n",
            "epoch 352| loss: 0.50551 | train_accuracy: 0.81563 | val_accuracy: 0.7625  |  0:03:23s\n",
            "epoch 353| loss: 0.49685 | train_accuracy: 0.82136 | val_accuracy: 0.7553  |  0:03:23s\n",
            "epoch 354| loss: 0.49488 | train_accuracy: 0.82376 | val_accuracy: 0.7617  |  0:03:24s\n",
            "epoch 355| loss: 0.47642 | train_accuracy: 0.82811 | val_accuracy: 0.76409 |  0:03:24s\n",
            "epoch 356| loss: 0.47021 | train_accuracy: 0.82563 | val_accuracy: 0.76529 |  0:03:25s\n",
            "epoch 357| loss: 0.47468 | train_accuracy: 0.82576 | val_accuracy: 0.77329 |  0:03:25s\n",
            "epoch 358| loss: 0.47672 | train_accuracy: 0.82394 | val_accuracy: 0.77409 |  0:03:26s\n",
            "epoch 359| loss: 0.48035 | train_accuracy: 0.82616 | val_accuracy: 0.76529 |  0:03:27s\n",
            "epoch 360| loss: 0.47928 | train_accuracy: 0.82891 | val_accuracy: 0.78089 |  0:03:27s\n",
            "epoch 361| loss: 0.47675 | train_accuracy: 0.82989 | val_accuracy: 0.76809 |  0:03:28s\n",
            "epoch 362| loss: 0.48547 | train_accuracy: 0.82358 | val_accuracy: 0.76649 |  0:03:28s\n",
            "epoch 363| loss: 0.48495 | train_accuracy: 0.82638 | val_accuracy: 0.77169 |  0:03:29s\n",
            "epoch 364| loss: 0.4819  | train_accuracy: 0.82509 | val_accuracy: 0.77569 |  0:03:29s\n",
            "epoch 365| loss: 0.48326 | train_accuracy: 0.827   | val_accuracy: 0.77369 |  0:03:30s\n",
            "epoch 366| loss: 0.48017 | train_accuracy: 0.82651 | val_accuracy: 0.77209 |  0:03:31s\n",
            "epoch 367| loss: 0.47886 | train_accuracy: 0.8246  | val_accuracy: 0.76929 |  0:03:31s\n",
            "epoch 368| loss: 0.4905  | train_accuracy: 0.81172 | val_accuracy: 0.7533  |  0:03:32s\n",
            "epoch 369| loss: 0.50482 | train_accuracy: 0.81265 | val_accuracy: 0.7545  |  0:03:32s\n",
            "epoch 370| loss: 0.5107  | train_accuracy: 0.81514 | val_accuracy: 0.7613  |  0:03:33s\n",
            "epoch 371| loss: 0.496   | train_accuracy: 0.82252 | val_accuracy: 0.76929 |  0:03:33s\n",
            "epoch 372| loss: 0.48027 | train_accuracy: 0.82776 | val_accuracy: 0.77209 |  0:03:34s\n",
            "epoch 373| loss: 0.46848 | train_accuracy: 0.83433 | val_accuracy: 0.77049 |  0:03:35s\n",
            "epoch 374| loss: 0.46283 | train_accuracy: 0.83611 | val_accuracy: 0.77609 |  0:03:35s\n",
            "epoch 375| loss: 0.45386 | train_accuracy: 0.83864 | val_accuracy: 0.77929 |  0:03:36s\n",
            "epoch 376| loss: 0.44969 | train_accuracy: 0.8386  | val_accuracy: 0.78768 |  0:03:36s\n",
            "epoch 377| loss: 0.4448  | train_accuracy: 0.83718 | val_accuracy: 0.78808 |  0:03:37s\n",
            "epoch 378| loss: 0.44259 | train_accuracy: 0.84562 | val_accuracy: 0.78808 |  0:03:37s\n",
            "epoch 379| loss: 0.43518 | train_accuracy: 0.84935 | val_accuracy: 0.79088 |  0:03:38s\n",
            "epoch 380| loss: 0.43063 | train_accuracy: 0.84531 | val_accuracy: 0.79088 |  0:03:39s\n",
            "epoch 381| loss: 0.44084 | train_accuracy: 0.83922 | val_accuracy: 0.78369 |  0:03:39s\n",
            "epoch 382| loss: 0.44776 | train_accuracy: 0.84029 | val_accuracy: 0.78888 |  0:03:40s\n",
            "epoch 383| loss: 0.43833 | train_accuracy: 0.84002 | val_accuracy: 0.79048 |  0:03:40s\n",
            "epoch 384| loss: 0.44072 | train_accuracy: 0.84366 | val_accuracy: 0.78848 |  0:03:41s\n",
            "epoch 385| loss: 0.4331  | train_accuracy: 0.84691 | val_accuracy: 0.79688 |  0:03:42s\n",
            "epoch 386| loss: 0.41792 | train_accuracy: 0.85042 | val_accuracy: 0.79288 |  0:03:43s\n",
            "epoch 387| loss: 0.41608 | train_accuracy: 0.85539 | val_accuracy: 0.79608 |  0:03:43s\n",
            "epoch 388| loss: 0.40552 | train_accuracy: 0.85992 | val_accuracy: 0.80288 |  0:03:44s\n",
            "epoch 389| loss: 0.40108 | train_accuracy: 0.86294 | val_accuracy: 0.80488 |  0:03:44s\n",
            "epoch 390| loss: 0.38897 | train_accuracy: 0.86414 | val_accuracy: 0.80848 |  0:03:45s\n",
            "epoch 391| loss: 0.39237 | train_accuracy: 0.86508 | val_accuracy: 0.81407 |  0:03:46s\n",
            "epoch 392| loss: 0.38528 | train_accuracy: 0.86672 | val_accuracy: 0.80768 |  0:03:46s\n",
            "epoch 393| loss: 0.37413 | train_accuracy: 0.8713  | val_accuracy: 0.81447 |  0:03:47s\n",
            "epoch 394| loss: 0.37029 | train_accuracy: 0.87245 | val_accuracy: 0.81407 |  0:03:47s\n",
            "epoch 395| loss: 0.36149 | train_accuracy: 0.87623 | val_accuracy: 0.82167 |  0:03:48s\n",
            "epoch 396| loss: 0.35957 | train_accuracy: 0.87987 | val_accuracy: 0.82847 |  0:03:48s\n",
            "epoch 397| loss: 0.34744 | train_accuracy: 0.88436 | val_accuracy: 0.82447 |  0:03:49s\n",
            "epoch 398| loss: 0.33896 | train_accuracy: 0.88418 | val_accuracy: 0.83087 |  0:03:50s\n",
            "epoch 399| loss: 0.34005 | train_accuracy: 0.87951 | val_accuracy: 0.82047 |  0:03:50s\n",
            "epoch 400| loss: 0.35729 | train_accuracy: 0.87765 | val_accuracy: 0.82327 |  0:03:51s\n",
            "epoch 401| loss: 0.3623  | train_accuracy: 0.88049 | val_accuracy: 0.82607 |  0:03:51s\n",
            "epoch 402| loss: 0.35253 | train_accuracy: 0.88085 | val_accuracy: 0.82647 |  0:03:52s\n",
            "epoch 403| loss: 0.34468 | train_accuracy: 0.88218 | val_accuracy: 0.82967 |  0:03:52s\n",
            "epoch 404| loss: 0.3426  | train_accuracy: 0.88605 | val_accuracy: 0.82887 |  0:03:53s\n",
            "epoch 405| loss: 0.33267 | train_accuracy: 0.88618 | val_accuracy: 0.82687 |  0:03:54s\n",
            "epoch 406| loss: 0.34324 | train_accuracy: 0.88196 | val_accuracy: 0.82447 |  0:03:54s\n",
            "epoch 407| loss: 0.34191 | train_accuracy: 0.87983 | val_accuracy: 0.82127 |  0:03:55s\n",
            "epoch 408| loss: 0.34729 | train_accuracy: 0.87858 | val_accuracy: 0.82487 |  0:03:55s\n",
            "epoch 409| loss: 0.35217 | train_accuracy: 0.8832  | val_accuracy: 0.82087 |  0:03:56s\n",
            "epoch 410| loss: 0.35195 | train_accuracy: 0.88209 | val_accuracy: 0.82487 |  0:03:56s\n",
            "epoch 411| loss: 0.35324 | train_accuracy: 0.88454 | val_accuracy: 0.82647 |  0:03:57s\n",
            "epoch 412| loss: 0.34205 | train_accuracy: 0.88831 | val_accuracy: 0.82407 |  0:03:58s\n",
            "epoch 413| loss: 0.33241 | train_accuracy: 0.88924 | val_accuracy: 0.83047 |  0:03:58s\n",
            "epoch 414| loss: 0.33912 | train_accuracy: 0.88334 | val_accuracy: 0.82887 |  0:03:59s\n",
            "epoch 415| loss: 0.34437 | train_accuracy: 0.88454 | val_accuracy: 0.82567 |  0:03:59s\n",
            "epoch 416| loss: 0.35241 | train_accuracy: 0.88183 | val_accuracy: 0.82607 |  0:04:00s\n",
            "epoch 417| loss: 0.36019 | train_accuracy: 0.88222 | val_accuracy: 0.82567 |  0:04:00s\n",
            "epoch 418| loss: 0.35034 | train_accuracy: 0.8864  | val_accuracy: 0.82607 |  0:04:01s\n",
            "epoch 419| loss: 0.34131 | train_accuracy: 0.88183 | val_accuracy: 0.82687 |  0:04:02s\n",
            "epoch 420| loss: 0.34982 | train_accuracy: 0.88267 | val_accuracy: 0.82127 |  0:04:02s\n",
            "epoch 421| loss: 0.34029 | train_accuracy: 0.88902 | val_accuracy: 0.82527 |  0:04:03s\n",
            "epoch 422| loss: 0.32386 | train_accuracy: 0.89204 | val_accuracy: 0.82847 |  0:04:03s\n",
            "epoch 423| loss: 0.31786 | train_accuracy: 0.89737 | val_accuracy: 0.83647 |  0:04:04s\n",
            "epoch 424| loss: 0.30453 | train_accuracy: 0.90022 | val_accuracy: 0.83886 |  0:04:04s\n",
            "epoch 425| loss: 0.29943 | train_accuracy: 0.90377 | val_accuracy: 0.84166 |  0:04:05s\n",
            "epoch 426| loss: 0.28628 | train_accuracy: 0.90741 | val_accuracy: 0.84566 |  0:04:06s\n",
            "epoch 427| loss: 0.282   | train_accuracy: 0.90888 | val_accuracy: 0.84566 |  0:04:06s\n",
            "epoch 428| loss: 0.28208 | train_accuracy: 0.90626 | val_accuracy: 0.84126 |  0:04:07s\n",
            "epoch 429| loss: 0.30713 | train_accuracy: 0.90693 | val_accuracy: 0.84446 |  0:04:07s\n",
            "epoch 430| loss: 0.29462 | train_accuracy: 0.90497 | val_accuracy: 0.84766 |  0:04:08s\n",
            "epoch 431| loss: 0.27747 | train_accuracy: 0.9135  | val_accuracy: 0.85566 |  0:04:08s\n",
            "epoch 432| loss: 0.26761 | train_accuracy: 0.91581 | val_accuracy: 0.85726 |  0:04:09s\n",
            "epoch 433| loss: 0.25316 | train_accuracy: 0.91861 | val_accuracy: 0.86405 |  0:04:10s\n",
            "epoch 434| loss: 0.25057 | train_accuracy: 0.91968 | val_accuracy: 0.86086 |  0:04:10s\n",
            "epoch 435| loss: 0.24503 | train_accuracy: 0.92425 | val_accuracy: 0.86405 |  0:04:11s\n",
            "epoch 436| loss: 0.23789 | train_accuracy: 0.92279 | val_accuracy: 0.87005 |  0:04:11s\n",
            "epoch 437| loss: 0.23053 | train_accuracy: 0.92616 | val_accuracy: 0.86485 |  0:04:12s\n",
            "epoch 438| loss: 0.23019 | train_accuracy: 0.92683 | val_accuracy: 0.86805 |  0:04:13s\n",
            "epoch 439| loss: 0.23274 | train_accuracy: 0.92505 | val_accuracy: 0.86405 |  0:04:13s\n",
            "epoch 440| loss: 0.24517 | train_accuracy: 0.92092 | val_accuracy: 0.86046 |  0:04:14s\n",
            "epoch 441| loss: 0.24951 | train_accuracy: 0.9211  | val_accuracy: 0.86565 |  0:04:14s\n",
            "epoch 442| loss: 0.24126 | train_accuracy: 0.92643 | val_accuracy: 0.87405 |  0:04:15s\n",
            "epoch 443| loss: 0.23602 | train_accuracy: 0.92958 | val_accuracy: 0.87845 |  0:04:15s\n",
            "epoch 444| loss: 0.22094 | train_accuracy: 0.9322  | val_accuracy: 0.87965 |  0:04:16s\n",
            "epoch 445| loss: 0.21923 | train_accuracy: 0.93074 | val_accuracy: 0.88045 |  0:04:17s\n",
            "epoch 446| loss: 0.21969 | train_accuracy: 0.93394 | val_accuracy: 0.88445 |  0:04:17s\n",
            "epoch 447| loss: 0.21035 | train_accuracy: 0.93523 | val_accuracy: 0.88884 |  0:04:18s\n",
            "epoch 448| loss: 0.21016 | train_accuracy: 0.93674 | val_accuracy: 0.88884 |  0:04:18s\n",
            "epoch 449| loss: 0.20447 | train_accuracy: 0.93252 | val_accuracy: 0.88804 |  0:04:19s\n",
            "epoch 450| loss: 0.22458 | train_accuracy: 0.93096 | val_accuracy: 0.87885 |  0:04:20s\n",
            "epoch 451| loss: 0.2218  | train_accuracy: 0.93158 | val_accuracy: 0.87885 |  0:04:20s\n",
            "epoch 452| loss: 0.21528 | train_accuracy: 0.93598 | val_accuracy: 0.88764 |  0:04:21s\n",
            "epoch 453| loss: 0.2059  | train_accuracy: 0.93847 | val_accuracy: 0.88964 |  0:04:21s\n",
            "epoch 454| loss: 0.20097 | train_accuracy: 0.93931 | val_accuracy: 0.88685 |  0:04:22s\n",
            "epoch 455| loss: 0.19994 | train_accuracy: 0.94016 | val_accuracy: 0.89084 |  0:04:22s\n",
            "epoch 456| loss: 0.19117 | train_accuracy: 0.94256 | val_accuracy: 0.89244 |  0:04:23s\n",
            "epoch 457| loss: 0.19335 | train_accuracy: 0.94118 | val_accuracy: 0.88964 |  0:04:24s\n",
            "epoch 458| loss: 0.19261 | train_accuracy: 0.94353 | val_accuracy: 0.88605 |  0:04:24s\n",
            "epoch 459| loss: 0.18115 | train_accuracy: 0.94482 | val_accuracy: 0.88924 |  0:04:25s\n",
            "epoch 460| loss: 0.17701 | train_accuracy: 0.94869 | val_accuracy: 0.89164 |  0:04:25s\n",
            "epoch 461| loss: 0.17946 | train_accuracy: 0.94344 | val_accuracy: 0.89004 |  0:04:26s\n",
            "epoch 462| loss: 0.18672 | train_accuracy: 0.94327 | val_accuracy: 0.88884 |  0:04:26s\n",
            "epoch 463| loss: 0.19007 | train_accuracy: 0.94251 | val_accuracy: 0.89164 |  0:04:27s\n",
            "epoch 464| loss: 0.19193 | train_accuracy: 0.94487 | val_accuracy: 0.89004 |  0:04:28s\n",
            "epoch 465| loss: 0.17886 | train_accuracy: 0.94584 | val_accuracy: 0.89964 |  0:04:28s\n",
            "epoch 466| loss: 0.17937 | train_accuracy: 0.94602 | val_accuracy: 0.88964 |  0:04:29s\n",
            "epoch 467| loss: 0.18775 | train_accuracy: 0.94238 | val_accuracy: 0.89764 |  0:04:29s\n",
            "epoch 468| loss: 0.20357 | train_accuracy: 0.94287 | val_accuracy: 0.89324 |  0:04:30s\n",
            "epoch 469| loss: 0.18855 | train_accuracy: 0.94496 | val_accuracy: 0.89404 |  0:04:30s\n",
            "epoch 470| loss: 0.19269 | train_accuracy: 0.93874 | val_accuracy: 0.88725 |  0:04:31s\n",
            "epoch 471| loss: 0.22516 | train_accuracy: 0.93878 | val_accuracy: 0.88924 |  0:04:32s\n",
            "epoch 472| loss: 0.20912 | train_accuracy: 0.9386  | val_accuracy: 0.89084 |  0:04:32s\n",
            "epoch 473| loss: 0.20436 | train_accuracy: 0.94247 | val_accuracy: 0.89324 |  0:04:33s\n",
            "epoch 474| loss: 0.18969 | train_accuracy: 0.94513 | val_accuracy: 0.89844 |  0:04:33s\n",
            "epoch 475| loss: 0.1822  | train_accuracy: 0.94895 | val_accuracy: 0.90604 |  0:04:34s\n",
            "epoch 476| loss: 0.16946 | train_accuracy: 0.94909 | val_accuracy: 0.90564 |  0:04:34s\n",
            "epoch 477| loss: 0.17082 | train_accuracy: 0.94824 | val_accuracy: 0.90204 |  0:04:35s\n",
            "epoch 478| loss: 0.16644 | train_accuracy: 0.94904 | val_accuracy: 0.90004 |  0:04:36s\n",
            "epoch 479| loss: 0.17094 | train_accuracy: 0.95131 | val_accuracy: 0.90164 |  0:04:36s\n",
            "epoch 480| loss: 0.15837 | train_accuracy: 0.95362 | val_accuracy: 0.90484 |  0:04:37s\n",
            "epoch 481| loss: 0.15375 | train_accuracy: 0.95544 | val_accuracy: 0.90644 |  0:04:37s\n",
            "epoch 482| loss: 0.14469 | train_accuracy: 0.95784 | val_accuracy: 0.90524 |  0:04:38s\n",
            "epoch 483| loss: 0.13982 | train_accuracy: 0.95855 | val_accuracy: 0.90804 |  0:04:38s\n",
            "epoch 484| loss: 0.13844 | train_accuracy: 0.9613  | val_accuracy: 0.90644 |  0:04:39s\n",
            "epoch 485| loss: 0.17704 | train_accuracy: 0.93789 | val_accuracy: 0.88685 |  0:04:40s\n",
            "epoch 486| loss: 0.21628 | train_accuracy: 0.94509 | val_accuracy: 0.89124 |  0:04:40s\n",
            "epoch 487| loss: 0.18843 | train_accuracy: 0.94727 | val_accuracy: 0.89844 |  0:04:41s\n",
            "epoch 488| loss: 0.17153 | train_accuracy: 0.94713 | val_accuracy: 0.90444 |  0:04:41s\n",
            "epoch 489| loss: 0.17491 | train_accuracy: 0.95126 | val_accuracy: 0.90644 |  0:04:42s\n",
            "epoch 490| loss: 0.16051 | train_accuracy: 0.95575 | val_accuracy: 0.90724 |  0:04:42s\n",
            "epoch 491| loss: 0.15808 | train_accuracy: 0.95024 | val_accuracy: 0.90084 |  0:04:43s\n",
            "epoch 492| loss: 0.1783  | train_accuracy: 0.94789 | val_accuracy: 0.89684 |  0:04:44s\n",
            "epoch 493| loss: 0.17231 | train_accuracy: 0.95242 | val_accuracy: 0.90724 |  0:04:44s\n",
            "epoch 494| loss: 0.16228 | train_accuracy: 0.95455 | val_accuracy: 0.90444 |  0:04:45s\n",
            "epoch 495| loss: 0.15885 | train_accuracy: 0.95691 | val_accuracy: 0.91443 |  0:04:45s\n",
            "epoch 496| loss: 0.15604 | train_accuracy: 0.95397 | val_accuracy: 0.90844 |  0:04:46s\n",
            "epoch 497| loss: 0.16324 | train_accuracy: 0.95206 | val_accuracy: 0.90364 |  0:04:46s\n",
            "epoch 498| loss: 0.18771 | train_accuracy: 0.94189 | val_accuracy: 0.90044 |  0:04:47s\n",
            "epoch 499| loss: 0.18848 | train_accuracy: 0.94549 | val_accuracy: 0.90164 |  0:04:48s\n",
            "epoch 500| loss: 0.17817 | train_accuracy: 0.95202 | val_accuracy: 0.90764 |  0:04:48s\n",
            "epoch 501| loss: 0.1731  | train_accuracy: 0.94833 | val_accuracy: 0.90604 |  0:04:49s\n",
            "epoch 502| loss: 0.16916 | train_accuracy: 0.95202 | val_accuracy: 0.91244 |  0:04:49s\n",
            "epoch 503| loss: 0.16964 | train_accuracy: 0.94398 | val_accuracy: 0.90284 |  0:04:50s\n",
            "epoch 504| loss: 0.2099  | train_accuracy: 0.93785 | val_accuracy: 0.89164 |  0:04:50s\n",
            "epoch 505| loss: 0.20204 | train_accuracy: 0.94096 | val_accuracy: 0.90524 |  0:04:51s\n",
            "epoch 506| loss: 0.20877 | train_accuracy: 0.93816 | val_accuracy: 0.90244 |  0:04:52s\n",
            "epoch 507| loss: 0.20826 | train_accuracy: 0.94136 | val_accuracy: 0.90004 |  0:04:52s\n",
            "epoch 508| loss: 0.19722 | train_accuracy: 0.94682 | val_accuracy: 0.91204 |  0:04:53s\n",
            "epoch 509| loss: 0.18506 | train_accuracy: 0.94944 | val_accuracy: 0.90964 |  0:04:53s\n",
            "epoch 510| loss: 0.17461 | train_accuracy: 0.9514  | val_accuracy: 0.90924 |  0:04:54s\n",
            "epoch 511| loss: 0.17172 | train_accuracy: 0.9506  | val_accuracy: 0.90484 |  0:04:54s\n",
            "epoch 512| loss: 0.17112 | train_accuracy: 0.95144 | val_accuracy: 0.90564 |  0:04:55s\n",
            "epoch 513| loss: 0.16706 | train_accuracy: 0.95331 | val_accuracy: 0.91004 |  0:04:56s\n",
            "epoch 514| loss: 0.16436 | train_accuracy: 0.94895 | val_accuracy: 0.90204 |  0:04:56s\n",
            "epoch 515| loss: 0.16628 | train_accuracy: 0.95051 | val_accuracy: 0.90604 |  0:04:57s\n",
            "epoch 516| loss: 0.15386 | train_accuracy: 0.95664 | val_accuracy: 0.91004 |  0:04:57s\n",
            "epoch 517| loss: 0.14703 | train_accuracy: 0.95962 | val_accuracy: 0.91084 |  0:04:58s\n",
            "epoch 518| loss: 0.13511 | train_accuracy: 0.96264 | val_accuracy: 0.91124 |  0:04:58s\n",
            "epoch 519| loss: 0.13214 | train_accuracy: 0.96313 | val_accuracy: 0.91403 |  0:04:59s\n",
            "epoch 520| loss: 0.13124 | train_accuracy: 0.96184 | val_accuracy: 0.91723 |  0:04:59s\n",
            "epoch 521| loss: 0.12859 | train_accuracy: 0.96517 | val_accuracy: 0.91723 |  0:05:00s\n",
            "epoch 522| loss: 0.12549 | train_accuracy: 0.96446 | val_accuracy: 0.91883 |  0:05:01s\n",
            "epoch 523| loss: 0.12216 | train_accuracy: 0.96588 | val_accuracy: 0.92283 |  0:05:01s\n",
            "epoch 524| loss: 0.12459 | train_accuracy: 0.96353 | val_accuracy: 0.91843 |  0:05:02s\n",
            "epoch 525| loss: 0.12769 | train_accuracy: 0.9625  | val_accuracy: 0.91963 |  0:05:02s\n",
            "epoch 526| loss: 0.1317  | train_accuracy: 0.95793 | val_accuracy: 0.91244 |  0:05:03s\n",
            "epoch 527| loss: 0.1677  | train_accuracy: 0.95628 | val_accuracy: 0.90164 |  0:05:04s\n",
            "epoch 528| loss: 0.15435 | train_accuracy: 0.95735 | val_accuracy: 0.91323 |  0:05:04s\n",
            "epoch 529| loss: 0.14204 | train_accuracy: 0.9621  | val_accuracy: 0.91403 |  0:05:05s\n",
            "epoch 530| loss: 0.12642 | train_accuracy: 0.96535 | val_accuracy: 0.91204 |  0:05:05s\n",
            "epoch 531| loss: 0.11628 | train_accuracy: 0.96513 | val_accuracy: 0.91244 |  0:05:06s\n",
            "epoch 532| loss: 0.13848 | train_accuracy: 0.95584 | val_accuracy: 0.90844 |  0:05:06s\n",
            "epoch 533| loss: 0.15947 | train_accuracy: 0.95668 | val_accuracy: 0.91124 |  0:05:07s\n",
            "epoch 534| loss: 0.146   | train_accuracy: 0.96077 | val_accuracy: 0.91563 |  0:05:08s\n",
            "epoch 535| loss: 0.13729 | train_accuracy: 0.96255 | val_accuracy: 0.91843 |  0:05:08s\n",
            "epoch 536| loss: 0.12769 | train_accuracy: 0.96468 | val_accuracy: 0.91803 |  0:05:09s\n",
            "epoch 537| loss: 0.1187  | train_accuracy: 0.9669  | val_accuracy: 0.92083 |  0:05:09s\n",
            "epoch 538| loss: 0.11384 | train_accuracy: 0.97001 | val_accuracy: 0.92203 |  0:05:10s\n",
            "epoch 539| loss: 0.10759 | train_accuracy: 0.9673  | val_accuracy: 0.92403 |  0:05:10s\n",
            "epoch 540| loss: 0.13826 | train_accuracy: 0.96313 | val_accuracy: 0.91483 |  0:05:11s\n",
            "epoch 541| loss: 0.14768 | train_accuracy: 0.96277 | val_accuracy: 0.91244 |  0:05:11s\n",
            "epoch 542| loss: 0.1295  | train_accuracy: 0.96477 | val_accuracy: 0.91683 |  0:05:12s\n",
            "epoch 543| loss: 0.13578 | train_accuracy: 0.9601  | val_accuracy: 0.91523 |  0:05:13s\n",
            "epoch 544| loss: 0.13217 | train_accuracy: 0.96708 | val_accuracy: 0.92323 |  0:05:13s\n",
            "epoch 545| loss: 0.11516 | train_accuracy: 0.96917 | val_accuracy: 0.92563 |  0:05:14s\n",
            "epoch 546| loss: 0.10572 | train_accuracy: 0.97099 | val_accuracy: 0.93163 |  0:05:14s\n",
            "epoch 547| loss: 0.09608 | train_accuracy: 0.97485 | val_accuracy: 0.93163 |  0:05:15s\n",
            "epoch 548| loss: 0.09344 | train_accuracy: 0.97765 | val_accuracy: 0.93483 |  0:05:16s\n",
            "epoch 549| loss: 0.09042 | train_accuracy: 0.97765 | val_accuracy: 0.93123 |  0:05:16s\n",
            "epoch 550| loss: 0.08514 | train_accuracy: 0.97872 | val_accuracy: 0.93083 |  0:05:17s\n",
            "epoch 551| loss: 0.08642 | train_accuracy: 0.97574 | val_accuracy: 0.93083 |  0:05:17s\n",
            "epoch 552| loss: 0.0956  | train_accuracy: 0.97459 | val_accuracy: 0.92923 |  0:05:18s\n",
            "epoch 553| loss: 0.09583 | train_accuracy: 0.97557 | val_accuracy: 0.93123 |  0:05:18s\n",
            "epoch 554| loss: 0.10102 | train_accuracy: 0.97188 | val_accuracy: 0.93323 |  0:05:19s\n",
            "epoch 555| loss: 0.10091 | train_accuracy: 0.97326 | val_accuracy: 0.93203 |  0:05:20s\n",
            "epoch 556| loss: 0.09467 | train_accuracy: 0.97512 | val_accuracy: 0.93363 |  0:05:20s\n",
            "epoch 557| loss: 0.09676 | train_accuracy: 0.97894 | val_accuracy: 0.93123 |  0:05:21s\n",
            "epoch 558| loss: 0.08563 | train_accuracy: 0.97885 | val_accuracy: 0.93243 |  0:05:21s\n",
            "epoch 559| loss: 0.07803 | train_accuracy: 0.97947 | val_accuracy: 0.93123 |  0:05:22s\n",
            "epoch 560| loss: 0.07856 | train_accuracy: 0.9801  | val_accuracy: 0.93203 |  0:05:22s\n",
            "epoch 561| loss: 0.07284 | train_accuracy: 0.98183 | val_accuracy: 0.93163 |  0:05:23s\n",
            "epoch 562| loss: 0.0731  | train_accuracy: 0.98023 | val_accuracy: 0.93163 |  0:05:24s\n",
            "epoch 563| loss: 0.07836 | train_accuracy: 0.9805  | val_accuracy: 0.93443 |  0:05:24s\n",
            "epoch 564| loss: 0.07532 | train_accuracy: 0.98112 | val_accuracy: 0.93363 |  0:05:25s\n",
            "epoch 565| loss: 0.07344 | train_accuracy: 0.98196 | val_accuracy: 0.93083 |  0:05:25s\n",
            "epoch 566| loss: 0.07522 | train_accuracy: 0.98174 | val_accuracy: 0.93163 |  0:05:26s\n",
            "epoch 567| loss: 0.06896 | train_accuracy: 0.9825  | val_accuracy: 0.93443 |  0:05:26s\n",
            "epoch 568| loss: 0.07601 | train_accuracy: 0.97539 | val_accuracy: 0.92123 |  0:05:27s\n",
            "epoch 569| loss: 0.102   | train_accuracy: 0.97712 | val_accuracy: 0.92163 |  0:05:28s\n",
            "epoch 570| loss: 0.08929 | train_accuracy: 0.9785  | val_accuracy: 0.92163 |  0:05:28s\n",
            "epoch 571| loss: 0.08213 | train_accuracy: 0.98276 | val_accuracy: 0.92763 |  0:05:29s\n",
            "epoch 572| loss: 0.07115 | train_accuracy: 0.9829  | val_accuracy: 0.92923 |  0:05:29s\n",
            "epoch 573| loss: 0.06163 | train_accuracy: 0.98312 | val_accuracy: 0.93123 |  0:05:30s\n",
            "epoch 574| loss: 0.07144 | train_accuracy: 0.98103 | val_accuracy: 0.92723 |  0:05:30s\n",
            "epoch 575| loss: 0.07669 | train_accuracy: 0.98179 | val_accuracy: 0.93203 |  0:05:31s\n",
            "epoch 576| loss: 0.07134 | train_accuracy: 0.98365 | val_accuracy: 0.93563 |  0:05:32s\n",
            "epoch 577| loss: 0.06129 | train_accuracy: 0.98556 | val_accuracy: 0.93643 |  0:05:32s\n",
            "epoch 578| loss: 0.05935 | train_accuracy: 0.98609 | val_accuracy: 0.93683 |  0:05:33s\n",
            "epoch 579| loss: 0.05939 | train_accuracy: 0.98592 | val_accuracy: 0.93723 |  0:05:33s\n",
            "epoch 580| loss: 0.06264 | train_accuracy: 0.98427 | val_accuracy: 0.93762 |  0:05:34s\n",
            "epoch 581| loss: 0.06806 | train_accuracy: 0.98365 | val_accuracy: 0.93683 |  0:05:34s\n",
            "epoch 582| loss: 0.06572 | train_accuracy: 0.98458 | val_accuracy: 0.93882 |  0:05:35s\n",
            "epoch 583| loss: 0.06036 | train_accuracy: 0.98601 | val_accuracy: 0.93842 |  0:05:36s\n",
            "epoch 584| loss: 0.05794 | train_accuracy: 0.98632 | val_accuracy: 0.93243 |  0:05:36s\n",
            "epoch 585| loss: 0.06177 | train_accuracy: 0.98521 | val_accuracy: 0.93363 |  0:05:37s\n",
            "epoch 586| loss: 0.06673 | train_accuracy: 0.98427 | val_accuracy: 0.92603 |  0:05:37s\n",
            "epoch 587| loss: 0.06767 | train_accuracy: 0.98307 | val_accuracy: 0.92923 |  0:05:38s\n",
            "epoch 588| loss: 0.07078 | train_accuracy: 0.98263 | val_accuracy: 0.92683 |  0:05:39s\n",
            "epoch 589| loss: 0.06914 | train_accuracy: 0.98161 | val_accuracy: 0.93243 |  0:05:39s\n",
            "epoch 590| loss: 0.06769 | train_accuracy: 0.98263 | val_accuracy: 0.92843 |  0:05:40s\n",
            "epoch 591| loss: 0.06582 | train_accuracy: 0.98414 | val_accuracy: 0.92963 |  0:05:40s\n",
            "epoch 592| loss: 0.06456 | train_accuracy: 0.98547 | val_accuracy: 0.92923 |  0:05:41s\n",
            "epoch 593| loss: 0.05878 | train_accuracy: 0.98689 | val_accuracy: 0.93203 |  0:05:41s\n",
            "epoch 594| loss: 0.05906 | train_accuracy: 0.98556 | val_accuracy: 0.93683 |  0:05:42s\n",
            "epoch 595| loss: 0.06305 | train_accuracy: 0.98445 | val_accuracy: 0.92923 |  0:05:43s\n",
            "epoch 596| loss: 0.06447 | train_accuracy: 0.98374 | val_accuracy: 0.93123 |  0:05:43s\n",
            "epoch 597| loss: 0.0683  | train_accuracy: 0.98356 | val_accuracy: 0.93203 |  0:05:44s\n",
            "epoch 598| loss: 0.0624  | train_accuracy: 0.98556 | val_accuracy: 0.93643 |  0:05:44s\n",
            "epoch 599| loss: 0.05707 | train_accuracy: 0.98618 | val_accuracy: 0.93483 |  0:05:45s\n",
            "epoch 600| loss: 0.06071 | train_accuracy: 0.98538 | val_accuracy: 0.93403 |  0:05:45s\n",
            "epoch 601| loss: 0.06658 | train_accuracy: 0.98152 | val_accuracy: 0.93922 |  0:05:46s\n",
            "epoch 602| loss: 0.08375 | train_accuracy: 0.97286 | val_accuracy: 0.92283 |  0:05:47s\n",
            "epoch 603| loss: 0.12372 | train_accuracy: 0.96957 | val_accuracy: 0.92043 |  0:05:47s\n",
            "epoch 604| loss: 0.11824 | train_accuracy: 0.96797 | val_accuracy: 0.91963 |  0:05:48s\n",
            "epoch 605| loss: 0.11545 | train_accuracy: 0.9697  | val_accuracy: 0.92083 |  0:05:48s\n",
            "epoch 606| loss: 0.11028 | train_accuracy: 0.97174 | val_accuracy: 0.92163 |  0:05:49s\n",
            "epoch 607| loss: 0.10732 | train_accuracy: 0.9733  | val_accuracy: 0.92523 |  0:05:49s\n",
            "epoch 608| loss: 0.11205 | train_accuracy: 0.96459 | val_accuracy: 0.92443 |  0:05:50s\n",
            "epoch 609| loss: 0.14069 | train_accuracy: 0.96326 | val_accuracy: 0.91803 |  0:05:51s\n",
            "epoch 610| loss: 0.12557 | train_accuracy: 0.96815 | val_accuracy: 0.92203 |  0:05:51s\n",
            "epoch 611| loss: 0.11917 | train_accuracy: 0.96815 | val_accuracy: 0.92003 |  0:05:52s\n",
            "epoch 612| loss: 0.11579 | train_accuracy: 0.97032 | val_accuracy: 0.92243 |  0:05:52s\n",
            "epoch 613| loss: 0.10857 | train_accuracy: 0.97094 | val_accuracy: 0.92163 |  0:05:53s\n",
            "epoch 614| loss: 0.11101 | train_accuracy: 0.97055 | val_accuracy: 0.92763 |  0:05:53s\n",
            "epoch 615| loss: 0.09966 | train_accuracy: 0.97143 | val_accuracy: 0.92963 |  0:05:54s\n",
            "epoch 616| loss: 0.09279 | train_accuracy: 0.97392 | val_accuracy: 0.92763 |  0:05:55s\n",
            "epoch 617| loss: 0.09612 | train_accuracy: 0.97268 | val_accuracy: 0.92523 |  0:05:55s\n",
            "epoch 618| loss: 0.10656 | train_accuracy: 0.96988 | val_accuracy: 0.92003 |  0:05:56s\n",
            "epoch 619| loss: 0.10955 | train_accuracy: 0.97223 | val_accuracy: 0.93003 |  0:05:56s\n",
            "epoch 620| loss: 0.10544 | train_accuracy: 0.97361 | val_accuracy: 0.93003 |  0:05:57s\n",
            "epoch 621| loss: 0.10172 | train_accuracy: 0.97197 | val_accuracy: 0.93043 |  0:05:57s\n",
            "epoch 622| loss: 0.0994  | train_accuracy: 0.97179 | val_accuracy: 0.92723 |  0:05:58s\n",
            "epoch 623| loss: 0.09828 | train_accuracy: 0.97557 | val_accuracy: 0.93523 |  0:05:59s\n",
            "epoch 624| loss: 0.08346 | train_accuracy: 0.97801 | val_accuracy: 0.93403 |  0:05:59s\n",
            "epoch 625| loss: 0.07894 | train_accuracy: 0.98094 | val_accuracy: 0.93762 |  0:06:00s\n",
            "epoch 626| loss: 0.07539 | train_accuracy: 0.97899 | val_accuracy: 0.93762 |  0:06:00s\n",
            "epoch 627| loss: 0.07254 | train_accuracy: 0.98165 | val_accuracy: 0.94202 |  0:06:01s\n",
            "epoch 628| loss: 0.06829 | train_accuracy: 0.98312 | val_accuracy: 0.94442 |  0:06:02s\n",
            "epoch 629| loss: 0.0631  | train_accuracy: 0.98441 | val_accuracy: 0.94202 |  0:06:02s\n",
            "epoch 630| loss: 0.05878 | train_accuracy: 0.98596 | val_accuracy: 0.94002 |  0:06:03s\n",
            "epoch 631| loss: 0.05747 | train_accuracy: 0.98072 | val_accuracy: 0.93643 |  0:06:03s\n",
            "epoch 632| loss: 0.07181 | train_accuracy: 0.98103 | val_accuracy: 0.93962 |  0:06:04s\n",
            "epoch 633| loss: 0.07266 | train_accuracy: 0.98085 | val_accuracy: 0.93363 |  0:06:04s\n",
            "epoch 634| loss: 0.06683 | train_accuracy: 0.98205 | val_accuracy: 0.94122 |  0:06:05s\n",
            "epoch 635| loss: 0.06359 | train_accuracy: 0.98356 | val_accuracy: 0.94242 |  0:06:06s\n",
            "epoch 636| loss: 0.0583  | train_accuracy: 0.98232 | val_accuracy: 0.93842 |  0:06:06s\n",
            "epoch 637| loss: 0.08218 | train_accuracy: 0.97823 | val_accuracy: 0.93523 |  0:06:07s\n",
            "epoch 638| loss: 0.0804  | train_accuracy: 0.97903 | val_accuracy: 0.93563 |  0:06:07s\n",
            "epoch 639| loss: 0.07539 | train_accuracy: 0.98307 | val_accuracy: 0.93882 |  0:06:08s\n",
            "epoch 640| loss: 0.06144 | train_accuracy: 0.98258 | val_accuracy: 0.93842 |  0:06:08s\n",
            "epoch 641| loss: 0.06627 | train_accuracy: 0.98232 | val_accuracy: 0.94122 |  0:06:09s\n",
            "epoch 642| loss: 0.06485 | train_accuracy: 0.98285 | val_accuracy: 0.94682 |  0:06:10s\n",
            "epoch 643| loss: 0.09067 | train_accuracy: 0.97445 | val_accuracy: 0.93842 |  0:06:10s\n",
            "epoch 644| loss: 0.11407 | train_accuracy: 0.97499 | val_accuracy: 0.94002 |  0:06:11s\n",
            "epoch 645| loss: 0.09052 | train_accuracy: 0.97859 | val_accuracy: 0.94162 |  0:06:11s\n",
            "epoch 646| loss: 0.07514 | train_accuracy: 0.98125 | val_accuracy: 0.94802 |  0:06:12s\n",
            "epoch 647| loss: 0.0642  | train_accuracy: 0.98356 | val_accuracy: 0.94922 |  0:06:12s\n",
            "epoch 648| loss: 0.06754 | train_accuracy: 0.98174 | val_accuracy: 0.94842 |  0:06:13s\n",
            "epoch 649| loss: 0.07993 | train_accuracy: 0.98063 | val_accuracy: 0.94362 |  0:06:14s\n",
            "epoch 650| loss: 0.0715  | train_accuracy: 0.98254 | val_accuracy: 0.94642 |  0:06:14s\n",
            "epoch 651| loss: 0.06917 | train_accuracy: 0.98267 | val_accuracy: 0.94882 |  0:06:15s\n",
            "epoch 652| loss: 0.06889 | train_accuracy: 0.98401 | val_accuracy: 0.94162 |  0:06:15s\n",
            "epoch 653| loss: 0.06189 | train_accuracy: 0.98476 | val_accuracy: 0.94642 |  0:06:16s\n",
            "epoch 654| loss: 0.06037 | train_accuracy: 0.98614 | val_accuracy: 0.94642 |  0:06:16s\n",
            "epoch 655| loss: 0.05693 | train_accuracy: 0.98672 | val_accuracy: 0.95202 |  0:06:17s\n",
            "epoch 656| loss: 0.05197 | train_accuracy: 0.98645 | val_accuracy: 0.95282 |  0:06:18s\n",
            "epoch 657| loss: 0.05593 | train_accuracy: 0.98538 | val_accuracy: 0.94882 |  0:06:18s\n",
            "epoch 658| loss: 0.05661 | train_accuracy: 0.98654 | val_accuracy: 0.95322 |  0:06:19s\n",
            "epoch 659| loss: 0.05132 | train_accuracy: 0.98685 | val_accuracy: 0.94962 |  0:06:19s\n",
            "epoch 660| loss: 0.0522  | train_accuracy: 0.98752 | val_accuracy: 0.94802 |  0:06:20s\n",
            "epoch 661| loss: 0.04569 | train_accuracy: 0.98938 | val_accuracy: 0.95002 |  0:06:20s\n",
            "epoch 662| loss: 0.04505 | train_accuracy: 0.98867 | val_accuracy: 0.95362 |  0:06:21s\n",
            "epoch 663| loss: 0.04626 | train_accuracy: 0.98929 | val_accuracy: 0.94962 |  0:06:22s\n",
            "epoch 664| loss: 0.04487 | train_accuracy: 0.99054 | val_accuracy: 0.95122 |  0:06:22s\n",
            "epoch 665| loss: 0.04254 | train_accuracy: 0.9916  | val_accuracy: 0.95362 |  0:06:23s\n",
            "epoch 666| loss: 0.03836 | train_accuracy: 0.99143 | val_accuracy: 0.95242 |  0:06:23s\n",
            "epoch 667| loss: 0.03438 | train_accuracy: 0.9924  | val_accuracy: 0.95322 |  0:06:24s\n",
            "epoch 668| loss: 0.03335 | train_accuracy: 0.99245 | val_accuracy: 0.95282 |  0:06:25s\n",
            "epoch 669| loss: 0.03263 | train_accuracy: 0.99338 | val_accuracy: 0.95242 |  0:06:25s\n",
            "epoch 670| loss: 0.03048 | train_accuracy: 0.99378 | val_accuracy: 0.95602 |  0:06:26s\n",
            "epoch 671| loss: 0.03105 | train_accuracy: 0.99414 | val_accuracy: 0.95842 |  0:06:26s\n",
            "epoch 672| loss: 0.02942 | train_accuracy: 0.99365 | val_accuracy: 0.95682 |  0:06:27s\n",
            "epoch 673| loss: 0.04059 | train_accuracy: 0.99018 | val_accuracy: 0.95042 |  0:06:27s\n",
            "epoch 674| loss: 0.05344 | train_accuracy: 0.98974 | val_accuracy: 0.95242 |  0:06:28s\n",
            "epoch 675| loss: 0.0467  | train_accuracy: 0.99156 | val_accuracy: 0.95602 |  0:06:28s\n",
            "epoch 676| loss: 0.03941 | train_accuracy: 0.99231 | val_accuracy: 0.95482 |  0:06:29s\n",
            "epoch 677| loss: 0.03559 | train_accuracy: 0.99338 | val_accuracy: 0.95642 |  0:06:30s\n",
            "epoch 678| loss: 0.03128 | train_accuracy: 0.9944  | val_accuracy: 0.95562 |  0:06:30s\n",
            "epoch 679| loss: 0.02928 | train_accuracy: 0.99445 | val_accuracy: 0.95722 |  0:06:31s\n",
            "epoch 680| loss: 0.02615 | train_accuracy: 0.99471 | val_accuracy: 0.95522 |  0:06:31s\n",
            "epoch 681| loss: 0.02818 | train_accuracy: 0.99338 | val_accuracy: 0.95602 |  0:06:32s\n",
            "epoch 682| loss: 0.04109 | train_accuracy: 0.99098 | val_accuracy: 0.95322 |  0:06:32s\n",
            "epoch 683| loss: 0.04558 | train_accuracy: 0.99218 | val_accuracy: 0.95042 |  0:06:33s\n",
            "epoch 684| loss: 0.04058 | train_accuracy: 0.99156 | val_accuracy: 0.95602 |  0:06:34s\n",
            "epoch 685| loss: 0.03643 | train_accuracy: 0.99307 | val_accuracy: 0.95642 |  0:06:34s\n",
            "epoch 686| loss: 0.03391 | train_accuracy: 0.99374 | val_accuracy: 0.95762 |  0:06:35s\n",
            "epoch 687| loss: 0.03088 | train_accuracy: 0.99529 | val_accuracy: 0.96042 |  0:06:35s\n",
            "epoch 688| loss: 0.02666 | train_accuracy: 0.99511 | val_accuracy: 0.96082 |  0:06:36s\n",
            "epoch 689| loss: 0.02535 | train_accuracy: 0.99569 | val_accuracy: 0.95962 |  0:06:37s\n",
            "epoch 690| loss: 0.02278 | train_accuracy: 0.99507 | val_accuracy: 0.95882 |  0:06:37s\n",
            "epoch 691| loss: 0.02289 | train_accuracy: 0.99631 | val_accuracy: 0.96002 |  0:06:38s\n",
            "epoch 692| loss: 0.02119 | train_accuracy: 0.99725 | val_accuracy: 0.96042 |  0:06:38s\n",
            "epoch 693| loss: 0.01958 | train_accuracy: 0.99671 | val_accuracy: 0.95802 |  0:06:39s\n",
            "epoch 694| loss: 0.02092 | train_accuracy: 0.99662 | val_accuracy: 0.95882 |  0:06:39s\n",
            "epoch 695| loss: 0.01977 | train_accuracy: 0.99667 | val_accuracy: 0.95882 |  0:06:40s\n",
            "epoch 696| loss: 0.0213  | train_accuracy: 0.9976  | val_accuracy: 0.95842 |  0:06:40s\n",
            "epoch 697| loss: 0.01749 | train_accuracy: 0.99676 | val_accuracy: 0.95762 |  0:06:41s\n",
            "epoch 698| loss: 0.02443 | train_accuracy: 0.99294 | val_accuracy: 0.95522 |  0:06:42s\n",
            "epoch 699| loss: 0.02917 | train_accuracy: 0.99427 | val_accuracy: 0.95642 |  0:06:42s\n",
            "epoch 700| loss: 0.02938 | train_accuracy: 0.99498 | val_accuracy: 0.95682 |  0:06:43s\n",
            "epoch 701| loss: 0.03121 | train_accuracy: 0.99325 | val_accuracy: 0.95322 |  0:06:43s\n",
            "epoch 702| loss: 0.03775 | train_accuracy: 0.99396 | val_accuracy: 0.95722 |  0:06:44s\n",
            "epoch 703| loss: 0.02687 | train_accuracy: 0.99534 | val_accuracy: 0.96042 |  0:06:44s\n",
            "epoch 704| loss: 0.02769 | train_accuracy: 0.99525 | val_accuracy: 0.95802 |  0:06:45s\n",
            "epoch 705| loss: 0.02459 | train_accuracy: 0.99569 | val_accuracy: 0.95722 |  0:06:46s\n",
            "epoch 706| loss: 0.02547 | train_accuracy: 0.99529 | val_accuracy: 0.96042 |  0:06:46s\n",
            "epoch 707| loss: 0.02633 | train_accuracy: 0.99507 | val_accuracy: 0.95882 |  0:06:47s\n",
            "epoch 708| loss: 0.02793 | train_accuracy: 0.99511 | val_accuracy: 0.95882 |  0:06:47s\n",
            "epoch 709| loss: 0.02375 | train_accuracy: 0.99582 | val_accuracy: 0.96002 |  0:06:48s\n",
            "epoch 710| loss: 0.02435 | train_accuracy: 0.99578 | val_accuracy: 0.95922 |  0:06:48s\n",
            "epoch 711| loss: 0.02051 | train_accuracy: 0.99649 | val_accuracy: 0.96002 |  0:06:49s\n",
            "epoch 712| loss: 0.0179  | train_accuracy: 0.99716 | val_accuracy: 0.96122 |  0:06:50s\n",
            "epoch 713| loss: 0.01805 | train_accuracy: 0.99733 | val_accuracy: 0.96162 |  0:06:50s\n",
            "epoch 714| loss: 0.01503 | train_accuracy: 0.99769 | val_accuracy: 0.96082 |  0:06:51s\n",
            "epoch 715| loss: 0.01478 | train_accuracy: 0.99791 | val_accuracy: 0.96082 |  0:06:51s\n",
            "epoch 716| loss: 0.01595 | train_accuracy: 0.99809 | val_accuracy: 0.96122 |  0:06:52s\n",
            "epoch 717| loss: 0.0147  | train_accuracy: 0.99805 | val_accuracy: 0.96242 |  0:06:52s\n",
            "epoch 718| loss: 0.01255 | train_accuracy: 0.9984  | val_accuracy: 0.96202 |  0:06:53s\n",
            "epoch 719| loss: 0.01213 | train_accuracy: 0.99831 | val_accuracy: 0.96242 |  0:06:54s\n",
            "epoch 720| loss: 0.01571 | train_accuracy: 0.99778 | val_accuracy: 0.96202 |  0:06:54s\n",
            "epoch 721| loss: 0.01595 | train_accuracy: 0.99787 | val_accuracy: 0.95922 |  0:06:55s\n",
            "epoch 722| loss: 0.01807 | train_accuracy: 0.99742 | val_accuracy: 0.96002 |  0:06:55s\n",
            "epoch 723| loss: 0.01586 | train_accuracy: 0.99809 | val_accuracy: 0.95842 |  0:06:56s\n",
            "epoch 724| loss: 0.01475 | train_accuracy: 0.99813 | val_accuracy: 0.96082 |  0:06:57s\n",
            "epoch 725| loss: 0.01395 | train_accuracy: 0.99845 | val_accuracy: 0.96122 |  0:06:57s\n",
            "epoch 726| loss: 0.01277 | train_accuracy: 0.99818 | val_accuracy: 0.96162 |  0:06:58s\n",
            "epoch 727| loss: 0.0159  | train_accuracy: 0.99711 | val_accuracy: 0.96082 |  0:06:58s\n",
            "epoch 728| loss: 0.02138 | train_accuracy: 0.9972  | val_accuracy: 0.96162 |  0:06:59s\n",
            "epoch 729| loss: 0.02026 | train_accuracy: 0.99742 | val_accuracy: 0.96082 |  0:06:59s\n",
            "epoch 730| loss: 0.02038 | train_accuracy: 0.99738 | val_accuracy: 0.96281 |  0:07:00s\n",
            "epoch 731| loss: 0.01523 | train_accuracy: 0.99733 | val_accuracy: 0.96441 |  0:07:01s\n",
            "epoch 732| loss: 0.01759 | train_accuracy: 0.99782 | val_accuracy: 0.96242 |  0:07:01s\n",
            "epoch 733| loss: 0.01601 | train_accuracy: 0.99836 | val_accuracy: 0.96122 |  0:07:02s\n",
            "epoch 734| loss: 0.01266 | train_accuracy: 0.99836 | val_accuracy: 0.96321 |  0:07:02s\n",
            "epoch 735| loss: 0.01321 | train_accuracy: 0.99853 | val_accuracy: 0.96441 |  0:07:03s\n",
            "epoch 736| loss: 0.01275 | train_accuracy: 0.99889 | val_accuracy: 0.96401 |  0:07:03s\n",
            "epoch 737| loss: 0.0126  | train_accuracy: 0.99893 | val_accuracy: 0.96601 |  0:07:04s\n",
            "epoch 738| loss: 0.01051 | train_accuracy: 0.9988  | val_accuracy: 0.96481 |  0:07:05s\n",
            "epoch 739| loss: 0.0122  | train_accuracy: 0.9988  | val_accuracy: 0.96561 |  0:07:05s\n",
            "epoch 740| loss: 0.01136 | train_accuracy: 0.99876 | val_accuracy: 0.96401 |  0:07:06s\n",
            "epoch 741| loss: 0.0205  | train_accuracy: 0.99311 | val_accuracy: 0.95882 |  0:07:06s\n",
            "epoch 742| loss: 0.04614 | train_accuracy: 0.99369 | val_accuracy: 0.95962 |  0:07:07s\n",
            "epoch 743| loss: 0.02977 | train_accuracy: 0.99445 | val_accuracy: 0.96002 |  0:07:07s\n",
            "epoch 744| loss: 0.02189 | train_accuracy: 0.99574 | val_accuracy: 0.96401 |  0:07:08s\n",
            "epoch 745| loss: 0.02097 | train_accuracy: 0.99578 | val_accuracy: 0.96521 |  0:07:09s\n",
            "epoch 746| loss: 0.02774 | train_accuracy: 0.99076 | val_accuracy: 0.96122 |  0:07:09s\n",
            "epoch 747| loss: 0.04894 | train_accuracy: 0.99107 | val_accuracy: 0.96242 |  0:07:10s\n",
            "epoch 748| loss: 0.04209 | train_accuracy: 0.99378 | val_accuracy: 0.96042 |  0:07:10s\n",
            "epoch 749| loss: 0.02714 | train_accuracy: 0.99382 | val_accuracy: 0.96242 |  0:07:11s\n",
            "epoch 750| loss: 0.02861 | train_accuracy: 0.99551 | val_accuracy: 0.95922 |  0:07:11s\n",
            "epoch 751| loss: 0.02313 | train_accuracy: 0.99565 | val_accuracy: 0.96361 |  0:07:12s\n",
            "epoch 752| loss: 0.02125 | train_accuracy: 0.99636 | val_accuracy: 0.96321 |  0:07:13s\n",
            "epoch 753| loss: 0.01735 | train_accuracy: 0.99693 | val_accuracy: 0.96481 |  0:07:13s\n",
            "epoch 754| loss: 0.02311 | train_accuracy: 0.99711 | val_accuracy: 0.96202 |  0:07:14s\n",
            "epoch 755| loss: 0.01573 | train_accuracy: 0.99738 | val_accuracy: 0.96521 |  0:07:14s\n",
            "epoch 756| loss: 0.02241 | train_accuracy: 0.99471 | val_accuracy: 0.95762 |  0:07:15s\n",
            "epoch 757| loss: 0.02621 | train_accuracy: 0.9944  | val_accuracy: 0.95962 |  0:07:15s\n",
            "epoch 758| loss: 0.02178 | train_accuracy: 0.99534 | val_accuracy: 0.96122 |  0:07:16s\n",
            "epoch 759| loss: 0.01922 | train_accuracy: 0.99693 | val_accuracy: 0.96202 |  0:07:17s\n",
            "epoch 760| loss: 0.0182  | train_accuracy: 0.99707 | val_accuracy: 0.96281 |  0:07:17s\n",
            "epoch 761| loss: 0.01414 | train_accuracy: 0.99707 | val_accuracy: 0.96242 |  0:07:18s\n",
            "epoch 762| loss: 0.01712 | train_accuracy: 0.99765 | val_accuracy: 0.96281 |  0:07:18s\n",
            "epoch 763| loss: 0.01571 | train_accuracy: 0.99822 | val_accuracy: 0.96242 |  0:07:19s\n",
            "epoch 764| loss: 0.01321 | train_accuracy: 0.99849 | val_accuracy: 0.96321 |  0:07:20s\n",
            "epoch 765| loss: 0.01021 | train_accuracy: 0.99849 | val_accuracy: 0.96401 |  0:07:20s\n",
            "epoch 766| loss: 0.01313 | train_accuracy: 0.99871 | val_accuracy: 0.96441 |  0:07:21s\n",
            "epoch 767| loss: 0.01166 | train_accuracy: 0.99884 | val_accuracy: 0.96401 |  0:07:21s\n",
            "epoch 768| loss: 0.01074 | train_accuracy: 0.99898 | val_accuracy: 0.96521 |  0:07:22s\n",
            "epoch 769| loss: 0.00772 | train_accuracy: 0.99893 | val_accuracy: 0.96441 |  0:07:22s\n",
            "epoch 770| loss: 0.00838 | train_accuracy: 0.9992  | val_accuracy: 0.96561 |  0:07:23s\n",
            "epoch 771| loss: 0.00951 | train_accuracy: 0.99871 | val_accuracy: 0.96641 |  0:07:24s\n",
            "epoch 772| loss: 0.00978 | train_accuracy: 0.99916 | val_accuracy: 0.96321 |  0:07:24s\n",
            "epoch 773| loss: 0.00911 | train_accuracy: 0.99929 | val_accuracy: 0.96721 |  0:07:25s\n",
            "epoch 774| loss: 0.00743 | train_accuracy: 0.99942 | val_accuracy: 0.96441 |  0:07:25s\n",
            "epoch 775| loss: 0.00697 | train_accuracy: 0.99924 | val_accuracy: 0.96401 |  0:07:26s\n",
            "epoch 776| loss: 0.00695 | train_accuracy: 0.99924 | val_accuracy: 0.96401 |  0:07:26s\n",
            "epoch 777| loss: 0.00655 | train_accuracy: 0.99942 | val_accuracy: 0.96441 |  0:07:27s\n",
            "epoch 778| loss: 0.00584 | train_accuracy: 0.99964 | val_accuracy: 0.96122 |  0:07:28s\n",
            "epoch 779| loss: 0.00591 | train_accuracy: 0.99956 | val_accuracy: 0.96441 |  0:07:28s\n",
            "epoch 780| loss: 0.00515 | train_accuracy: 0.99947 | val_accuracy: 0.96321 |  0:07:29s\n",
            "epoch 781| loss: 0.00581 | train_accuracy: 0.99956 | val_accuracy: 0.96401 |  0:07:29s\n",
            "epoch 782| loss: 0.00647 | train_accuracy: 0.99947 | val_accuracy: 0.96441 |  0:07:30s\n",
            "epoch 783| loss: 0.00438 | train_accuracy: 0.99951 | val_accuracy: 0.96401 |  0:07:31s\n",
            "epoch 784| loss: 0.00434 | train_accuracy: 0.99956 | val_accuracy: 0.96441 |  0:07:31s\n",
            "epoch 785| loss: 0.00541 | train_accuracy: 0.99964 | val_accuracy: 0.96641 |  0:07:32s\n",
            "epoch 786| loss: 0.00557 | train_accuracy: 0.9996  | val_accuracy: 0.96601 |  0:07:32s\n",
            "epoch 787| loss: 0.00437 | train_accuracy: 0.99964 | val_accuracy: 0.96561 |  0:07:33s\n",
            "epoch 788| loss: 0.00426 | train_accuracy: 0.99973 | val_accuracy: 0.96681 |  0:07:33s\n",
            "epoch 789| loss: 0.00447 | train_accuracy: 0.9996  | val_accuracy: 0.96601 |  0:07:34s\n",
            "epoch 790| loss: 0.00557 | train_accuracy: 0.99951 | val_accuracy: 0.96481 |  0:07:35s\n",
            "epoch 791| loss: 0.00638 | train_accuracy: 0.99916 | val_accuracy: 0.96441 |  0:07:35s\n",
            "epoch 792| loss: 0.01438 | train_accuracy: 0.99658 | val_accuracy: 0.96202 |  0:07:36s\n",
            "epoch 793| loss: 0.02492 | train_accuracy: 0.9956  | val_accuracy: 0.96082 |  0:07:36s\n",
            "epoch 794| loss: 0.02361 | train_accuracy: 0.99698 | val_accuracy: 0.96002 |  0:07:37s\n",
            "epoch 795| loss: 0.0203  | train_accuracy: 0.99542 | val_accuracy: 0.96002 |  0:07:37s\n",
            "epoch 796| loss: 0.0355  | train_accuracy: 0.9944  | val_accuracy: 0.96082 |  0:07:38s\n",
            "epoch 797| loss: 0.02634 | train_accuracy: 0.99289 | val_accuracy: 0.95442 |  0:07:38s\n",
            "epoch 798| loss: 0.02613 | train_accuracy: 0.99636 | val_accuracy: 0.96002 |  0:07:39s\n",
            "epoch 799| loss: 0.02361 | train_accuracy: 0.99245 | val_accuracy: 0.95522 |  0:07:40s\n",
            "Stop training because you reached max_epochs = 800 with best_epoch = 773 and best_val_accuracy = 0.96721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/callbacks.py:155: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "jVmT4_CKdznN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "test_acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "print(f\"FINAL TEST SCORE FOR {dataset_name} : {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6f4b435-b1f3-403a-8d84-17796476436b",
        "id": "l6kP1F-4bl3L"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TEST SCORE FOR poker-hand-train : 0.966511\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and load model"
      ],
      "metadata": {
        "id": "wAkc0Yhfd61M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "saved_filename = clf.save_model('poker-hand')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiR6Uob5TqVh",
        "outputId": "d4076a1a-f777-4f50-8f2c-5c1b39e2e521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully saved model at poker-hand.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_clf = TabNetClassifier()\n",
        "loaded_clf.load_model('poker-hand.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcgbWAAOTuZi",
        "outputId": "11cdeed3-c10a-4164-fa68-814ff7f214a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_preds = loaded_clf.predict(X_test)\n",
        "#loaded_y_pred = np.vectorize(preds_mapper.get)(np.argmax(loaded_preds, axis=1))\n",
        "\n",
        "loaded_test_acc = accuracy_score(y_pred=loaded_preds, y_true=y_test)\n",
        "\n",
        "print(f\"FINAL TEST SCORE FOR {dataset_name} : {loaded_test_acc}\")"
      ],
      "metadata": {
        "id": "l0QHFIjNVEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Global explainability: feat importance summing to 1"
      ],
      "metadata": {
        "id": "r46VTg2ieuHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_clf._compute_feature_importances(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cguf4zMt4AqG",
        "outputId": "bd7723bd-2c09-43b5-c825-83ab9cace7da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02054544, 0.22912998, 0.00661577, 0.23512226, 0.00986172,\n",
              "       0.06326218, 0.0049203 , 0.16504643, 0.0719154 , 0.19358052])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_clf._compute_feature_importances(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "814K4pc16ngc",
        "outputId": "f63a1767-3008-4e26-9415-0de15e809002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02105085, 0.22631548, 0.0066539 , 0.2353577 , 0.00994821,\n",
              "       0.06405305, 0.00482431, 0.1665125 , 0.07141772, 0.19386628])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_clf._compute_feature_importances(X_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a86T6mmm70TV",
        "outputId": "c1f97fec-41ba-41a9-d7c1-f548e2ff8f0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02026774, 0.22975839, 0.00675487, 0.23404117, 0.00958988,\n",
              "       0.06038228, 0.00536242, 0.16497866, 0.07522375, 0.19364085])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.feature_importances_"
      ],
      "metadata": {
        "id": "kEOHLwBmewRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea79c82a-8758-49ef-c382-5a44178c8aa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02105085, 0.22631548, 0.0066539 , 0.2353577 , 0.0099482 ,\n",
              "       0.06405305, 0.00482431, 0.16651251, 0.07141772, 0.19386628])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "feature_importances[\"feature\"] = features\n",
        "feature_importances[\"importance\"] = clf.feature_importances_"
      ],
      "metadata": {
        "id": "IlgUqgOK08bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances.sort_values(\n",
        "    by = \"importance\", \n",
        "    ascending = True, \n",
        "    inplace = True\n",
        ")\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.barh(feature_importances[\"feature\"], feature_importances[\"importance\"])\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "3CRxAAyk1FUA",
        "outputId": "17567e47-d2a8-43bf-d9d9-69aecf8fc658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local explainability and masks"
      ],
      "metadata": {
        "id": "yMBdAnKneyUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explain_matrix, masks = clf.explain(X_test)"
      ],
      "metadata": {
        "id": "F9ccSwWOe0kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explain_matrix.sum(axis = 0)/np.sum(explain_matrix.sum(axis = 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG5TnuEV19zI",
        "outputId": "b52c3b24-d70d-4320-abba-34741fd6c813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.02054544, 0.22912998, 0.00661577, 0.23512227, 0.00986172,\n",
              "       0.06326218, 0.0049203 , 0.16504643, 0.07191539, 0.19358052])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, figsize=(18,18))\n",
        "\n",
        "axs.imshow(explain_matrix[:50])\n",
        "axs.set_title(f\"mask agg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U6Oy7Loj1VMA",
        "outputId": "95127026-3352-4dc2-a764-db0d6c783d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'mask agg')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1296x1296 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(20,20))\n",
        "\n",
        "for i in range(4):\n",
        "    axs[i].imshow(masks[i][:50])\n",
        "    axs[i].set_title(f\"mask {i}\")"
      ],
      "metadata": {
        "id": "JDqMrImie2L_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "2d226049-7054-4749-e311-44b6032b30a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "kzo4kpUaeRVD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(out, header = None, names = feature_columns)"
      ],
      "metadata": {
        "id": "MPxkvimaqSUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv(out_1, header = None, names = feature_columns)"
      ],
      "metadata": {
        "id": "xUslo0-KqfwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in feature_columns:\n",
        "  if col != 'Poker Hand':\n",
        "    train[col]= train[col].astype(\"category\")\n",
        "    test[col]= test[col].astype(\"category\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3DYaJvqeqmhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-yo_11GelWG",
        "outputId": "2c83a2e3-8ad4-4774-c604-9f5f37ee01aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S1            category\n",
              "C1            category\n",
              "S2            category\n",
              "C2            category\n",
              "S3            category\n",
              "C3            category\n",
              "S4            category\n",
              "C4            category\n",
              "S5            category\n",
              "C5            category\n",
              "Poker Hand       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BY5q_VbaKYX",
        "outputId": "04320910-0638-4d31-d785-bdd4273b964b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "S1            category\n",
              "C1            category\n",
              "S2            category\n",
              "C2            category\n",
              "S3            category\n",
              "C3            category\n",
              "S4            category\n",
              "C4            category\n",
              "S5            category\n",
              "C5            category\n",
              "Poker Hand       int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esf7-UlwdSMy",
        "outputId": "1cb794ad-303c-49dc-c51d-a5ea7c5030c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: xgboost 0.90\n",
            "Uninstalling xgboost-0.90:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost-0.90.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost/*\n",
            "    /usr/local/xgboost/libxgboost.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled xgboost-0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost==1.6.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UAWqneZdV4U",
        "outputId": "123f29c8-623b-4ae1-827a-a81eb291f8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.6.1\n",
            "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 192.9 MB 59 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.1) (1.4.1)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "l1mOAY-5bHPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "PARAMETERS = { 'learning_rate': [1e-3, 1e-2, 0.1, 0.3],'max_depth': [3, 5, 10],'n_estimators': [50, 100, 500, 1000],}"
      ],
      "metadata": {
        "id": "J3Jk9I3DcdUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(train.drop(columns = ['Poker Hand']), train['Poker Hand'], test_size = 0.1)"
      ],
      "metadata": {
        "id": "9L5xaY0Qh8Ix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(n_estimators=100, n_jobs=-1, scale_pos_weight=2400)\n",
        "model_gs = GridSearchCV(model,param_grid=PARAMETERS,cv=3,scoring=\"accuracy\")\n",
        "model_gs.fit(x_train,y_train,early_stopping_rounds=10,eval_set=eval_set,verbose=0)\n",
        "print(model_gs.best_params_)"
      ],
      "metadata": {
        "id": "p_Pyq9fVrqzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_set = [(x_train, y_train), (x_val, y_val)]"
      ],
      "metadata": {
        "id": "S_aNLCtotf1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier(tree_method=\"gpu_hist\", enable_categorical=True, use_label_encoder=False,n_estimators=100, n_jobs=-1)\n",
        "model_gs = GridSearchCV(model,param_grid=PARAMETERS,cv=3,scoring=\"accuracy\")\n",
        "model_gs.fit(x_train,y_train,early_stopping_rounds=10,eval_set=eval_set,verbose=0)\n",
        "print(model_gs.best_params_)"
      ],
      "metadata": {
        "id": "0lA6nE8nceQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = xgb.XGBClassifier(\n",
        "    tree_method=\"gpu_hist\", enable_categorical=True, use_label_encoder=False, max_depth=5,learning_rate=0.3,n_estimators=500,max_cat_to_one_hot=20\n",
        ")"
      ],
      "metadata": {
        "id": "diexfRsIfpvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_set = [(x_train, y_train), (x_val, y_val)]"
      ],
      "metadata": {
        "id": "dU341FN-qlkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, y_train,eval_set=eval_set,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Pt41ToibAf",
        "outputId": "79e44b60-8688-4add-de89-c8706b90f31b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10:49:51] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"max_cat_to_one_hot\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "[0]\tvalidation_0-mlogloss:1.76990\tvalidation_1-mlogloss:1.78384\n",
            "[1]\tvalidation_0-mlogloss:1.51361\tvalidation_1-mlogloss:1.53339\n",
            "[2]\tvalidation_0-mlogloss:1.35362\tvalidation_1-mlogloss:1.38043\n",
            "[3]\tvalidation_0-mlogloss:1.23786\tvalidation_1-mlogloss:1.27222\n",
            "[4]\tvalidation_0-mlogloss:1.15036\tvalidation_1-mlogloss:1.19091\n",
            "[5]\tvalidation_0-mlogloss:1.08295\tvalidation_1-mlogloss:1.12896\n",
            "[6]\tvalidation_0-mlogloss:1.03237\tvalidation_1-mlogloss:1.08487\n",
            "[7]\tvalidation_0-mlogloss:0.98605\tvalidation_1-mlogloss:1.04272\n",
            "[8]\tvalidation_0-mlogloss:0.95070\tvalidation_1-mlogloss:1.01498\n",
            "[9]\tvalidation_0-mlogloss:0.91947\tvalidation_1-mlogloss:0.98816\n",
            "[10]\tvalidation_0-mlogloss:0.89215\tvalidation_1-mlogloss:0.96665\n",
            "[11]\tvalidation_0-mlogloss:0.86904\tvalidation_1-mlogloss:0.94945\n",
            "[12]\tvalidation_0-mlogloss:0.85019\tvalidation_1-mlogloss:0.93547\n",
            "[13]\tvalidation_0-mlogloss:0.83022\tvalidation_1-mlogloss:0.92022\n",
            "[14]\tvalidation_0-mlogloss:0.81220\tvalidation_1-mlogloss:0.90851\n",
            "[15]\tvalidation_0-mlogloss:0.79473\tvalidation_1-mlogloss:0.89710\n",
            "[16]\tvalidation_0-mlogloss:0.77974\tvalidation_1-mlogloss:0.88845\n",
            "[17]\tvalidation_0-mlogloss:0.76467\tvalidation_1-mlogloss:0.87936\n",
            "[18]\tvalidation_0-mlogloss:0.75014\tvalidation_1-mlogloss:0.86876\n",
            "[19]\tvalidation_0-mlogloss:0.73678\tvalidation_1-mlogloss:0.85962\n",
            "[20]\tvalidation_0-mlogloss:0.72397\tvalidation_1-mlogloss:0.85195\n",
            "[21]\tvalidation_0-mlogloss:0.71259\tvalidation_1-mlogloss:0.84536\n",
            "[22]\tvalidation_0-mlogloss:0.70188\tvalidation_1-mlogloss:0.84018\n",
            "[23]\tvalidation_0-mlogloss:0.69139\tvalidation_1-mlogloss:0.83440\n",
            "[24]\tvalidation_0-mlogloss:0.67997\tvalidation_1-mlogloss:0.82712\n",
            "[25]\tvalidation_0-mlogloss:0.66872\tvalidation_1-mlogloss:0.82108\n",
            "[26]\tvalidation_0-mlogloss:0.65833\tvalidation_1-mlogloss:0.81437\n",
            "[27]\tvalidation_0-mlogloss:0.64875\tvalidation_1-mlogloss:0.80923\n",
            "[28]\tvalidation_0-mlogloss:0.63793\tvalidation_1-mlogloss:0.80199\n",
            "[29]\tvalidation_0-mlogloss:0.62763\tvalidation_1-mlogloss:0.79630\n",
            "[30]\tvalidation_0-mlogloss:0.61733\tvalidation_1-mlogloss:0.79055\n",
            "[31]\tvalidation_0-mlogloss:0.60810\tvalidation_1-mlogloss:0.78509\n",
            "[32]\tvalidation_0-mlogloss:0.59819\tvalidation_1-mlogloss:0.77995\n",
            "[33]\tvalidation_0-mlogloss:0.58933\tvalidation_1-mlogloss:0.77448\n",
            "[34]\tvalidation_0-mlogloss:0.58049\tvalidation_1-mlogloss:0.76882\n",
            "[35]\tvalidation_0-mlogloss:0.57138\tvalidation_1-mlogloss:0.76114\n",
            "[36]\tvalidation_0-mlogloss:0.56221\tvalidation_1-mlogloss:0.75543\n",
            "[37]\tvalidation_0-mlogloss:0.55391\tvalidation_1-mlogloss:0.75081\n",
            "[38]\tvalidation_0-mlogloss:0.54631\tvalidation_1-mlogloss:0.74636\n",
            "[39]\tvalidation_0-mlogloss:0.53895\tvalidation_1-mlogloss:0.74222\n",
            "[40]\tvalidation_0-mlogloss:0.53064\tvalidation_1-mlogloss:0.73667\n",
            "[41]\tvalidation_0-mlogloss:0.52267\tvalidation_1-mlogloss:0.73159\n",
            "[42]\tvalidation_0-mlogloss:0.51543\tvalidation_1-mlogloss:0.72790\n",
            "[43]\tvalidation_0-mlogloss:0.50814\tvalidation_1-mlogloss:0.72596\n",
            "[44]\tvalidation_0-mlogloss:0.50114\tvalidation_1-mlogloss:0.72147\n",
            "[45]\tvalidation_0-mlogloss:0.49374\tvalidation_1-mlogloss:0.71740\n",
            "[46]\tvalidation_0-mlogloss:0.48742\tvalidation_1-mlogloss:0.71341\n",
            "[47]\tvalidation_0-mlogloss:0.48133\tvalidation_1-mlogloss:0.70850\n",
            "[48]\tvalidation_0-mlogloss:0.47498\tvalidation_1-mlogloss:0.70463\n",
            "[49]\tvalidation_0-mlogloss:0.46970\tvalidation_1-mlogloss:0.70217\n",
            "[50]\tvalidation_0-mlogloss:0.46360\tvalidation_1-mlogloss:0.69910\n",
            "[51]\tvalidation_0-mlogloss:0.45727\tvalidation_1-mlogloss:0.69474\n",
            "[52]\tvalidation_0-mlogloss:0.45186\tvalidation_1-mlogloss:0.69130\n",
            "[53]\tvalidation_0-mlogloss:0.44636\tvalidation_1-mlogloss:0.68798\n",
            "[54]\tvalidation_0-mlogloss:0.44084\tvalidation_1-mlogloss:0.68463\n",
            "[55]\tvalidation_0-mlogloss:0.43555\tvalidation_1-mlogloss:0.68262\n",
            "[56]\tvalidation_0-mlogloss:0.43026\tvalidation_1-mlogloss:0.68004\n",
            "[57]\tvalidation_0-mlogloss:0.42454\tvalidation_1-mlogloss:0.67818\n",
            "[58]\tvalidation_0-mlogloss:0.41848\tvalidation_1-mlogloss:0.67319\n",
            "[59]\tvalidation_0-mlogloss:0.41266\tvalidation_1-mlogloss:0.66937\n",
            "[60]\tvalidation_0-mlogloss:0.40818\tvalidation_1-mlogloss:0.66783\n",
            "[61]\tvalidation_0-mlogloss:0.40284\tvalidation_1-mlogloss:0.66466\n",
            "[62]\tvalidation_0-mlogloss:0.39762\tvalidation_1-mlogloss:0.66091\n",
            "[63]\tvalidation_0-mlogloss:0.39247\tvalidation_1-mlogloss:0.65661\n",
            "[64]\tvalidation_0-mlogloss:0.38740\tvalidation_1-mlogloss:0.65450\n",
            "[65]\tvalidation_0-mlogloss:0.38243\tvalidation_1-mlogloss:0.65187\n",
            "[66]\tvalidation_0-mlogloss:0.37758\tvalidation_1-mlogloss:0.64939\n",
            "[67]\tvalidation_0-mlogloss:0.37309\tvalidation_1-mlogloss:0.64599\n",
            "[68]\tvalidation_0-mlogloss:0.36857\tvalidation_1-mlogloss:0.64250\n",
            "[69]\tvalidation_0-mlogloss:0.36430\tvalidation_1-mlogloss:0.63948\n",
            "[70]\tvalidation_0-mlogloss:0.35924\tvalidation_1-mlogloss:0.63635\n",
            "[71]\tvalidation_0-mlogloss:0.35541\tvalidation_1-mlogloss:0.63479\n",
            "[72]\tvalidation_0-mlogloss:0.35137\tvalidation_1-mlogloss:0.63288\n",
            "[73]\tvalidation_0-mlogloss:0.34718\tvalidation_1-mlogloss:0.63063\n",
            "[74]\tvalidation_0-mlogloss:0.34281\tvalidation_1-mlogloss:0.62741\n",
            "[75]\tvalidation_0-mlogloss:0.33921\tvalidation_1-mlogloss:0.62483\n",
            "[76]\tvalidation_0-mlogloss:0.33561\tvalidation_1-mlogloss:0.62271\n",
            "[77]\tvalidation_0-mlogloss:0.33191\tvalidation_1-mlogloss:0.62031\n",
            "[78]\tvalidation_0-mlogloss:0.32800\tvalidation_1-mlogloss:0.61739\n",
            "[79]\tvalidation_0-mlogloss:0.32391\tvalidation_1-mlogloss:0.61361\n",
            "[80]\tvalidation_0-mlogloss:0.31973\tvalidation_1-mlogloss:0.61050\n",
            "[81]\tvalidation_0-mlogloss:0.31585\tvalidation_1-mlogloss:0.60757\n",
            "[82]\tvalidation_0-mlogloss:0.31222\tvalidation_1-mlogloss:0.60489\n",
            "[83]\tvalidation_0-mlogloss:0.30878\tvalidation_1-mlogloss:0.60211\n",
            "[84]\tvalidation_0-mlogloss:0.30541\tvalidation_1-mlogloss:0.59936\n",
            "[85]\tvalidation_0-mlogloss:0.30226\tvalidation_1-mlogloss:0.59791\n",
            "[86]\tvalidation_0-mlogloss:0.29855\tvalidation_1-mlogloss:0.59508\n",
            "[87]\tvalidation_0-mlogloss:0.29492\tvalidation_1-mlogloss:0.59283\n",
            "[88]\tvalidation_0-mlogloss:0.29135\tvalidation_1-mlogloss:0.59102\n",
            "[89]\tvalidation_0-mlogloss:0.28783\tvalidation_1-mlogloss:0.58738\n",
            "[90]\tvalidation_0-mlogloss:0.28493\tvalidation_1-mlogloss:0.58541\n",
            "[91]\tvalidation_0-mlogloss:0.28143\tvalidation_1-mlogloss:0.58309\n",
            "[92]\tvalidation_0-mlogloss:0.27829\tvalidation_1-mlogloss:0.58082\n",
            "[93]\tvalidation_0-mlogloss:0.27467\tvalidation_1-mlogloss:0.57775\n",
            "[94]\tvalidation_0-mlogloss:0.27196\tvalidation_1-mlogloss:0.57474\n",
            "[95]\tvalidation_0-mlogloss:0.26904\tvalidation_1-mlogloss:0.57186\n",
            "[96]\tvalidation_0-mlogloss:0.26546\tvalidation_1-mlogloss:0.56857\n",
            "[97]\tvalidation_0-mlogloss:0.26266\tvalidation_1-mlogloss:0.56637\n",
            "[98]\tvalidation_0-mlogloss:0.26000\tvalidation_1-mlogloss:0.56489\n",
            "[99]\tvalidation_0-mlogloss:0.25718\tvalidation_1-mlogloss:0.56357\n",
            "[100]\tvalidation_0-mlogloss:0.25422\tvalidation_1-mlogloss:0.56102\n",
            "[101]\tvalidation_0-mlogloss:0.25103\tvalidation_1-mlogloss:0.55836\n",
            "[102]\tvalidation_0-mlogloss:0.24805\tvalidation_1-mlogloss:0.55579\n",
            "[103]\tvalidation_0-mlogloss:0.24583\tvalidation_1-mlogloss:0.55391\n",
            "[104]\tvalidation_0-mlogloss:0.24360\tvalidation_1-mlogloss:0.55256\n",
            "[105]\tvalidation_0-mlogloss:0.24088\tvalidation_1-mlogloss:0.55003\n",
            "[106]\tvalidation_0-mlogloss:0.23859\tvalidation_1-mlogloss:0.54886\n",
            "[107]\tvalidation_0-mlogloss:0.23631\tvalidation_1-mlogloss:0.54806\n",
            "[108]\tvalidation_0-mlogloss:0.23408\tvalidation_1-mlogloss:0.54657\n",
            "[109]\tvalidation_0-mlogloss:0.23163\tvalidation_1-mlogloss:0.54517\n",
            "[110]\tvalidation_0-mlogloss:0.22939\tvalidation_1-mlogloss:0.54355\n",
            "[111]\tvalidation_0-mlogloss:0.22697\tvalidation_1-mlogloss:0.54183\n",
            "[112]\tvalidation_0-mlogloss:0.22459\tvalidation_1-mlogloss:0.54104\n",
            "[113]\tvalidation_0-mlogloss:0.22175\tvalidation_1-mlogloss:0.53836\n",
            "[114]\tvalidation_0-mlogloss:0.21911\tvalidation_1-mlogloss:0.53559\n",
            "[115]\tvalidation_0-mlogloss:0.21729\tvalidation_1-mlogloss:0.53433\n",
            "[116]\tvalidation_0-mlogloss:0.21465\tvalidation_1-mlogloss:0.53225\n",
            "[117]\tvalidation_0-mlogloss:0.21231\tvalidation_1-mlogloss:0.53067\n",
            "[118]\tvalidation_0-mlogloss:0.21016\tvalidation_1-mlogloss:0.52853\n",
            "[119]\tvalidation_0-mlogloss:0.20770\tvalidation_1-mlogloss:0.52568\n",
            "[120]\tvalidation_0-mlogloss:0.20553\tvalidation_1-mlogloss:0.52342\n",
            "[121]\tvalidation_0-mlogloss:0.20360\tvalidation_1-mlogloss:0.52185\n",
            "[122]\tvalidation_0-mlogloss:0.20160\tvalidation_1-mlogloss:0.52114\n",
            "[123]\tvalidation_0-mlogloss:0.19943\tvalidation_1-mlogloss:0.51934\n",
            "[124]\tvalidation_0-mlogloss:0.19715\tvalidation_1-mlogloss:0.51817\n",
            "[125]\tvalidation_0-mlogloss:0.19517\tvalidation_1-mlogloss:0.51612\n",
            "[126]\tvalidation_0-mlogloss:0.19331\tvalidation_1-mlogloss:0.51505\n",
            "[127]\tvalidation_0-mlogloss:0.19170\tvalidation_1-mlogloss:0.51380\n",
            "[128]\tvalidation_0-mlogloss:0.18985\tvalidation_1-mlogloss:0.51240\n",
            "[129]\tvalidation_0-mlogloss:0.18780\tvalidation_1-mlogloss:0.51027\n",
            "[130]\tvalidation_0-mlogloss:0.18571\tvalidation_1-mlogloss:0.50859\n",
            "[131]\tvalidation_0-mlogloss:0.18366\tvalidation_1-mlogloss:0.50719\n",
            "[132]\tvalidation_0-mlogloss:0.18195\tvalidation_1-mlogloss:0.50581\n",
            "[133]\tvalidation_0-mlogloss:0.18040\tvalidation_1-mlogloss:0.50516\n",
            "[134]\tvalidation_0-mlogloss:0.17873\tvalidation_1-mlogloss:0.50449\n",
            "[135]\tvalidation_0-mlogloss:0.17669\tvalidation_1-mlogloss:0.50286\n",
            "[136]\tvalidation_0-mlogloss:0.17464\tvalidation_1-mlogloss:0.50214\n",
            "[137]\tvalidation_0-mlogloss:0.17273\tvalidation_1-mlogloss:0.50056\n",
            "[138]\tvalidation_0-mlogloss:0.17103\tvalidation_1-mlogloss:0.49957\n",
            "[139]\tvalidation_0-mlogloss:0.16921\tvalidation_1-mlogloss:0.49787\n",
            "[140]\tvalidation_0-mlogloss:0.16770\tvalidation_1-mlogloss:0.49723\n",
            "[141]\tvalidation_0-mlogloss:0.16578\tvalidation_1-mlogloss:0.49621\n",
            "[142]\tvalidation_0-mlogloss:0.16414\tvalidation_1-mlogloss:0.49528\n",
            "[143]\tvalidation_0-mlogloss:0.16253\tvalidation_1-mlogloss:0.49399\n",
            "[144]\tvalidation_0-mlogloss:0.16111\tvalidation_1-mlogloss:0.49275\n",
            "[145]\tvalidation_0-mlogloss:0.15923\tvalidation_1-mlogloss:0.49093\n",
            "[146]\tvalidation_0-mlogloss:0.15770\tvalidation_1-mlogloss:0.48999\n",
            "[147]\tvalidation_0-mlogloss:0.15622\tvalidation_1-mlogloss:0.48850\n",
            "[148]\tvalidation_0-mlogloss:0.15472\tvalidation_1-mlogloss:0.48801\n",
            "[149]\tvalidation_0-mlogloss:0.15316\tvalidation_1-mlogloss:0.48632\n",
            "[150]\tvalidation_0-mlogloss:0.15198\tvalidation_1-mlogloss:0.48541\n",
            "[151]\tvalidation_0-mlogloss:0.15027\tvalidation_1-mlogloss:0.48364\n",
            "[152]\tvalidation_0-mlogloss:0.14924\tvalidation_1-mlogloss:0.48235\n",
            "[153]\tvalidation_0-mlogloss:0.14778\tvalidation_1-mlogloss:0.48122\n",
            "[154]\tvalidation_0-mlogloss:0.14640\tvalidation_1-mlogloss:0.48043\n",
            "[155]\tvalidation_0-mlogloss:0.14476\tvalidation_1-mlogloss:0.47873\n",
            "[156]\tvalidation_0-mlogloss:0.14372\tvalidation_1-mlogloss:0.47793\n",
            "[157]\tvalidation_0-mlogloss:0.14269\tvalidation_1-mlogloss:0.47704\n",
            "[158]\tvalidation_0-mlogloss:0.14131\tvalidation_1-mlogloss:0.47563\n",
            "[159]\tvalidation_0-mlogloss:0.13987\tvalidation_1-mlogloss:0.47468\n",
            "[160]\tvalidation_0-mlogloss:0.13836\tvalidation_1-mlogloss:0.47326\n",
            "[161]\tvalidation_0-mlogloss:0.13698\tvalidation_1-mlogloss:0.47232\n",
            "[162]\tvalidation_0-mlogloss:0.13564\tvalidation_1-mlogloss:0.47079\n",
            "[163]\tvalidation_0-mlogloss:0.13414\tvalidation_1-mlogloss:0.46950\n",
            "[164]\tvalidation_0-mlogloss:0.13278\tvalidation_1-mlogloss:0.46829\n",
            "[165]\tvalidation_0-mlogloss:0.13158\tvalidation_1-mlogloss:0.46828\n",
            "[166]\tvalidation_0-mlogloss:0.13034\tvalidation_1-mlogloss:0.46655\n",
            "[167]\tvalidation_0-mlogloss:0.12910\tvalidation_1-mlogloss:0.46615\n",
            "[168]\tvalidation_0-mlogloss:0.12779\tvalidation_1-mlogloss:0.46526\n",
            "[169]\tvalidation_0-mlogloss:0.12651\tvalidation_1-mlogloss:0.46432\n",
            "[170]\tvalidation_0-mlogloss:0.12537\tvalidation_1-mlogloss:0.46303\n",
            "[171]\tvalidation_0-mlogloss:0.12450\tvalidation_1-mlogloss:0.46186\n",
            "[172]\tvalidation_0-mlogloss:0.12334\tvalidation_1-mlogloss:0.46087\n",
            "[173]\tvalidation_0-mlogloss:0.12211\tvalidation_1-mlogloss:0.45948\n",
            "[174]\tvalidation_0-mlogloss:0.12129\tvalidation_1-mlogloss:0.45867\n",
            "[175]\tvalidation_0-mlogloss:0.12029\tvalidation_1-mlogloss:0.45747\n",
            "[176]\tvalidation_0-mlogloss:0.11892\tvalidation_1-mlogloss:0.45621\n",
            "[177]\tvalidation_0-mlogloss:0.11795\tvalidation_1-mlogloss:0.45564\n",
            "[178]\tvalidation_0-mlogloss:0.11657\tvalidation_1-mlogloss:0.45485\n",
            "[179]\tvalidation_0-mlogloss:0.11556\tvalidation_1-mlogloss:0.45363\n",
            "[180]\tvalidation_0-mlogloss:0.11486\tvalidation_1-mlogloss:0.45271\n",
            "[181]\tvalidation_0-mlogloss:0.11356\tvalidation_1-mlogloss:0.45147\n",
            "[182]\tvalidation_0-mlogloss:0.11236\tvalidation_1-mlogloss:0.45074\n",
            "[183]\tvalidation_0-mlogloss:0.11118\tvalidation_1-mlogloss:0.44935\n",
            "[184]\tvalidation_0-mlogloss:0.11003\tvalidation_1-mlogloss:0.44827\n",
            "[185]\tvalidation_0-mlogloss:0.10892\tvalidation_1-mlogloss:0.44740\n",
            "[186]\tvalidation_0-mlogloss:0.10814\tvalidation_1-mlogloss:0.44648\n",
            "[187]\tvalidation_0-mlogloss:0.10748\tvalidation_1-mlogloss:0.44602\n",
            "[188]\tvalidation_0-mlogloss:0.10641\tvalidation_1-mlogloss:0.44510\n",
            "[189]\tvalidation_0-mlogloss:0.10584\tvalidation_1-mlogloss:0.44491\n",
            "[190]\tvalidation_0-mlogloss:0.10490\tvalidation_1-mlogloss:0.44379\n",
            "[191]\tvalidation_0-mlogloss:0.10417\tvalidation_1-mlogloss:0.44327\n",
            "[192]\tvalidation_0-mlogloss:0.10328\tvalidation_1-mlogloss:0.44289\n",
            "[193]\tvalidation_0-mlogloss:0.10201\tvalidation_1-mlogloss:0.44142\n",
            "[194]\tvalidation_0-mlogloss:0.10110\tvalidation_1-mlogloss:0.44099\n",
            "[195]\tvalidation_0-mlogloss:0.10010\tvalidation_1-mlogloss:0.44044\n",
            "[196]\tvalidation_0-mlogloss:0.09937\tvalidation_1-mlogloss:0.43974\n",
            "[197]\tvalidation_0-mlogloss:0.09838\tvalidation_1-mlogloss:0.43884\n",
            "[198]\tvalidation_0-mlogloss:0.09740\tvalidation_1-mlogloss:0.43780\n",
            "[199]\tvalidation_0-mlogloss:0.09628\tvalidation_1-mlogloss:0.43668\n",
            "[200]\tvalidation_0-mlogloss:0.09572\tvalidation_1-mlogloss:0.43660\n",
            "[201]\tvalidation_0-mlogloss:0.09470\tvalidation_1-mlogloss:0.43563\n",
            "[202]\tvalidation_0-mlogloss:0.09385\tvalidation_1-mlogloss:0.43528\n",
            "[203]\tvalidation_0-mlogloss:0.09296\tvalidation_1-mlogloss:0.43496\n",
            "[204]\tvalidation_0-mlogloss:0.09204\tvalidation_1-mlogloss:0.43437\n",
            "[205]\tvalidation_0-mlogloss:0.09120\tvalidation_1-mlogloss:0.43344\n",
            "[206]\tvalidation_0-mlogloss:0.09028\tvalidation_1-mlogloss:0.43313\n",
            "[207]\tvalidation_0-mlogloss:0.08935\tvalidation_1-mlogloss:0.43224\n",
            "[208]\tvalidation_0-mlogloss:0.08820\tvalidation_1-mlogloss:0.43145\n",
            "[209]\tvalidation_0-mlogloss:0.08751\tvalidation_1-mlogloss:0.43119\n",
            "[210]\tvalidation_0-mlogloss:0.08684\tvalidation_1-mlogloss:0.43039\n",
            "[211]\tvalidation_0-mlogloss:0.08597\tvalidation_1-mlogloss:0.42991\n",
            "[212]\tvalidation_0-mlogloss:0.08524\tvalidation_1-mlogloss:0.42968\n",
            "[213]\tvalidation_0-mlogloss:0.08437\tvalidation_1-mlogloss:0.42913\n",
            "[214]\tvalidation_0-mlogloss:0.08357\tvalidation_1-mlogloss:0.42820\n",
            "[215]\tvalidation_0-mlogloss:0.08273\tvalidation_1-mlogloss:0.42814\n",
            "[216]\tvalidation_0-mlogloss:0.08205\tvalidation_1-mlogloss:0.42721\n",
            "[217]\tvalidation_0-mlogloss:0.08125\tvalidation_1-mlogloss:0.42643\n",
            "[218]\tvalidation_0-mlogloss:0.08090\tvalidation_1-mlogloss:0.42627\n",
            "[219]\tvalidation_0-mlogloss:0.08022\tvalidation_1-mlogloss:0.42565\n",
            "[220]\tvalidation_0-mlogloss:0.07943\tvalidation_1-mlogloss:0.42441\n",
            "[221]\tvalidation_0-mlogloss:0.07877\tvalidation_1-mlogloss:0.42342\n",
            "[222]\tvalidation_0-mlogloss:0.07807\tvalidation_1-mlogloss:0.42269\n",
            "[223]\tvalidation_0-mlogloss:0.07741\tvalidation_1-mlogloss:0.42222\n",
            "[224]\tvalidation_0-mlogloss:0.07668\tvalidation_1-mlogloss:0.42217\n",
            "[225]\tvalidation_0-mlogloss:0.07607\tvalidation_1-mlogloss:0.42142\n",
            "[226]\tvalidation_0-mlogloss:0.07547\tvalidation_1-mlogloss:0.42128\n",
            "[227]\tvalidation_0-mlogloss:0.07479\tvalidation_1-mlogloss:0.42077\n",
            "[228]\tvalidation_0-mlogloss:0.07403\tvalidation_1-mlogloss:0.42032\n",
            "[229]\tvalidation_0-mlogloss:0.07329\tvalidation_1-mlogloss:0.41960\n",
            "[230]\tvalidation_0-mlogloss:0.07297\tvalidation_1-mlogloss:0.41961\n",
            "[231]\tvalidation_0-mlogloss:0.07240\tvalidation_1-mlogloss:0.41878\n",
            "[232]\tvalidation_0-mlogloss:0.07184\tvalidation_1-mlogloss:0.41839\n",
            "[233]\tvalidation_0-mlogloss:0.07120\tvalidation_1-mlogloss:0.41779\n",
            "[234]\tvalidation_0-mlogloss:0.07061\tvalidation_1-mlogloss:0.41722\n",
            "[235]\tvalidation_0-mlogloss:0.07021\tvalidation_1-mlogloss:0.41684\n",
            "[236]\tvalidation_0-mlogloss:0.06959\tvalidation_1-mlogloss:0.41619\n",
            "[237]\tvalidation_0-mlogloss:0.06895\tvalidation_1-mlogloss:0.41579\n",
            "[238]\tvalidation_0-mlogloss:0.06834\tvalidation_1-mlogloss:0.41538\n",
            "[239]\tvalidation_0-mlogloss:0.06749\tvalidation_1-mlogloss:0.41447\n",
            "[240]\tvalidation_0-mlogloss:0.06683\tvalidation_1-mlogloss:0.41408\n",
            "[241]\tvalidation_0-mlogloss:0.06643\tvalidation_1-mlogloss:0.41307\n",
            "[242]\tvalidation_0-mlogloss:0.06580\tvalidation_1-mlogloss:0.41253\n",
            "[243]\tvalidation_0-mlogloss:0.06515\tvalidation_1-mlogloss:0.41160\n",
            "[244]\tvalidation_0-mlogloss:0.06455\tvalidation_1-mlogloss:0.41054\n",
            "[245]\tvalidation_0-mlogloss:0.06392\tvalidation_1-mlogloss:0.41028\n",
            "[246]\tvalidation_0-mlogloss:0.06346\tvalidation_1-mlogloss:0.41020\n",
            "[247]\tvalidation_0-mlogloss:0.06308\tvalidation_1-mlogloss:0.41001\n",
            "[248]\tvalidation_0-mlogloss:0.06265\tvalidation_1-mlogloss:0.40936\n",
            "[249]\tvalidation_0-mlogloss:0.06218\tvalidation_1-mlogloss:0.40910\n",
            "[250]\tvalidation_0-mlogloss:0.06166\tvalidation_1-mlogloss:0.40948\n",
            "[251]\tvalidation_0-mlogloss:0.06116\tvalidation_1-mlogloss:0.40886\n",
            "[252]\tvalidation_0-mlogloss:0.06065\tvalidation_1-mlogloss:0.40837\n",
            "[253]\tvalidation_0-mlogloss:0.06004\tvalidation_1-mlogloss:0.40781\n",
            "[254]\tvalidation_0-mlogloss:0.05975\tvalidation_1-mlogloss:0.40797\n",
            "[255]\tvalidation_0-mlogloss:0.05913\tvalidation_1-mlogloss:0.40723\n",
            "[256]\tvalidation_0-mlogloss:0.05874\tvalidation_1-mlogloss:0.40701\n",
            "[257]\tvalidation_0-mlogloss:0.05826\tvalidation_1-mlogloss:0.40659\n",
            "[258]\tvalidation_0-mlogloss:0.05778\tvalidation_1-mlogloss:0.40633\n",
            "[259]\tvalidation_0-mlogloss:0.05722\tvalidation_1-mlogloss:0.40577\n",
            "[260]\tvalidation_0-mlogloss:0.05693\tvalidation_1-mlogloss:0.40557\n",
            "[261]\tvalidation_0-mlogloss:0.05642\tvalidation_1-mlogloss:0.40486\n",
            "[262]\tvalidation_0-mlogloss:0.05607\tvalidation_1-mlogloss:0.40414\n",
            "[263]\tvalidation_0-mlogloss:0.05569\tvalidation_1-mlogloss:0.40361\n",
            "[264]\tvalidation_0-mlogloss:0.05508\tvalidation_1-mlogloss:0.40279\n",
            "[265]\tvalidation_0-mlogloss:0.05454\tvalidation_1-mlogloss:0.40230\n",
            "[266]\tvalidation_0-mlogloss:0.05415\tvalidation_1-mlogloss:0.40212\n",
            "[267]\tvalidation_0-mlogloss:0.05388\tvalidation_1-mlogloss:0.40208\n",
            "[268]\tvalidation_0-mlogloss:0.05362\tvalidation_1-mlogloss:0.40176\n",
            "[269]\tvalidation_0-mlogloss:0.05315\tvalidation_1-mlogloss:0.40113\n",
            "[270]\tvalidation_0-mlogloss:0.05290\tvalidation_1-mlogloss:0.40088\n",
            "[271]\tvalidation_0-mlogloss:0.05247\tvalidation_1-mlogloss:0.40099\n",
            "[272]\tvalidation_0-mlogloss:0.05195\tvalidation_1-mlogloss:0.40057\n",
            "[273]\tvalidation_0-mlogloss:0.05148\tvalidation_1-mlogloss:0.39953\n",
            "[274]\tvalidation_0-mlogloss:0.05111\tvalidation_1-mlogloss:0.39950\n",
            "[275]\tvalidation_0-mlogloss:0.05078\tvalidation_1-mlogloss:0.39927\n",
            "[276]\tvalidation_0-mlogloss:0.05027\tvalidation_1-mlogloss:0.39897\n",
            "[277]\tvalidation_0-mlogloss:0.04982\tvalidation_1-mlogloss:0.39833\n",
            "[278]\tvalidation_0-mlogloss:0.04962\tvalidation_1-mlogloss:0.39789\n",
            "[279]\tvalidation_0-mlogloss:0.04939\tvalidation_1-mlogloss:0.39785\n",
            "[280]\tvalidation_0-mlogloss:0.04893\tvalidation_1-mlogloss:0.39770\n",
            "[281]\tvalidation_0-mlogloss:0.04843\tvalidation_1-mlogloss:0.39731\n",
            "[282]\tvalidation_0-mlogloss:0.04813\tvalidation_1-mlogloss:0.39707\n",
            "[283]\tvalidation_0-mlogloss:0.04779\tvalidation_1-mlogloss:0.39657\n",
            "[284]\tvalidation_0-mlogloss:0.04752\tvalidation_1-mlogloss:0.39615\n",
            "[285]\tvalidation_0-mlogloss:0.04710\tvalidation_1-mlogloss:0.39560\n",
            "[286]\tvalidation_0-mlogloss:0.04664\tvalidation_1-mlogloss:0.39507\n",
            "[287]\tvalidation_0-mlogloss:0.04622\tvalidation_1-mlogloss:0.39476\n",
            "[288]\tvalidation_0-mlogloss:0.04595\tvalidation_1-mlogloss:0.39508\n",
            "[289]\tvalidation_0-mlogloss:0.04567\tvalidation_1-mlogloss:0.39498\n",
            "[290]\tvalidation_0-mlogloss:0.04540\tvalidation_1-mlogloss:0.39466\n",
            "[291]\tvalidation_0-mlogloss:0.04494\tvalidation_1-mlogloss:0.39389\n",
            "[292]\tvalidation_0-mlogloss:0.04466\tvalidation_1-mlogloss:0.39352\n",
            "[293]\tvalidation_0-mlogloss:0.04426\tvalidation_1-mlogloss:0.39268\n",
            "[294]\tvalidation_0-mlogloss:0.04390\tvalidation_1-mlogloss:0.39239\n",
            "[295]\tvalidation_0-mlogloss:0.04361\tvalidation_1-mlogloss:0.39217\n",
            "[296]\tvalidation_0-mlogloss:0.04322\tvalidation_1-mlogloss:0.39171\n",
            "[297]\tvalidation_0-mlogloss:0.04287\tvalidation_1-mlogloss:0.39126\n",
            "[298]\tvalidation_0-mlogloss:0.04248\tvalidation_1-mlogloss:0.39101\n",
            "[299]\tvalidation_0-mlogloss:0.04225\tvalidation_1-mlogloss:0.39081\n",
            "[300]\tvalidation_0-mlogloss:0.04193\tvalidation_1-mlogloss:0.39028\n",
            "[301]\tvalidation_0-mlogloss:0.04159\tvalidation_1-mlogloss:0.39012\n",
            "[302]\tvalidation_0-mlogloss:0.04136\tvalidation_1-mlogloss:0.38942\n",
            "[303]\tvalidation_0-mlogloss:0.04105\tvalidation_1-mlogloss:0.38913\n",
            "[304]\tvalidation_0-mlogloss:0.04076\tvalidation_1-mlogloss:0.38901\n",
            "[305]\tvalidation_0-mlogloss:0.04046\tvalidation_1-mlogloss:0.38857\n",
            "[306]\tvalidation_0-mlogloss:0.04024\tvalidation_1-mlogloss:0.38836\n",
            "[307]\tvalidation_0-mlogloss:0.03999\tvalidation_1-mlogloss:0.38839\n",
            "[308]\tvalidation_0-mlogloss:0.03972\tvalidation_1-mlogloss:0.38815\n",
            "[309]\tvalidation_0-mlogloss:0.03935\tvalidation_1-mlogloss:0.38782\n",
            "[310]\tvalidation_0-mlogloss:0.03908\tvalidation_1-mlogloss:0.38792\n",
            "[311]\tvalidation_0-mlogloss:0.03871\tvalidation_1-mlogloss:0.38742\n",
            "[312]\tvalidation_0-mlogloss:0.03852\tvalidation_1-mlogloss:0.38752\n",
            "[313]\tvalidation_0-mlogloss:0.03820\tvalidation_1-mlogloss:0.38768\n",
            "[314]\tvalidation_0-mlogloss:0.03796\tvalidation_1-mlogloss:0.38755\n",
            "[315]\tvalidation_0-mlogloss:0.03773\tvalidation_1-mlogloss:0.38725\n",
            "[316]\tvalidation_0-mlogloss:0.03738\tvalidation_1-mlogloss:0.38690\n",
            "[317]\tvalidation_0-mlogloss:0.03720\tvalidation_1-mlogloss:0.38671\n",
            "[318]\tvalidation_0-mlogloss:0.03695\tvalidation_1-mlogloss:0.38592\n",
            "[319]\tvalidation_0-mlogloss:0.03662\tvalidation_1-mlogloss:0.38514\n",
            "[320]\tvalidation_0-mlogloss:0.03637\tvalidation_1-mlogloss:0.38486\n",
            "[321]\tvalidation_0-mlogloss:0.03606\tvalidation_1-mlogloss:0.38518\n",
            "[322]\tvalidation_0-mlogloss:0.03579\tvalidation_1-mlogloss:0.38530\n",
            "[323]\tvalidation_0-mlogloss:0.03550\tvalidation_1-mlogloss:0.38518\n",
            "[324]\tvalidation_0-mlogloss:0.03522\tvalidation_1-mlogloss:0.38539\n",
            "[325]\tvalidation_0-mlogloss:0.03504\tvalidation_1-mlogloss:0.38538\n",
            "[326]\tvalidation_0-mlogloss:0.03479\tvalidation_1-mlogloss:0.38466\n",
            "[327]\tvalidation_0-mlogloss:0.03452\tvalidation_1-mlogloss:0.38466\n",
            "[328]\tvalidation_0-mlogloss:0.03424\tvalidation_1-mlogloss:0.38462\n",
            "[329]\tvalidation_0-mlogloss:0.03399\tvalidation_1-mlogloss:0.38451\n",
            "[330]\tvalidation_0-mlogloss:0.03374\tvalidation_1-mlogloss:0.38416\n",
            "[331]\tvalidation_0-mlogloss:0.03360\tvalidation_1-mlogloss:0.38406\n",
            "[332]\tvalidation_0-mlogloss:0.03344\tvalidation_1-mlogloss:0.38368\n",
            "[333]\tvalidation_0-mlogloss:0.03315\tvalidation_1-mlogloss:0.38314\n",
            "[334]\tvalidation_0-mlogloss:0.03288\tvalidation_1-mlogloss:0.38325\n",
            "[335]\tvalidation_0-mlogloss:0.03261\tvalidation_1-mlogloss:0.38270\n",
            "[336]\tvalidation_0-mlogloss:0.03234\tvalidation_1-mlogloss:0.38208\n",
            "[337]\tvalidation_0-mlogloss:0.03209\tvalidation_1-mlogloss:0.38201\n",
            "[338]\tvalidation_0-mlogloss:0.03183\tvalidation_1-mlogloss:0.38146\n",
            "[339]\tvalidation_0-mlogloss:0.03158\tvalidation_1-mlogloss:0.38133\n",
            "[340]\tvalidation_0-mlogloss:0.03128\tvalidation_1-mlogloss:0.38099\n",
            "[341]\tvalidation_0-mlogloss:0.03107\tvalidation_1-mlogloss:0.38102\n",
            "[342]\tvalidation_0-mlogloss:0.03085\tvalidation_1-mlogloss:0.38051\n",
            "[343]\tvalidation_0-mlogloss:0.03067\tvalidation_1-mlogloss:0.38053\n",
            "[344]\tvalidation_0-mlogloss:0.03046\tvalidation_1-mlogloss:0.38074\n",
            "[345]\tvalidation_0-mlogloss:0.03034\tvalidation_1-mlogloss:0.38057\n",
            "[346]\tvalidation_0-mlogloss:0.03015\tvalidation_1-mlogloss:0.38016\n",
            "[347]\tvalidation_0-mlogloss:0.02992\tvalidation_1-mlogloss:0.38060\n",
            "[348]\tvalidation_0-mlogloss:0.02971\tvalidation_1-mlogloss:0.38079\n",
            "[349]\tvalidation_0-mlogloss:0.02950\tvalidation_1-mlogloss:0.38029\n",
            "[350]\tvalidation_0-mlogloss:0.02925\tvalidation_1-mlogloss:0.38011\n",
            "[351]\tvalidation_0-mlogloss:0.02902\tvalidation_1-mlogloss:0.37979\n",
            "[352]\tvalidation_0-mlogloss:0.02889\tvalidation_1-mlogloss:0.37977\n",
            "[353]\tvalidation_0-mlogloss:0.02866\tvalidation_1-mlogloss:0.37983\n",
            "[354]\tvalidation_0-mlogloss:0.02853\tvalidation_1-mlogloss:0.37979\n",
            "[355]\tvalidation_0-mlogloss:0.02833\tvalidation_1-mlogloss:0.37974\n",
            "[356]\tvalidation_0-mlogloss:0.02816\tvalidation_1-mlogloss:0.37981\n",
            "[357]\tvalidation_0-mlogloss:0.02792\tvalidation_1-mlogloss:0.38018\n",
            "[358]\tvalidation_0-mlogloss:0.02771\tvalidation_1-mlogloss:0.38004\n",
            "[359]\tvalidation_0-mlogloss:0.02746\tvalidation_1-mlogloss:0.37962\n",
            "[360]\tvalidation_0-mlogloss:0.02730\tvalidation_1-mlogloss:0.37902\n",
            "[361]\tvalidation_0-mlogloss:0.02716\tvalidation_1-mlogloss:0.37887\n",
            "[362]\tvalidation_0-mlogloss:0.02695\tvalidation_1-mlogloss:0.37884\n",
            "[363]\tvalidation_0-mlogloss:0.02680\tvalidation_1-mlogloss:0.37897\n",
            "[364]\tvalidation_0-mlogloss:0.02664\tvalidation_1-mlogloss:0.37916\n",
            "[365]\tvalidation_0-mlogloss:0.02642\tvalidation_1-mlogloss:0.37912\n",
            "[366]\tvalidation_0-mlogloss:0.02622\tvalidation_1-mlogloss:0.37900\n",
            "[367]\tvalidation_0-mlogloss:0.02613\tvalidation_1-mlogloss:0.37920\n",
            "[368]\tvalidation_0-mlogloss:0.02600\tvalidation_1-mlogloss:0.37941\n",
            "[369]\tvalidation_0-mlogloss:0.02576\tvalidation_1-mlogloss:0.37873\n",
            "[370]\tvalidation_0-mlogloss:0.02560\tvalidation_1-mlogloss:0.37885\n",
            "[371]\tvalidation_0-mlogloss:0.02548\tvalidation_1-mlogloss:0.37914\n",
            "[372]\tvalidation_0-mlogloss:0.02529\tvalidation_1-mlogloss:0.37931\n",
            "[373]\tvalidation_0-mlogloss:0.02512\tvalidation_1-mlogloss:0.37947\n",
            "[374]\tvalidation_0-mlogloss:0.02499\tvalidation_1-mlogloss:0.37958\n",
            "[375]\tvalidation_0-mlogloss:0.02478\tvalidation_1-mlogloss:0.37937\n",
            "[376]\tvalidation_0-mlogloss:0.02463\tvalidation_1-mlogloss:0.37964\n",
            "[377]\tvalidation_0-mlogloss:0.02446\tvalidation_1-mlogloss:0.37996\n",
            "[378]\tvalidation_0-mlogloss:0.02429\tvalidation_1-mlogloss:0.38023\n",
            "[379]\tvalidation_0-mlogloss:0.02419\tvalidation_1-mlogloss:0.38030\n",
            "[380]\tvalidation_0-mlogloss:0.02399\tvalidation_1-mlogloss:0.38069\n",
            "[381]\tvalidation_0-mlogloss:0.02381\tvalidation_1-mlogloss:0.38093\n",
            "[382]\tvalidation_0-mlogloss:0.02368\tvalidation_1-mlogloss:0.38134\n",
            "[383]\tvalidation_0-mlogloss:0.02353\tvalidation_1-mlogloss:0.38130\n",
            "[384]\tvalidation_0-mlogloss:0.02342\tvalidation_1-mlogloss:0.38130\n",
            "[385]\tvalidation_0-mlogloss:0.02325\tvalidation_1-mlogloss:0.38100\n",
            "[386]\tvalidation_0-mlogloss:0.02310\tvalidation_1-mlogloss:0.38154\n",
            "[387]\tvalidation_0-mlogloss:0.02296\tvalidation_1-mlogloss:0.38176\n",
            "[388]\tvalidation_0-mlogloss:0.02282\tvalidation_1-mlogloss:0.38134\n",
            "[389]\tvalidation_0-mlogloss:0.02263\tvalidation_1-mlogloss:0.38120\n",
            "[390]\tvalidation_0-mlogloss:0.02246\tvalidation_1-mlogloss:0.38089\n",
            "[391]\tvalidation_0-mlogloss:0.02232\tvalidation_1-mlogloss:0.38076\n",
            "[392]\tvalidation_0-mlogloss:0.02211\tvalidation_1-mlogloss:0.38059\n",
            "[393]\tvalidation_0-mlogloss:0.02194\tvalidation_1-mlogloss:0.38036\n",
            "[394]\tvalidation_0-mlogloss:0.02178\tvalidation_1-mlogloss:0.37997\n",
            "[395]\tvalidation_0-mlogloss:0.02160\tvalidation_1-mlogloss:0.37955\n",
            "[396]\tvalidation_0-mlogloss:0.02144\tvalidation_1-mlogloss:0.37937\n",
            "[397]\tvalidation_0-mlogloss:0.02124\tvalidation_1-mlogloss:0.37909\n",
            "[398]\tvalidation_0-mlogloss:0.02112\tvalidation_1-mlogloss:0.37896\n",
            "[399]\tvalidation_0-mlogloss:0.02098\tvalidation_1-mlogloss:0.37906\n",
            "[400]\tvalidation_0-mlogloss:0.02084\tvalidation_1-mlogloss:0.37903\n",
            "[401]\tvalidation_0-mlogloss:0.02070\tvalidation_1-mlogloss:0.37926\n",
            "[402]\tvalidation_0-mlogloss:0.02058\tvalidation_1-mlogloss:0.37917\n",
            "[403]\tvalidation_0-mlogloss:0.02045\tvalidation_1-mlogloss:0.37941\n",
            "[404]\tvalidation_0-mlogloss:0.02034\tvalidation_1-mlogloss:0.37938\n",
            "[405]\tvalidation_0-mlogloss:0.02019\tvalidation_1-mlogloss:0.37961\n",
            "[406]\tvalidation_0-mlogloss:0.02005\tvalidation_1-mlogloss:0.37975\n",
            "[407]\tvalidation_0-mlogloss:0.01991\tvalidation_1-mlogloss:0.37957\n",
            "[408]\tvalidation_0-mlogloss:0.01977\tvalidation_1-mlogloss:0.37971\n",
            "[409]\tvalidation_0-mlogloss:0.01963\tvalidation_1-mlogloss:0.37958\n",
            "[410]\tvalidation_0-mlogloss:0.01951\tvalidation_1-mlogloss:0.37977\n",
            "[411]\tvalidation_0-mlogloss:0.01943\tvalidation_1-mlogloss:0.37965\n",
            "[412]\tvalidation_0-mlogloss:0.01931\tvalidation_1-mlogloss:0.37954\n",
            "[413]\tvalidation_0-mlogloss:0.01918\tvalidation_1-mlogloss:0.37941\n",
            "[414]\tvalidation_0-mlogloss:0.01904\tvalidation_1-mlogloss:0.37923\n",
            "[415]\tvalidation_0-mlogloss:0.01894\tvalidation_1-mlogloss:0.37927\n",
            "[416]\tvalidation_0-mlogloss:0.01885\tvalidation_1-mlogloss:0.37893\n",
            "[417]\tvalidation_0-mlogloss:0.01875\tvalidation_1-mlogloss:0.37920\n",
            "[418]\tvalidation_0-mlogloss:0.01860\tvalidation_1-mlogloss:0.37923\n",
            "[419]\tvalidation_0-mlogloss:0.01853\tvalidation_1-mlogloss:0.37932\n",
            "[420]\tvalidation_0-mlogloss:0.01839\tvalidation_1-mlogloss:0.37937\n",
            "[421]\tvalidation_0-mlogloss:0.01826\tvalidation_1-mlogloss:0.37947\n",
            "[422]\tvalidation_0-mlogloss:0.01814\tvalidation_1-mlogloss:0.37938\n",
            "[423]\tvalidation_0-mlogloss:0.01802\tvalidation_1-mlogloss:0.37927\n",
            "[424]\tvalidation_0-mlogloss:0.01793\tvalidation_1-mlogloss:0.37933\n",
            "[425]\tvalidation_0-mlogloss:0.01781\tvalidation_1-mlogloss:0.37977\n",
            "[426]\tvalidation_0-mlogloss:0.01768\tvalidation_1-mlogloss:0.37952\n",
            "[427]\tvalidation_0-mlogloss:0.01756\tvalidation_1-mlogloss:0.37927\n",
            "[428]\tvalidation_0-mlogloss:0.01744\tvalidation_1-mlogloss:0.37889\n",
            "[429]\tvalidation_0-mlogloss:0.01734\tvalidation_1-mlogloss:0.37861\n",
            "[430]\tvalidation_0-mlogloss:0.01725\tvalidation_1-mlogloss:0.37867\n",
            "[431]\tvalidation_0-mlogloss:0.01715\tvalidation_1-mlogloss:0.37836\n",
            "[432]\tvalidation_0-mlogloss:0.01707\tvalidation_1-mlogloss:0.37854\n",
            "[433]\tvalidation_0-mlogloss:0.01699\tvalidation_1-mlogloss:0.37859\n",
            "[434]\tvalidation_0-mlogloss:0.01689\tvalidation_1-mlogloss:0.37841\n",
            "[435]\tvalidation_0-mlogloss:0.01678\tvalidation_1-mlogloss:0.37846\n",
            "[436]\tvalidation_0-mlogloss:0.01664\tvalidation_1-mlogloss:0.37821\n",
            "[437]\tvalidation_0-mlogloss:0.01651\tvalidation_1-mlogloss:0.37786\n",
            "[438]\tvalidation_0-mlogloss:0.01640\tvalidation_1-mlogloss:0.37802\n",
            "[439]\tvalidation_0-mlogloss:0.01634\tvalidation_1-mlogloss:0.37804\n",
            "[440]\tvalidation_0-mlogloss:0.01626\tvalidation_1-mlogloss:0.37833\n",
            "[441]\tvalidation_0-mlogloss:0.01618\tvalidation_1-mlogloss:0.37828\n",
            "[442]\tvalidation_0-mlogloss:0.01605\tvalidation_1-mlogloss:0.37781\n",
            "[443]\tvalidation_0-mlogloss:0.01594\tvalidation_1-mlogloss:0.37801\n",
            "[444]\tvalidation_0-mlogloss:0.01583\tvalidation_1-mlogloss:0.37812\n",
            "[445]\tvalidation_0-mlogloss:0.01574\tvalidation_1-mlogloss:0.37820\n",
            "[446]\tvalidation_0-mlogloss:0.01563\tvalidation_1-mlogloss:0.37793\n",
            "[447]\tvalidation_0-mlogloss:0.01554\tvalidation_1-mlogloss:0.37789\n",
            "[448]\tvalidation_0-mlogloss:0.01545\tvalidation_1-mlogloss:0.37793\n",
            "[449]\tvalidation_0-mlogloss:0.01536\tvalidation_1-mlogloss:0.37780\n",
            "[450]\tvalidation_0-mlogloss:0.01527\tvalidation_1-mlogloss:0.37806\n",
            "[451]\tvalidation_0-mlogloss:0.01518\tvalidation_1-mlogloss:0.37818\n",
            "[452]\tvalidation_0-mlogloss:0.01509\tvalidation_1-mlogloss:0.37812\n",
            "[453]\tvalidation_0-mlogloss:0.01500\tvalidation_1-mlogloss:0.37797\n",
            "[454]\tvalidation_0-mlogloss:0.01490\tvalidation_1-mlogloss:0.37799\n",
            "[455]\tvalidation_0-mlogloss:0.01482\tvalidation_1-mlogloss:0.37819\n",
            "[456]\tvalidation_0-mlogloss:0.01474\tvalidation_1-mlogloss:0.37809\n",
            "[457]\tvalidation_0-mlogloss:0.01464\tvalidation_1-mlogloss:0.37769\n",
            "[458]\tvalidation_0-mlogloss:0.01454\tvalidation_1-mlogloss:0.37746\n",
            "[459]\tvalidation_0-mlogloss:0.01449\tvalidation_1-mlogloss:0.37729\n",
            "[460]\tvalidation_0-mlogloss:0.01440\tvalidation_1-mlogloss:0.37745\n",
            "[461]\tvalidation_0-mlogloss:0.01434\tvalidation_1-mlogloss:0.37790\n",
            "[462]\tvalidation_0-mlogloss:0.01424\tvalidation_1-mlogloss:0.37774\n",
            "[463]\tvalidation_0-mlogloss:0.01415\tvalidation_1-mlogloss:0.37757\n",
            "[464]\tvalidation_0-mlogloss:0.01403\tvalidation_1-mlogloss:0.37742\n",
            "[465]\tvalidation_0-mlogloss:0.01394\tvalidation_1-mlogloss:0.37764\n",
            "[466]\tvalidation_0-mlogloss:0.01385\tvalidation_1-mlogloss:0.37755\n",
            "[467]\tvalidation_0-mlogloss:0.01378\tvalidation_1-mlogloss:0.37744\n",
            "[468]\tvalidation_0-mlogloss:0.01371\tvalidation_1-mlogloss:0.37729\n",
            "[469]\tvalidation_0-mlogloss:0.01361\tvalidation_1-mlogloss:0.37720\n",
            "[470]\tvalidation_0-mlogloss:0.01354\tvalidation_1-mlogloss:0.37734\n",
            "[471]\tvalidation_0-mlogloss:0.01347\tvalidation_1-mlogloss:0.37733\n",
            "[472]\tvalidation_0-mlogloss:0.01339\tvalidation_1-mlogloss:0.37726\n",
            "[473]\tvalidation_0-mlogloss:0.01334\tvalidation_1-mlogloss:0.37719\n",
            "[474]\tvalidation_0-mlogloss:0.01323\tvalidation_1-mlogloss:0.37700\n",
            "[475]\tvalidation_0-mlogloss:0.01317\tvalidation_1-mlogloss:0.37720\n",
            "[476]\tvalidation_0-mlogloss:0.01309\tvalidation_1-mlogloss:0.37667\n",
            "[477]\tvalidation_0-mlogloss:0.01301\tvalidation_1-mlogloss:0.37683\n",
            "[478]\tvalidation_0-mlogloss:0.01292\tvalidation_1-mlogloss:0.37707\n",
            "[479]\tvalidation_0-mlogloss:0.01285\tvalidation_1-mlogloss:0.37703\n",
            "[480]\tvalidation_0-mlogloss:0.01276\tvalidation_1-mlogloss:0.37688\n",
            "[481]\tvalidation_0-mlogloss:0.01268\tvalidation_1-mlogloss:0.37691\n",
            "[482]\tvalidation_0-mlogloss:0.01261\tvalidation_1-mlogloss:0.37686\n",
            "[483]\tvalidation_0-mlogloss:0.01256\tvalidation_1-mlogloss:0.37700\n",
            "[484]\tvalidation_0-mlogloss:0.01248\tvalidation_1-mlogloss:0.37665\n",
            "[485]\tvalidation_0-mlogloss:0.01238\tvalidation_1-mlogloss:0.37668\n",
            "[486]\tvalidation_0-mlogloss:0.01229\tvalidation_1-mlogloss:0.37681\n",
            "[487]\tvalidation_0-mlogloss:0.01223\tvalidation_1-mlogloss:0.37702\n",
            "[488]\tvalidation_0-mlogloss:0.01217\tvalidation_1-mlogloss:0.37702\n",
            "[489]\tvalidation_0-mlogloss:0.01211\tvalidation_1-mlogloss:0.37720\n",
            "[490]\tvalidation_0-mlogloss:0.01206\tvalidation_1-mlogloss:0.37743\n",
            "[491]\tvalidation_0-mlogloss:0.01201\tvalidation_1-mlogloss:0.37747\n",
            "[492]\tvalidation_0-mlogloss:0.01195\tvalidation_1-mlogloss:0.37757\n",
            "[493]\tvalidation_0-mlogloss:0.01190\tvalidation_1-mlogloss:0.37765\n",
            "[494]\tvalidation_0-mlogloss:0.01186\tvalidation_1-mlogloss:0.37772\n",
            "[495]\tvalidation_0-mlogloss:0.01180\tvalidation_1-mlogloss:0.37769\n",
            "[496]\tvalidation_0-mlogloss:0.01174\tvalidation_1-mlogloss:0.37787\n",
            "[497]\tvalidation_0-mlogloss:0.01170\tvalidation_1-mlogloss:0.37774\n",
            "[498]\tvalidation_0-mlogloss:0.01165\tvalidation_1-mlogloss:0.37760\n",
            "[499]\tvalidation_0-mlogloss:0.01159\tvalidation_1-mlogloss:0.37754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
              "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
              "              early_stopping_rounds=None, enable_categorical=True,\n",
              "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
              "              importance_type=None, interaction_constraints='',\n",
              "              learning_rate=0.3, max_bin=256, max_cat_to_one_hot=20,\n",
              "              max_cat_to_onehot=4, max_delta_step=0, max_depth=5, max_leaves=0,\n",
              "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
              "              n_estimators=500, n_jobs=0, num_parallel_tree=1,\n",
              "              objective='multi:softprob', predictor='auto', random_state=0, ...)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict(x_val)\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy:',accuracy_score(y_val, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhqEuLAdVTK5",
        "outputId": "ade900f9-0bb9-46ae-bed9-b3d9a4910f97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9260295881647341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = clf.predict(test.drop(columns = ['Poker Hand']))\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('Accuracy:',accuracy_score(test['Poker Hand'], predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRoncyD4VW2p",
        "outputId": "95030cb2-2b2f-44ea-b407-5499abd98a7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.929466\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = pd.DataFrame()\n",
        "feature_importances[\"feature\"] = features\n",
        "feature_importances[\"importance\"] = x.feature_importances_"
      ],
      "metadata": {
        "id": "i7NPOTyhhuuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances.sort_values(\n",
        "    by = \"importance\", \n",
        "    ascending = True, \n",
        "    inplace = True\n",
        ")\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.barh(feature_importances[\"feature\"], feature_importances[\"importance\"])\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "QlJpWDDniR9f",
        "outputId": "74b3e0a7-26ee-42eb-8228-4d945b053797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test tham số TabNet"
      ],
      "metadata": {
        "id": "mAyfSol1x_wT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##N_d lớn"
      ],
      "metadata": {
        "id": "ZzfnZGYNyEIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    n_d=512, n_a=16, n_steps=4,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=[3,12,3,12,3,12,3,12,3,12],\n",
        "    gamma=1.5, n_ind=2, n_shared=2,\n",
        "    lambda_sparse=1e-6, momentum=0.05, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 80},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181949a0-d2be-4fe7-d2d4-1c8aba931a30",
        "id": "4W4q2HJeyV5x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name = ['train', 'val'],\n",
        "    max_epochs=800, patience=100,\n",
        "    batch_size=4096, vbs=1024 #, augmentations=aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oPHyoa6EvVg",
        "outputId": "2a94268f-851d-4c65-cfd3-78f72910e945"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 5.04429 | train_accuracy: 0.44942 | val_accuracy: 0.44302 |  0:00:01s\n",
            "epoch 1  | loss: 2.29237 | train_accuracy: 0.47212 | val_accuracy: 0.45062 |  0:00:02s\n",
            "epoch 2  | loss: 1.88303 | train_accuracy: 0.4675  | val_accuracy: 0.46421 |  0:00:03s\n",
            "epoch 3  | loss: 1.73831 | train_accuracy: 0.48025 | val_accuracy: 0.4882  |  0:00:03s\n",
            "epoch 4  | loss: 1.57719 | train_accuracy: 0.46381 | val_accuracy: 0.44702 |  0:00:05s\n",
            "epoch 5  | loss: 1.45227 | train_accuracy: 0.47114 | val_accuracy: 0.45942 |  0:00:05s\n",
            "epoch 6  | loss: 1.41251 | train_accuracy: 0.47785 | val_accuracy: 0.45622 |  0:00:06s\n",
            "epoch 7  | loss: 1.34491 | train_accuracy: 0.47763 | val_accuracy: 0.47341 |  0:00:07s\n",
            "epoch 8  | loss: 1.28263 | train_accuracy: 0.48701 | val_accuracy: 0.47341 |  0:00:08s\n",
            "epoch 9  | loss: 1.26255 | train_accuracy: 0.46133 | val_accuracy: 0.43782 |  0:00:09s\n",
            "epoch 10 | loss: 1.24574 | train_accuracy: 0.47994 | val_accuracy: 0.46661 |  0:00:10s\n",
            "epoch 11 | loss: 1.15139 | train_accuracy: 0.50949 | val_accuracy: 0.509   |  0:00:11s\n",
            "epoch 12 | loss: 1.1568  | train_accuracy: 0.51317 | val_accuracy: 0.505   |  0:00:12s\n",
            "epoch 13 | loss: 1.08509 | train_accuracy: 0.51504 | val_accuracy: 0.5058  |  0:00:13s\n",
            "epoch 14 | loss: 1.05549 | train_accuracy: 0.49216 | val_accuracy: 0.44142 |  0:00:14s\n",
            "epoch 15 | loss: 1.06226 | train_accuracy: 0.48478 | val_accuracy: 0.43303 |  0:00:15s\n",
            "epoch 16 | loss: 1.02394 | train_accuracy: 0.52792 | val_accuracy: 0.47541 |  0:00:16s\n",
            "epoch 17 | loss: 0.99641 | train_accuracy: 0.52997 | val_accuracy: 0.48341 |  0:00:17s\n",
            "epoch 18 | loss: 0.9839  | train_accuracy: 0.51957 | val_accuracy: 0.46421 |  0:00:18s\n",
            "epoch 19 | loss: 0.97272 | train_accuracy: 0.54023 | val_accuracy: 0.4946  |  0:00:19s\n",
            "epoch 20 | loss: 0.96481 | train_accuracy: 0.54423 | val_accuracy: 0.4918  |  0:00:20s\n",
            "epoch 21 | loss: 0.96321 | train_accuracy: 0.54636 | val_accuracy: 0.495   |  0:00:21s\n",
            "epoch 22 | loss: 0.97201 | train_accuracy: 0.54245 | val_accuracy: 0.495   |  0:00:22s\n",
            "epoch 23 | loss: 0.97837 | train_accuracy: 0.51984 | val_accuracy: 0.46701 |  0:00:23s\n",
            "epoch 24 | loss: 0.98137 | train_accuracy: 0.54911 | val_accuracy: 0.48181 |  0:00:24s\n",
            "epoch 25 | loss: 0.95485 | train_accuracy: 0.54978 | val_accuracy: 0.5094  |  0:00:25s\n",
            "epoch 26 | loss: 0.94785 | train_accuracy: 0.54725 | val_accuracy: 0.47861 |  0:00:26s\n",
            "epoch 27 | loss: 0.94555 | train_accuracy: 0.5468  | val_accuracy: 0.46661 |  0:00:27s\n",
            "epoch 28 | loss: 0.93919 | train_accuracy: 0.55302 | val_accuracy: 0.51659 |  0:00:28s\n",
            "epoch 29 | loss: 0.93679 | train_accuracy: 0.55751 | val_accuracy: 0.48461 |  0:00:29s\n",
            "epoch 30 | loss: 0.92985 | train_accuracy: 0.56933 | val_accuracy: 0.48381 |  0:00:30s\n",
            "epoch 31 | loss: 0.92054 | train_accuracy: 0.56911 | val_accuracy: 0.5018  |  0:00:31s\n",
            "epoch 32 | loss: 0.90901 | train_accuracy: 0.56933 | val_accuracy: 0.5062  |  0:00:32s\n",
            "epoch 33 | loss: 0.91675 | train_accuracy: 0.5672  | val_accuracy: 0.48661 |  0:00:33s\n",
            "epoch 34 | loss: 0.90693 | train_accuracy: 0.57288 | val_accuracy: 0.4918  |  0:00:34s\n",
            "epoch 35 | loss: 0.91171 | train_accuracy: 0.57364 | val_accuracy: 0.5062  |  0:00:35s\n",
            "epoch 36 | loss: 0.90999 | train_accuracy: 0.57533 | val_accuracy: 0.5038  |  0:00:36s\n",
            "epoch 37 | loss: 0.90523 | train_accuracy: 0.57812 | val_accuracy: 0.5118  |  0:00:37s\n",
            "epoch 38 | loss: 0.90494 | train_accuracy: 0.57448 | val_accuracy: 0.51539 |  0:00:38s\n",
            "epoch 39 | loss: 0.90395 | train_accuracy: 0.57835 | val_accuracy: 0.5006  |  0:00:39s\n",
            "epoch 40 | loss: 0.90348 | train_accuracy: 0.57368 | val_accuracy: 0.51339 |  0:00:40s\n",
            "epoch 41 | loss: 0.90361 | train_accuracy: 0.57866 | val_accuracy: 0.48221 |  0:00:41s\n",
            "epoch 42 | loss: 0.89711 | train_accuracy: 0.5851  | val_accuracy: 0.5058  |  0:00:42s\n",
            "epoch 43 | loss: 0.8906  | train_accuracy: 0.58443 | val_accuracy: 0.48141 |  0:00:43s\n",
            "epoch 44 | loss: 0.88095 | train_accuracy: 0.59096 | val_accuracy: 0.4926  |  0:00:44s\n",
            "epoch 45 | loss: 0.87309 | train_accuracy: 0.59643 | val_accuracy: 0.503   |  0:00:45s\n",
            "epoch 46 | loss: 0.87361 | train_accuracy: 0.58719 | val_accuracy: 0.5038  |  0:00:46s\n",
            "epoch 47 | loss: 0.88059 | train_accuracy: 0.59714 | val_accuracy: 0.4902  |  0:00:47s\n",
            "epoch 48 | loss: 0.88361 | train_accuracy: 0.59167 | val_accuracy: 0.495   |  0:00:48s\n",
            "epoch 49 | loss: 0.87993 | train_accuracy: 0.59665 | val_accuracy: 0.4914  |  0:00:49s\n",
            "epoch 50 | loss: 0.87191 | train_accuracy: 0.5951  | val_accuracy: 0.48341 |  0:00:50s\n",
            "epoch 51 | loss: 0.86684 | train_accuracy: 0.60056 | val_accuracy: 0.4926  |  0:00:51s\n",
            "epoch 52 | loss: 0.85993 | train_accuracy: 0.60753 | val_accuracy: 0.493   |  0:00:52s\n",
            "epoch 53 | loss: 0.85681 | train_accuracy: 0.60798 | val_accuracy: 0.51299 |  0:00:53s\n",
            "epoch 54 | loss: 0.85191 | train_accuracy: 0.60549 | val_accuracy: 0.5006  |  0:00:54s\n",
            "epoch 55 | loss: 0.85036 | train_accuracy: 0.60634 | val_accuracy: 0.4962  |  0:00:55s\n",
            "epoch 56 | loss: 0.84528 | train_accuracy: 0.6166  | val_accuracy: 0.51339 |  0:00:56s\n",
            "epoch 57 | loss: 0.83681 | train_accuracy: 0.61669 | val_accuracy: 0.51539 |  0:00:57s\n",
            "epoch 58 | loss: 0.84512 | train_accuracy: 0.60785 | val_accuracy: 0.48701 |  0:00:58s\n",
            "epoch 59 | loss: 0.84164 | train_accuracy: 0.62193 | val_accuracy: 0.51899 |  0:00:59s\n",
            "epoch 60 | loss: 0.83642 | train_accuracy: 0.62588 | val_accuracy: 0.4974  |  0:01:00s\n",
            "epoch 61 | loss: 0.82987 | train_accuracy: 0.62055 | val_accuracy: 0.5078  |  0:01:01s\n",
            "epoch 62 | loss: 0.83841 | train_accuracy: 0.62597 | val_accuracy: 0.5102  |  0:01:02s\n",
            "epoch 63 | loss: 0.83366 | train_accuracy: 0.62388 | val_accuracy: 0.5062  |  0:01:03s\n",
            "epoch 64 | loss: 0.82553 | train_accuracy: 0.63059 | val_accuracy: 0.5066  |  0:01:04s\n",
            "epoch 65 | loss: 0.81433 | train_accuracy: 0.63419 | val_accuracy: 0.52579 |  0:01:05s\n",
            "epoch 66 | loss: 0.81395 | train_accuracy: 0.63943 | val_accuracy: 0.52419 |  0:01:06s\n",
            "epoch 67 | loss: 0.80629 | train_accuracy: 0.63921 | val_accuracy: 0.52099 |  0:01:07s\n",
            "epoch 68 | loss: 0.79737 | train_accuracy: 0.64099 | val_accuracy: 0.52579 |  0:01:08s\n",
            "epoch 69 | loss: 0.78965 | train_accuracy: 0.64028 | val_accuracy: 0.51539 |  0:01:09s\n",
            "epoch 70 | loss: 0.79871 | train_accuracy: 0.63921 | val_accuracy: 0.51819 |  0:01:10s\n",
            "epoch 71 | loss: 0.80042 | train_accuracy: 0.63832 | val_accuracy: 0.51899 |  0:01:11s\n",
            "epoch 72 | loss: 0.80728 | train_accuracy: 0.6389  | val_accuracy: 0.5062  |  0:01:12s\n",
            "epoch 73 | loss: 0.79738 | train_accuracy: 0.6457  | val_accuracy: 0.51299 |  0:01:13s\n",
            "epoch 74 | loss: 0.78508 | train_accuracy: 0.65249 | val_accuracy: 0.5066  |  0:01:14s\n",
            "epoch 75 | loss: 0.78054 | train_accuracy: 0.65321 | val_accuracy: 0.51459 |  0:01:15s\n",
            "epoch 76 | loss: 0.77942 | train_accuracy: 0.65267 | val_accuracy: 0.5062  |  0:01:16s\n",
            "epoch 77 | loss: 0.78411 | train_accuracy: 0.64419 | val_accuracy: 0.51539 |  0:01:17s\n",
            "epoch 78 | loss: 0.78945 | train_accuracy: 0.64659 | val_accuracy: 0.5114  |  0:01:18s\n",
            "epoch 79 | loss: 0.78625 | train_accuracy: 0.63917 | val_accuracy: 0.505   |  0:01:19s\n",
            "epoch 80 | loss: 0.79858 | train_accuracy: 0.64259 | val_accuracy: 0.5102  |  0:01:20s\n",
            "epoch 81 | loss: 0.79913 | train_accuracy: 0.64676 | val_accuracy: 0.5002  |  0:01:21s\n",
            "epoch 82 | loss: 0.78393 | train_accuracy: 0.64263 | val_accuracy: 0.489   |  0:01:21s\n",
            "epoch 83 | loss: 0.78459 | train_accuracy: 0.64725 | val_accuracy: 0.489   |  0:01:23s\n",
            "epoch 84 | loss: 0.78473 | train_accuracy: 0.64014 | val_accuracy: 0.4906  |  0:01:23s\n",
            "epoch 85 | loss: 0.79221 | train_accuracy: 0.64792 | val_accuracy: 0.507   |  0:01:24s\n",
            "epoch 86 | loss: 0.79126 | train_accuracy: 0.64636 | val_accuracy: 0.493   |  0:01:25s\n",
            "epoch 87 | loss: 0.78413 | train_accuracy: 0.65325 | val_accuracy: 0.511   |  0:01:26s\n",
            "epoch 88 | loss: 0.77853 | train_accuracy: 0.64219 | val_accuracy: 0.4934  |  0:01:27s\n",
            "epoch 89 | loss: 0.78078 | train_accuracy: 0.64925 | val_accuracy: 0.51499 |  0:01:28s\n",
            "epoch 90 | loss: 0.77486 | train_accuracy: 0.64974 | val_accuracy: 0.4902  |  0:01:29s\n",
            "epoch 91 | loss: 0.77356 | train_accuracy: 0.64961 | val_accuracy: 0.5022  |  0:01:30s\n",
            "epoch 92 | loss: 0.7681  | train_accuracy: 0.65867 | val_accuracy: 0.5022  |  0:01:31s\n",
            "epoch 93 | loss: 0.76344 | train_accuracy: 0.66227 | val_accuracy: 0.511   |  0:01:32s\n",
            "epoch 94 | loss: 0.75462 | train_accuracy: 0.66813 | val_accuracy: 0.509   |  0:01:33s\n",
            "epoch 95 | loss: 0.74105 | train_accuracy: 0.67027 | val_accuracy: 0.5014  |  0:01:34s\n",
            "epoch 96 | loss: 0.73074 | train_accuracy: 0.68026 | val_accuracy: 0.5102  |  0:01:35s\n",
            "epoch 97 | loss: 0.72729 | train_accuracy: 0.68315 | val_accuracy: 0.51579 |  0:01:36s\n",
            "epoch 98 | loss: 0.7213  | train_accuracy: 0.68639 | val_accuracy: 0.5098  |  0:01:37s\n",
            "epoch 99 | loss: 0.72515 | train_accuracy: 0.68026 | val_accuracy: 0.505   |  0:01:38s\n",
            "epoch 100| loss: 0.72598 | train_accuracy: 0.6744  | val_accuracy: 0.51979 |  0:01:39s\n",
            "epoch 101| loss: 0.73288 | train_accuracy: 0.68355 | val_accuracy: 0.4966  |  0:01:40s\n",
            "epoch 102| loss: 0.71977 | train_accuracy: 0.6927  | val_accuracy: 0.5018  |  0:01:41s\n",
            "epoch 103| loss: 0.7054  | train_accuracy: 0.68484 | val_accuracy: 0.51459 |  0:01:42s\n",
            "epoch 104| loss: 0.70809 | train_accuracy: 0.68733 | val_accuracy: 0.48621 |  0:01:43s\n",
            "epoch 105| loss: 0.71412 | train_accuracy: 0.68177 | val_accuracy: 0.51459 |  0:01:44s\n",
            "epoch 106| loss: 0.71809 | train_accuracy: 0.68066 | val_accuracy: 0.489   |  0:01:45s\n",
            "epoch 107| loss: 0.71933 | train_accuracy: 0.69079 | val_accuracy: 0.4974  |  0:01:46s\n",
            "epoch 108| loss: 0.7024  | train_accuracy: 0.70438 | val_accuracy: 0.51539 |  0:01:47s\n",
            "epoch 109| loss: 0.6993  | train_accuracy: 0.69919 | val_accuracy: 0.511   |  0:01:48s\n",
            "epoch 110| loss: 0.69659 | train_accuracy: 0.69652 | val_accuracy: 0.5102  |  0:01:49s\n",
            "epoch 111| loss: 0.69288 | train_accuracy: 0.69839 | val_accuracy: 0.4934  |  0:01:50s\n",
            "epoch 112| loss: 0.69284 | train_accuracy: 0.70434 | val_accuracy: 0.5006  |  0:01:51s\n",
            "epoch 113| loss: 0.68998 | train_accuracy: 0.70003 | val_accuracy: 0.4978  |  0:01:52s\n",
            "epoch 114| loss: 0.6918  | train_accuracy: 0.69781 | val_accuracy: 0.5006  |  0:01:53s\n",
            "epoch 115| loss: 0.69489 | train_accuracy: 0.69372 | val_accuracy: 0.4926  |  0:01:54s\n",
            "epoch 116| loss: 0.70209 | train_accuracy: 0.68888 | val_accuracy: 0.4934  |  0:01:55s\n",
            "epoch 117| loss: 0.71255 | train_accuracy: 0.6931  | val_accuracy: 0.5026  |  0:01:56s\n",
            "epoch 118| loss: 0.7129  | train_accuracy: 0.69808 | val_accuracy: 0.5066  |  0:01:57s\n",
            "epoch 119| loss: 0.7098  | train_accuracy: 0.69261 | val_accuracy: 0.5102  |  0:01:58s\n",
            "epoch 120| loss: 0.70345 | train_accuracy: 0.69137 | val_accuracy: 0.48341 |  0:01:59s\n",
            "epoch 121| loss: 0.68928 | train_accuracy: 0.71092 | val_accuracy: 0.5114  |  0:02:00s\n",
            "epoch 122| loss: 0.66799 | train_accuracy: 0.71323 | val_accuracy: 0.5022  |  0:02:01s\n",
            "epoch 123| loss: 0.65721 | train_accuracy: 0.72149 | val_accuracy: 0.5106  |  0:02:02s\n",
            "epoch 124| loss: 0.64854 | train_accuracy: 0.72793 | val_accuracy: 0.51339 |  0:02:03s\n",
            "epoch 125| loss: 0.64355 | train_accuracy: 0.73451 | val_accuracy: 0.5066  |  0:02:04s\n",
            "epoch 126| loss: 0.63533 | train_accuracy: 0.72829 | val_accuracy: 0.51499 |  0:02:05s\n",
            "epoch 127| loss: 0.62661 | train_accuracy: 0.73611 | val_accuracy: 0.5026  |  0:02:06s\n",
            "epoch 128| loss: 0.61977 | train_accuracy: 0.74295 | val_accuracy: 0.503   |  0:02:07s\n",
            "epoch 129| loss: 0.615   | train_accuracy: 0.74259 | val_accuracy: 0.52099 |  0:02:08s\n",
            "epoch 130| loss: 0.60202 | train_accuracy: 0.74477 | val_accuracy: 0.5054  |  0:02:09s\n",
            "epoch 131| loss: 0.6011  | train_accuracy: 0.74695 | val_accuracy: 0.505   |  0:02:10s\n",
            "epoch 132| loss: 0.60724 | train_accuracy: 0.74108 | val_accuracy: 0.5074  |  0:02:11s\n",
            "epoch 133| loss: 0.60564 | train_accuracy: 0.74672 | val_accuracy: 0.493   |  0:02:12s\n",
            "epoch 134| loss: 0.6138  | train_accuracy: 0.7413  | val_accuracy: 0.4934  |  0:02:13s\n",
            "epoch 135| loss: 0.6161  | train_accuracy: 0.74775 | val_accuracy: 0.5058  |  0:02:14s\n",
            "epoch 136| loss: 0.60664 | train_accuracy: 0.7489  | val_accuracy: 0.5082  |  0:02:15s\n",
            "epoch 137| loss: 0.59127 | train_accuracy: 0.75494 | val_accuracy: 0.5038  |  0:02:16s\n",
            "epoch 138| loss: 0.58658 | train_accuracy: 0.76063 | val_accuracy: 0.4922  |  0:02:17s\n",
            "epoch 139| loss: 0.57987 | train_accuracy: 0.76285 | val_accuracy: 0.5014  |  0:02:18s\n",
            "epoch 140| loss: 0.58876 | train_accuracy: 0.74695 | val_accuracy: 0.4998  |  0:02:19s\n",
            "epoch 141| loss: 0.6154  | train_accuracy: 0.75041 | val_accuracy: 0.491   |  0:02:20s\n",
            "epoch 142| loss: 0.6063  | train_accuracy: 0.75023 | val_accuracy: 0.5086  |  0:02:21s\n",
            "epoch 143| loss: 0.60326 | train_accuracy: 0.75308 | val_accuracy: 0.5066  |  0:02:22s\n",
            "epoch 144| loss: 0.59716 | train_accuracy: 0.76001 | val_accuracy: 0.5102  |  0:02:23s\n",
            "epoch 145| loss: 0.58612 | train_accuracy: 0.77227 | val_accuracy: 0.5034  |  0:02:24s\n",
            "epoch 146| loss: 0.56338 | train_accuracy: 0.78084 | val_accuracy: 0.5086  |  0:02:25s\n",
            "epoch 147| loss: 0.5524  | train_accuracy: 0.77498 | val_accuracy: 0.51379 |  0:02:26s\n",
            "epoch 148| loss: 0.5442  | train_accuracy: 0.77884 | val_accuracy: 0.4986  |  0:02:27s\n",
            "epoch 149| loss: 0.54708 | train_accuracy: 0.78631 | val_accuracy: 0.5086  |  0:02:28s\n",
            "epoch 150| loss: 0.54451 | train_accuracy: 0.77667 | val_accuracy: 0.509   |  0:02:29s\n",
            "epoch 151| loss: 0.55616 | train_accuracy: 0.77254 | val_accuracy: 0.5014  |  0:02:30s\n",
            "epoch 152| loss: 0.55818 | train_accuracy: 0.77511 | val_accuracy: 0.5026  |  0:02:31s\n",
            "epoch 153| loss: 0.55664 | train_accuracy: 0.77707 | val_accuracy: 0.52059 |  0:02:32s\n",
            "epoch 154| loss: 0.54883 | train_accuracy: 0.78338 | val_accuracy: 0.503   |  0:02:33s\n",
            "epoch 155| loss: 0.53913 | train_accuracy: 0.79097 | val_accuracy: 0.5002  |  0:02:34s\n",
            "epoch 156| loss: 0.52292 | train_accuracy: 0.79861 | val_accuracy: 0.5058  |  0:02:35s\n",
            "epoch 157| loss: 0.50596 | train_accuracy: 0.80692 | val_accuracy: 0.5078  |  0:02:36s\n",
            "epoch 158| loss: 0.49428 | train_accuracy: 0.81119 | val_accuracy: 0.51259 |  0:02:37s\n",
            "epoch 159| loss: 0.47902 | train_accuracy: 0.81341 | val_accuracy: 0.5054  |  0:02:38s\n",
            "epoch 160| loss: 0.47146 | train_accuracy: 0.81923 | val_accuracy: 0.52019 |  0:02:39s\n",
            "epoch 161| loss: 0.491   | train_accuracy: 0.79733 | val_accuracy: 0.52819 |  0:02:40s\n",
            "epoch 162| loss: 0.53004 | train_accuracy: 0.79604 | val_accuracy: 0.51659 |  0:02:41s\n",
            "epoch 163| loss: 0.51502 | train_accuracy: 0.7963  | val_accuracy: 0.5086  |  0:02:42s\n",
            "epoch 164| loss: 0.52907 | train_accuracy: 0.78382 | val_accuracy: 0.51659 |  0:02:43s\n",
            "epoch 165| loss: 0.53886 | train_accuracy: 0.79195 | val_accuracy: 0.4986  |  0:02:44s\n",
            "epoch 166| loss: 0.51373 | train_accuracy: 0.80208 | val_accuracy: 0.51659 |  0:02:45s\n",
            "epoch 167| loss: 0.49739 | train_accuracy: 0.80879 | val_accuracy: 0.4914  |  0:02:46s\n",
            "epoch 168| loss: 0.47736 | train_accuracy: 0.81758 | val_accuracy: 0.5018  |  0:02:47s\n",
            "epoch 169| loss: 0.46552 | train_accuracy: 0.8234  | val_accuracy: 0.5014  |  0:02:48s\n",
            "epoch 170| loss: 0.47024 | train_accuracy: 0.81074 | val_accuracy: 0.505   |  0:02:49s\n",
            "epoch 171| loss: 0.50741 | train_accuracy: 0.80825 | val_accuracy: 0.511   |  0:02:50s\n",
            "epoch 172| loss: 0.49198 | train_accuracy: 0.81434 | val_accuracy: 0.5078  |  0:02:51s\n",
            "epoch 173| loss: 0.48626 | train_accuracy: 0.80999 | val_accuracy: 0.4982  |  0:02:52s\n",
            "epoch 174| loss: 0.47545 | train_accuracy: 0.81332 | val_accuracy: 0.5022  |  0:02:53s\n",
            "epoch 175| loss: 0.46766 | train_accuracy: 0.82563 | val_accuracy: 0.4978  |  0:02:54s\n",
            "epoch 176| loss: 0.46296 | train_accuracy: 0.82411 | val_accuracy: 0.4882  |  0:02:55s\n",
            "epoch 177| loss: 0.47101 | train_accuracy: 0.81585 | val_accuracy: 0.499   |  0:02:55s\n",
            "epoch 178| loss: 0.47076 | train_accuracy: 0.82327 | val_accuracy: 0.4982  |  0:02:57s\n",
            "epoch 179| loss: 0.45467 | train_accuracy: 0.83447 | val_accuracy: 0.51499 |  0:02:57s\n",
            "epoch 180| loss: 0.44435 | train_accuracy: 0.829   | val_accuracy: 0.5018  |  0:02:58s\n",
            "epoch 181| loss: 0.46466 | train_accuracy: 0.82274 | val_accuracy: 0.5066  |  0:02:59s\n",
            "epoch 182| loss: 0.47348 | train_accuracy: 0.82145 | val_accuracy: 0.5038  |  0:03:00s\n",
            "epoch 183| loss: 0.4697  | train_accuracy: 0.82487 | val_accuracy: 0.4922  |  0:03:01s\n",
            "epoch 184| loss: 0.45533 | train_accuracy: 0.82811 | val_accuracy: 0.4926  |  0:03:02s\n",
            "epoch 185| loss: 0.45484 | train_accuracy: 0.83171 | val_accuracy: 0.509   |  0:03:03s\n",
            "epoch 186| loss: 0.45493 | train_accuracy: 0.82314 | val_accuracy: 0.5026  |  0:03:04s\n",
            "epoch 187| loss: 0.47689 | train_accuracy: 0.81585 | val_accuracy: 0.4906  |  0:03:05s\n",
            "epoch 188| loss: 0.47719 | train_accuracy: 0.82034 | val_accuracy: 0.48661 |  0:03:06s\n",
            "epoch 189| loss: 0.46589 | train_accuracy: 0.82816 | val_accuracy: 0.5078  |  0:03:07s\n",
            "epoch 190| loss: 0.45178 | train_accuracy: 0.84109 | val_accuracy: 0.48261 |  0:03:08s\n",
            "epoch 191| loss: 0.4338  | train_accuracy: 0.84393 | val_accuracy: 0.4994  |  0:03:09s\n",
            "epoch 192| loss: 0.43634 | train_accuracy: 0.84366 | val_accuracy: 0.5074  |  0:03:10s\n",
            "epoch 193| loss: 0.43235 | train_accuracy: 0.8454  | val_accuracy: 0.51379 |  0:03:11s\n",
            "epoch 194| loss: 0.41172 | train_accuracy: 0.85317 | val_accuracy: 0.51979 |  0:03:12s\n",
            "epoch 195| loss: 0.40322 | train_accuracy: 0.86228 | val_accuracy: 0.5106  |  0:03:13s\n",
            "epoch 196| loss: 0.38465 | train_accuracy: 0.87076 | val_accuracy: 0.5058  |  0:03:14s\n",
            "epoch 197| loss: 0.37567 | train_accuracy: 0.87134 | val_accuracy: 0.51419 |  0:03:15s\n",
            "epoch 198| loss: 0.36102 | train_accuracy: 0.88174 | val_accuracy: 0.503   |  0:03:16s\n",
            "epoch 199| loss: 0.34074 | train_accuracy: 0.88338 | val_accuracy: 0.5114  |  0:03:17s\n",
            "epoch 200| loss: 0.34103 | train_accuracy: 0.88231 | val_accuracy: 0.507   |  0:03:18s\n",
            "epoch 201| loss: 0.35283 | train_accuracy: 0.87907 | val_accuracy: 0.52059 |  0:03:19s\n",
            "epoch 202| loss: 0.35438 | train_accuracy: 0.88209 | val_accuracy: 0.51819 |  0:03:20s\n",
            "epoch 203| loss: 0.3364  | train_accuracy: 0.8888  | val_accuracy: 0.5094  |  0:03:21s\n",
            "epoch 204| loss: 0.33532 | train_accuracy: 0.89098 | val_accuracy: 0.5058  |  0:03:22s\n",
            "epoch 205| loss: 0.32459 | train_accuracy: 0.88609 | val_accuracy: 0.5022  |  0:03:24s\n",
            "epoch 206| loss: 0.32453 | train_accuracy: 0.89142 | val_accuracy: 0.51499 |  0:03:25s\n",
            "epoch 207| loss: 0.33511 | train_accuracy: 0.89013 | val_accuracy: 0.5034  |  0:03:26s\n",
            "epoch 208| loss: 0.32199 | train_accuracy: 0.88973 | val_accuracy: 0.5122  |  0:03:27s\n",
            "epoch 209| loss: 0.34882 | train_accuracy: 0.88098 | val_accuracy: 0.5082  |  0:03:28s\n",
            "epoch 210| loss: 0.35007 | train_accuracy: 0.88147 | val_accuracy: 0.5106  |  0:03:29s\n",
            "epoch 211| loss: 0.34834 | train_accuracy: 0.87556 | val_accuracy: 0.5114  |  0:03:30s\n",
            "epoch 212| loss: 0.34913 | train_accuracy: 0.88698 | val_accuracy: 0.5046  |  0:03:31s\n",
            "epoch 213| loss: 0.32699 | train_accuracy: 0.89071 | val_accuracy: 0.51699 |  0:03:32s\n",
            "epoch 214| loss: 0.31524 | train_accuracy: 0.89866 | val_accuracy: 0.51979 |  0:03:33s\n",
            "epoch 215| loss: 0.30665 | train_accuracy: 0.9     | val_accuracy: 0.5122  |  0:03:34s\n",
            "epoch 216| loss: 0.32434 | train_accuracy: 0.8784  | val_accuracy: 0.5022  |  0:03:35s\n",
            "epoch 217| loss: 0.3752  | train_accuracy: 0.8597  | val_accuracy: 0.511   |  0:03:36s\n",
            "epoch 218| loss: 0.40834 | train_accuracy: 0.85775 | val_accuracy: 0.5058  |  0:03:37s\n",
            "epoch 219| loss: 0.39198 | train_accuracy: 0.85903 | val_accuracy: 0.5018  |  0:03:38s\n",
            "epoch 220| loss: 0.37976 | train_accuracy: 0.87805 | val_accuracy: 0.507   |  0:03:39s\n",
            "epoch 221| loss: 0.35407 | train_accuracy: 0.88591 | val_accuracy: 0.5098  |  0:03:40s\n",
            "epoch 222| loss: 0.32857 | train_accuracy: 0.89178 | val_accuracy: 0.52979 |  0:03:41s\n",
            "epoch 223| loss: 0.30486 | train_accuracy: 0.90168 | val_accuracy: 0.5114  |  0:03:42s\n",
            "epoch 224| loss: 0.30233 | train_accuracy: 0.90013 | val_accuracy: 0.5066  |  0:03:43s\n",
            "epoch 225| loss: 0.29986 | train_accuracy: 0.91097 | val_accuracy: 0.52859 |  0:03:44s\n",
            "epoch 226| loss: 0.281   | train_accuracy: 0.91208 | val_accuracy: 0.52739 |  0:03:45s\n",
            "epoch 227| loss: 0.2618  | train_accuracy: 0.92092 | val_accuracy: 0.53299 |  0:03:46s\n",
            "epoch 228| loss: 0.24597 | train_accuracy: 0.92772 | val_accuracy: 0.51779 |  0:03:47s\n",
            "epoch 229| loss: 0.25212 | train_accuracy: 0.92203 | val_accuracy: 0.52019 |  0:03:48s\n",
            "epoch 230| loss: 0.26489 | train_accuracy: 0.92208 | val_accuracy: 0.51659 |  0:03:49s\n",
            "epoch 231| loss: 0.25707 | train_accuracy: 0.9247  | val_accuracy: 0.52579 |  0:03:50s\n",
            "epoch 232| loss: 0.244   | train_accuracy: 0.92239 | val_accuracy: 0.52139 |  0:03:51s\n",
            "epoch 233| loss: 0.23643 | train_accuracy: 0.93318 | val_accuracy: 0.51539 |  0:03:52s\n",
            "epoch 234| loss: 0.24191 | train_accuracy: 0.92767 | val_accuracy: 0.52219 |  0:03:53s\n",
            "epoch 235| loss: 0.23831 | train_accuracy: 0.92936 | val_accuracy: 0.52819 |  0:03:54s\n",
            "epoch 236| loss: 0.23842 | train_accuracy: 0.93345 | val_accuracy: 0.52059 |  0:03:55s\n",
            "epoch 237| loss: 0.22306 | train_accuracy: 0.94198 | val_accuracy: 0.52099 |  0:03:56s\n",
            "epoch 238| loss: 0.21088 | train_accuracy: 0.94322 | val_accuracy: 0.51379 |  0:03:57s\n",
            "epoch 239| loss: 0.20199 | train_accuracy: 0.9486  | val_accuracy: 0.52259 |  0:03:58s\n",
            "epoch 240| loss: 0.1956  | train_accuracy: 0.94998 | val_accuracy: 0.51499 |  0:03:59s\n",
            "epoch 241| loss: 0.18845 | train_accuracy: 0.94971 | val_accuracy: 0.53539 |  0:04:00s\n",
            "epoch 242| loss: 0.18766 | train_accuracy: 0.95202 | val_accuracy: 0.52619 |  0:04:01s\n",
            "epoch 243| loss: 0.18252 | train_accuracy: 0.95153 | val_accuracy: 0.52379 |  0:04:02s\n",
            "epoch 244| loss: 0.18011 | train_accuracy: 0.95393 | val_accuracy: 0.52699 |  0:04:02s\n",
            "epoch 245| loss: 0.17413 | train_accuracy: 0.96028 | val_accuracy: 0.51979 |  0:04:03s\n",
            "epoch 246| loss: 0.15909 | train_accuracy: 0.96264 | val_accuracy: 0.51499 |  0:04:05s\n",
            "epoch 247| loss: 0.15764 | train_accuracy: 0.96495 | val_accuracy: 0.51459 |  0:04:05s\n",
            "epoch 248| loss: 0.15015 | train_accuracy: 0.96308 | val_accuracy: 0.5094  |  0:04:07s\n",
            "epoch 249| loss: 0.1482  | train_accuracy: 0.96903 | val_accuracy: 0.51619 |  0:04:07s\n",
            "epoch 250| loss: 0.13796 | train_accuracy: 0.96708 | val_accuracy: 0.52619 |  0:04:08s\n",
            "epoch 251| loss: 0.14143 | train_accuracy: 0.96006 | val_accuracy: 0.51579 |  0:04:09s\n",
            "epoch 252| loss: 0.17746 | train_accuracy: 0.95971 | val_accuracy: 0.51419 |  0:04:10s\n",
            "epoch 253| loss: 0.17836 | train_accuracy: 0.95584 | val_accuracy: 0.51299 |  0:04:11s\n",
            "epoch 254| loss: 0.17188 | train_accuracy: 0.95535 | val_accuracy: 0.5118  |  0:04:12s\n",
            "epoch 255| loss: 0.16603 | train_accuracy: 0.95833 | val_accuracy: 0.5106  |  0:04:13s\n",
            "epoch 256| loss: 0.16817 | train_accuracy: 0.96055 | val_accuracy: 0.51259 |  0:04:14s\n",
            "epoch 257| loss: 0.15617 | train_accuracy: 0.96406 | val_accuracy: 0.51339 |  0:04:15s\n",
            "epoch 258| loss: 0.14744 | train_accuracy: 0.96477 | val_accuracy: 0.51339 |  0:04:16s\n",
            "epoch 259| loss: 0.15701 | train_accuracy: 0.95917 | val_accuracy: 0.51379 |  0:04:17s\n",
            "epoch 260| loss: 0.16443 | train_accuracy: 0.95984 | val_accuracy: 0.5106  |  0:04:18s\n",
            "epoch 261| loss: 0.16318 | train_accuracy: 0.96108 | val_accuracy: 0.52539 |  0:04:19s\n",
            "epoch 262| loss: 0.15097 | train_accuracy: 0.96468 | val_accuracy: 0.52299 |  0:04:20s\n",
            "epoch 263| loss: 0.15167 | train_accuracy: 0.96433 | val_accuracy: 0.51859 |  0:04:21s\n",
            "epoch 264| loss: 0.15116 | train_accuracy: 0.96504 | val_accuracy: 0.51739 |  0:04:22s\n",
            "epoch 265| loss: 0.13973 | train_accuracy: 0.97228 | val_accuracy: 0.52499 |  0:04:23s\n",
            "epoch 266| loss: 0.12425 | train_accuracy: 0.97521 | val_accuracy: 0.5114  |  0:04:24s\n",
            "epoch 267| loss: 0.12021 | train_accuracy: 0.97574 | val_accuracy: 0.51419 |  0:04:25s\n",
            "epoch 268| loss: 0.12112 | train_accuracy: 0.9745  | val_accuracy: 0.51979 |  0:04:26s\n",
            "epoch 269| loss: 0.12909 | train_accuracy: 0.97286 | val_accuracy: 0.51979 |  0:04:27s\n",
            "epoch 270| loss: 0.1189  | train_accuracy: 0.97694 | val_accuracy: 0.51339 |  0:04:28s\n",
            "epoch 271| loss: 0.11911 | train_accuracy: 0.97237 | val_accuracy: 0.51899 |  0:04:29s\n",
            "epoch 272| loss: 0.14056 | train_accuracy: 0.96766 | val_accuracy: 0.51779 |  0:04:30s\n",
            "epoch 273| loss: 0.13765 | train_accuracy: 0.96601 | val_accuracy: 0.52019 |  0:04:31s\n",
            "epoch 274| loss: 0.14824 | train_accuracy: 0.96624 | val_accuracy: 0.52219 |  0:04:32s\n",
            "epoch 275| loss: 0.13733 | train_accuracy: 0.97272 | val_accuracy: 0.51459 |  0:04:33s\n",
            "epoch 276| loss: 0.12695 | train_accuracy: 0.97041 | val_accuracy: 0.5102  |  0:04:34s\n",
            "epoch 277| loss: 0.13741 | train_accuracy: 0.97326 | val_accuracy: 0.5042  |  0:04:35s\n",
            "epoch 278| loss: 0.12938 | train_accuracy: 0.97605 | val_accuracy: 0.5122  |  0:04:36s\n",
            "epoch 279| loss: 0.11384 | train_accuracy: 0.97823 | val_accuracy: 0.51419 |  0:04:37s\n",
            "epoch 280| loss: 0.10395 | train_accuracy: 0.97979 | val_accuracy: 0.51299 |  0:04:38s\n",
            "epoch 281| loss: 0.09757 | train_accuracy: 0.98396 | val_accuracy: 0.52419 |  0:04:39s\n",
            "epoch 282| loss: 0.09287 | train_accuracy: 0.98489 | val_accuracy: 0.52099 |  0:04:40s\n",
            "epoch 283| loss: 0.08951 | train_accuracy: 0.98245 | val_accuracy: 0.52179 |  0:04:41s\n",
            "epoch 284| loss: 0.09117 | train_accuracy: 0.9813  | val_accuracy: 0.51979 |  0:04:42s\n",
            "epoch 285| loss: 0.11275 | train_accuracy: 0.9781  | val_accuracy: 0.52539 |  0:04:43s\n",
            "epoch 286| loss: 0.0989  | train_accuracy: 0.97943 | val_accuracy: 0.52059 |  0:04:44s\n",
            "epoch 287| loss: 0.09665 | train_accuracy: 0.98223 | val_accuracy: 0.52859 |  0:04:45s\n",
            "epoch 288| loss: 0.09778 | train_accuracy: 0.98001 | val_accuracy: 0.52059 |  0:04:46s\n",
            "epoch 289| loss: 0.1112  | train_accuracy: 0.97397 | val_accuracy: 0.51459 |  0:04:47s\n",
            "epoch 290| loss: 0.1127  | train_accuracy: 0.97561 | val_accuracy: 0.51339 |  0:04:48s\n",
            "epoch 291| loss: 0.11804 | train_accuracy: 0.97934 | val_accuracy: 0.511   |  0:04:49s\n",
            "epoch 292| loss: 0.10252 | train_accuracy: 0.97961 | val_accuracy: 0.51819 |  0:04:50s\n",
            "epoch 293| loss: 0.11274 | train_accuracy: 0.97912 | val_accuracy: 0.52419 |  0:04:51s\n",
            "epoch 294| loss: 0.10498 | train_accuracy: 0.9717  | val_accuracy: 0.52459 |  0:04:52s\n",
            "epoch 295| loss: 0.14003 | train_accuracy: 0.9677  | val_accuracy: 0.5118  |  0:04:53s\n",
            "epoch 296| loss: 0.1324  | train_accuracy: 0.96957 | val_accuracy: 0.52059 |  0:04:54s\n",
            "epoch 297| loss: 0.15649 | train_accuracy: 0.95962 | val_accuracy: 0.51779 |  0:04:55s\n",
            "epoch 298| loss: 0.18113 | train_accuracy: 0.94895 | val_accuracy: 0.51819 |  0:04:56s\n",
            "epoch 299| loss: 0.2131  | train_accuracy: 0.94042 | val_accuracy: 0.51379 |  0:04:57s\n",
            "epoch 300| loss: 0.21806 | train_accuracy: 0.94673 | val_accuracy: 0.51819 |  0:04:58s\n",
            "epoch 301| loss: 0.20674 | train_accuracy: 0.947   | val_accuracy: 0.51819 |  0:04:59s\n",
            "epoch 302| loss: 0.20623 | train_accuracy: 0.9546  | val_accuracy: 0.52539 |  0:05:00s\n",
            "epoch 303| loss: 0.17132 | train_accuracy: 0.95926 | val_accuracy: 0.51299 |  0:05:01s\n",
            "epoch 304| loss: 0.15108 | train_accuracy: 0.96739 | val_accuracy: 0.51739 |  0:05:02s\n",
            "epoch 305| loss: 0.12905 | train_accuracy: 0.97228 | val_accuracy: 0.52219 |  0:05:03s\n",
            "epoch 306| loss: 0.12153 | train_accuracy: 0.9769  | val_accuracy: 0.52699 |  0:05:04s\n",
            "epoch 307| loss: 0.10925 | train_accuracy: 0.9785  | val_accuracy: 0.51339 |  0:05:05s\n",
            "epoch 308| loss: 0.10926 | train_accuracy: 0.97716 | val_accuracy: 0.51819 |  0:05:06s\n",
            "epoch 309| loss: 0.11035 | train_accuracy: 0.98094 | val_accuracy: 0.52859 |  0:05:07s\n",
            "epoch 310| loss: 0.08987 | train_accuracy: 0.98343 | val_accuracy: 0.51379 |  0:05:08s\n",
            "epoch 311| loss: 0.09684 | train_accuracy: 0.98236 | val_accuracy: 0.52419 |  0:05:09s\n",
            "epoch 312| loss: 0.08765 | train_accuracy: 0.98578 | val_accuracy: 0.53619 |  0:05:10s\n",
            "epoch 313| loss: 0.08667 | train_accuracy: 0.98085 | val_accuracy: 0.52259 |  0:05:11s\n",
            "epoch 314| loss: 0.12071 | train_accuracy: 0.96304 | val_accuracy: 0.52019 |  0:05:12s\n",
            "epoch 315| loss: 0.16694 | train_accuracy: 0.96672 | val_accuracy: 0.52779 |  0:05:13s\n",
            "epoch 316| loss: 0.14589 | train_accuracy: 0.9697  | val_accuracy: 0.51619 |  0:05:14s\n",
            "epoch 317| loss: 0.12338 | train_accuracy: 0.97454 | val_accuracy: 0.52059 |  0:05:15s\n",
            "epoch 318| loss: 0.10449 | train_accuracy: 0.97841 | val_accuracy: 0.53019 |  0:05:16s\n",
            "epoch 319| loss: 0.10144 | train_accuracy: 0.98116 | val_accuracy: 0.52099 |  0:05:17s\n",
            "epoch 320| loss: 0.09361 | train_accuracy: 0.98152 | val_accuracy: 0.52459 |  0:05:18s\n",
            "epoch 321| loss: 0.09349 | train_accuracy: 0.98543 | val_accuracy: 0.52619 |  0:05:19s\n",
            "epoch 322| loss: 0.10185 | train_accuracy: 0.97103 | val_accuracy: 0.51499 |  0:05:20s\n",
            "epoch 323| loss: 0.13906 | train_accuracy: 0.97303 | val_accuracy: 0.52859 |  0:05:21s\n",
            "epoch 324| loss: 0.12276 | train_accuracy: 0.97059 | val_accuracy: 0.52259 |  0:05:22s\n",
            "epoch 325| loss: 0.14111 | train_accuracy: 0.9697  | val_accuracy: 0.51499 |  0:05:23s\n",
            "epoch 326| loss: 0.1335  | train_accuracy: 0.97041 | val_accuracy: 0.51299 |  0:05:24s\n",
            "epoch 327| loss: 0.12523 | train_accuracy: 0.97605 | val_accuracy: 0.52299 |  0:05:25s\n",
            "epoch 328| loss: 0.10978 | train_accuracy: 0.97845 | val_accuracy: 0.52739 |  0:05:26s\n",
            "epoch 329| loss: 0.09525 | train_accuracy: 0.98312 | val_accuracy: 0.52299 |  0:05:27s\n",
            "epoch 330| loss: 0.09509 | train_accuracy: 0.98414 | val_accuracy: 0.51659 |  0:05:28s\n",
            "epoch 331| loss: 0.088   | train_accuracy: 0.98681 | val_accuracy: 0.52019 |  0:05:29s\n",
            "epoch 332| loss: 0.08657 | train_accuracy: 0.98587 | val_accuracy: 0.51699 |  0:05:30s\n",
            "epoch 333| loss: 0.08012 | train_accuracy: 0.98578 | val_accuracy: 0.51459 |  0:05:31s\n",
            "epoch 334| loss: 0.08285 | train_accuracy: 0.98596 | val_accuracy: 0.51339 |  0:05:32s\n",
            "epoch 335| loss: 0.08168 | train_accuracy: 0.98858 | val_accuracy: 0.52179 |  0:05:33s\n",
            "epoch 336| loss: 0.06625 | train_accuracy: 0.98956 | val_accuracy: 0.52099 |  0:05:34s\n",
            "epoch 337| loss: 0.06644 | train_accuracy: 0.98956 | val_accuracy: 0.51539 |  0:05:35s\n",
            "epoch 338| loss: 0.06594 | train_accuracy: 0.98965 | val_accuracy: 0.51699 |  0:05:36s\n",
            "epoch 339| loss: 0.05835 | train_accuracy: 0.99227 | val_accuracy: 0.51859 |  0:05:37s\n",
            "epoch 340| loss: 0.0606  | train_accuracy: 0.99209 | val_accuracy: 0.52379 |  0:05:38s\n",
            "epoch 341| loss: 0.054   | train_accuracy: 0.99294 | val_accuracy: 0.5094  |  0:05:39s\n",
            "epoch 342| loss: 0.05214 | train_accuracy: 0.994   | val_accuracy: 0.5086  |  0:05:40s\n",
            "epoch 343| loss: 0.04696 | train_accuracy: 0.99574 | val_accuracy: 0.501   |  0:05:41s\n",
            "epoch 344| loss: 0.04097 | train_accuracy: 0.99551 | val_accuracy: 0.51539 |  0:05:42s\n",
            "epoch 345| loss: 0.04119 | train_accuracy: 0.99587 | val_accuracy: 0.51459 |  0:05:43s\n",
            "epoch 346| loss: 0.03714 | train_accuracy: 0.99591 | val_accuracy: 0.51819 |  0:05:44s\n",
            "epoch 347| loss: 0.04579 | train_accuracy: 0.99156 | val_accuracy: 0.52019 |  0:05:45s\n",
            "epoch 348| loss: 0.06309 | train_accuracy: 0.99076 | val_accuracy: 0.52339 |  0:05:46s\n",
            "epoch 349| loss: 0.05908 | train_accuracy: 0.99049 | val_accuracy: 0.51659 |  0:05:47s\n",
            "epoch 350| loss: 0.06344 | train_accuracy: 0.99103 | val_accuracy: 0.5118  |  0:05:48s\n",
            "epoch 351| loss: 0.05946 | train_accuracy: 0.99018 | val_accuracy: 0.51299 |  0:05:49s\n",
            "epoch 352| loss: 0.05771 | train_accuracy: 0.98925 | val_accuracy: 0.5102  |  0:05:50s\n",
            "epoch 353| loss: 0.058   | train_accuracy: 0.99111 | val_accuracy: 0.52259 |  0:05:50s\n",
            "epoch 354| loss: 0.04995 | train_accuracy: 0.99254 | val_accuracy: 0.52659 |  0:05:52s\n",
            "epoch 355| loss: 0.04728 | train_accuracy: 0.99476 | val_accuracy: 0.51419 |  0:05:52s\n",
            "epoch 356| loss: 0.04281 | train_accuracy: 0.99365 | val_accuracy: 0.5114  |  0:05:54s\n",
            "epoch 357| loss: 0.04242 | train_accuracy: 0.99165 | val_accuracy: 0.51579 |  0:05:54s\n",
            "epoch 358| loss: 0.04934 | train_accuracy: 0.99374 | val_accuracy: 0.5078  |  0:05:55s\n",
            "epoch 359| loss: 0.04223 | train_accuracy: 0.99489 | val_accuracy: 0.5086  |  0:05:56s\n",
            "epoch 360| loss: 0.03994 | train_accuracy: 0.99574 | val_accuracy: 0.5122  |  0:05:57s\n",
            "epoch 361| loss: 0.03584 | train_accuracy: 0.99485 | val_accuracy: 0.51819 |  0:05:58s\n",
            "epoch 362| loss: 0.03264 | train_accuracy: 0.99636 | val_accuracy: 0.52259 |  0:05:59s\n",
            "epoch 363| loss: 0.03647 | train_accuracy: 0.99596 | val_accuracy: 0.52739 |  0:06:00s\n",
            "epoch 364| loss: 0.03157 | train_accuracy: 0.99738 | val_accuracy: 0.51739 |  0:06:01s\n",
            "epoch 365| loss: 0.02868 | train_accuracy: 0.99787 | val_accuracy: 0.52019 |  0:06:02s\n",
            "epoch 366| loss: 0.02853 | train_accuracy: 0.9948  | val_accuracy: 0.51499 |  0:06:03s\n",
            "epoch 367| loss: 0.03995 | train_accuracy: 0.99471 | val_accuracy: 0.51739 |  0:06:04s\n",
            "epoch 368| loss: 0.04114 | train_accuracy: 0.99378 | val_accuracy: 0.52539 |  0:06:05s\n",
            "epoch 369| loss: 0.046   | train_accuracy: 0.99165 | val_accuracy: 0.51899 |  0:06:06s\n",
            "epoch 370| loss: 0.05351 | train_accuracy: 0.98467 | val_accuracy: 0.52299 |  0:06:07s\n",
            "epoch 371| loss: 0.11305 | train_accuracy: 0.97965 | val_accuracy: 0.52179 |  0:06:08s\n",
            "epoch 372| loss: 0.10865 | train_accuracy: 0.98254 | val_accuracy: 0.52339 |  0:06:09s\n",
            "epoch 373| loss: 0.09073 | train_accuracy: 0.98467 | val_accuracy: 0.51539 |  0:06:10s\n",
            "epoch 374| loss: 0.09029 | train_accuracy: 0.98156 | val_accuracy: 0.52299 |  0:06:11s\n",
            "epoch 375| loss: 0.11024 | train_accuracy: 0.96983 | val_accuracy: 0.51699 |  0:06:12s\n",
            "epoch 376| loss: 0.13688 | train_accuracy: 0.97721 | val_accuracy: 0.51939 |  0:06:13s\n",
            "epoch 377| loss: 0.12518 | train_accuracy: 0.96988 | val_accuracy: 0.52579 |  0:06:14s\n",
            "epoch 378| loss: 0.12342 | train_accuracy: 0.97361 | val_accuracy: 0.52739 |  0:06:15s\n",
            "epoch 379| loss: 0.10982 | train_accuracy: 0.98121 | val_accuracy: 0.52419 |  0:06:16s\n",
            "epoch 380| loss: 0.08551 | train_accuracy: 0.98587 | val_accuracy: 0.52459 |  0:06:17s\n",
            "epoch 381| loss: 0.07484 | train_accuracy: 0.98774 | val_accuracy: 0.52339 |  0:06:18s\n",
            "epoch 382| loss: 0.07559 | train_accuracy: 0.98729 | val_accuracy: 0.52459 |  0:06:19s\n",
            "epoch 383| loss: 0.065   | train_accuracy: 0.99094 | val_accuracy: 0.53059 |  0:06:20s\n",
            "epoch 384| loss: 0.05083 | train_accuracy: 0.99236 | val_accuracy: 0.52339 |  0:06:21s\n",
            "epoch 385| loss: 0.05259 | train_accuracy: 0.99267 | val_accuracy: 0.52379 |  0:06:22s\n",
            "epoch 386| loss: 0.05187 | train_accuracy: 0.9928  | val_accuracy: 0.5086  |  0:06:23s\n",
            "epoch 387| loss: 0.04987 | train_accuracy: 0.99369 | val_accuracy: 0.5086  |  0:06:24s\n",
            "epoch 388| loss: 0.04265 | train_accuracy: 0.99045 | val_accuracy: 0.51579 |  0:06:25s\n",
            "epoch 389| loss: 0.09361 | train_accuracy: 0.97756 | val_accuracy: 0.51779 |  0:06:26s\n",
            "epoch 390| loss: 0.10524 | train_accuracy: 0.97765 | val_accuracy: 0.51659 |  0:06:27s\n",
            "epoch 391| loss: 0.11711 | train_accuracy: 0.97899 | val_accuracy: 0.51859 |  0:06:28s\n",
            "epoch 392| loss: 0.09886 | train_accuracy: 0.98281 | val_accuracy: 0.52219 |  0:06:29s\n",
            "epoch 393| loss: 0.09105 | train_accuracy: 0.9845  | val_accuracy: 0.51979 |  0:06:30s\n",
            "epoch 394| loss: 0.07757 | train_accuracy: 0.98849 | val_accuracy: 0.51819 |  0:06:31s\n",
            "epoch 395| loss: 0.06345 | train_accuracy: 0.99063 | val_accuracy: 0.52659 |  0:06:32s\n",
            "epoch 396| loss: 0.05442 | train_accuracy: 0.99111 | val_accuracy: 0.52899 |  0:06:33s\n",
            "epoch 397| loss: 0.05394 | train_accuracy: 0.99289 | val_accuracy: 0.52499 |  0:06:34s\n",
            "epoch 398| loss: 0.04017 | train_accuracy: 0.99476 | val_accuracy: 0.52179 |  0:06:35s\n",
            "epoch 399| loss: 0.03973 | train_accuracy: 0.99582 | val_accuracy: 0.51819 |  0:06:36s\n",
            "epoch 400| loss: 0.0341  | train_accuracy: 0.99738 | val_accuracy: 0.51579 |  0:06:37s\n",
            "epoch 401| loss: 0.03093 | train_accuracy: 0.99751 | val_accuracy: 0.51379 |  0:06:38s\n",
            "epoch 402| loss: 0.02882 | train_accuracy: 0.99769 | val_accuracy: 0.51459 |  0:06:39s\n",
            "epoch 403| loss: 0.02564 | train_accuracy: 0.99787 | val_accuracy: 0.52259 |  0:06:40s\n",
            "epoch 404| loss: 0.0243  | train_accuracy: 0.99849 | val_accuracy: 0.52059 |  0:06:41s\n",
            "epoch 405| loss: 0.02407 | train_accuracy: 0.99813 | val_accuracy: 0.52099 |  0:06:42s\n",
            "epoch 406| loss: 0.02171 | train_accuracy: 0.99796 | val_accuracy: 0.51579 |  0:06:43s\n",
            "epoch 407| loss: 0.02178 | train_accuracy: 0.99796 | val_accuracy: 0.52299 |  0:06:44s\n",
            "epoch 408| loss: 0.02216 | train_accuracy: 0.99845 | val_accuracy: 0.51779 |  0:06:45s\n",
            "epoch 409| loss: 0.02094 | train_accuracy: 0.99845 | val_accuracy: 0.51539 |  0:06:46s\n",
            "epoch 410| loss: 0.01755 | train_accuracy: 0.9988  | val_accuracy: 0.52019 |  0:06:47s\n",
            "epoch 411| loss: 0.01566 | train_accuracy: 0.99916 | val_accuracy: 0.51459 |  0:06:48s\n",
            "epoch 412| loss: 0.01708 | train_accuracy: 0.99893 | val_accuracy: 0.51619 |  0:06:49s\n",
            "\n",
            "Early stopping occurred at epoch 412 with best_epoch = 312 and best_val_accuracy = 0.53619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/callbacks.py:155: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(X_test)\n",
        "test_acc = accuracy_score(y_pred=y_pred, y_true=y_test)\n",
        "print(f\"FINAL TEST SCORE FOR {dataset_name} : {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaJ1NHn-sGeQ",
        "outputId": "88d1eb75-ac06-4b51-9fed-1eecfeea048e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FINAL TEST SCORE FOR poker-hand-train : 0.521548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(clf.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "pOsPnPAZTpac",
        "outputId": "c85753ed-5e1c-4ba8-99ca-14898f243816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa8c6b7de90>]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdT0lEQVR4nO3deXzddZ3v8dfnLFlOmrVJ2izdF9rS0hZSyi6UQQERcAdxfTDW6+AdveMdR/Ti6KgzOvc+FBdQUdQZFdRhE0EZWVq2YktKoQule5vuWZp9OUnO+d4/cpomOaUJbU/Ot+37+XjkkbP8cvLJ99G+883nfH/fnznnEBERfwXSXYCIiBybglpExHMKahERzymoRUQ8p6AWEfFcKBUvWlxc7CZPnpyKlxYROS2tXr263jlXcrTnUhLUkydPprq6OhUvLSJyWjKzXW/2nFofIiKeU1CLiHhOQS0i4jkFtYiI5xTUIiKeU1CLiHhOQS0i4rkRBbWZ7TSzdWb2qpmlbIH0D57ewrOb61L18iIip6S3MqO+wjm3wDlXlapi7l6+jRe31qfq5UVETkletT4CBvG4LmQgIjLQSIPaAX8xs9VmtvRoB5jZUjOrNrPqurrja18EzFBOi4gMNtKgvsQ5dy5wDXCbmV029ADn3D3OuSrnXFVJyVH3FRmeQVyXBhMRGWREQe2c25v4XAs8DJyfkmLMUvGyIiKntGGD2sxyzCz38G3g7cD6lBSjGbWISJKRbHM6DnjY+ma7IeA+59wTqSimr0etoBYRGWjYoHbObQfmj0ItmKE3E0VEhvBqeZ6ZoQm1iMhgXgV1wMApqUVEBvEsqNWjFhEZyqugNtSjFhEZyq+gVo9aRCSJV0EdCKhHLSIylF9BrR61iEgSr4JaPWoRkWReBXXADOW0iMhgXgW1aa8PEZEkXgV1wExvJoqIDOFVUJtBPJ7uKkRE/OJVUPf1qDWjFhEZyKugNl2KS0QkiV9BjU54EREZyqugDgS0jlpEZCi/glqrPkREkngV1OpRi4gk8yuo0QkvIiJDeRXUAUt3BSIi/vEsqLV7nojIUP4Ftc5MFBEZxKugRpsyiYgk8SqoA4ZOIBcRGcKzoNY6ahGRobwLaq2jFhEZzKug1oUDRESSeRbUhnJaRGQwr4I6YNo9T0RkKM+CWj1qEZGhRhzUZhY0szVm9liqitFeHyIiyd7KjPqzwMZUFQLqUYuIHM2IgtrMKoF3Aj9LaTFa9SEikmSkM+o7gS8Ab7oTh5ktNbNqM6uuq6s7vmI0oxYRSTJsUJvZdUCtc271sY5zzt3jnKtyzlWVlJQcVzFaRy0ikmwkM+qLgevNbCfwW2CJmf06JcWYaa8PEZEhhg1q59ztzrlK59xk4CbgGefch1NRjGbUIiLJvFtHrZwWERks9FYOds4tB5anpBI0oxYRORrNqEVEPOdVUGtGLSKSzKug1oxaRCSZV0GtvT5ERJJ5FdSaUYuIJPMrqAOaUYuIDOVVUJv2oxYRSeJXUKMrvIiIDOVVUGuvDxGRZJ4FtXrUIiJDeRXUZkZcTWoRkUE8C2q0PE9EZAivglo9ahGRZJ4FtXrUIiJDeRbUpqAWERnCq6DG0AkvIiJDeBXUATPUpBYRGcyzoFaPWkRkKK+C2lCPWkRkKK+COqAetYhIEq+C2swAbcwkIjKQV0Ed6A/qNBciIuIRr4I6kdPqU4uIDOBVUAf6gzq9dYiI+MSroO7vUWsxtYhIP6+CWj1qEZFkXgW1etQiIsm8CurDPWrltIjIEZ4FdV9Sa0YtInKEV0Ft/UGd5kJERDwybFCbWZaZrTKz18xsg5l9LVXFJDofOjNRRGSA0AiOiQJLnHNtZhYGXjCzPzvn/nqyi1GPWkQk2bBB7fqmt22Ju+HER0qiNBBQj1pEZKgR9ajNLGhmrwK1wJPOuZWpKEY9ahGRZCMKaudczDm3AKgEzjezuUOPMbOlZlZtZtV1dXXHVYx61CIiyd7Sqg/nXBOwDLj6KM/d45yrcs5VlZSUHF8x/aeQi4jIYSNZ9VFiZgWJ29nAVcAbKSlGZyaKiCQZyaqPMuA/zCxIX7D/3jn3WCqKCahHLSKSZCSrPtYCC0ehlv4mdVxJLSLSz6szEw/PqEVE5AjPgrrvs3rUIiJHeBbU6lGLiAzlVVBrP2oRkWSeBbWu8CIiMpRXQX1kUyYltYjIYZ4FtXrUIiJDeRXUhxfnqUctInKEX0GtHrWISBKvglrrqEVEknkW1JpRi4gM5VVQax21iEgyr4Ja+1GLiCTzKqg1oxYRSeZVUB/pUSuoRUQO8yqoj8yo01uHiIhPvApqrfoQEUnmVVCrRy0iksyvoObwXh8KahGRw7wK6iO756W3DhERn/gV1AH1qEVEhvIrqNWjFhFJ4llQ9yV1TOvzRET6eRXUkYwQAB3dsTRXIiLiD8+COghAR3dvmisREfGHp0GtGbWIyGFeBXVOZl/ro10zahGRfl4FdWYoQMCgI6oZtYjIYV4FtZmRkxFS60NEZACvghogOyOoNxNFRAbwLqhzMkO0a0YtItJv2KA2swlmtszMXjezDWb22VQWFMkI0hHVjFpE5LDQCI7pBT7vnHvFzHKB1Wb2pHPu9VQUlJMR0qoPEZEBhp1RO+f2O+deSdxuBTYCFakqKJIZpFOtDxGRfm+pR21mk4GFwMqjPLfUzKrNrLquru64C4pkBNWjFhEZYMRBbWZjgAeBzznnWoY+75y7xzlX5ZyrKikpOe6CIhkh9ahFRAYYUVCbWZi+kP6Nc+6hVBaUoxm1iMggI1n1YcC9wEbn3HdSXVAkM6QetYjIACOZUV8MfARYYmavJj6uTVVBYzJDdMfidPUorEVEYATL85xzL0DiqrOjoLwgC4A9jZ1MLx0zWt9WRMRb3p2ZOLEoAsDuQx1prkRExA/eBfWEwkRQNyqoRUTAw6Auyc0kMxSgpkFBLSICHga1mTGhKKIZtYhIgndBDX196t2HOtNdhoiIF7wM6gmF2ew+1IFzLt2liIiknZ9BXRShNdpLc2dPuksREUk7b4MaoEZL9EREPA3qw0v01KcWEfE0qIuyAc2oRUTA06DOzQpTGAlriZ6ICJ4GNRxeoqegFhHxNqgrFdQiIoDHQT2xKMLepk5ica2lFpEzm7dBPaEwQk/McaClK92liIiklbdBPa0kB4DqnYfSXImISHp5G9SLJhcxrSSHnzy7XaeSi8gZzdugDgSMj144mdf3t7Cjvj3d5YiIpI23QQ2wZFYpAMs21aW5EhGR9PE6qCcURZheOoblm2rTXYqISNp4HdTQN6teuf0Q7dHedJciIpIW3gf15WeV0B2Ls0yzahE5Q3kf1FWTiphanMMXH1zH6l1aqiciZx7vgzojFOC+T15ASW4m/+PXr2ipnoiccbwPaoDx+Vl88tKp1LVGtUe1iJxxTomgBphXkQ/Aur3Naa5ERGR0nTJBPXP8GABuu+8Vtte1pbkaEZHRc8oEdWYoyJWJE2DuX1WT5mpEREbPKRPUAPd+fBEXTh3LC1sb0l2KiMioOaWCGuDi6WPZuL+FvU16U1FEzgzDBrWZ/dzMas1s/WgUNJwbFlSQEQpw8bee4Tt/2ZTuckREUm4kM+pfAlenuI4Rm1AU4Zs3zgXgx89u56AuLCAip7lhg9o59xzg1SmB76+awHP/eAUA//yHDbpcl4ic1k5aj9rMlppZtZlV19WlflvSiWMjfP7tM3liwwHec/eLrNhWz6odh7j9obXcfM9f2VqrJXwicnqwkZySbWaTgcecc3NH8qJVVVWuurr6xCobAeccj63dz9f+uIH6tm4AIhlBOrpjTCvJ4SMXTGLRlCJmlOaSETrl3jcVkTOIma12zlUd7bnQaBdzMpkZ75pfzt/MHseyTbX0xOJcOXscr9Y08YUHXuOrf3wdgNzMEO+vmsBN508gOxykNC+TcCBAIGBp/glERIZ3Ss+oj8W5viuYv7StgeWb6vjTuv30DuhlZ4UDTCsZQ0YoQDgYoLIwm+vOKeNtM0sJKsBFZJQda0Y9bFCb2f3A5UAxcBD4Z+fcvcf6Gh+Ceqid9e38ef0BWrt6AOjojrGroZ3euKO7N84bB1pp7uxh0tgIF00rpnrnIZo6ezhvYiHXLyhnyaxSssLBNP8UInK6OqGgPh4+BvVwunvjPLXxIPc8t52ttW3Mn5DPuLwsnttcT31blMxQgFlleZxdnsf8ynzMjPL8bM6dVEBzZw/FYzIJB9UHF5Hjo6A+AbG4Y8W2ep7dVMeGfS2s39dMa1fyZcHyskL87aVTufysEs4uz1f7RETeEgX1SeScY9WOQ2SGgzR1dPPClnpyMkNs2NfCUxsPAjCxKML188tpaI/y6u5mIhlBll42latmj6O9u5fNB1tZueMQNQ0d3LJ4EhWF2by88xDZ4SCLpxaRGVKLReRMo6AeJZsPtrJuTzO/fbmGl3c2MiYzxIxxY6htibK3qZPCSJiWrt7+E3QCBkPP1cnJCFIQyWBOeR6zy/J457wyZo4bg5lm6CKnMwV1GtQ0dDB2TAY5mSF6Y3EeX7efF7bUU5qXydzyfErzsphYFOHR1/bhnGNOWR7RWJwnXz9IU0c3mw60sqO+nbiDs8vz+Jcbzua8SUXp/rFEJEUU1KeoutYoT6zfz4+f3c6+5k7OnVjIuLxM9jR2svtQB//w9rO4/pxyXtrewPb6NpbMKmXW+Lyk1+nsjrFhXzP52WGmlYzR+nERDymoT3Ht0V5+9vwOlm+upa41SmVhNofau9l8cPBp8tnhIIumFFFZmM2EwgiFkTA7Gtp5+JW91LZGAagoyOZb753HpTNK0vGjiMibUFCfhuJxxwOv7KGuNcqiyUWU5Wfx3ac2s7W2jd2HOmjs6FsvHjC4aFoxtyyeSFu0l58+v50d9e384OaFvOPs8ep9i3hCQX0Gau3qoamjh/H5WYPWdzd39nDTPX9l4/4Wqib1ncxz48IK8rLCaaxWRBTUMki0N8bvXt7Nf6zYyba6diIZQW5YUM6NCyo4f0oRzZ09rN/bwp7GDq6aM46xYzIBWL+3me5YnIUTCjQTFznJFNTyptbuaeI/X9rF42v309kTozAS7m+bAORmhbjjujnMHJfLTfe8RFdPnMJImGvnlfG/rppJcSLEReTEKKhlWF09MX763HZ2NLQzvXQMk4pyqCzM5ksPr2PDvhYAMoIBPvW2qexp7OSxtfuYNDaH3y29oH/GXdvaRbQnTkVBtlaWiLxFCmo5brG449XdTWzY18xVc8ZRlp8NwIpt9Xzs56vICAZYNKWIxvZuXtvTDMCU4hw+ffk03n9e5aAWiXOO3rhj2Ru1XDBtrPriIgMoqCUlthxs5XtPb2Hj/haCAePquWWU5Gby+5d3s25vMzefP4Gv3zCXUDDAX7c38LGfryLaGwfg0hnF/OLjiwgFA3T3xumNx4lknNLbo4ucEAW1jCrnHP/vL5u4a9k25k8o4M4PLuCfHljLqp2HGJuTwcKJhTy18SCXzSzhrg8t5PaH1vHspjr+6ZpZ3LiwgjGZCmw58yioJS0efW0fX/nDepoSb05+48a53LJ4ImbGb1fV8H8eWU9WOEhb9MhuhAWRMDfML2dvUycFkQz+4aqZ3PvCDtbUNHLN3DKumTeeLz28nlU7GvhA1QS+eM0szcTltKCglrTZfaiDu5dvo6Igi9uumD6oZ/3Clnq++NBaJhZF+NGHz2NbXRt3PbOV5ZvrKM3NpLY12r+B1YzSMWwZcMHii6ePZcW2BqaMzeGTl03lvEmFzByXO+o/n8jJoqCWU0q0N0ZGMMC6vc3c+dQWrjunjHcvrODZzXUcaO5iSnEOi6eOZcXWepb+anX/jPyb757LzYsmntCKk31NneRlh9V+kVGnoJbT1qH2bvY1dfLNxzfy0vYGrpxVyp03LSD3OFaU1LZ2cfn/XU4kI8QvP7GIuRX5KahY5OiOFdS6dpSc0opyMphbkc+vbj2fO66bw9Nv1HLZvy/juc11fRc4bu4i2hsb0Wvd9cxWOrpj1LdFec/dK3htd1OKqxcZGc2o5bSydk8TX3hgLVtq25hROoY3DrRSUZDNbVdM513zy1i14xDVuxr5zxU76Yk7xuVl8pMPVzG1JIdF33yKK2eVcsd1c7j+hy9iBo///aXkZ2u9t6SeWh9yRmnu6OEz97/C3sZOrphVyiNr9tLQ3j3omPmV+VwwbSx/WLOPzp4YF08fy5/WHeDXty7mkhnFvFLTyAd+/BJLZpXyb++ZR1FOhvY3kZRSUMsZrbs3zpqaRp7bUkd2OEhHd4xPXz6N3Kww2+ra+OqjG3h+Sz3XzhvPD28+t//NyJ89v51vPL4RgPMnF/HTj1aRH9HsWlJDQS0yjB317UwqigxaMeKcY8W2BtbUNPK9p7cwozSX79+8kD++to/JxRFumF+hPU3kpFFQi5yg5Ztq+dSvVvefAg9wTmU+ZflZFGRncNb4XD564SRCQb0/L8dHQS1yEqypaWTZpjqunTeedXuauWvZVnpijo7uXho7elg0uZAvv3MO8yvzT4l+dizu+O6Tm1m/r5lr5o7n6rlleuM0jRTUIin2yJq93PHIelqjvcwuy+PciQWcXZ7P+VOKmFaSMyi426O9/atSctJ4Ys19K2v40sPrCAWM3rhjwYQCHv67i06JXzKnIwW1yCho7erhkTV7efCVvWyva6Olq++MyUtnFPO+8yq5dEYJeVkh3vn9F9h0sJXMUIDppWM4p7KA955bwePr9tPc2cN7z61kXF4Wk8ZGBl1G7WTaWd/Ou37wArPL8/j1rYu5e/lW7nxqC//67nl8aPHEo35NbUsX33h8I39/5Qyml45JSV1nMgW1yChzzrGjvp0/rz/A957eQneit12Uk8Gh9m5uvWQKvbE4Gw+08mpNE92xOBnBAJmhAK2JU+KnFOdw5wcXMLssj437W5hSksO3/vwGa2qaqG+L8q5zyskIBbh23njOqSwYUV29sTj//OgGfrOyhoJImD9+5hImFEWIxR0f/8UqVmxr4Ee3nMvbzx6f9LXffuINfrR8G+X5WTz0dxczPj8LgL1Nndy9bCuH2rsZl5fFRy6cxLQSP4K8PXFB58vPKmVueZ7X7yEoqEXSKNobY+2eZlZsbeDJjQdYNLmIr1w3p7/FUNPQwYpt9Vw5exxZ4QDPb6mntauH7z+9lb1NnYSDRk/syP/TKcU5hIPG5oN9m1QFA8b/XDKdDy2eSGluFpsOtPLgK3v4+EWT2dfUyQOr97C1to2CSAYb97ewt6kTgF98YhFXnFXa/7pt0V4++JOX2LCvhUtnFPe3cK6eW0ZHdy+XfnsZlYXZbKtrpyw/i39/3zksmFDAZ+5fw+Nr9wMQDhqxuONL187m1kumpKWN8ssXd3CwNcrfXjKFbz/xBr+v3gPApLERfvKR85g1Pu+oX/fX7Q388JmtfOLiyVw5e9xolgwoqEVOSQ1tUR5YvYfGjh4KImF2NXTwtpklXD13PM45ttS2kZ8d5uuPvc5jiaCcNT6XnQ3tdPUcWZ2SkxEkkhmirjUKQNWkQu775AVkhJJnl23RXu5buYu7lm2jsztGd6zvdQ5fS/PBT19ItCfOx3/xMt2xOLmZIVqjvbzj7HHcfP5Ezi7P545H1vPEhgNkhQNcNK2Y2WW55GeHqSyMcM3c8SkN76aObhb8y5MAmIFzcMviicwuy+MHz2whFAjwnQ/MZ3Z53qArDP3qpZ3c8YcNhAJGzDmunVvG12+cS1FORspqHeqEg9rMrga+BwSBnznnvnWs4xXUIqNr04FWnnz9AKt3NRIKBnj3wgr2NnaSGQ5w48IKcjNDbDrYSmVhhFDAyAoHh33NaG+Mr/3xdepao2yra+OyGSV89fqzATjQ3MVzm+tYs7uRWePz+NDiif39dOccv6/ezZqaJqp3NbK9ro3EbrVMKc4hPzvM3Io8JhRGmFeZz7kTC8kKB+mNxfnhsq3sPtRJe7SXysJsCnMyuHRGMTPH5RIMGG1dvRQeIzx/s3IXX354PXdcN4cVW+s5uzyPz/3NTAIB47XdTXz43pW0dvWSmxXiH99xFjNKc4lkBPnUr1ZTWZjNjz9yHr94cQc/fW4HRTkZfPryaVwwdSxnjU/9FronFNRmFgQ2A1cBe4CXgZudc6+/2dcoqEXksOaOHjB4YPUeVu1ooLY1yhv7W+ns6dssKzscpLIwm+5YnF0NHWSGApQXZLOvqXPQuvWscICunjizy/KYNT6XMZkhwsEAs8bn8tL2BlbvaqTmUAdTi3N4+vNvO+rMvaEtyovbGrh/ZQ0vbW8Y9NydH1zAjQsrAFi/t5n//V+v8caBVgIG8yoLOKcinznleZTmZlKam0VpXiZZ4SChgJEdDp7wyU8nGtQXAl91zr0jcf92AOfcv73Z1yioRWQ4+5s72bi/hWc31bG/uYumzh5uWTyRGxb0haVzjsaOHp7fUkdNQwf1bVGyM0Js3N/C5oOttHT20Bt3RHvjZIYCvG1mCRdNG8u75pczdkzmMb93LO6o3nmIWNzR0N7Nlto2brtiGpmhI39pxOOObXVt/GZlDa/vb2HD3mbau4++E2NGKMC4vExyM8P86bOXHtd4HCuoR7KIswLYPeD+HmDxcVUiIpJQlp9NWX42S2Yd/Y07M6MoJ6M/uI+mNxZnd2MnhZEwBZGR95ODAWPx1LHHPCYQMGaMy+1v9/TG4hxsjVLb0kVta5Ta1ijRnhhx56hv6+ZgSxfFw/yCOF4nbbW9mS0FlgJMnHj0dZgiIidTKBhgSnHOqH2vioJsKgqyR+X7DTSSRYV7gQkD7lcmHhvEOXePc67KOVdVUlJysuoTETnjjSSoXwZmmNkUM8sAbgIeTW1ZIiJy2LCtD+dcr5l9Bvhv+pbn/dw5tyHllYmICDDCHrVz7k/An1Jci4iIHIW/J76LiAigoBYR8Z6CWkTEcwpqERHPpWT3PDOrA3Yd55cXA/UnsZzTlcZpZDROw9MYjUyqx2mSc+6oJ6GkJKhPhJlVv9n57nKExmlkNE7D0xiNTDrHSa0PERHPKahFRDznY1Dfk+4CThEap5HROA1PYzQyaRsn73rUIiIymI8zahERGUBBLSLiOW+C2syuNrNNZrbVzL6Y7nrSycx+bma1ZrZ+wGNFZvakmW1JfC5MPG5m9v3EuK01s3PTV/noMrMJZrbMzF43sw1m9tnE4xqrAcwsy8xWmdlriXH6WuLxKWa2MjEev0tsY4yZZSbub008Pzmd9Y8mMwua2Rozeyxx34sx8iKoExfQvQu4BpgD3Gxmc9JbVVr9Erh6yGNfBJ52zs0Ank7ch74xm5H4WAr8aJRq9EEv8Hnn3BzgAuC2xL8bjdVgUWCJc24+sAC42swuAL4NfNc5Nx1oBG5NHH8r0Jh4/LuJ484UnwU2Drjvxxg559L+AVwI/PeA+7cDt6e7rjSPyWRg/YD7m4CyxO0yYFPi9k/ouyp80nFn2gfwB+AqjdUxxygCvELfdU/rgVDi8f7/g/TtPX9h4nYocZylu/ZRGJtK+n6xLwEeA8yXMfJiRs3RL6D75le0PDONc87tT9w+ABy+IqjGDkj86bkQWInGKkniT/pXgVrgSWAb0OSc600cMnAs+scp8XwzcOwrwZ4e7gS+AMQT98fiyRj5EtTyFri+X+NaV5lgZmOAB4HPOedaBj6nserjnIs55xbQN2s8H5iV5pK8YmbXAbXOudXpruVofAnqEV1A9wx30MzKABKfaxOPn9FjZ2Zh+kL6N865hxIPa6zehHOuCVhG35/xBWZ2+CpPA8eif5wSz+cDDaNc6mi7GLjezHYCv6Wv/fE9PBkjX4JaF9Ad3qPAxxK3P0ZfP/bw4x9NrGi4AGge8Gf/ac3MDLgX2Oic+86ApzRWA5hZiZkVJG5n09fH30hfYL8vcdjQcTo8fu8Dnkn8ZXLacs7d7pyrdM5Npi9/nnHO3YIvY5TuBv6ARv61wGb6emdfTnc9aR6L+4H9QA99fbFb6et/PQ1sAZ4CihLHGn0rZrYB64CqdNc/iuN0CX1tjbXAq4mPazVWSeN0DrAmMU7rga8kHp8KrAK2Av8FZCYez0rc35p4fmq6f4ZRHq/Lgcd8GiOdQi4i4jlfWh8iIvImFNQiIp5TUIuIeE5BLSLiOQW1iIjnFNQiIp5TUIuIeO7/AxHRk9lM8wToAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot mse\n",
        "plt.plot(clf.history['train_accuracy'])\n",
        "plt.plot(clf.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "RmZhhMf4TsJ7",
        "outputId": "12ce16e1-0384-4f67-b600-ce0be4c38bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa8c6b582d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##N_d nhỏ"
      ],
      "metadata": {
        "id": "cOsBz7z6yIOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    n_d=2, n_a=16, n_steps=5,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=[3,12,3,12,3,12,3,12,3,12],\n",
        "    gamma=1.5, n_ind=2, n_shared=2,\n",
        "    lambda_sparse=1e-6, momentum=0.05, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 80},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65accc68-b053-4814-e6b5-1b643177b1c9",
        "id": "iRdI2BwXNxjE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cpu\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name = ['train', 'val'],\n",
        "    max_epochs=3000, patience=1000,\n",
        "    batch_size=4096, vbs=1024 #, augmentations=aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8kkXD3hNsfp",
        "outputId": "6f5beabd-fa1c-47e1-b039-2eb95a85b120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 2.81962 | train_accuracy: 0.00538 | val_accuracy: 0.0064  |  0:00:02s\n",
            "epoch 1  | loss: 2.36511 | train_accuracy: 0.10694 | val_accuracy: 0.11236 |  0:00:06s\n",
            "epoch 2  | loss: 2.19846 | train_accuracy: 0.22347 | val_accuracy: 0.22191 |  0:00:09s\n",
            "epoch 3  | loss: 2.09406 | train_accuracy: 0.32138 | val_accuracy: 0.32107 |  0:00:12s\n",
            "epoch 4  | loss: 1.99059 | train_accuracy: 0.38211 | val_accuracy: 0.37185 |  0:00:15s\n",
            "epoch 5  | loss: 1.89216 | train_accuracy: 0.40344 | val_accuracy: 0.39464 |  0:00:18s\n",
            "epoch 6  | loss: 1.79916 | train_accuracy: 0.41299 | val_accuracy: 0.40224 |  0:00:21s\n",
            "epoch 7  | loss: 1.71847 | train_accuracy: 0.41721 | val_accuracy: 0.40944 |  0:00:24s\n",
            "epoch 8  | loss: 1.63206 | train_accuracy: 0.41877 | val_accuracy: 0.41024 |  0:00:26s\n",
            "epoch 9  | loss: 1.55038 | train_accuracy: 0.4221  | val_accuracy: 0.41263 |  0:00:29s\n",
            "epoch 10 | loss: 1.46426 | train_accuracy: 0.42303 | val_accuracy: 0.41423 |  0:00:32s\n",
            "epoch 11 | loss: 1.36901 | train_accuracy: 0.42396 | val_accuracy: 0.41423 |  0:00:35s\n",
            "epoch 12 | loss: 1.27371 | train_accuracy: 0.42436 | val_accuracy: 0.41583 |  0:00:38s\n",
            "epoch 13 | loss: 1.18716 | train_accuracy: 0.42454 | val_accuracy: 0.41583 |  0:00:40s\n",
            "epoch 14 | loss: 1.13145 | train_accuracy: 0.49909 | val_accuracy: 0.5018  |  0:00:43s\n",
            "epoch 15 | loss: 1.10396 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:00:46s\n",
            "epoch 16 | loss: 1.09472 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:00:49s\n",
            "epoch 17 | loss: 1.07057 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:00:52s\n",
            "epoch 18 | loss: 1.05126 | train_accuracy: 0.49891 | val_accuracy: 0.501   |  0:00:54s\n",
            "epoch 19 | loss: 1.03548 | train_accuracy: 0.49909 | val_accuracy: 0.4998  |  0:00:57s\n",
            "epoch 20 | loss: 1.02697 | train_accuracy: 0.49931 | val_accuracy: 0.4994  |  0:01:00s\n",
            "epoch 21 | loss: 1.02142 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:01:03s\n",
            "epoch 22 | loss: 1.01183 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:01:06s\n",
            "epoch 23 | loss: 1.0034  | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:01:08s\n",
            "epoch 24 | loss: 1.00191 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:01:11s\n",
            "epoch 25 | loss: 0.99523 | train_accuracy: 0.49922 | val_accuracy: 0.5018  |  0:01:14s\n",
            "epoch 26 | loss: 0.99835 | train_accuracy: 0.49918 | val_accuracy: 0.5018  |  0:01:17s\n",
            "epoch 27 | loss: 0.9902  | train_accuracy: 0.49922 | val_accuracy: 0.5022  |  0:01:19s\n",
            "epoch 28 | loss: 0.98926 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:01:22s\n",
            "epoch 29 | loss: 0.99046 | train_accuracy: 0.49918 | val_accuracy: 0.5018  |  0:01:25s\n",
            "epoch 30 | loss: 0.9919  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:01:28s\n",
            "epoch 31 | loss: 0.98652 | train_accuracy: 0.49931 | val_accuracy: 0.5014  |  0:01:31s\n",
            "epoch 32 | loss: 0.98653 | train_accuracy: 0.49927 | val_accuracy: 0.501   |  0:01:33s\n",
            "epoch 33 | loss: 0.98547 | train_accuracy: 0.49922 | val_accuracy: 0.501   |  0:01:36s\n",
            "epoch 34 | loss: 0.9869  | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:01:39s\n",
            "epoch 35 | loss: 0.98708 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:01:42s\n",
            "epoch 36 | loss: 0.9873  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:01:44s\n",
            "epoch 37 | loss: 0.98579 | train_accuracy: 0.49922 | val_accuracy: 0.5014  |  0:01:47s\n",
            "epoch 38 | loss: 0.98546 | train_accuracy: 0.49918 | val_accuracy: 0.501   |  0:01:50s\n",
            "epoch 39 | loss: 0.98565 | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:01:53s\n",
            "epoch 40 | loss: 0.98547 | train_accuracy: 0.49922 | val_accuracy: 0.5014  |  0:01:56s\n",
            "epoch 41 | loss: 0.98712 | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:01:59s\n",
            "epoch 42 | loss: 0.98686 | train_accuracy: 0.49931 | val_accuracy: 0.501   |  0:02:02s\n",
            "epoch 43 | loss: 0.9884  | train_accuracy: 0.49953 | val_accuracy: 0.5018  |  0:02:05s\n",
            "epoch 44 | loss: 0.98768 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:02:08s\n",
            "epoch 45 | loss: 0.98499 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:02:10s\n",
            "epoch 46 | loss: 0.98648 | train_accuracy: 0.49944 | val_accuracy: 0.5018  |  0:02:13s\n",
            "epoch 47 | loss: 0.98275 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:02:16s\n",
            "epoch 48 | loss: 0.98599 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:02:19s\n",
            "epoch 49 | loss: 0.98514 | train_accuracy: 0.4994  | val_accuracy: 0.5022  |  0:02:22s\n",
            "epoch 50 | loss: 0.98399 | train_accuracy: 0.49944 | val_accuracy: 0.5022  |  0:02:25s\n",
            "epoch 51 | loss: 0.98823 | train_accuracy: 0.49944 | val_accuracy: 0.5022  |  0:02:27s\n",
            "epoch 52 | loss: 0.9847  | train_accuracy: 0.4994  | val_accuracy: 0.5022  |  0:02:30s\n",
            "epoch 53 | loss: 0.98617 | train_accuracy: 0.49931 | val_accuracy: 0.5022  |  0:02:34s\n",
            "epoch 54 | loss: 0.98526 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:02:36s\n",
            "epoch 55 | loss: 0.98657 | train_accuracy: 0.49953 | val_accuracy: 0.5018  |  0:02:39s\n",
            "epoch 56 | loss: 0.98614 | train_accuracy: 0.49944 | val_accuracy: 0.5018  |  0:02:42s\n",
            "epoch 57 | loss: 0.98607 | train_accuracy: 0.49936 | val_accuracy: 0.5014  |  0:02:45s\n",
            "epoch 58 | loss: 0.98394 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:02:48s\n",
            "epoch 59 | loss: 0.98371 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:02:50s\n",
            "epoch 60 | loss: 0.98129 | train_accuracy: 0.4994  | val_accuracy: 0.5014  |  0:02:53s\n",
            "epoch 61 | loss: 0.98628 | train_accuracy: 0.49931 | val_accuracy: 0.5014  |  0:02:56s\n",
            "epoch 62 | loss: 0.98319 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:02:59s\n",
            "epoch 63 | loss: 0.98446 | train_accuracy: 0.49944 | val_accuracy: 0.5018  |  0:03:01s\n",
            "epoch 64 | loss: 0.98367 | train_accuracy: 0.49936 | val_accuracy: 0.5014  |  0:03:04s\n",
            "epoch 65 | loss: 0.98479 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:03:07s\n",
            "epoch 66 | loss: 0.98318 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:03:10s\n",
            "epoch 67 | loss: 0.98213 | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:03:13s\n",
            "epoch 68 | loss: 0.98288 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:03:15s\n",
            "epoch 69 | loss: 0.98573 | train_accuracy: 0.49927 | val_accuracy: 0.5014  |  0:03:18s\n",
            "epoch 70 | loss: 0.98404 | train_accuracy: 0.49931 | val_accuracy: 0.5014  |  0:03:21s\n",
            "epoch 71 | loss: 0.98388 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:03:24s\n",
            "epoch 72 | loss: 0.98011 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:03:26s\n",
            "epoch 73 | loss: 0.98327 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:03:29s\n",
            "epoch 74 | loss: 0.98253 | train_accuracy: 0.49931 | val_accuracy: 0.5014  |  0:03:32s\n",
            "epoch 75 | loss: 0.98423 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:03:35s\n",
            "epoch 76 | loss: 0.98082 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:03:38s\n",
            "epoch 77 | loss: 0.97959 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:03:40s\n",
            "epoch 78 | loss: 0.98216 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:03:43s\n",
            "epoch 79 | loss: 0.98125 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:03:46s\n",
            "epoch 80 | loss: 0.98114 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:03:49s\n",
            "epoch 81 | loss: 0.98109 | train_accuracy: 0.49958 | val_accuracy: 0.5018  |  0:03:52s\n",
            "epoch 82 | loss: 0.98019 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:03:54s\n",
            "epoch 83 | loss: 0.98293 | train_accuracy: 0.49953 | val_accuracy: 0.5018  |  0:03:57s\n",
            "epoch 84 | loss: 0.98181 | train_accuracy: 0.49953 | val_accuracy: 0.5018  |  0:04:00s\n",
            "epoch 85 | loss: 0.98091 | train_accuracy: 0.49944 | val_accuracy: 0.5022  |  0:04:03s\n",
            "epoch 86 | loss: 0.98226 | train_accuracy: 0.4994  | val_accuracy: 0.5022  |  0:04:06s\n",
            "epoch 87 | loss: 0.98344 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:09s\n",
            "epoch 88 | loss: 0.98393 | train_accuracy: 0.49922 | val_accuracy: 0.5014  |  0:04:11s\n",
            "epoch 89 | loss: 0.9814  | train_accuracy: 0.49931 | val_accuracy: 0.5022  |  0:04:14s\n",
            "epoch 90 | loss: 0.98579 | train_accuracy: 0.49936 | val_accuracy: 0.5022  |  0:04:17s\n",
            "epoch 91 | loss: 0.98126 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:20s\n",
            "epoch 92 | loss: 0.98404 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:22s\n",
            "epoch 93 | loss: 0.98249 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:04:25s\n",
            "epoch 94 | loss: 0.98327 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:29s\n",
            "epoch 95 | loss: 0.97909 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:31s\n",
            "epoch 96 | loss: 0.98007 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:04:34s\n",
            "epoch 97 | loss: 0.98108 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:37s\n",
            "epoch 98 | loss: 0.98504 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:40s\n",
            "epoch 99 | loss: 0.98225 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:42s\n",
            "epoch 100| loss: 0.98413 | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:04:45s\n",
            "epoch 101| loss: 0.97978 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:48s\n",
            "epoch 102| loss: 0.98022 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:04:51s\n",
            "epoch 103| loss: 0.97895 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:54s\n",
            "epoch 104| loss: 0.97873 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:56s\n",
            "epoch 105| loss: 0.98425 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:04:59s\n",
            "epoch 106| loss: 0.98017 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:02s\n",
            "epoch 107| loss: 0.97962 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:05s\n",
            "epoch 108| loss: 0.98246 | train_accuracy: 0.49922 | val_accuracy: 0.5018  |  0:05:08s\n",
            "epoch 109| loss: 0.98037 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:05:10s\n",
            "epoch 110| loss: 0.97913 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:13s\n",
            "epoch 111| loss: 0.98107 | train_accuracy: 0.49949 | val_accuracy: 0.5014  |  0:05:16s\n",
            "epoch 112| loss: 0.98198 | train_accuracy: 0.49971 | val_accuracy: 0.5022  |  0:05:19s\n",
            "epoch 113| loss: 0.98362 | train_accuracy: 0.4998  | val_accuracy: 0.5014  |  0:05:22s\n",
            "epoch 114| loss: 0.98184 | train_accuracy: 0.49918 | val_accuracy: 0.5018  |  0:05:24s\n",
            "epoch 115| loss: 0.9768  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:27s\n",
            "epoch 116| loss: 0.98066 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:30s\n",
            "epoch 117| loss: 0.98199 | train_accuracy: 0.49922 | val_accuracy: 0.5018  |  0:05:33s\n",
            "epoch 118| loss: 0.97913 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:05:36s\n",
            "epoch 119| loss: 0.97895 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:05:38s\n",
            "epoch 120| loss: 0.97926 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:05:41s\n",
            "epoch 121| loss: 0.98076 | train_accuracy: 0.4994  | val_accuracy: 0.5018  |  0:05:44s\n",
            "epoch 122| loss: 0.98123 | train_accuracy: 0.499   | val_accuracy: 0.5038  |  0:05:47s\n",
            "epoch 123| loss: 0.98324 | train_accuracy: 0.499   | val_accuracy: 0.5034  |  0:05:50s\n",
            "epoch 124| loss: 0.98197 | train_accuracy: 0.49904 | val_accuracy: 0.5038  |  0:05:52s\n",
            "epoch 125| loss: 0.98034 | train_accuracy: 0.49869 | val_accuracy: 0.503   |  0:05:55s\n",
            "epoch 126| loss: 0.97882 | train_accuracy: 0.49873 | val_accuracy: 0.5026  |  0:05:58s\n",
            "epoch 127| loss: 0.98109 | train_accuracy: 0.49887 | val_accuracy: 0.5026  |  0:06:01s\n",
            "epoch 128| loss: 0.98672 | train_accuracy: 0.49922 | val_accuracy: 0.5022  |  0:06:03s\n",
            "epoch 129| loss: 0.98224 | train_accuracy: 0.49944 | val_accuracy: 0.5022  |  0:06:06s\n",
            "epoch 130| loss: 0.97988 | train_accuracy: 0.49958 | val_accuracy: 0.5022  |  0:06:09s\n",
            "epoch 131| loss: 0.98198 | train_accuracy: 0.49909 | val_accuracy: 0.5026  |  0:06:12s\n",
            "epoch 132| loss: 0.98294 | train_accuracy: 0.499   | val_accuracy: 0.5018  |  0:06:15s\n",
            "epoch 133| loss: 0.98395 | train_accuracy: 0.49913 | val_accuracy: 0.5026  |  0:06:17s\n",
            "epoch 134| loss: 0.9821  | train_accuracy: 0.49922 | val_accuracy: 0.503   |  0:06:20s\n",
            "epoch 135| loss: 0.9805  | train_accuracy: 0.49918 | val_accuracy: 0.503   |  0:06:23s\n",
            "epoch 136| loss: 0.98155 | train_accuracy: 0.499   | val_accuracy: 0.5034  |  0:06:26s\n",
            "epoch 137| loss: 0.97895 | train_accuracy: 0.49909 | val_accuracy: 0.503   |  0:06:29s\n",
            "epoch 138| loss: 0.97875 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:06:32s\n",
            "epoch 139| loss: 0.97955 | train_accuracy: 0.49922 | val_accuracy: 0.5026  |  0:06:34s\n",
            "epoch 140| loss: 0.98305 | train_accuracy: 0.49904 | val_accuracy: 0.5026  |  0:06:37s\n",
            "epoch 141| loss: 0.97729 | train_accuracy: 0.49873 | val_accuracy: 0.5018  |  0:06:40s\n",
            "epoch 142| loss: 0.97701 | train_accuracy: 0.49918 | val_accuracy: 0.5014  |  0:06:43s\n",
            "epoch 143| loss: 0.98097 | train_accuracy: 0.49967 | val_accuracy: 0.5014  |  0:06:46s\n",
            "epoch 144| loss: 0.97893 | train_accuracy: 0.49962 | val_accuracy: 0.5014  |  0:06:49s\n",
            "epoch 145| loss: 0.97665 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:06:51s\n",
            "epoch 146| loss: 0.97845 | train_accuracy: 0.49949 | val_accuracy: 0.5018  |  0:06:54s\n",
            "epoch 147| loss: 0.97644 | train_accuracy: 0.49936 | val_accuracy: 0.5018  |  0:06:57s\n",
            "epoch 148| loss: 0.97884 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:07:00s\n",
            "epoch 149| loss: 0.98014 | train_accuracy: 0.49913 | val_accuracy: 0.5022  |  0:07:02s\n",
            "epoch 150| loss: 0.98172 | train_accuracy: 0.49931 | val_accuracy: 0.5022  |  0:07:05s\n",
            "epoch 151| loss: 0.98001 | train_accuracy: 0.49953 | val_accuracy: 0.5022  |  0:07:08s\n",
            "epoch 152| loss: 0.978   | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:07:11s\n",
            "epoch 153| loss: 0.9797  | train_accuracy: 0.49904 | val_accuracy: 0.5022  |  0:07:13s\n",
            "epoch 154| loss: 0.98132 | train_accuracy: 0.49918 | val_accuracy: 0.5026  |  0:07:16s\n",
            "epoch 155| loss: 0.97905 | train_accuracy: 0.49904 | val_accuracy: 0.5022  |  0:07:19s\n",
            "epoch 156| loss: 0.98095 | train_accuracy: 0.49927 | val_accuracy: 0.5022  |  0:07:22s\n",
            "epoch 157| loss: 0.97986 | train_accuracy: 0.49913 | val_accuracy: 0.5022  |  0:07:25s\n",
            "epoch 158| loss: 0.97743 | train_accuracy: 0.499   | val_accuracy: 0.5022  |  0:07:27s\n",
            "epoch 159| loss: 0.98074 | train_accuracy: 0.499   | val_accuracy: 0.5026  |  0:07:30s\n",
            "epoch 160| loss: 0.98108 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:07:33s\n",
            "epoch 161| loss: 0.97989 | train_accuracy: 0.499   | val_accuracy: 0.5018  |  0:07:36s\n",
            "epoch 162| loss: 0.9826  | train_accuracy: 0.49882 | val_accuracy: 0.5022  |  0:07:38s\n",
            "epoch 163| loss: 0.98048 | train_accuracy: 0.49931 | val_accuracy: 0.5018  |  0:07:41s\n",
            "epoch 164| loss: 0.97914 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:44s\n",
            "epoch 165| loss: 0.98215 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:47s\n",
            "epoch 166| loss: 0.98103 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:49s\n",
            "epoch 167| loss: 0.98175 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:52s\n",
            "epoch 168| loss: 0.97929 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:55s\n",
            "epoch 169| loss: 0.97981 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:07:58s\n",
            "epoch 170| loss: 0.98154 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:01s\n",
            "epoch 171| loss: 0.98024 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:03s\n",
            "epoch 172| loss: 0.98035 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:06s\n",
            "epoch 173| loss: 0.97849 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:09s\n",
            "epoch 174| loss: 0.97964 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:12s\n",
            "epoch 175| loss: 0.98542 | train_accuracy: 0.49882 | val_accuracy: 0.5026  |  0:08:15s\n",
            "epoch 176| loss: 0.97817 | train_accuracy: 0.49891 | val_accuracy: 0.5026  |  0:08:18s\n",
            "epoch 177| loss: 0.98049 | train_accuracy: 0.499   | val_accuracy: 0.5022  |  0:08:21s\n",
            "epoch 178| loss: 0.98202 | train_accuracy: 0.49913 | val_accuracy: 0.5022  |  0:08:23s\n",
            "epoch 179| loss: 0.98001 | train_accuracy: 0.49918 | val_accuracy: 0.5018  |  0:08:26s\n",
            "epoch 180| loss: 0.98217 | train_accuracy: 0.49922 | val_accuracy: 0.5018  |  0:08:29s\n",
            "epoch 181| loss: 0.983   | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:32s\n",
            "epoch 182| loss: 0.9784  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:35s\n",
            "epoch 183| loss: 0.9796  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:37s\n",
            "epoch 184| loss: 0.98006 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:40s\n",
            "epoch 185| loss: 0.97922 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:43s\n",
            "epoch 186| loss: 0.98075 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:46s\n",
            "epoch 187| loss: 0.97964 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:49s\n",
            "epoch 188| loss: 0.98015 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:52s\n",
            "epoch 189| loss: 0.97886 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:55s\n",
            "epoch 190| loss: 0.97995 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:08:57s\n",
            "epoch 191| loss: 0.98275 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:00s\n",
            "epoch 192| loss: 0.9779  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:03s\n",
            "epoch 193| loss: 0.9764  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:07s\n",
            "epoch 194| loss: 0.97663 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:09s\n",
            "epoch 195| loss: 0.97998 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:12s\n",
            "epoch 196| loss: 0.9786  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:15s\n",
            "epoch 197| loss: 0.98055 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:18s\n",
            "epoch 198| loss: 0.97764 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:21s\n",
            "epoch 199| loss: 0.97847 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:24s\n",
            "epoch 200| loss: 0.97954 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:26s\n",
            "epoch 201| loss: 0.98176 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:29s\n",
            "epoch 202| loss: 0.98127 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:32s\n",
            "epoch 203| loss: 0.97981 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:35s\n",
            "epoch 204| loss: 0.97984 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:37s\n",
            "epoch 205| loss: 0.97702 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:40s\n",
            "epoch 206| loss: 0.98142 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:43s\n",
            "epoch 207| loss: 0.97858 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:46s\n",
            "epoch 208| loss: 0.98005 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:49s\n",
            "epoch 209| loss: 0.9799  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:51s\n",
            "epoch 210| loss: 0.97967 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:54s\n",
            "epoch 211| loss: 0.98198 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:09:57s\n",
            "epoch 212| loss: 0.98101 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:00s\n",
            "epoch 213| loss: 0.98146 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:02s\n",
            "epoch 214| loss: 0.98093 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:05s\n",
            "epoch 215| loss: 0.98225 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:08s\n",
            "epoch 216| loss: 0.98048 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:11s\n",
            "epoch 217| loss: 0.98025 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:14s\n",
            "epoch 218| loss: 0.98115 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:16s\n",
            "epoch 219| loss: 0.98226 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:19s\n",
            "epoch 220| loss: 0.98043 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:22s\n",
            "epoch 221| loss: 0.98109 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:25s\n",
            "epoch 222| loss: 0.98225 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:27s\n",
            "epoch 223| loss: 0.97985 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:30s\n",
            "epoch 224| loss: 0.98105 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:33s\n",
            "epoch 225| loss: 0.98254 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:36s\n",
            "epoch 226| loss: 0.9817  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:39s\n",
            "epoch 227| loss: 0.98034 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:41s\n",
            "epoch 228| loss: 0.97934 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:44s\n",
            "epoch 229| loss: 0.98027 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:47s\n",
            "epoch 230| loss: 0.98308 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:50s\n",
            "epoch 231| loss: 0.9787  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:52s\n",
            "epoch 232| loss: 0.97831 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:55s\n",
            "epoch 233| loss: 0.9825  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:10:58s\n",
            "epoch 234| loss: 0.97981 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:01s\n",
            "epoch 235| loss: 0.97921 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:04s\n",
            "epoch 236| loss: 0.97802 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:06s\n",
            "epoch 237| loss: 0.97801 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:09s\n",
            "epoch 238| loss: 0.98026 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:12s\n",
            "epoch 239| loss: 0.97701 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:15s\n",
            "epoch 240| loss: 0.97846 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:18s\n",
            "epoch 241| loss: 0.9783  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:20s\n",
            "epoch 242| loss: 0.98032 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:23s\n",
            "epoch 243| loss: 0.97593 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:26s\n",
            "epoch 244| loss: 0.97662 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:29s\n",
            "epoch 245| loss: 0.98045 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:31s\n",
            "epoch 246| loss: 0.97631 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:34s\n",
            "epoch 247| loss: 0.98168 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:37s\n",
            "epoch 248| loss: 0.98153 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:40s\n",
            "epoch 249| loss: 0.97834 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:42s\n",
            "epoch 250| loss: 0.97972 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:45s\n",
            "epoch 251| loss: 0.97765 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:48s\n",
            "epoch 252| loss: 0.97858 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:51s\n",
            "epoch 253| loss: 0.979   | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:53s\n",
            "epoch 254| loss: 0.97799 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:56s\n",
            "epoch 255| loss: 0.9797  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:11:59s\n",
            "epoch 256| loss: 0.97663 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:02s\n",
            "epoch 257| loss: 0.97691 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:05s\n",
            "epoch 258| loss: 0.97907 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:07s\n",
            "epoch 259| loss: 0.97957 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:10s\n",
            "epoch 260| loss: 0.97798 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:13s\n",
            "epoch 261| loss: 0.97969 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:16s\n",
            "epoch 262| loss: 0.97599 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:18s\n",
            "epoch 263| loss: 0.97713 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:21s\n",
            "epoch 264| loss: 0.97774 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:24s\n",
            "epoch 265| loss: 0.97965 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:26s\n",
            "epoch 266| loss: 0.97848 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:29s\n",
            "epoch 267| loss: 0.97979 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:32s\n",
            "epoch 268| loss: 0.97629 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:35s\n",
            "epoch 269| loss: 0.97874 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:37s\n",
            "epoch 270| loss: 0.97976 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:40s\n",
            "epoch 271| loss: 0.97907 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:43s\n",
            "epoch 272| loss: 0.97866 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:46s\n",
            "epoch 273| loss: 0.98125 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:48s\n",
            "epoch 274| loss: 0.97617 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:51s\n",
            "epoch 275| loss: 0.97436 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:54s\n",
            "epoch 276| loss: 0.97733 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:12:57s\n",
            "epoch 277| loss: 0.97759 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:00s\n",
            "epoch 278| loss: 0.97529 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:02s\n",
            "epoch 279| loss: 0.97899 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:05s\n",
            "epoch 280| loss: 0.97501 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:08s\n",
            "epoch 281| loss: 0.97807 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:10s\n",
            "epoch 282| loss: 0.97881 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:13s\n",
            "epoch 283| loss: 0.98196 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:16s\n",
            "epoch 284| loss: 0.97515 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:19s\n",
            "epoch 285| loss: 0.97553 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:22s\n",
            "epoch 286| loss: 0.97303 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:24s\n",
            "epoch 287| loss: 0.98028 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:27s\n",
            "epoch 288| loss: 0.97852 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:30s\n",
            "epoch 289| loss: 0.97717 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:33s\n",
            "epoch 290| loss: 0.97543 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:36s\n",
            "epoch 291| loss: 0.97447 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:39s\n",
            "epoch 292| loss: 0.97827 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:42s\n",
            "epoch 293| loss: 0.97667 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:44s\n",
            "epoch 294| loss: 0.97488 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:47s\n",
            "epoch 295| loss: 0.97251 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:50s\n",
            "epoch 296| loss: 0.97976 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:53s\n",
            "epoch 297| loss: 0.97555 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:55s\n",
            "epoch 298| loss: 0.97815 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:13:58s\n",
            "epoch 299| loss: 0.97713 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:01s\n",
            "epoch 300| loss: 0.97709 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:04s\n",
            "epoch 301| loss: 0.9786  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:06s\n",
            "epoch 302| loss: 0.98152 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:09s\n",
            "epoch 303| loss: 0.98025 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:12s\n",
            "epoch 304| loss: 0.98188 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:15s\n",
            "epoch 305| loss: 0.97956 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:17s\n",
            "epoch 306| loss: 0.97948 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:20s\n",
            "epoch 307| loss: 0.97736 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:23s\n",
            "epoch 308| loss: 0.97722 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:26s\n",
            "epoch 309| loss: 0.97939 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:28s\n",
            "epoch 310| loss: 0.98161 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:31s\n",
            "epoch 311| loss: 0.97926 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:34s\n",
            "epoch 312| loss: 0.98121 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:37s\n",
            "epoch 313| loss: 0.97896 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:39s\n",
            "epoch 314| loss: 0.97616 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:42s\n",
            "epoch 315| loss: 0.9805  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:45s\n",
            "epoch 316| loss: 0.97878 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:47s\n",
            "epoch 317| loss: 0.97774 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:50s\n",
            "epoch 318| loss: 0.97414 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:53s\n",
            "epoch 319| loss: 0.97846 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:56s\n",
            "epoch 320| loss: 0.97684 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:14:59s\n",
            "epoch 321| loss: 0.97867 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:01s\n",
            "epoch 322| loss: 0.97664 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:04s\n",
            "epoch 323| loss: 0.97624 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:07s\n",
            "epoch 324| loss: 0.98012 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:10s\n",
            "epoch 325| loss: 0.97659 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:12s\n",
            "epoch 326| loss: 0.97561 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:15s\n",
            "epoch 327| loss: 0.97552 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:18s\n",
            "epoch 328| loss: 0.97962 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:21s\n",
            "epoch 329| loss: 0.97785 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:23s\n",
            "epoch 330| loss: 0.97566 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:26s\n",
            "epoch 331| loss: 0.97779 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:29s\n",
            "epoch 332| loss: 0.97868 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:31s\n",
            "epoch 333| loss: 0.97813 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:34s\n",
            "epoch 334| loss: 0.97596 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:37s\n",
            "epoch 335| loss: 0.97858 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:40s\n",
            "epoch 336| loss: 0.97385 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:42s\n",
            "epoch 337| loss: 0.97677 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:45s\n",
            "epoch 338| loss: 0.97994 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:48s\n",
            "epoch 339| loss: 0.97633 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:51s\n",
            "epoch 340| loss: 0.97543 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:53s\n",
            "epoch 341| loss: 0.97495 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:56s\n",
            "epoch 342| loss: 0.97612 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:15:59s\n",
            "epoch 343| loss: 0.97561 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:02s\n",
            "epoch 344| loss: 0.97333 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:05s\n",
            "epoch 345| loss: 0.97805 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:07s\n",
            "epoch 346| loss: 0.9796  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:10s\n",
            "epoch 347| loss: 0.97878 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:13s\n",
            "epoch 348| loss: 0.97578 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:16s\n",
            "epoch 349| loss: 0.97637 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:18s\n",
            "epoch 350| loss: 0.9791  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:21s\n",
            "epoch 351| loss: 0.9786  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:24s\n",
            "epoch 352| loss: 0.97911 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:27s\n",
            "epoch 353| loss: 0.97855 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:29s\n",
            "epoch 354| loss: 0.97907 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:32s\n",
            "epoch 355| loss: 0.97852 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:35s\n",
            "epoch 356| loss: 0.97742 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:38s\n",
            "epoch 357| loss: 0.97684 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:40s\n",
            "epoch 358| loss: 0.97824 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:43s\n",
            "epoch 359| loss: 0.97755 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:46s\n",
            "epoch 360| loss: 0.97898 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:49s\n",
            "epoch 361| loss: 0.98026 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:51s\n",
            "epoch 362| loss: 0.97745 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:54s\n",
            "epoch 363| loss: 0.97895 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:16:57s\n",
            "epoch 364| loss: 0.97503 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:00s\n",
            "epoch 365| loss: 0.97524 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:02s\n",
            "epoch 366| loss: 0.97894 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:05s\n",
            "epoch 367| loss: 0.9736  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:08s\n",
            "epoch 368| loss: 0.97209 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:11s\n",
            "epoch 369| loss: 0.97628 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:13s\n",
            "epoch 370| loss: 0.97565 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:16s\n",
            "epoch 371| loss: 0.97736 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:19s\n",
            "epoch 372| loss: 0.97332 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:22s\n",
            "epoch 373| loss: 0.97478 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:24s\n",
            "epoch 374| loss: 0.97349 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:27s\n",
            "epoch 375| loss: 0.9731  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:30s\n",
            "epoch 376| loss: 0.97435 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:33s\n",
            "epoch 377| loss: 0.97682 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:35s\n",
            "epoch 378| loss: 0.97465 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:38s\n",
            "epoch 379| loss: 0.97737 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:41s\n",
            "epoch 380| loss: 0.97431 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:44s\n",
            "epoch 381| loss: 0.97794 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:46s\n",
            "epoch 382| loss: 0.97403 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:49s\n",
            "epoch 383| loss: 0.97525 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:52s\n",
            "epoch 384| loss: 0.97303 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:55s\n",
            "epoch 385| loss: 0.97509 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:17:57s\n",
            "epoch 386| loss: 0.9764  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:00s\n",
            "epoch 387| loss: 0.97612 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:03s\n",
            "epoch 388| loss: 0.97591 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:06s\n",
            "epoch 389| loss: 0.97952 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:09s\n",
            "epoch 390| loss: 0.97647 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:12s\n",
            "epoch 391| loss: 0.97417 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:14s\n",
            "epoch 392| loss: 0.97687 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:17s\n",
            "epoch 393| loss: 0.97278 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:20s\n",
            "epoch 394| loss: 0.97395 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:23s\n",
            "epoch 395| loss: 0.975   | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:26s\n",
            "epoch 396| loss: 0.97406 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:29s\n",
            "epoch 397| loss: 0.97381 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:31s\n",
            "epoch 398| loss: 0.97678 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:34s\n",
            "epoch 399| loss: 0.97359 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:37s\n",
            "epoch 400| loss: 0.97566 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:40s\n",
            "epoch 401| loss: 0.97745 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:42s\n",
            "epoch 402| loss: 0.97421 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:45s\n",
            "epoch 403| loss: 0.9749  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:48s\n",
            "epoch 404| loss: 0.9722  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:51s\n",
            "epoch 405| loss: 0.97355 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:53s\n",
            "epoch 406| loss: 0.97553 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:56s\n",
            "epoch 407| loss: 0.97587 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:18:59s\n",
            "epoch 408| loss: 0.97129 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:02s\n",
            "epoch 409| loss: 0.97487 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:04s\n",
            "epoch 410| loss: 0.97367 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:07s\n",
            "epoch 411| loss: 0.97777 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:10s\n",
            "epoch 412| loss: 0.97446 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:13s\n",
            "epoch 413| loss: 0.97771 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:15s\n",
            "epoch 414| loss: 0.97682 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:18s\n",
            "epoch 415| loss: 0.9768  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:21s\n",
            "epoch 416| loss: 0.97284 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:24s\n",
            "epoch 417| loss: 0.97693 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:26s\n",
            "epoch 418| loss: 0.97742 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:29s\n",
            "epoch 419| loss: 0.97391 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:32s\n",
            "epoch 420| loss: 0.97687 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:35s\n",
            "epoch 421| loss: 0.9757  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:37s\n",
            "epoch 422| loss: 0.97599 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:40s\n",
            "epoch 423| loss: 0.97771 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:43s\n",
            "epoch 424| loss: 0.97567 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:46s\n",
            "epoch 425| loss: 0.97888 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:48s\n",
            "epoch 426| loss: 0.97564 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:51s\n",
            "epoch 427| loss: 0.9776  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:54s\n",
            "epoch 428| loss: 0.97715 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:19:57s\n",
            "epoch 429| loss: 0.97768 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:00s\n",
            "epoch 430| loss: 0.97989 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:02s\n",
            "epoch 431| loss: 0.97699 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:05s\n",
            "epoch 432| loss: 0.9762  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:08s\n",
            "epoch 433| loss: 0.97794 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:11s\n",
            "epoch 434| loss: 0.97533 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:14s\n",
            "epoch 435| loss: 0.98    | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:16s\n",
            "epoch 436| loss: 0.97545 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:19s\n",
            "epoch 437| loss: 0.97956 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:22s\n",
            "epoch 438| loss: 0.97857 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:25s\n",
            "epoch 439| loss: 0.97462 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:27s\n",
            "epoch 440| loss: 0.97857 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:30s\n",
            "epoch 441| loss: 0.97881 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:33s\n",
            "epoch 442| loss: 0.97912 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:36s\n",
            "epoch 443| loss: 0.97738 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:38s\n",
            "epoch 444| loss: 0.97969 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:41s\n",
            "epoch 445| loss: 0.97943 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:44s\n",
            "epoch 446| loss: 0.98045 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:47s\n",
            "epoch 447| loss: 0.97924 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:49s\n",
            "epoch 448| loss: 0.97782 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:52s\n",
            "epoch 449| loss: 0.97993 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:55s\n",
            "epoch 450| loss: 0.97298 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:20:58s\n",
            "epoch 451| loss: 0.97661 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:00s\n",
            "epoch 452| loss: 0.97582 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:03s\n",
            "epoch 453| loss: 0.97815 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:06s\n",
            "epoch 454| loss: 0.9767  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:09s\n",
            "epoch 455| loss: 0.97689 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:11s\n",
            "epoch 456| loss: 0.97902 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:14s\n",
            "epoch 457| loss: 0.97717 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:17s\n",
            "epoch 458| loss: 0.97651 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:20s\n",
            "epoch 459| loss: 0.97553 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:22s\n",
            "epoch 460| loss: 0.97658 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:25s\n",
            "epoch 461| loss: 0.98166 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:28s\n",
            "epoch 462| loss: 0.97731 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:31s\n",
            "epoch 463| loss: 0.97709 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:34s\n",
            "epoch 464| loss: 0.97744 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:36s\n",
            "epoch 465| loss: 0.97703 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:39s\n",
            "epoch 466| loss: 0.97485 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:42s\n",
            "epoch 467| loss: 0.9747  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:45s\n",
            "epoch 468| loss: 0.97725 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:47s\n",
            "epoch 469| loss: 0.98113 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:50s\n",
            "epoch 470| loss: 0.97931 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:53s\n",
            "epoch 471| loss: 0.97985 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:56s\n",
            "epoch 472| loss: 0.97803 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:21:58s\n",
            "epoch 473| loss: 0.9784  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:01s\n",
            "epoch 474| loss: 0.97773 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:04s\n",
            "epoch 475| loss: 0.98096 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:06s\n",
            "epoch 476| loss: 0.97596 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:09s\n",
            "epoch 477| loss: 0.9827  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:12s\n",
            "epoch 478| loss: 0.97706 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:15s\n",
            "epoch 479| loss: 0.97836 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:17s\n",
            "epoch 480| loss: 0.98031 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:20s\n",
            "epoch 481| loss: 0.97683 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:23s\n",
            "epoch 482| loss: 0.97887 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:26s\n",
            "epoch 483| loss: 0.97936 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:28s\n",
            "epoch 484| loss: 0.97542 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:31s\n",
            "epoch 485| loss: 0.97721 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:34s\n",
            "epoch 486| loss: 0.97488 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:37s\n",
            "epoch 487| loss: 0.9751  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:40s\n",
            "epoch 488| loss: 0.97622 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:43s\n",
            "epoch 489| loss: 0.97697 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:46s\n",
            "epoch 490| loss: 0.97587 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:48s\n",
            "epoch 491| loss: 0.97913 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:51s\n",
            "epoch 492| loss: 0.97684 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:54s\n",
            "epoch 493| loss: 0.97425 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:22:57s\n",
            "epoch 494| loss: 0.97524 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:00s\n",
            "epoch 495| loss: 0.9777  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:02s\n",
            "epoch 496| loss: 0.97741 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:05s\n",
            "epoch 497| loss: 0.97725 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:08s\n",
            "epoch 498| loss: 0.97701 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:11s\n",
            "epoch 499| loss: 0.97769 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:14s\n",
            "epoch 500| loss: 0.97398 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:16s\n",
            "epoch 501| loss: 0.97744 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:19s\n",
            "epoch 502| loss: 0.97754 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:22s\n",
            "epoch 503| loss: 0.9754  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:25s\n",
            "epoch 504| loss: 0.97461 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:28s\n",
            "epoch 505| loss: 0.97277 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:30s\n",
            "epoch 506| loss: 0.97697 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:33s\n",
            "epoch 507| loss: 0.97719 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:36s\n",
            "epoch 508| loss: 0.97828 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:39s\n",
            "epoch 509| loss: 0.97501 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:42s\n",
            "epoch 510| loss: 0.9777  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:45s\n",
            "epoch 511| loss: 0.97488 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:48s\n",
            "epoch 512| loss: 0.97568 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:50s\n",
            "epoch 513| loss: 0.97608 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:53s\n",
            "epoch 514| loss: 0.97574 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:56s\n",
            "epoch 515| loss: 0.97571 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:23:59s\n",
            "epoch 516| loss: 0.97393 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:02s\n",
            "epoch 517| loss: 0.97541 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:05s\n",
            "epoch 518| loss: 0.97522 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:08s\n",
            "epoch 519| loss: 0.97751 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:10s\n",
            "epoch 520| loss: 0.97736 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:13s\n",
            "epoch 521| loss: 0.97831 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:16s\n",
            "epoch 522| loss: 0.97776 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:19s\n",
            "epoch 523| loss: 0.97752 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:22s\n",
            "epoch 524| loss: 0.97623 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:24s\n",
            "epoch 525| loss: 0.97739 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:27s\n",
            "epoch 526| loss: 0.97727 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:30s\n",
            "epoch 527| loss: 0.97484 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:33s\n",
            "epoch 528| loss: 0.97229 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:35s\n",
            "epoch 529| loss: 0.97183 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:38s\n",
            "epoch 530| loss: 0.9762  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:41s\n",
            "epoch 531| loss: 0.97561 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:44s\n",
            "epoch 532| loss: 0.9733  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:47s\n",
            "epoch 533| loss: 0.97335 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:49s\n",
            "epoch 534| loss: 0.97821 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:52s\n",
            "epoch 535| loss: 0.97509 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:55s\n",
            "epoch 536| loss: 0.9754  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:24:58s\n",
            "epoch 537| loss: 0.97412 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:01s\n",
            "epoch 538| loss: 0.97609 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:03s\n",
            "epoch 539| loss: 0.9716  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:06s\n",
            "epoch 540| loss: 0.97348 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:09s\n",
            "epoch 541| loss: 0.97151 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:12s\n",
            "epoch 542| loss: 0.97576 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:14s\n",
            "epoch 543| loss: 0.97446 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:17s\n",
            "epoch 544| loss: 0.97175 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:20s\n",
            "epoch 545| loss: 0.97118 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:23s\n",
            "epoch 546| loss: 0.97316 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:26s\n",
            "epoch 547| loss: 0.97064 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:28s\n",
            "epoch 548| loss: 0.97656 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:31s\n",
            "epoch 549| loss: 0.9737  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:34s\n",
            "epoch 550| loss: 0.97281 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:37s\n",
            "epoch 551| loss: 0.97492 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:40s\n",
            "epoch 552| loss: 0.97236 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:42s\n",
            "epoch 553| loss: 0.97385 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:45s\n",
            "epoch 554| loss: 0.9714  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:48s\n",
            "epoch 555| loss: 0.97194 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:51s\n",
            "epoch 556| loss: 0.97189 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:54s\n",
            "epoch 557| loss: 0.97107 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:25:57s\n",
            "epoch 558| loss: 0.97288 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:00s\n",
            "epoch 559| loss: 0.97307 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:02s\n",
            "epoch 560| loss: 0.97376 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:05s\n",
            "epoch 561| loss: 0.9741  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:08s\n",
            "epoch 562| loss: 0.97121 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:11s\n",
            "epoch 563| loss: 0.97042 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:14s\n",
            "epoch 564| loss: 0.96969 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:16s\n",
            "epoch 565| loss: 0.97254 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:19s\n",
            "epoch 566| loss: 0.96749 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:22s\n",
            "epoch 567| loss: 0.96988 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:25s\n",
            "epoch 568| loss: 0.97159 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:27s\n",
            "epoch 569| loss: 0.97109 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:30s\n",
            "epoch 570| loss: 0.96975 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:33s\n",
            "epoch 571| loss: 0.97212 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:36s\n",
            "epoch 572| loss: 0.97222 | train_accuracy: 0.50171 | val_accuracy: 0.48701 |  0:26:38s\n",
            "epoch 573| loss: 0.97717 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:41s\n",
            "epoch 574| loss: 0.97008 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:44s\n",
            "epoch 575| loss: 0.97101 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:47s\n",
            "epoch 576| loss: 0.9736  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:49s\n",
            "epoch 577| loss: 0.97145 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:52s\n",
            "epoch 578| loss: 0.97352 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:26:55s\n",
            "epoch 579| loss: 0.97511 | train_accuracy: 0.50291 | val_accuracy: 0.4886  |  0:26:58s\n",
            "epoch 580| loss: 0.97063 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:00s\n",
            "epoch 581| loss: 0.96994 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:03s\n",
            "epoch 582| loss: 0.97429 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:06s\n",
            "epoch 583| loss: 0.97637 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:11s\n",
            "epoch 584| loss: 0.97343 | train_accuracy: 0.50726 | val_accuracy: 0.48421 |  0:27:15s\n",
            "epoch 585| loss: 0.97069 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:19s\n",
            "epoch 586| loss: 0.97355 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:22s\n",
            "epoch 587| loss: 0.97303 | train_accuracy: 0.50566 | val_accuracy: 0.4914  |  0:27:24s\n",
            "epoch 588| loss: 0.97318 | train_accuracy: 0.50606 | val_accuracy: 0.4934  |  0:27:27s\n",
            "epoch 589| loss: 0.9733  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:30s\n",
            "epoch 590| loss: 0.9713  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:33s\n",
            "epoch 591| loss: 0.97437 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:35s\n",
            "epoch 592| loss: 0.97371 | train_accuracy: 0.50198 | val_accuracy: 0.48701 |  0:27:38s\n",
            "epoch 593| loss: 0.97402 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:41s\n",
            "epoch 594| loss: 0.97095 | train_accuracy: 0.50522 | val_accuracy: 0.4886  |  0:27:43s\n",
            "epoch 595| loss: 0.97241 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:46s\n",
            "epoch 596| loss: 0.9716  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:49s\n",
            "epoch 597| loss: 0.9711  | train_accuracy: 0.50646 | val_accuracy: 0.495   |  0:27:52s\n",
            "epoch 598| loss: 0.97438 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:55s\n",
            "epoch 599| loss: 0.97209 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:27:57s\n",
            "epoch 600| loss: 0.97292 | train_accuracy: 0.50655 | val_accuracy: 0.4882  |  0:28:00s\n",
            "epoch 601| loss: 0.97161 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:03s\n",
            "epoch 602| loss: 0.97129 | train_accuracy: 0.50544 | val_accuracy: 0.48661 |  0:28:05s\n",
            "epoch 603| loss: 0.97317 | train_accuracy: 0.50713 | val_accuracy: 0.48661 |  0:28:08s\n",
            "epoch 604| loss: 0.9732  | train_accuracy: 0.50646 | val_accuracy: 0.4882  |  0:28:11s\n",
            "epoch 605| loss: 0.97108 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:14s\n",
            "epoch 606| loss: 0.96863 | train_accuracy: 0.50535 | val_accuracy: 0.48221 |  0:28:17s\n",
            "epoch 607| loss: 0.96971 | train_accuracy: 0.50633 | val_accuracy: 0.48421 |  0:28:19s\n",
            "epoch 608| loss: 0.97152 | train_accuracy: 0.50571 | val_accuracy: 0.48501 |  0:28:22s\n",
            "epoch 609| loss: 0.97091 | train_accuracy: 0.50589 | val_accuracy: 0.4906  |  0:28:25s\n",
            "epoch 610| loss: 0.97297 | train_accuracy: 0.5058  | val_accuracy: 0.48701 |  0:28:28s\n",
            "epoch 611| loss: 0.97272 | train_accuracy: 0.50486 | val_accuracy: 0.48221 |  0:28:31s\n",
            "epoch 612| loss: 0.97127 | train_accuracy: 0.50731 | val_accuracy: 0.48701 |  0:28:34s\n",
            "epoch 613| loss: 0.97369 | train_accuracy: 0.50451 | val_accuracy: 0.4878  |  0:28:37s\n",
            "epoch 614| loss: 0.97275 | train_accuracy: 0.5046  | val_accuracy: 0.48501 |  0:28:40s\n",
            "epoch 615| loss: 0.97413 | train_accuracy: 0.50624 | val_accuracy: 0.4882  |  0:28:42s\n",
            "epoch 616| loss: 0.97589 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:45s\n",
            "epoch 617| loss: 0.97431 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:48s\n",
            "epoch 618| loss: 0.97539 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:51s\n",
            "epoch 619| loss: 0.97281 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:53s\n",
            "epoch 620| loss: 0.97513 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:56s\n",
            "epoch 621| loss: 0.97516 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:28:59s\n",
            "epoch 622| loss: 0.97108 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:02s\n",
            "epoch 623| loss: 0.9742  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:06s\n",
            "epoch 624| loss: 0.97269 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:09s\n",
            "epoch 625| loss: 0.97177 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:12s\n",
            "epoch 626| loss: 0.97372 | train_accuracy: 0.50198 | val_accuracy: 0.48101 |  0:29:15s\n",
            "epoch 627| loss: 0.97329 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:17s\n",
            "epoch 628| loss: 0.9723  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:20s\n",
            "epoch 629| loss: 0.9744  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:23s\n",
            "epoch 630| loss: 0.97421 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:26s\n",
            "epoch 631| loss: 0.97372 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:29s\n",
            "epoch 632| loss: 0.97293 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:32s\n",
            "epoch 633| loss: 0.97313 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:35s\n",
            "epoch 634| loss: 0.97223 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:37s\n",
            "epoch 635| loss: 0.9739  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:40s\n",
            "epoch 636| loss: 0.97483 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:43s\n",
            "epoch 637| loss: 0.97222 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:46s\n",
            "epoch 638| loss: 0.97477 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:48s\n",
            "epoch 639| loss: 0.9756  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:51s\n",
            "epoch 640| loss: 0.97193 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:54s\n",
            "epoch 641| loss: 0.97425 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:29:57s\n",
            "epoch 642| loss: 0.97446 | train_accuracy: 0.50087 | val_accuracy: 0.47541 |  0:29:59s\n",
            "epoch 643| loss: 0.97111 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:02s\n",
            "epoch 644| loss: 0.97285 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:05s\n",
            "epoch 645| loss: 0.97535 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:08s\n",
            "epoch 646| loss: 0.97139 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:10s\n",
            "epoch 647| loss: 0.97146 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:13s\n",
            "epoch 648| loss: 0.97299 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:16s\n",
            "epoch 649| loss: 0.97345 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:19s\n",
            "epoch 650| loss: 0.97054 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:21s\n",
            "epoch 651| loss: 0.97355 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:24s\n",
            "epoch 652| loss: 0.97451 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:27s\n",
            "epoch 653| loss: 0.97334 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:30s\n",
            "epoch 654| loss: 0.97478 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:32s\n",
            "epoch 655| loss: 0.97482 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:35s\n",
            "epoch 656| loss: 0.9752  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:38s\n",
            "epoch 657| loss: 0.97582 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:41s\n",
            "epoch 658| loss: 0.9752  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:43s\n",
            "epoch 659| loss: 0.97064 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:46s\n",
            "epoch 660| loss: 0.97396 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:49s\n",
            "epoch 661| loss: 0.97404 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:52s\n",
            "epoch 662| loss: 0.97375 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:55s\n",
            "epoch 663| loss: 0.97173 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:30:57s\n",
            "epoch 664| loss: 0.97285 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:00s\n",
            "epoch 665| loss: 0.9749  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:03s\n",
            "epoch 666| loss: 0.9765  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:06s\n",
            "epoch 667| loss: 0.97146 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:09s\n",
            "epoch 668| loss: 0.97382 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:12s\n",
            "epoch 669| loss: 0.97597 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:14s\n",
            "epoch 670| loss: 0.97381 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:17s\n",
            "epoch 671| loss: 0.97746 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:20s\n",
            "epoch 672| loss: 0.9735  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:22s\n",
            "epoch 673| loss: 0.97706 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:25s\n",
            "epoch 674| loss: 0.97494 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:28s\n",
            "epoch 675| loss: 0.97662 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:31s\n",
            "epoch 676| loss: 0.97345 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:33s\n",
            "epoch 677| loss: 0.9758  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:36s\n",
            "epoch 678| loss: 0.97411 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:40s\n",
            "epoch 679| loss: 0.97377 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:42s\n",
            "epoch 680| loss: 0.97614 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:45s\n",
            "epoch 681| loss: 0.97346 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:48s\n",
            "epoch 682| loss: 0.97303 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:51s\n",
            "epoch 683| loss: 0.97483 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:53s\n",
            "epoch 684| loss: 0.97052 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:56s\n",
            "epoch 685| loss: 0.97629 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:31:59s\n",
            "epoch 686| loss: 0.97105 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:02s\n",
            "epoch 687| loss: 0.97308 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:04s\n",
            "epoch 688| loss: 0.97153 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:07s\n",
            "epoch 689| loss: 0.97361 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:10s\n",
            "epoch 690| loss: 0.97286 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:13s\n",
            "epoch 691| loss: 0.97657 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:16s\n",
            "epoch 692| loss: 0.97646 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:18s\n",
            "epoch 693| loss: 0.97497 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:21s\n",
            "epoch 694| loss: 0.9778  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:24s\n",
            "epoch 695| loss: 0.97415 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:27s\n",
            "epoch 696| loss: 0.97216 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:30s\n",
            "epoch 697| loss: 0.97374 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:32s\n",
            "epoch 698| loss: 0.9713  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:35s\n",
            "epoch 699| loss: 0.97046 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:38s\n",
            "epoch 700| loss: 0.97186 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:41s\n",
            "epoch 701| loss: 0.97371 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:43s\n",
            "epoch 702| loss: 0.97072 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:46s\n",
            "epoch 703| loss: 0.97515 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:49s\n",
            "epoch 704| loss: 0.97259 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:52s\n",
            "epoch 705| loss: 0.97289 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:54s\n",
            "epoch 706| loss: 0.96989 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:32:57s\n",
            "epoch 707| loss: 0.97218 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:00s\n",
            "epoch 708| loss: 0.97393 | train_accuracy: 0.50282 | val_accuracy: 0.4982  |  0:33:03s\n",
            "epoch 709| loss: 0.97256 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:05s\n",
            "epoch 710| loss: 0.97227 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:08s\n",
            "epoch 711| loss: 0.97321 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:11s\n",
            "epoch 712| loss: 0.97144 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:14s\n",
            "epoch 713| loss: 0.973   | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:16s\n",
            "epoch 714| loss: 0.97016 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:19s\n",
            "epoch 715| loss: 0.97077 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:22s\n",
            "epoch 716| loss: 0.97122 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:25s\n",
            "epoch 717| loss: 0.96911 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:27s\n",
            "epoch 718| loss: 0.97266 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:30s\n",
            "epoch 719| loss: 0.97098 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:33s\n",
            "epoch 720| loss: 0.97126 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:36s\n",
            "epoch 721| loss: 0.97207 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:39s\n",
            "epoch 722| loss: 0.97189 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:41s\n",
            "epoch 723| loss: 0.9685  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:44s\n",
            "epoch 724| loss: 0.97013 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:47s\n",
            "epoch 725| loss: 0.97134 | train_accuracy: 0.50016 | val_accuracy: 0.4942  |  0:33:50s\n",
            "epoch 726| loss: 0.96812 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:53s\n",
            "epoch 727| loss: 0.96662 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:55s\n",
            "epoch 728| loss: 0.96663 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:33:58s\n",
            "epoch 729| loss: 0.97012 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:01s\n",
            "epoch 730| loss: 0.96769 | train_accuracy: 0.50162 | val_accuracy: 0.491   |  0:34:04s\n",
            "epoch 731| loss: 0.97323 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:06s\n",
            "epoch 732| loss: 0.97026 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:09s\n",
            "epoch 733| loss: 0.97149 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:12s\n",
            "epoch 734| loss: 0.97028 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:15s\n",
            "epoch 735| loss: 0.97401 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:17s\n",
            "epoch 736| loss: 0.97139 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:20s\n",
            "epoch 737| loss: 0.97087 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:23s\n",
            "epoch 738| loss: 0.97612 | train_accuracy: 0.49984 | val_accuracy: 0.501   |  0:34:26s\n",
            "epoch 739| loss: 0.97153 | train_accuracy: 0.49936 | val_accuracy: 0.4946  |  0:34:28s\n",
            "epoch 740| loss: 0.97117 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:33s\n",
            "epoch 741| loss: 0.97531 | train_accuracy: 0.50255 | val_accuracy: 0.497   |  0:34:36s\n",
            "epoch 742| loss: 0.97592 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:39s\n",
            "epoch 743| loss: 0.97559 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:42s\n",
            "epoch 744| loss: 0.97626 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:45s\n",
            "epoch 745| loss: 0.97437 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:47s\n",
            "epoch 746| loss: 0.97438 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:50s\n",
            "epoch 747| loss: 0.97419 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:53s\n",
            "epoch 748| loss: 0.97522 | train_accuracy: 0.50184 | val_accuracy: 0.4914  |  0:34:56s\n",
            "epoch 749| loss: 0.97127 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:34:58s\n",
            "epoch 750| loss: 0.97186 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:01s\n",
            "epoch 751| loss: 0.97107 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:04s\n",
            "epoch 752| loss: 0.97349 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:07s\n",
            "epoch 753| loss: 0.9742  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:10s\n",
            "epoch 754| loss: 0.97391 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:12s\n",
            "epoch 755| loss: 0.97146 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:15s\n",
            "epoch 756| loss: 0.97139 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:18s\n",
            "epoch 757| loss: 0.97095 | train_accuracy: 0.50318 | val_accuracy: 0.5086  |  0:35:21s\n",
            "epoch 758| loss: 0.97348 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:24s\n",
            "epoch 759| loss: 0.96866 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:26s\n",
            "epoch 760| loss: 0.96961 | train_accuracy: 0.50438 | val_accuracy: 0.5034  |  0:35:29s\n",
            "epoch 761| loss: 0.97317 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:32s\n",
            "epoch 762| loss: 0.97094 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:35s\n",
            "epoch 763| loss: 0.96858 | train_accuracy: 0.5042  | val_accuracy: 0.5014  |  0:35:37s\n",
            "epoch 764| loss: 0.97062 | train_accuracy: 0.50162 | val_accuracy: 0.4998  |  0:35:40s\n",
            "epoch 765| loss: 0.97269 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:43s\n",
            "epoch 766| loss: 0.97452 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:46s\n",
            "epoch 767| loss: 0.97343 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:48s\n",
            "epoch 768| loss: 0.97554 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:51s\n",
            "epoch 769| loss: 0.9775  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:54s\n",
            "epoch 770| loss: 0.9801  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:35:57s\n",
            "epoch 771| loss: 0.97956 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:00s\n",
            "epoch 772| loss: 0.97621 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:02s\n",
            "epoch 773| loss: 0.97356 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:05s\n",
            "epoch 774| loss: 0.97206 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:08s\n",
            "epoch 775| loss: 0.97228 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:11s\n",
            "epoch 776| loss: 0.97614 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:14s\n",
            "epoch 777| loss: 0.97405 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:17s\n",
            "epoch 778| loss: 0.9762  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:20s\n",
            "epoch 779| loss: 0.97836 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:23s\n",
            "epoch 780| loss: 0.97529 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:26s\n",
            "epoch 781| loss: 0.97389 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:28s\n",
            "epoch 782| loss: 0.97664 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:31s\n",
            "epoch 783| loss: 0.97269 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:34s\n",
            "epoch 784| loss: 0.97669 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:37s\n",
            "epoch 785| loss: 0.97794 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:39s\n",
            "epoch 786| loss: 0.97554 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:42s\n",
            "epoch 787| loss: 0.9777  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:45s\n",
            "epoch 788| loss: 0.9766  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:48s\n",
            "epoch 789| loss: 0.97456 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:51s\n",
            "epoch 790| loss: 0.97418 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:55s\n",
            "epoch 791| loss: 0.97629 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:36:58s\n",
            "epoch 792| loss: 0.97738 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:00s\n",
            "epoch 793| loss: 0.97558 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:03s\n",
            "epoch 794| loss: 0.97599 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:06s\n",
            "epoch 795| loss: 0.97291 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:09s\n",
            "epoch 796| loss: 0.97434 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:11s\n",
            "epoch 797| loss: 0.97305 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:14s\n",
            "epoch 798| loss: 0.9735  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:17s\n",
            "epoch 799| loss: 0.97549 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:20s\n",
            "epoch 800| loss: 0.97635 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:22s\n",
            "epoch 801| loss: 0.97623 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:25s\n",
            "epoch 802| loss: 0.9761  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:28s\n",
            "epoch 803| loss: 0.97198 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:31s\n",
            "epoch 804| loss: 0.97202 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:33s\n",
            "epoch 805| loss: 0.97372 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:36s\n",
            "epoch 806| loss: 0.97267 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:39s\n",
            "epoch 807| loss: 0.97812 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:42s\n",
            "epoch 808| loss: 0.97454 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:45s\n",
            "epoch 809| loss: 0.97338 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:47s\n",
            "epoch 810| loss: 0.97505 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:50s\n",
            "epoch 811| loss: 0.97384 | train_accuracy: 0.4994  | val_accuracy: 0.48541 |  0:37:53s\n",
            "epoch 812| loss: 0.97604 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:56s\n",
            "epoch 813| loss: 0.97539 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:37:59s\n",
            "epoch 814| loss: 0.97453 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:01s\n",
            "epoch 815| loss: 0.97722 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:04s\n",
            "epoch 816| loss: 0.97401 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:07s\n",
            "epoch 817| loss: 0.97469 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:10s\n",
            "epoch 818| loss: 0.9783  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:12s\n",
            "epoch 819| loss: 0.97607 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:15s\n",
            "epoch 820| loss: 0.97574 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:18s\n",
            "epoch 821| loss: 0.9771  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:21s\n",
            "epoch 822| loss: 0.97578 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:24s\n",
            "epoch 823| loss: 0.9763  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:27s\n",
            "epoch 824| loss: 0.97667 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:30s\n",
            "epoch 825| loss: 0.97573 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:32s\n",
            "epoch 826| loss: 0.97379 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:35s\n",
            "epoch 827| loss: 0.97603 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:38s\n",
            "epoch 828| loss: 0.9788  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:41s\n",
            "epoch 829| loss: 0.97553 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:44s\n",
            "epoch 830| loss: 0.97735 | train_accuracy: 0.5022  | val_accuracy: 0.4914  |  0:38:47s\n",
            "epoch 831| loss: 0.9782  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:50s\n",
            "epoch 832| loss: 0.9757  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:38:52s\n",
            "epoch 833| loss: 0.9761  | train_accuracy: 0.50398 | val_accuracy: 0.4946  |  0:38:55s\n",
            "epoch 834| loss: 0.97531 | train_accuracy: 0.50295 | val_accuracy: 0.4926  |  0:38:58s\n",
            "epoch 835| loss: 0.97657 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:01s\n",
            "epoch 836| loss: 0.97393 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:04s\n",
            "epoch 837| loss: 0.97432 | train_accuracy: 0.5018  | val_accuracy: 0.4882  |  0:39:07s\n",
            "epoch 838| loss: 0.97338 | train_accuracy: 0.49984 | val_accuracy: 0.489   |  0:39:10s\n",
            "epoch 839| loss: 0.97686 | train_accuracy: 0.5014  | val_accuracy: 0.4978  |  0:39:12s\n",
            "epoch 840| loss: 0.97471 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:15s\n",
            "epoch 841| loss: 0.97242 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:18s\n",
            "epoch 842| loss: 0.9746  | train_accuracy: 0.50433 | val_accuracy: 0.4902  |  0:39:21s\n",
            "epoch 843| loss: 0.97333 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:23s\n",
            "epoch 844| loss: 0.97664 | train_accuracy: 0.50295 | val_accuracy: 0.4954  |  0:39:26s\n",
            "epoch 845| loss: 0.97484 | train_accuracy: 0.50251 | val_accuracy: 0.4998  |  0:39:29s\n",
            "epoch 846| loss: 0.97684 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:32s\n",
            "epoch 847| loss: 0.97657 | train_accuracy: 0.5014  | val_accuracy: 0.4882  |  0:39:34s\n",
            "epoch 848| loss: 0.97599 | train_accuracy: 0.50149 | val_accuracy: 0.4934  |  0:39:38s\n",
            "epoch 849| loss: 0.97562 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:42s\n",
            "epoch 850| loss: 0.9735  | train_accuracy: 0.50247 | val_accuracy: 0.4922  |  0:39:45s\n",
            "epoch 851| loss: 0.97431 | train_accuracy: 0.50229 | val_accuracy: 0.48741 |  0:39:48s\n",
            "epoch 852| loss: 0.97105 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:50s\n",
            "epoch 853| loss: 0.97287 | train_accuracy: 0.50442 | val_accuracy: 0.4898  |  0:39:53s\n",
            "epoch 854| loss: 0.97144 | train_accuracy: 0.50389 | val_accuracy: 0.4882  |  0:39:56s\n",
            "epoch 855| loss: 0.97723 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:39:59s\n",
            "epoch 856| loss: 0.97607 | train_accuracy: 0.50664 | val_accuracy: 0.48701 |  0:40:02s\n",
            "epoch 857| loss: 0.97558 | train_accuracy: 0.50398 | val_accuracy: 0.48501 |  0:40:04s\n",
            "epoch 858| loss: 0.97619 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:07s\n",
            "epoch 859| loss: 0.97912 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:10s\n",
            "epoch 860| loss: 0.97681 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:13s\n",
            "epoch 861| loss: 0.97848 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:15s\n",
            "epoch 862| loss: 0.97603 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:18s\n",
            "epoch 863| loss: 0.97715 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:21s\n",
            "epoch 864| loss: 0.97704 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:24s\n",
            "epoch 865| loss: 0.97548 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:27s\n",
            "epoch 866| loss: 0.97728 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:30s\n",
            "epoch 867| loss: 0.97715 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:32s\n",
            "epoch 868| loss: 0.97567 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:36s\n",
            "epoch 869| loss: 0.97516 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:39s\n",
            "epoch 870| loss: 0.97532 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:41s\n",
            "epoch 871| loss: 0.97738 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:44s\n",
            "epoch 872| loss: 0.9776  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:47s\n",
            "epoch 873| loss: 0.97476 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:50s\n",
            "epoch 874| loss: 0.97533 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:52s\n",
            "epoch 875| loss: 0.97412 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:40:55s\n",
            "epoch 876| loss: 0.97316 | train_accuracy: 0.50091 | val_accuracy: 0.501   |  0:40:58s\n",
            "epoch 877| loss: 0.97429 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:01s\n",
            "epoch 878| loss: 0.97425 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:03s\n",
            "epoch 879| loss: 0.97282 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:06s\n",
            "epoch 880| loss: 0.97567 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:09s\n",
            "epoch 881| loss: 0.9743  | train_accuracy: 0.50167 | val_accuracy: 0.4982  |  0:41:12s\n",
            "epoch 882| loss: 0.9758  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:14s\n",
            "epoch 883| loss: 0.97214 | train_accuracy: 0.50353 | val_accuracy: 0.4998  |  0:41:17s\n",
            "epoch 884| loss: 0.97149 | train_accuracy: 0.5018  | val_accuracy: 0.4974  |  0:41:20s\n",
            "epoch 885| loss: 0.97516 | train_accuracy: 0.50171 | val_accuracy: 0.4966  |  0:41:23s\n",
            "epoch 886| loss: 0.97204 | train_accuracy: 0.5046  | val_accuracy: 0.4974  |  0:41:25s\n",
            "epoch 887| loss: 0.97432 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:29s\n",
            "epoch 888| loss: 0.97423 | train_accuracy: 0.50096 | val_accuracy: 0.5002  |  0:41:32s\n",
            "epoch 889| loss: 0.97283 | train_accuracy: 0.50069 | val_accuracy: 0.493   |  0:41:34s\n",
            "epoch 890| loss: 0.97198 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:37s\n",
            "epoch 891| loss: 0.97157 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:41:40s\n",
            "epoch 892| loss: 0.97115 | train_accuracy: 0.49976 | val_accuracy: 0.4886  |  0:41:43s\n",
            "epoch 893| loss: 0.97448 | train_accuracy: 0.50224 | val_accuracy: 0.4954  |  0:41:45s\n",
            "epoch 894| loss: 0.97183 | train_accuracy: 0.50411 | val_accuracy: 0.4962  |  0:41:48s\n",
            "epoch 895| loss: 0.97536 | train_accuracy: 0.50713 | val_accuracy: 0.4958  |  0:41:51s\n",
            "epoch 896| loss: 0.97198 | train_accuracy: 0.50678 | val_accuracy: 0.4978  |  0:41:54s\n",
            "epoch 897| loss: 0.97147 | train_accuracy: 0.50486 | val_accuracy: 0.491   |  0:41:56s\n",
            "epoch 898| loss: 0.97053 | train_accuracy: 0.50535 | val_accuracy: 0.4954  |  0:41:59s\n",
            "epoch 899| loss: 0.97525 | train_accuracy: 0.50429 | val_accuracy: 0.4982  |  0:42:02s\n",
            "epoch 900| loss: 0.9732  | train_accuracy: 0.50318 | val_accuracy: 0.4954  |  0:42:05s\n",
            "epoch 901| loss: 0.97295 | train_accuracy: 0.50518 | val_accuracy: 0.4938  |  0:42:08s\n",
            "epoch 902| loss: 0.97274 | train_accuracy: 0.5046  | val_accuracy: 0.493   |  0:42:10s\n",
            "epoch 903| loss: 0.97113 | train_accuracy: 0.50424 | val_accuracy: 0.4966  |  0:42:13s\n",
            "epoch 904| loss: 0.97334 | train_accuracy: 0.50513 | val_accuracy: 0.4934  |  0:42:16s\n",
            "epoch 905| loss: 0.97349 | train_accuracy: 0.50562 | val_accuracy: 0.4898  |  0:42:19s\n",
            "epoch 906| loss: 0.96972 | train_accuracy: 0.50682 | val_accuracy: 0.4946  |  0:42:21s\n",
            "epoch 907| loss: 0.96952 | train_accuracy: 0.50646 | val_accuracy: 0.4934  |  0:42:24s\n",
            "epoch 908| loss: 0.97269 | train_accuracy: 0.50566 | val_accuracy: 0.4994  |  0:42:27s\n",
            "epoch 909| loss: 0.97258 | train_accuracy: 0.50615 | val_accuracy: 0.5014  |  0:42:29s\n",
            "epoch 910| loss: 0.97143 | train_accuracy: 0.50415 | val_accuracy: 0.5038  |  0:42:32s\n",
            "epoch 911| loss: 0.97528 | train_accuracy: 0.50442 | val_accuracy: 0.5006  |  0:42:35s\n",
            "epoch 912| loss: 0.97349 | train_accuracy: 0.50375 | val_accuracy: 0.4982  |  0:42:38s\n",
            "epoch 913| loss: 0.97525 | train_accuracy: 0.5026  | val_accuracy: 0.4942  |  0:42:40s\n",
            "epoch 914| loss: 0.97255 | train_accuracy: 0.50473 | val_accuracy: 0.4974  |  0:42:43s\n",
            "epoch 915| loss: 0.97121 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:42:46s\n",
            "epoch 916| loss: 0.97703 | train_accuracy: 0.505   | val_accuracy: 0.4958  |  0:42:49s\n",
            "epoch 917| loss: 0.97703 | train_accuracy: 0.5038  | val_accuracy: 0.4954  |  0:42:51s\n",
            "epoch 918| loss: 0.97421 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:42:54s\n",
            "epoch 919| loss: 0.97373 | train_accuracy: 0.50491 | val_accuracy: 0.4938  |  0:42:57s\n",
            "epoch 920| loss: 0.97541 | train_accuracy: 0.50411 | val_accuracy: 0.4942  |  0:42:59s\n",
            "epoch 921| loss: 0.97166 | train_accuracy: 0.50615 | val_accuracy: 0.4926  |  0:43:02s\n",
            "epoch 922| loss: 0.97352 | train_accuracy: 0.50451 | val_accuracy: 0.4922  |  0:43:05s\n",
            "epoch 923| loss: 0.9758  | train_accuracy: 0.50384 | val_accuracy: 0.4934  |  0:43:08s\n",
            "epoch 924| loss: 0.97429 | train_accuracy: 0.50558 | val_accuracy: 0.4926  |  0:43:11s\n",
            "epoch 925| loss: 0.97047 | train_accuracy: 0.50282 | val_accuracy: 0.4886  |  0:43:14s\n",
            "epoch 926| loss: 0.97376 | train_accuracy: 0.50255 | val_accuracy: 0.495   |  0:43:17s\n",
            "epoch 927| loss: 0.97326 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:43:19s\n",
            "epoch 928| loss: 0.97716 | train_accuracy: 0.50407 | val_accuracy: 0.497   |  0:43:22s\n",
            "epoch 929| loss: 0.9764  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:43:25s\n",
            "epoch 930| loss: 0.97412 | train_accuracy: 0.50153 | val_accuracy: 0.4946  |  0:43:28s\n",
            "epoch 931| loss: 0.97286 | train_accuracy: 0.50402 | val_accuracy: 0.4918  |  0:43:30s\n",
            "epoch 932| loss: 0.97275 | train_accuracy: 0.50464 | val_accuracy: 0.4926  |  0:43:33s\n",
            "epoch 933| loss: 0.97713 | train_accuracy: 0.50398 | val_accuracy: 0.4922  |  0:43:36s\n",
            "epoch 934| loss: 0.97279 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:43:40s\n",
            "epoch 935| loss: 0.977   | train_accuracy: 0.50424 | val_accuracy: 0.4966  |  0:43:45s\n",
            "epoch 936| loss: 0.97416 | train_accuracy: 0.50451 | val_accuracy: 0.4978  |  0:43:47s\n",
            "epoch 937| loss: 0.97354 | train_accuracy: 0.50389 | val_accuracy: 0.4938  |  0:43:50s\n",
            "epoch 938| loss: 0.97544 | train_accuracy: 0.50384 | val_accuracy: 0.4974  |  0:43:53s\n",
            "epoch 939| loss: 0.97394 | train_accuracy: 0.50549 | val_accuracy: 0.495   |  0:43:56s\n",
            "epoch 940| loss: 0.97412 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:01s\n",
            "epoch 941| loss: 0.97169 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:04s\n",
            "epoch 942| loss: 0.97243 | train_accuracy: 0.50531 | val_accuracy: 0.4978  |  0:44:07s\n",
            "epoch 943| loss: 0.97383 | train_accuracy: 0.50522 | val_accuracy: 0.4934  |  0:44:10s\n",
            "epoch 944| loss: 0.9723  | train_accuracy: 0.50478 | val_accuracy: 0.493   |  0:44:13s\n",
            "epoch 945| loss: 0.972   | train_accuracy: 0.50526 | val_accuracy: 0.495   |  0:44:15s\n",
            "epoch 946| loss: 0.9726  | train_accuracy: 0.50602 | val_accuracy: 0.4998  |  0:44:18s\n",
            "epoch 947| loss: 0.97642 | train_accuracy: 0.50513 | val_accuracy: 0.5002  |  0:44:21s\n",
            "epoch 948| loss: 0.97174 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:24s\n",
            "epoch 949| loss: 0.97176 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:26s\n",
            "epoch 950| loss: 0.97373 | train_accuracy: 0.50327 | val_accuracy: 0.4954  |  0:44:29s\n",
            "epoch 951| loss: 0.97424 | train_accuracy: 0.50375 | val_accuracy: 0.4902  |  0:44:32s\n",
            "epoch 952| loss: 0.97219 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:35s\n",
            "epoch 953| loss: 0.97251 | train_accuracy: 0.50104 | val_accuracy: 0.489   |  0:44:37s\n",
            "epoch 954| loss: 0.97648 | train_accuracy: 0.50042 | val_accuracy: 0.48661 |  0:44:40s\n",
            "epoch 955| loss: 0.97067 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:43s\n",
            "epoch 956| loss: 0.97498 | train_accuracy: 0.50078 | val_accuracy: 0.4962  |  0:44:45s\n",
            "epoch 957| loss: 0.97389 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:48s\n",
            "epoch 958| loss: 0.97645 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:51s\n",
            "epoch 959| loss: 0.97481 | train_accuracy: 0.50198 | val_accuracy: 0.497   |  0:44:54s\n",
            "epoch 960| loss: 0.97354 | train_accuracy: 0.50318 | val_accuracy: 0.5038  |  0:44:57s\n",
            "epoch 961| loss: 0.97415 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:44:59s\n",
            "epoch 962| loss: 0.97493 | train_accuracy: 0.50349 | val_accuracy: 0.5094  |  0:45:02s\n",
            "epoch 963| loss: 0.9714  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:45:05s\n",
            "epoch 964| loss: 0.97531 | train_accuracy: 0.50029 | val_accuracy: 0.5094  |  0:45:08s\n",
            "epoch 965| loss: 0.97222 | train_accuracy: 0.50144 | val_accuracy: 0.5062  |  0:45:11s\n",
            "epoch 966| loss: 0.97551 | train_accuracy: 0.50109 | val_accuracy: 0.509   |  0:45:13s\n",
            "epoch 967| loss: 0.9755  | train_accuracy: 0.49958 | val_accuracy: 0.4974  |  0:45:16s\n",
            "epoch 968| loss: 0.97468 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:45:19s\n",
            "epoch 969| loss: 0.97322 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:45:22s\n",
            "epoch 970| loss: 0.97443 | train_accuracy: 0.50051 | val_accuracy: 0.5054  |  0:45:24s\n",
            "epoch 971| loss: 0.9754  | train_accuracy: 0.49962 | val_accuracy: 0.5038  |  0:45:27s\n",
            "epoch 972| loss: 0.97503 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:45:30s\n",
            "epoch 973| loss: 0.97338 | train_accuracy: 0.50091 | val_accuracy: 0.499   |  0:45:33s\n",
            "epoch 974| loss: 0.97206 | train_accuracy: 0.50211 | val_accuracy: 0.5066  |  0:45:35s\n",
            "epoch 975| loss: 0.97516 | train_accuracy: 0.50082 | val_accuracy: 0.5046  |  0:45:38s\n",
            "epoch 976| loss: 0.97427 | train_accuracy: 0.50358 | val_accuracy: 0.5002  |  0:45:41s\n",
            "epoch 977| loss: 0.9727  | train_accuracy: 0.50389 | val_accuracy: 0.499   |  0:45:43s\n",
            "epoch 978| loss: 0.97652 | train_accuracy: 0.50367 | val_accuracy: 0.505   |  0:45:46s\n",
            "epoch 979| loss: 0.97203 | train_accuracy: 0.50349 | val_accuracy: 0.5042  |  0:45:50s\n",
            "epoch 980| loss: 0.97618 | train_accuracy: 0.50149 | val_accuracy: 0.5058  |  0:45:52s\n",
            "epoch 981| loss: 0.97548 | train_accuracy: 0.50353 | val_accuracy: 0.4974  |  0:45:55s\n",
            "epoch 982| loss: 0.97321 | train_accuracy: 0.5006  | val_accuracy: 0.4946  |  0:45:58s\n",
            "epoch 983| loss: 0.97454 | train_accuracy: 0.50096 | val_accuracy: 0.4894  |  0:46:01s\n",
            "epoch 984| loss: 0.97299 | train_accuracy: 0.5014  | val_accuracy: 0.48741 |  0:46:03s\n",
            "epoch 985| loss: 0.97361 | train_accuracy: 0.50016 | val_accuracy: 0.4902  |  0:46:06s\n",
            "epoch 986| loss: 0.974   | train_accuracy: 0.49971 | val_accuracy: 0.48421 |  0:46:09s\n",
            "epoch 987| loss: 0.97655 | train_accuracy: 0.49842 | val_accuracy: 0.4906  |  0:46:12s\n",
            "epoch 988| loss: 0.97499 | train_accuracy: 0.49829 | val_accuracy: 0.495   |  0:46:14s\n",
            "epoch 989| loss: 0.97615 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:46:17s\n",
            "epoch 990| loss: 0.9724  | train_accuracy: 0.50113 | val_accuracy: 0.4906  |  0:46:20s\n",
            "epoch 991| loss: 0.97233 | train_accuracy: 0.50171 | val_accuracy: 0.5002  |  0:46:23s\n",
            "epoch 992| loss: 0.97245 | train_accuracy: 0.50091 | val_accuracy: 0.505   |  0:46:25s\n",
            "epoch 993| loss: 0.97403 | train_accuracy: 0.50047 | val_accuracy: 0.5026  |  0:46:28s\n",
            "epoch 994| loss: 0.97167 | train_accuracy: 0.50282 | val_accuracy: 0.5022  |  0:46:31s\n",
            "epoch 995| loss: 0.97465 | train_accuracy: 0.50335 | val_accuracy: 0.5046  |  0:46:34s\n",
            "epoch 996| loss: 0.97823 | train_accuracy: 0.50264 | val_accuracy: 0.5026  |  0:46:36s\n",
            "epoch 997| loss: 0.97467 | train_accuracy: 0.50096 | val_accuracy: 0.499   |  0:46:39s\n",
            "epoch 998| loss: 0.97821 | train_accuracy: 0.50016 | val_accuracy: 0.5082  |  0:46:42s\n",
            "epoch 999| loss: 0.9716  | train_accuracy: 0.5026  | val_accuracy: 0.5034  |  0:46:44s\n",
            "epoch 1000| loss: 0.97376 | train_accuracy: 0.50424 | val_accuracy: 0.5046  |  0:46:47s\n",
            "epoch 1001| loss: 0.97728 | train_accuracy: 0.50353 | val_accuracy: 0.4994  |  0:46:50s\n",
            "epoch 1002| loss: 0.97232 | train_accuracy: 0.50375 | val_accuracy: 0.4974  |  0:46:53s\n",
            "epoch 1003| loss: 0.97418 | train_accuracy: 0.50029 | val_accuracy: 0.4998  |  0:46:55s\n",
            "epoch 1004| loss: 0.97133 | train_accuracy: 0.50486 | val_accuracy: 0.4942  |  0:46:58s\n",
            "epoch 1005| loss: 0.97127 | train_accuracy: 0.50327 | val_accuracy: 0.4986  |  0:47:01s\n",
            "epoch 1006| loss: 0.9751  | train_accuracy: 0.50184 | val_accuracy: 0.4954  |  0:47:04s\n",
            "epoch 1007| loss: 0.97244 | train_accuracy: 0.50544 | val_accuracy: 0.5066  |  0:47:06s\n",
            "epoch 1008| loss: 0.97563 | train_accuracy: 0.50402 | val_accuracy: 0.4982  |  0:47:09s\n",
            "epoch 1009| loss: 0.9734  | train_accuracy: 0.50535 | val_accuracy: 0.5002  |  0:47:12s\n",
            "epoch 1010| loss: 0.97202 | train_accuracy: 0.50331 | val_accuracy: 0.4986  |  0:47:15s\n",
            "epoch 1011| loss: 0.97659 | train_accuracy: 0.50638 | val_accuracy: 0.4982  |  0:47:17s\n",
            "epoch 1012| loss: 0.97456 | train_accuracy: 0.50309 | val_accuracy: 0.4974  |  0:47:20s\n",
            "epoch 1013| loss: 0.97481 | train_accuracy: 0.50402 | val_accuracy: 0.5018  |  0:47:23s\n",
            "epoch 1014| loss: 0.9769  | train_accuracy: 0.50331 | val_accuracy: 0.5034  |  0:47:26s\n",
            "epoch 1015| loss: 0.97595 | train_accuracy: 0.50509 | val_accuracy: 0.505   |  0:47:29s\n",
            "epoch 1016| loss: 0.97733 | train_accuracy: 0.50349 | val_accuracy: 0.5054  |  0:47:32s\n",
            "epoch 1017| loss: 0.97627 | train_accuracy: 0.50464 | val_accuracy: 0.5058  |  0:47:34s\n",
            "epoch 1018| loss: 0.97749 | train_accuracy: 0.50646 | val_accuracy: 0.5098  |  0:47:37s\n",
            "epoch 1019| loss: 0.97638 | train_accuracy: 0.50367 | val_accuracy: 0.5058  |  0:47:40s\n",
            "epoch 1020| loss: 0.97179 | train_accuracy: 0.50411 | val_accuracy: 0.5082  |  0:47:43s\n",
            "epoch 1021| loss: 0.97635 | train_accuracy: 0.50344 | val_accuracy: 0.5014  |  0:47:45s\n",
            "epoch 1022| loss: 0.974   | train_accuracy: 0.50553 | val_accuracy: 0.4978  |  0:47:48s\n",
            "epoch 1023| loss: 0.97389 | train_accuracy: 0.50566 | val_accuracy: 0.5002  |  0:47:51s\n",
            "epoch 1024| loss: 0.97461 | train_accuracy: 0.5038  | val_accuracy: 0.4994  |  0:47:53s\n",
            "epoch 1025| loss: 0.97586 | train_accuracy: 0.5042  | val_accuracy: 0.5022  |  0:47:56s\n",
            "epoch 1026| loss: 0.97689 | train_accuracy: 0.50651 | val_accuracy: 0.5014  |  0:47:59s\n",
            "epoch 1027| loss: 0.9741  | train_accuracy: 0.50611 | val_accuracy: 0.5042  |  0:48:02s\n",
            "epoch 1028| loss: 0.97595 | train_accuracy: 0.50602 | val_accuracy: 0.5062  |  0:48:04s\n",
            "epoch 1029| loss: 0.97699 | train_accuracy: 0.50584 | val_accuracy: 0.5022  |  0:48:07s\n",
            "epoch 1030| loss: 0.97747 | train_accuracy: 0.50629 | val_accuracy: 0.5034  |  0:48:10s\n",
            "epoch 1031| loss: 0.97653 | train_accuracy: 0.5082  | val_accuracy: 0.505   |  0:48:13s\n",
            "epoch 1032| loss: 0.97489 | train_accuracy: 0.5078  | val_accuracy: 0.505   |  0:48:15s\n",
            "epoch 1033| loss: 0.97344 | train_accuracy: 0.50797 | val_accuracy: 0.5018  |  0:48:18s\n",
            "epoch 1034| loss: 0.97469 | train_accuracy: 0.50762 | val_accuracy: 0.501   |  0:48:21s\n",
            "epoch 1035| loss: 0.97473 | train_accuracy: 0.50589 | val_accuracy: 0.5018  |  0:48:24s\n",
            "epoch 1036| loss: 0.97566 | train_accuracy: 0.50851 | val_accuracy: 0.5022  |  0:48:26s\n",
            "epoch 1037| loss: 0.9754  | train_accuracy: 0.5074  | val_accuracy: 0.5054  |  0:48:29s\n",
            "epoch 1038| loss: 0.97193 | train_accuracy: 0.50713 | val_accuracy: 0.505   |  0:48:32s\n",
            "epoch 1039| loss: 0.97294 | train_accuracy: 0.50869 | val_accuracy: 0.503   |  0:48:35s\n",
            "epoch 1040| loss: 0.97249 | train_accuracy: 0.50695 | val_accuracy: 0.5038  |  0:48:38s\n",
            "epoch 1041| loss: 0.97587 | train_accuracy: 0.50877 | val_accuracy: 0.5042  |  0:48:40s\n",
            "epoch 1042| loss: 0.97491 | train_accuracy: 0.50744 | val_accuracy: 0.507   |  0:48:43s\n",
            "epoch 1043| loss: 0.97527 | train_accuracy: 0.50935 | val_accuracy: 0.503   |  0:48:46s\n",
            "epoch 1044| loss: 0.9723  | train_accuracy: 0.51064 | val_accuracy: 0.5034  |  0:48:49s\n",
            "epoch 1045| loss: 0.97299 | train_accuracy: 0.50744 | val_accuracy: 0.5018  |  0:48:51s\n",
            "epoch 1046| loss: 0.97472 | train_accuracy: 0.50971 | val_accuracy: 0.505   |  0:48:54s\n",
            "epoch 1047| loss: 0.97384 | train_accuracy: 0.50993 | val_accuracy: 0.5034  |  0:48:57s\n",
            "epoch 1048| loss: 0.971   | train_accuracy: 0.50793 | val_accuracy: 0.509   |  0:49:00s\n",
            "epoch 1049| loss: 0.97409 | train_accuracy: 0.50784 | val_accuracy: 0.5034  |  0:49:02s\n",
            "epoch 1050| loss: 0.97632 | train_accuracy: 0.5082  | val_accuracy: 0.5066  |  0:49:05s\n",
            "epoch 1051| loss: 0.97388 | train_accuracy: 0.50926 | val_accuracy: 0.5066  |  0:49:08s\n",
            "epoch 1052| loss: 0.97559 | train_accuracy: 0.50864 | val_accuracy: 0.5034  |  0:49:10s\n",
            "epoch 1053| loss: 0.975   | train_accuracy: 0.50882 | val_accuracy: 0.4998  |  0:49:13s\n",
            "epoch 1054| loss: 0.97298 | train_accuracy: 0.50846 | val_accuracy: 0.503   |  0:49:16s\n",
            "epoch 1055| loss: 0.97132 | train_accuracy: 0.50997 | val_accuracy: 0.501   |  0:49:19s\n",
            "epoch 1056| loss: 0.9728  | train_accuracy: 0.50882 | val_accuracy: 0.501   |  0:49:21s\n",
            "epoch 1057| loss: 0.97155 | train_accuracy: 0.51002 | val_accuracy: 0.5022  |  0:49:24s\n",
            "epoch 1058| loss: 0.97152 | train_accuracy: 0.51122 | val_accuracy: 0.5042  |  0:49:27s\n",
            "epoch 1059| loss: 0.97027 | train_accuracy: 0.50966 | val_accuracy: 0.507   |  0:49:30s\n",
            "epoch 1060| loss: 0.97175 | train_accuracy: 0.51055 | val_accuracy: 0.501   |  0:49:33s\n",
            "epoch 1061| loss: 0.97612 | train_accuracy: 0.50966 | val_accuracy: 0.5006  |  0:49:36s\n",
            "epoch 1062| loss: 0.97148 | train_accuracy: 0.50953 | val_accuracy: 0.5038  |  0:49:38s\n",
            "epoch 1063| loss: 0.97142 | train_accuracy: 0.50882 | val_accuracy: 0.5018  |  0:49:41s\n",
            "epoch 1064| loss: 0.97314 | train_accuracy: 0.50722 | val_accuracy: 0.4998  |  0:49:44s\n",
            "epoch 1065| loss: 0.97588 | train_accuracy: 0.50775 | val_accuracy: 0.4966  |  0:49:47s\n",
            "epoch 1066| loss: 0.97256 | train_accuracy: 0.50398 | val_accuracy: 0.4894  |  0:49:50s\n",
            "epoch 1067| loss: 0.97376 | train_accuracy: 0.50384 | val_accuracy: 0.493   |  0:49:52s\n",
            "epoch 1068| loss: 0.97391 | train_accuracy: 0.50198 | val_accuracy: 0.4974  |  0:49:55s\n",
            "epoch 1069| loss: 0.97297 | train_accuracy: 0.50504 | val_accuracy: 0.4978  |  0:49:58s\n",
            "epoch 1070| loss: 0.97407 | train_accuracy: 0.50455 | val_accuracy: 0.4986  |  0:50:00s\n",
            "epoch 1071| loss: 0.97505 | train_accuracy: 0.50469 | val_accuracy: 0.4982  |  0:50:03s\n",
            "epoch 1072| loss: 0.97288 | train_accuracy: 0.5058  | val_accuracy: 0.497   |  0:50:06s\n",
            "epoch 1073| loss: 0.97146 | train_accuracy: 0.50602 | val_accuracy: 0.4962  |  0:50:09s\n",
            "epoch 1074| loss: 0.9707  | train_accuracy: 0.50549 | val_accuracy: 0.4994  |  0:50:11s\n",
            "epoch 1075| loss: 0.97459 | train_accuracy: 0.5078  | val_accuracy: 0.4986  |  0:50:14s\n",
            "epoch 1076| loss: 0.97278 | train_accuracy: 0.50709 | val_accuracy: 0.499   |  0:50:17s\n",
            "epoch 1077| loss: 0.97323 | train_accuracy: 0.50682 | val_accuracy: 0.4978  |  0:50:20s\n",
            "epoch 1078| loss: 0.97344 | train_accuracy: 0.50558 | val_accuracy: 0.495   |  0:50:22s\n",
            "epoch 1079| loss: 0.97095 | train_accuracy: 0.50606 | val_accuracy: 0.4978  |  0:50:25s\n",
            "epoch 1080| loss: 0.97349 | train_accuracy: 0.50864 | val_accuracy: 0.4994  |  0:50:28s\n",
            "epoch 1081| loss: 0.97215 | train_accuracy: 0.50749 | val_accuracy: 0.4942  |  0:50:31s\n",
            "epoch 1082| loss: 0.9735  | train_accuracy: 0.50833 | val_accuracy: 0.4974  |  0:50:33s\n",
            "epoch 1083| loss: 0.97229 | train_accuracy: 0.50904 | val_accuracy: 0.503   |  0:50:36s\n",
            "epoch 1084| loss: 0.97315 | train_accuracy: 0.50775 | val_accuracy: 0.5034  |  0:50:39s\n",
            "epoch 1085| loss: 0.97211 | train_accuracy: 0.507   | val_accuracy: 0.5018  |  0:50:41s\n",
            "epoch 1086| loss: 0.97407 | train_accuracy: 0.509   | val_accuracy: 0.5042  |  0:50:44s\n",
            "epoch 1087| loss: 0.97155 | train_accuracy: 0.51015 | val_accuracy: 0.5046  |  0:50:47s\n",
            "epoch 1088| loss: 0.97129 | train_accuracy: 0.5094  | val_accuracy: 0.5002  |  0:50:50s\n",
            "epoch 1089| loss: 0.97115 | train_accuracy: 0.51086 | val_accuracy: 0.509   |  0:50:52s\n",
            "epoch 1090| loss: 0.97829 | train_accuracy: 0.51002 | val_accuracy: 0.5046  |  0:50:55s\n",
            "epoch 1091| loss: 0.97117 | train_accuracy: 0.509   | val_accuracy: 0.5002  |  0:50:58s\n",
            "epoch 1092| loss: 0.96851 | train_accuracy: 0.50606 | val_accuracy: 0.4986  |  0:51:01s\n",
            "epoch 1093| loss: 0.97094 | train_accuracy: 0.51077 | val_accuracy: 0.5034  |  0:51:03s\n",
            "epoch 1094| loss: 0.97626 | train_accuracy: 0.51086 | val_accuracy: 0.499   |  0:51:06s\n",
            "epoch 1095| loss: 0.97478 | train_accuracy: 0.5094  | val_accuracy: 0.5018  |  0:51:09s\n",
            "epoch 1096| loss: 0.97217 | train_accuracy: 0.50957 | val_accuracy: 0.5074  |  0:51:12s\n",
            "epoch 1097| loss: 0.97104 | train_accuracy: 0.51122 | val_accuracy: 0.5046  |  0:51:14s\n",
            "epoch 1098| loss: 0.97479 | train_accuracy: 0.5114  | val_accuracy: 0.5022  |  0:51:17s\n",
            "epoch 1099| loss: 0.97325 | train_accuracy: 0.50673 | val_accuracy: 0.5078  |  0:51:20s\n",
            "epoch 1100| loss: 0.97644 | train_accuracy: 0.50478 | val_accuracy: 0.5022  |  0:51:23s\n",
            "epoch 1101| loss: 0.97659 | train_accuracy: 0.5054  | val_accuracy: 0.5014  |  0:51:25s\n",
            "epoch 1102| loss: 0.97681 | train_accuracy: 0.50455 | val_accuracy: 0.5014  |  0:51:28s\n",
            "epoch 1103| loss: 0.9768  | train_accuracy: 0.50682 | val_accuracy: 0.5054  |  0:51:31s\n",
            "epoch 1104| loss: 0.97432 | train_accuracy: 0.5074  | val_accuracy: 0.503   |  0:51:34s\n",
            "epoch 1105| loss: 0.97456 | train_accuracy: 0.50802 | val_accuracy: 0.5054  |  0:51:37s\n",
            "epoch 1106| loss: 0.97489 | train_accuracy: 0.50215 | val_accuracy: 0.5106  |  0:51:41s\n",
            "epoch 1107| loss: 0.9756  | train_accuracy: 0.50384 | val_accuracy: 0.5066  |  0:51:45s\n",
            "epoch 1108| loss: 0.97361 | train_accuracy: 0.50522 | val_accuracy: 0.505   |  0:51:48s\n",
            "epoch 1109| loss: 0.97433 | train_accuracy: 0.50469 | val_accuracy: 0.5074  |  0:51:50s\n",
            "epoch 1110| loss: 0.97501 | train_accuracy: 0.50571 | val_accuracy: 0.5018  |  0:51:53s\n",
            "epoch 1111| loss: 0.97859 | train_accuracy: 0.5046  | val_accuracy: 0.5026  |  0:51:56s\n",
            "epoch 1112| loss: 0.97419 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:51:59s\n",
            "epoch 1113| loss: 0.97303 | train_accuracy: 0.50633 | val_accuracy: 0.509   |  0:52:01s\n",
            "epoch 1114| loss: 0.97632 | train_accuracy: 0.50313 | val_accuracy: 0.4982  |  0:52:04s\n",
            "epoch 1115| loss: 0.97601 | train_accuracy: 0.50455 | val_accuracy: 0.4962  |  0:52:07s\n",
            "epoch 1116| loss: 0.97518 | train_accuracy: 0.50482 | val_accuracy: 0.4974  |  0:52:10s\n",
            "epoch 1117| loss: 0.97048 | train_accuracy: 0.5058  | val_accuracy: 0.5038  |  0:52:12s\n",
            "epoch 1118| loss: 0.9742  | train_accuracy: 0.50491 | val_accuracy: 0.4998  |  0:52:15s\n",
            "epoch 1119| loss: 0.97385 | train_accuracy: 0.50407 | val_accuracy: 0.4958  |  0:52:18s\n",
            "epoch 1120| loss: 0.97699 | train_accuracy: 0.50495 | val_accuracy: 0.501   |  0:52:21s\n",
            "epoch 1121| loss: 0.97725 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:52:23s\n",
            "epoch 1122| loss: 0.97693 | train_accuracy: 0.50402 | val_accuracy: 0.4974  |  0:52:26s\n",
            "epoch 1123| loss: 0.97441 | train_accuracy: 0.50371 | val_accuracy: 0.5002  |  0:52:29s\n",
            "epoch 1124| loss: 0.97481 | train_accuracy: 0.50064 | val_accuracy: 0.5046  |  0:52:32s\n",
            "epoch 1125| loss: 0.97309 | train_accuracy: 0.5038  | val_accuracy: 0.5074  |  0:52:34s\n",
            "epoch 1126| loss: 0.97711 | train_accuracy: 0.50464 | val_accuracy: 0.5026  |  0:52:37s\n",
            "epoch 1127| loss: 0.97744 | train_accuracy: 0.50495 | val_accuracy: 0.5094  |  0:52:40s\n",
            "epoch 1128| loss: 0.97661 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:52:43s\n",
            "epoch 1129| loss: 0.97428 | train_accuracy: 0.50402 | val_accuracy: 0.501   |  0:52:45s\n",
            "epoch 1130| loss: 0.97165 | train_accuracy: 0.50144 | val_accuracy: 0.501   |  0:52:48s\n",
            "epoch 1131| loss: 0.97433 | train_accuracy: 0.50282 | val_accuracy: 0.5046  |  0:52:51s\n",
            "epoch 1132| loss: 0.97619 | train_accuracy: 0.50535 | val_accuracy: 0.5058  |  0:52:54s\n",
            "epoch 1133| loss: 0.97489 | train_accuracy: 0.50504 | val_accuracy: 0.5034  |  0:52:57s\n",
            "epoch 1134| loss: 0.9764  | train_accuracy: 0.50358 | val_accuracy: 0.4982  |  0:52:59s\n",
            "epoch 1135| loss: 0.97873 | train_accuracy: 0.50091 | val_accuracy: 0.5022  |  0:53:02s\n",
            "epoch 1136| loss: 0.97389 | train_accuracy: 0.50375 | val_accuracy: 0.507   |  0:53:05s\n",
            "epoch 1137| loss: 0.9761  | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:53:08s\n",
            "epoch 1138| loss: 0.97686 | train_accuracy: 0.50478 | val_accuracy: 0.5006  |  0:53:11s\n",
            "epoch 1139| loss: 0.97747 | train_accuracy: 0.50411 | val_accuracy: 0.5062  |  0:53:13s\n",
            "epoch 1140| loss: 0.97419 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:53:16s\n",
            "epoch 1141| loss: 0.9741  | train_accuracy: 0.49927 | val_accuracy: 0.5066  |  0:53:19s\n",
            "epoch 1142| loss: 0.97334 | train_accuracy: 0.50153 | val_accuracy: 0.503   |  0:53:22s\n",
            "epoch 1143| loss: 0.97654 | train_accuracy: 0.50167 | val_accuracy: 0.505   |  0:53:25s\n",
            "epoch 1144| loss: 0.97366 | train_accuracy: 0.50149 | val_accuracy: 0.5042  |  0:53:28s\n",
            "epoch 1145| loss: 0.97367 | train_accuracy: 0.5022  | val_accuracy: 0.5102  |  0:53:30s\n",
            "epoch 1146| loss: 0.976   | train_accuracy: 0.5014  | val_accuracy: 0.5042  |  0:53:33s\n",
            "epoch 1147| loss: 0.97536 | train_accuracy: 0.50153 | val_accuracy: 0.5074  |  0:53:36s\n",
            "epoch 1148| loss: 0.97529 | train_accuracy: 0.50207 | val_accuracy: 0.4982  |  0:53:39s\n",
            "epoch 1149| loss: 0.97628 | train_accuracy: 0.50367 | val_accuracy: 0.499   |  0:53:42s\n",
            "epoch 1150| loss: 0.97549 | train_accuracy: 0.49993 | val_accuracy: 0.497   |  0:53:45s\n",
            "epoch 1151| loss: 0.97633 | train_accuracy: 0.50175 | val_accuracy: 0.4994  |  0:53:48s\n",
            "epoch 1152| loss: 0.97552 | train_accuracy: 0.50278 | val_accuracy: 0.4974  |  0:53:50s\n",
            "epoch 1153| loss: 0.9753  | train_accuracy: 0.50424 | val_accuracy: 0.5022  |  0:53:53s\n",
            "epoch 1154| loss: 0.9757  | train_accuracy: 0.50113 | val_accuracy: 0.4958  |  0:53:56s\n",
            "epoch 1155| loss: 0.97517 | train_accuracy: 0.49927 | val_accuracy: 0.5018  |  0:53:59s\n",
            "epoch 1156| loss: 0.9742  | train_accuracy: 0.5054  | val_accuracy: 0.501   |  0:54:02s\n",
            "epoch 1157| loss: 0.97173 | train_accuracy: 0.50393 | val_accuracy: 0.4998  |  0:54:05s\n",
            "epoch 1158| loss: 0.97752 | train_accuracy: 0.50242 | val_accuracy: 0.4986  |  0:54:08s\n",
            "epoch 1159| loss: 0.97343 | train_accuracy: 0.5002  | val_accuracy: 0.4978  |  0:54:11s\n",
            "epoch 1160| loss: 0.97688 | train_accuracy: 0.50233 | val_accuracy: 0.5006  |  0:54:13s\n",
            "epoch 1161| loss: 0.97615 | train_accuracy: 0.50389 | val_accuracy: 0.5046  |  0:54:16s\n",
            "epoch 1162| loss: 0.97456 | train_accuracy: 0.50193 | val_accuracy: 0.5058  |  0:54:19s\n",
            "epoch 1163| loss: 0.97498 | train_accuracy: 0.50367 | val_accuracy: 0.5078  |  0:54:22s\n",
            "epoch 1164| loss: 0.97204 | train_accuracy: 0.50353 | val_accuracy: 0.5118  |  0:54:25s\n",
            "epoch 1165| loss: 0.97453 | train_accuracy: 0.501   | val_accuracy: 0.5026  |  0:54:27s\n",
            "epoch 1166| loss: 0.97473 | train_accuracy: 0.50415 | val_accuracy: 0.5098  |  0:54:30s\n",
            "epoch 1167| loss: 0.97506 | train_accuracy: 0.50282 | val_accuracy: 0.5062  |  0:54:33s\n",
            "epoch 1168| loss: 0.97546 | train_accuracy: 0.5038  | val_accuracy: 0.5102  |  0:54:36s\n",
            "epoch 1169| loss: 0.97297 | train_accuracy: 0.5042  | val_accuracy: 0.51259 |  0:54:38s\n",
            "epoch 1170| loss: 0.97586 | train_accuracy: 0.50495 | val_accuracy: 0.51259 |  0:54:41s\n",
            "epoch 1171| loss: 0.97515 | train_accuracy: 0.50415 | val_accuracy: 0.5118  |  0:54:44s\n",
            "epoch 1172| loss: 0.97432 | train_accuracy: 0.50526 | val_accuracy: 0.51299 |  0:54:47s\n",
            "epoch 1173| loss: 0.9752  | train_accuracy: 0.50433 | val_accuracy: 0.5114  |  0:54:50s\n",
            "epoch 1174| loss: 0.97737 | train_accuracy: 0.50495 | val_accuracy: 0.51299 |  0:54:52s\n",
            "epoch 1175| loss: 0.9761  | train_accuracy: 0.50526 | val_accuracy: 0.5118  |  0:54:56s\n",
            "epoch 1176| loss: 0.97248 | train_accuracy: 0.50757 | val_accuracy: 0.51579 |  0:55:00s\n",
            "epoch 1177| loss: 0.9739  | train_accuracy: 0.50495 | val_accuracy: 0.51259 |  0:55:03s\n",
            "epoch 1178| loss: 0.97296 | train_accuracy: 0.50602 | val_accuracy: 0.5118  |  0:55:06s\n",
            "epoch 1179| loss: 0.96987 | train_accuracy: 0.50709 | val_accuracy: 0.5114  |  0:55:09s\n",
            "epoch 1180| loss: 0.9743  | train_accuracy: 0.507   | val_accuracy: 0.5034  |  0:55:11s\n",
            "epoch 1181| loss: 0.97259 | train_accuracy: 0.50602 | val_accuracy: 0.5094  |  0:55:14s\n",
            "epoch 1182| loss: 0.9738  | train_accuracy: 0.50598 | val_accuracy: 0.509   |  0:55:17s\n",
            "epoch 1183| loss: 0.97261 | train_accuracy: 0.50651 | val_accuracy: 0.5086  |  0:55:20s\n",
            "epoch 1184| loss: 0.97456 | train_accuracy: 0.50438 | val_accuracy: 0.5018  |  0:55:23s\n",
            "epoch 1185| loss: 0.97226 | train_accuracy: 0.50518 | val_accuracy: 0.5078  |  0:55:25s\n",
            "epoch 1186| loss: 0.97252 | train_accuracy: 0.50486 | val_accuracy: 0.5022  |  0:55:28s\n",
            "epoch 1187| loss: 0.97267 | train_accuracy: 0.50482 | val_accuracy: 0.503   |  0:55:31s\n",
            "epoch 1188| loss: 0.96998 | train_accuracy: 0.50611 | val_accuracy: 0.5082  |  0:55:33s\n",
            "epoch 1189| loss: 0.97344 | train_accuracy: 0.50713 | val_accuracy: 0.5066  |  0:55:36s\n",
            "epoch 1190| loss: 0.97049 | train_accuracy: 0.50629 | val_accuracy: 0.5082  |  0:55:39s\n",
            "epoch 1191| loss: 0.97319 | train_accuracy: 0.5078  | val_accuracy: 0.51259 |  0:55:42s\n",
            "epoch 1192| loss: 0.97205 | train_accuracy: 0.50598 | val_accuracy: 0.5018  |  0:55:44s\n",
            "epoch 1193| loss: 0.97256 | train_accuracy: 0.50646 | val_accuracy: 0.5058  |  0:55:47s\n",
            "epoch 1194| loss: 0.96972 | train_accuracy: 0.50793 | val_accuracy: 0.5086  |  0:55:50s\n",
            "epoch 1195| loss: 0.97119 | train_accuracy: 0.50709 | val_accuracy: 0.503   |  0:55:53s\n",
            "epoch 1196| loss: 0.96948 | train_accuracy: 0.5086  | val_accuracy: 0.5034  |  0:55:56s\n",
            "epoch 1197| loss: 0.97255 | train_accuracy: 0.50824 | val_accuracy: 0.5014  |  0:56:00s\n",
            "epoch 1198| loss: 0.97402 | train_accuracy: 0.50709 | val_accuracy: 0.4966  |  0:56:03s\n",
            "epoch 1199| loss: 0.97441 | train_accuracy: 0.50877 | val_accuracy: 0.5054  |  0:56:06s\n",
            "epoch 1200| loss: 0.97265 | train_accuracy: 0.5086  | val_accuracy: 0.4946  |  0:56:08s\n",
            "epoch 1201| loss: 0.9709  | train_accuracy: 0.50802 | val_accuracy: 0.5006  |  0:56:11s\n",
            "epoch 1202| loss: 0.9727  | train_accuracy: 0.50957 | val_accuracy: 0.5062  |  0:56:14s\n",
            "epoch 1203| loss: 0.97304 | train_accuracy: 0.50771 | val_accuracy: 0.4998  |  0:56:16s\n",
            "epoch 1204| loss: 0.97194 | train_accuracy: 0.50891 | val_accuracy: 0.501   |  0:56:19s\n",
            "epoch 1205| loss: 0.97054 | train_accuracy: 0.51015 | val_accuracy: 0.5038  |  0:56:22s\n",
            "epoch 1206| loss: 0.97169 | train_accuracy: 0.50749 | val_accuracy: 0.4978  |  0:56:25s\n",
            "epoch 1207| loss: 0.97166 | train_accuracy: 0.50966 | val_accuracy: 0.5038  |  0:56:28s\n",
            "epoch 1208| loss: 0.97318 | train_accuracy: 0.51055 | val_accuracy: 0.5078  |  0:56:30s\n",
            "epoch 1209| loss: 0.97192 | train_accuracy: 0.50913 | val_accuracy: 0.5042  |  0:56:33s\n",
            "epoch 1210| loss: 0.96978 | train_accuracy: 0.50611 | val_accuracy: 0.501   |  0:56:36s\n",
            "epoch 1211| loss: 0.97371 | train_accuracy: 0.50571 | val_accuracy: 0.5014  |  0:56:39s\n",
            "epoch 1212| loss: 0.97122 | train_accuracy: 0.50793 | val_accuracy: 0.5046  |  0:56:41s\n",
            "epoch 1213| loss: 0.96986 | train_accuracy: 0.5122  | val_accuracy: 0.509   |  0:56:44s\n",
            "epoch 1214| loss: 0.97026 | train_accuracy: 0.50949 | val_accuracy: 0.5014  |  0:56:47s\n",
            "epoch 1215| loss: 0.97238 | train_accuracy: 0.50735 | val_accuracy: 0.5034  |  0:56:50s\n",
            "epoch 1216| loss: 0.9711  | train_accuracy: 0.50971 | val_accuracy: 0.5046  |  0:56:52s\n",
            "epoch 1217| loss: 0.97131 | train_accuracy: 0.51011 | val_accuracy: 0.509   |  0:56:55s\n",
            "epoch 1218| loss: 0.97284 | train_accuracy: 0.50815 | val_accuracy: 0.5078  |  0:56:58s\n",
            "epoch 1219| loss: 0.96995 | train_accuracy: 0.50837 | val_accuracy: 0.5042  |  0:57:00s\n",
            "epoch 1220| loss: 0.9722  | train_accuracy: 0.51184 | val_accuracy: 0.51299 |  0:57:03s\n",
            "epoch 1221| loss: 0.96851 | train_accuracy: 0.51068 | val_accuracy: 0.5094  |  0:57:06s\n",
            "epoch 1222| loss: 0.97077 | train_accuracy: 0.50864 | val_accuracy: 0.5058  |  0:57:09s\n",
            "epoch 1223| loss: 0.97233 | train_accuracy: 0.50762 | val_accuracy: 0.5038  |  0:57:11s\n",
            "epoch 1224| loss: 0.97055 | train_accuracy: 0.5094  | val_accuracy: 0.5046  |  0:57:14s\n",
            "epoch 1225| loss: 0.97276 | train_accuracy: 0.50957 | val_accuracy: 0.5046  |  0:57:17s\n",
            "epoch 1226| loss: 0.968   | train_accuracy: 0.50957 | val_accuracy: 0.505   |  0:57:20s\n",
            "epoch 1227| loss: 0.97184 | train_accuracy: 0.51042 | val_accuracy: 0.5038  |  0:57:22s\n",
            "epoch 1228| loss: 0.97033 | train_accuracy: 0.51104 | val_accuracy: 0.5078  |  0:57:25s\n",
            "epoch 1229| loss: 0.96964 | train_accuracy: 0.50802 | val_accuracy: 0.5054  |  0:57:28s\n",
            "epoch 1230| loss: 0.96841 | train_accuracy: 0.50864 | val_accuracy: 0.5086  |  0:57:31s\n",
            "epoch 1231| loss: 0.9681  | train_accuracy: 0.50877 | val_accuracy: 0.5102  |  0:57:33s\n",
            "epoch 1232| loss: 0.96934 | train_accuracy: 0.51064 | val_accuracy: 0.5062  |  0:57:36s\n",
            "epoch 1233| loss: 0.9692  | train_accuracy: 0.51046 | val_accuracy: 0.5082  |  0:57:39s\n",
            "epoch 1234| loss: 0.9702  | train_accuracy: 0.50886 | val_accuracy: 0.5034  |  0:57:41s\n",
            "epoch 1235| loss: 0.96858 | train_accuracy: 0.51108 | val_accuracy: 0.5074  |  0:57:44s\n",
            "epoch 1236| loss: 0.97421 | train_accuracy: 0.50922 | val_accuracy: 0.5006  |  0:57:47s\n",
            "epoch 1237| loss: 0.96898 | train_accuracy: 0.50869 | val_accuracy: 0.5062  |  0:57:50s\n",
            "epoch 1238| loss: 0.97225 | train_accuracy: 0.5098  | val_accuracy: 0.5046  |  0:57:52s\n",
            "epoch 1239| loss: 0.97209 | train_accuracy: 0.51006 | val_accuracy: 0.5054  |  0:57:55s\n",
            "epoch 1240| loss: 0.97192 | train_accuracy: 0.51015 | val_accuracy: 0.5022  |  0:57:58s\n",
            "epoch 1241| loss: 0.96827 | train_accuracy: 0.50913 | val_accuracy: 0.5002  |  0:58:01s\n",
            "epoch 1242| loss: 0.97043 | train_accuracy: 0.51024 | val_accuracy: 0.5062  |  0:58:03s\n",
            "epoch 1243| loss: 0.97015 | train_accuracy: 0.51068 | val_accuracy: 0.5074  |  0:58:06s\n",
            "epoch 1244| loss: 0.97011 | train_accuracy: 0.50949 | val_accuracy: 0.5078  |  0:58:09s\n",
            "epoch 1245| loss: 0.97206 | train_accuracy: 0.50931 | val_accuracy: 0.5074  |  0:58:12s\n",
            "epoch 1246| loss: 0.97147 | train_accuracy: 0.509   | val_accuracy: 0.5042  |  0:58:15s\n",
            "epoch 1247| loss: 0.96988 | train_accuracy: 0.5102  | val_accuracy: 0.5042  |  0:58:17s\n",
            "epoch 1248| loss: 0.9711  | train_accuracy: 0.50917 | val_accuracy: 0.505   |  0:58:20s\n",
            "epoch 1249| loss: 0.97114 | train_accuracy: 0.5102  | val_accuracy: 0.505   |  0:58:23s\n",
            "epoch 1250| loss: 0.97101 | train_accuracy: 0.50962 | val_accuracy: 0.5074  |  0:58:25s\n",
            "epoch 1251| loss: 0.97316 | train_accuracy: 0.5098  | val_accuracy: 0.5094  |  0:58:28s\n",
            "epoch 1252| loss: 0.97102 | train_accuracy: 0.50949 | val_accuracy: 0.5066  |  0:58:31s\n",
            "epoch 1253| loss: 0.97402 | train_accuracy: 0.50984 | val_accuracy: 0.5086  |  0:58:34s\n",
            "epoch 1254| loss: 0.9707  | train_accuracy: 0.50775 | val_accuracy: 0.5078  |  0:58:37s\n",
            "epoch 1255| loss: 0.97151 | train_accuracy: 0.50988 | val_accuracy: 0.5074  |  0:58:40s\n",
            "epoch 1256| loss: 0.968   | train_accuracy: 0.50953 | val_accuracy: 0.503   |  0:58:42s\n",
            "epoch 1257| loss: 0.97118 | train_accuracy: 0.5086  | val_accuracy: 0.5026  |  0:58:45s\n",
            "epoch 1258| loss: 0.97314 | train_accuracy: 0.5106  | val_accuracy: 0.5038  |  0:58:48s\n",
            "epoch 1259| loss: 0.97098 | train_accuracy: 0.5098  | val_accuracy: 0.5058  |  0:58:51s\n",
            "epoch 1260| loss: 0.97178 | train_accuracy: 0.50882 | val_accuracy: 0.5062  |  0:58:53s\n",
            "epoch 1261| loss: 0.973   | train_accuracy: 0.50926 | val_accuracy: 0.5034  |  0:58:56s\n",
            "epoch 1262| loss: 0.97066 | train_accuracy: 0.50962 | val_accuracy: 0.5062  |  0:58:59s\n",
            "epoch 1263| loss: 0.96936 | train_accuracy: 0.51002 | val_accuracy: 0.5018  |  0:59:01s\n",
            "epoch 1264| loss: 0.96888 | train_accuracy: 0.51117 | val_accuracy: 0.5042  |  0:59:04s\n",
            "epoch 1265| loss: 0.96986 | train_accuracy: 0.5106  | val_accuracy: 0.5054  |  0:59:07s\n",
            "epoch 1266| loss: 0.96951 | train_accuracy: 0.51015 | val_accuracy: 0.501   |  0:59:10s\n",
            "epoch 1267| loss: 0.97091 | train_accuracy: 0.51188 | val_accuracy: 0.5062  |  0:59:12s\n",
            "epoch 1268| loss: 0.96904 | train_accuracy: 0.51095 | val_accuracy: 0.505   |  0:59:15s\n",
            "epoch 1269| loss: 0.96859 | train_accuracy: 0.5102  | val_accuracy: 0.5002  |  0:59:18s\n",
            "epoch 1270| loss: 0.96726 | train_accuracy: 0.51077 | val_accuracy: 0.505   |  0:59:21s\n",
            "epoch 1271| loss: 0.96937 | train_accuracy: 0.51024 | val_accuracy: 0.5014  |  0:59:23s\n",
            "epoch 1272| loss: 0.97062 | train_accuracy: 0.51108 | val_accuracy: 0.5014  |  0:59:26s\n",
            "epoch 1273| loss: 0.97043 | train_accuracy: 0.50949 | val_accuracy: 0.5014  |  0:59:29s\n",
            "epoch 1274| loss: 0.96719 | train_accuracy: 0.50811 | val_accuracy: 0.505   |  0:59:32s\n",
            "epoch 1275| loss: 0.96695 | train_accuracy: 0.50829 | val_accuracy: 0.5062  |  0:59:35s\n",
            "epoch 1276| loss: 0.97101 | train_accuracy: 0.50935 | val_accuracy: 0.4918  |  0:59:37s\n",
            "epoch 1277| loss: 0.97016 | train_accuracy: 0.50877 | val_accuracy: 0.505   |  0:59:40s\n",
            "epoch 1278| loss: 0.96518 | train_accuracy: 0.50806 | val_accuracy: 0.505   |  0:59:43s\n",
            "epoch 1279| loss: 0.96938 | train_accuracy: 0.50917 | val_accuracy: 0.4998  |  0:59:46s\n",
            "epoch 1280| loss: 0.96935 | train_accuracy: 0.50793 | val_accuracy: 0.5022  |  0:59:48s\n",
            "epoch 1281| loss: 0.97151 | train_accuracy: 0.50975 | val_accuracy: 0.503   |  0:59:51s\n",
            "epoch 1282| loss: 0.96882 | train_accuracy: 0.50993 | val_accuracy: 0.501   |  0:59:54s\n",
            "epoch 1283| loss: 0.97128 | train_accuracy: 0.50975 | val_accuracy: 0.4982  |  0:59:57s\n",
            "epoch 1284| loss: 0.9686  | train_accuracy: 0.50953 | val_accuracy: 0.5002  |  1:00:00s\n",
            "epoch 1285| loss: 0.96874 | train_accuracy: 0.50913 | val_accuracy: 0.5006  |  1:00:02s\n",
            "epoch 1286| loss: 0.97042 | train_accuracy: 0.50833 | val_accuracy: 0.5014  |  1:00:05s\n",
            "epoch 1287| loss: 0.96684 | train_accuracy: 0.50824 | val_accuracy: 0.5014  |  1:00:08s\n",
            "epoch 1288| loss: 0.96801 | train_accuracy: 0.50949 | val_accuracy: 0.5006  |  1:00:10s\n",
            "epoch 1289| loss: 0.96887 | train_accuracy: 0.50917 | val_accuracy: 0.499   |  1:00:13s\n",
            "epoch 1290| loss: 0.96663 | train_accuracy: 0.50917 | val_accuracy: 0.499   |  1:00:16s\n",
            "epoch 1291| loss: 0.96855 | train_accuracy: 0.51028 | val_accuracy: 0.4986  |  1:00:19s\n",
            "epoch 1292| loss: 0.96999 | train_accuracy: 0.51202 | val_accuracy: 0.4962  |  1:00:22s\n",
            "epoch 1293| loss: 0.96684 | train_accuracy: 0.5098  | val_accuracy: 0.4998  |  1:00:25s\n",
            "epoch 1294| loss: 0.9714  | train_accuracy: 0.51131 | val_accuracy: 0.503   |  1:00:27s\n",
            "epoch 1295| loss: 0.9682  | train_accuracy: 0.5098  | val_accuracy: 0.501   |  1:00:30s\n",
            "epoch 1296| loss: 0.96698 | train_accuracy: 0.51011 | val_accuracy: 0.501   |  1:00:33s\n",
            "epoch 1297| loss: 0.96811 | train_accuracy: 0.51024 | val_accuracy: 0.5066  |  1:00:35s\n",
            "epoch 1298| loss: 0.97245 | train_accuracy: 0.51162 | val_accuracy: 0.5006  |  1:00:38s\n",
            "epoch 1299| loss: 0.97039 | train_accuracy: 0.50993 | val_accuracy: 0.5002  |  1:00:41s\n",
            "epoch 1300| loss: 0.96933 | train_accuracy: 0.509   | val_accuracy: 0.505   |  1:00:45s\n",
            "epoch 1301| loss: 0.9677  | train_accuracy: 0.51051 | val_accuracy: 0.5058  |  1:00:48s\n",
            "epoch 1302| loss: 0.96726 | train_accuracy: 0.5098  | val_accuracy: 0.5058  |  1:00:51s\n",
            "epoch 1303| loss: 0.96722 | train_accuracy: 0.5102  | val_accuracy: 0.5106  |  1:00:54s\n",
            "epoch 1304| loss: 0.96809 | train_accuracy: 0.50824 | val_accuracy: 0.4982  |  1:00:57s\n",
            "epoch 1305| loss: 0.96972 | train_accuracy: 0.50837 | val_accuracy: 0.4978  |  1:00:59s\n",
            "epoch 1306| loss: 0.96898 | train_accuracy: 0.51055 | val_accuracy: 0.5026  |  1:01:02s\n",
            "epoch 1307| loss: 0.96722 | train_accuracy: 0.50873 | val_accuracy: 0.4986  |  1:01:05s\n",
            "epoch 1308| loss: 0.97046 | train_accuracy: 0.50926 | val_accuracy: 0.503   |  1:01:08s\n",
            "epoch 1309| loss: 0.96927 | train_accuracy: 0.50944 | val_accuracy: 0.4994  |  1:01:11s\n",
            "epoch 1310| loss: 0.96891 | train_accuracy: 0.50833 | val_accuracy: 0.505   |  1:01:13s\n",
            "epoch 1311| loss: 0.97019 | train_accuracy: 0.51157 | val_accuracy: 0.501   |  1:01:16s\n",
            "epoch 1312| loss: 0.96918 | train_accuracy: 0.5106  | val_accuracy: 0.505   |  1:01:19s\n",
            "epoch 1313| loss: 0.96624 | train_accuracy: 0.5102  | val_accuracy: 0.5034  |  1:01:22s\n",
            "epoch 1314| loss: 0.96525 | train_accuracy: 0.51006 | val_accuracy: 0.5054  |  1:01:24s\n",
            "epoch 1315| loss: 0.96568 | train_accuracy: 0.50949 | val_accuracy: 0.503   |  1:01:27s\n",
            "epoch 1316| loss: 0.9681  | train_accuracy: 0.51028 | val_accuracy: 0.4922  |  1:01:30s\n",
            "epoch 1317| loss: 0.9651  | train_accuracy: 0.51157 | val_accuracy: 0.5078  |  1:01:32s\n",
            "epoch 1318| loss: 0.96749 | train_accuracy: 0.51153 | val_accuracy: 0.505   |  1:01:35s\n",
            "epoch 1319| loss: 0.97065 | train_accuracy: 0.51037 | val_accuracy: 0.4982  |  1:01:38s\n",
            "epoch 1320| loss: 0.97076 | train_accuracy: 0.51162 | val_accuracy: 0.497   |  1:01:41s\n",
            "epoch 1321| loss: 0.96794 | train_accuracy: 0.51228 | val_accuracy: 0.5014  |  1:01:43s\n",
            "epoch 1322| loss: 0.96888 | train_accuracy: 0.5094  | val_accuracy: 0.5066  |  1:01:46s\n",
            "epoch 1323| loss: 0.968   | train_accuracy: 0.51113 | val_accuracy: 0.5042  |  1:01:49s\n",
            "epoch 1324| loss: 0.96806 | train_accuracy: 0.51064 | val_accuracy: 0.5034  |  1:01:52s\n",
            "epoch 1325| loss: 0.96736 | train_accuracy: 0.51126 | val_accuracy: 0.5094  |  1:01:55s\n",
            "epoch 1326| loss: 0.96662 | train_accuracy: 0.51064 | val_accuracy: 0.5034  |  1:01:57s\n",
            "epoch 1327| loss: 0.96563 | train_accuracy: 0.51033 | val_accuracy: 0.5034  |  1:02:00s\n",
            "epoch 1328| loss: 0.96362 | train_accuracy: 0.51108 | val_accuracy: 0.505   |  1:02:03s\n",
            "epoch 1329| loss: 0.96641 | train_accuracy: 0.51113 | val_accuracy: 0.5026  |  1:02:06s\n",
            "epoch 1330| loss: 0.97    | train_accuracy: 0.51082 | val_accuracy: 0.5062  |  1:02:08s\n",
            "epoch 1331| loss: 0.96742 | train_accuracy: 0.51006 | val_accuracy: 0.5038  |  1:02:11s\n",
            "epoch 1332| loss: 0.96694 | train_accuracy: 0.5114  | val_accuracy: 0.5066  |  1:02:14s\n",
            "epoch 1333| loss: 0.96609 | train_accuracy: 0.51331 | val_accuracy: 0.5062  |  1:02:17s\n",
            "epoch 1334| loss: 0.96997 | train_accuracy: 0.51255 | val_accuracy: 0.507   |  1:02:19s\n",
            "epoch 1335| loss: 0.96528 | train_accuracy: 0.51215 | val_accuracy: 0.5022  |  1:02:22s\n",
            "epoch 1336| loss: 0.96741 | train_accuracy: 0.51135 | val_accuracy: 0.511   |  1:02:25s\n",
            "epoch 1337| loss: 0.96576 | train_accuracy: 0.51162 | val_accuracy: 0.5078  |  1:02:28s\n",
            "epoch 1338| loss: 0.96909 | train_accuracy: 0.51495 | val_accuracy: 0.5062  |  1:02:31s\n",
            "epoch 1339| loss: 0.96697 | train_accuracy: 0.51322 | val_accuracy: 0.5062  |  1:02:33s\n",
            "epoch 1340| loss: 0.96685 | train_accuracy: 0.51184 | val_accuracy: 0.503   |  1:02:36s\n",
            "epoch 1341| loss: 0.96642 | train_accuracy: 0.51228 | val_accuracy: 0.505   |  1:02:39s\n",
            "epoch 1342| loss: 0.96415 | train_accuracy: 0.51308 | val_accuracy: 0.5022  |  1:02:41s\n",
            "epoch 1343| loss: 0.9683  | train_accuracy: 0.5122  | val_accuracy: 0.503   |  1:02:44s\n",
            "epoch 1344| loss: 0.96443 | train_accuracy: 0.51251 | val_accuracy: 0.503   |  1:02:47s\n",
            "epoch 1345| loss: 0.96725 | train_accuracy: 0.51339 | val_accuracy: 0.505   |  1:02:50s\n",
            "epoch 1346| loss: 0.96588 | train_accuracy: 0.51277 | val_accuracy: 0.5034  |  1:02:52s\n",
            "epoch 1347| loss: 0.96898 | train_accuracy: 0.51224 | val_accuracy: 0.5018  |  1:02:55s\n",
            "epoch 1348| loss: 0.96397 | train_accuracy: 0.51299 | val_accuracy: 0.5014  |  1:02:58s\n",
            "epoch 1349| loss: 0.96722 | train_accuracy: 0.51144 | val_accuracy: 0.5038  |  1:03:01s\n",
            "epoch 1350| loss: 0.96522 | train_accuracy: 0.51402 | val_accuracy: 0.5082  |  1:03:04s\n",
            "epoch 1351| loss: 0.96705 | train_accuracy: 0.51562 | val_accuracy: 0.5042  |  1:03:07s\n",
            "epoch 1352| loss: 0.96955 | train_accuracy: 0.51442 | val_accuracy: 0.4986  |  1:03:09s\n",
            "epoch 1353| loss: 0.96588 | train_accuracy: 0.51202 | val_accuracy: 0.4998  |  1:03:12s\n",
            "epoch 1354| loss: 0.96774 | train_accuracy: 0.51317 | val_accuracy: 0.5014  |  1:03:15s\n",
            "epoch 1355| loss: 0.96693 | train_accuracy: 0.51224 | val_accuracy: 0.5042  |  1:03:18s\n",
            "epoch 1356| loss: 0.96701 | train_accuracy: 0.51446 | val_accuracy: 0.5074  |  1:03:20s\n",
            "epoch 1357| loss: 0.96735 | train_accuracy: 0.51415 | val_accuracy: 0.507   |  1:03:23s\n",
            "epoch 1358| loss: 0.96635 | train_accuracy: 0.51575 | val_accuracy: 0.5114  |  1:03:26s\n",
            "epoch 1359| loss: 0.9636  | train_accuracy: 0.51504 | val_accuracy: 0.5074  |  1:03:29s\n",
            "epoch 1360| loss: 0.96524 | train_accuracy: 0.51459 | val_accuracy: 0.503   |  1:03:32s\n",
            "epoch 1361| loss: 0.96463 | train_accuracy: 0.51566 | val_accuracy: 0.5082  |  1:03:34s\n",
            "epoch 1362| loss: 0.96501 | train_accuracy: 0.51477 | val_accuracy: 0.509   |  1:03:37s\n",
            "epoch 1363| loss: 0.96707 | train_accuracy: 0.51579 | val_accuracy: 0.5058  |  1:03:40s\n",
            "epoch 1364| loss: 0.9673  | train_accuracy: 0.5157  | val_accuracy: 0.5002  |  1:03:43s\n",
            "epoch 1365| loss: 0.96732 | train_accuracy: 0.51451 | val_accuracy: 0.5038  |  1:03:45s\n",
            "epoch 1366| loss: 0.9669  | train_accuracy: 0.51419 | val_accuracy: 0.5034  |  1:03:48s\n",
            "epoch 1367| loss: 0.96848 | train_accuracy: 0.51739 | val_accuracy: 0.499   |  1:03:51s\n",
            "epoch 1368| loss: 0.96835 | train_accuracy: 0.51384 | val_accuracy: 0.5074  |  1:03:53s\n",
            "epoch 1369| loss: 0.96983 | train_accuracy: 0.51433 | val_accuracy: 0.507   |  1:03:56s\n",
            "epoch 1370| loss: 0.96885 | train_accuracy: 0.51553 | val_accuracy: 0.4966  |  1:03:59s\n",
            "epoch 1371| loss: 0.96857 | train_accuracy: 0.51522 | val_accuracy: 0.5038  |  1:04:02s\n",
            "epoch 1372| loss: 0.96966 | train_accuracy: 0.51415 | val_accuracy: 0.4994  |  1:04:04s\n",
            "epoch 1373| loss: 0.96483 | train_accuracy: 0.51437 | val_accuracy: 0.503   |  1:04:07s\n",
            "epoch 1374| loss: 0.97012 | train_accuracy: 0.51428 | val_accuracy: 0.5082  |  1:04:10s\n",
            "epoch 1375| loss: 0.96691 | train_accuracy: 0.51468 | val_accuracy: 0.5046  |  1:04:12s\n",
            "epoch 1376| loss: 0.96514 | train_accuracy: 0.51335 | val_accuracy: 0.507   |  1:04:15s\n",
            "epoch 1377| loss: 0.96657 | train_accuracy: 0.51628 | val_accuracy: 0.5022  |  1:04:18s\n",
            "epoch 1378| loss: 0.9666  | train_accuracy: 0.51459 | val_accuracy: 0.4954  |  1:04:21s\n",
            "epoch 1379| loss: 0.96681 | train_accuracy: 0.51535 | val_accuracy: 0.4994  |  1:04:23s\n",
            "epoch 1380| loss: 0.96674 | train_accuracy: 0.51397 | val_accuracy: 0.5034  |  1:04:26s\n",
            "epoch 1381| loss: 0.96291 | train_accuracy: 0.51442 | val_accuracy: 0.5074  |  1:04:29s\n",
            "epoch 1382| loss: 0.96629 | train_accuracy: 0.51477 | val_accuracy: 0.5098  |  1:04:31s\n",
            "epoch 1383| loss: 0.96609 | train_accuracy: 0.51579 | val_accuracy: 0.5054  |  1:04:34s\n",
            "epoch 1384| loss: 0.96708 | train_accuracy: 0.51655 | val_accuracy: 0.5058  |  1:04:37s\n",
            "epoch 1385| loss: 0.96418 | train_accuracy: 0.51584 | val_accuracy: 0.5066  |  1:04:40s\n",
            "epoch 1386| loss: 0.96867 | train_accuracy: 0.51397 | val_accuracy: 0.5058  |  1:04:42s\n",
            "epoch 1387| loss: 0.9678  | train_accuracy: 0.51406 | val_accuracy: 0.507   |  1:04:45s\n",
            "epoch 1388| loss: 0.96767 | train_accuracy: 0.51406 | val_accuracy: 0.51419 |  1:04:48s\n",
            "epoch 1389| loss: 0.96489 | train_accuracy: 0.51486 | val_accuracy: 0.5102  |  1:04:50s\n",
            "epoch 1390| loss: 0.96575 | train_accuracy: 0.51504 | val_accuracy: 0.507   |  1:04:53s\n",
            "epoch 1391| loss: 0.96328 | train_accuracy: 0.51517 | val_accuracy: 0.5082  |  1:04:56s\n",
            "epoch 1392| loss: 0.96355 | train_accuracy: 0.51553 | val_accuracy: 0.51579 |  1:04:58s\n",
            "epoch 1393| loss: 0.96887 | train_accuracy: 0.51664 | val_accuracy: 0.5082  |  1:05:01s\n",
            "epoch 1394| loss: 0.9655  | train_accuracy: 0.51562 | val_accuracy: 0.5082  |  1:05:04s\n",
            "epoch 1395| loss: 0.96558 | train_accuracy: 0.51775 | val_accuracy: 0.51539 |  1:05:07s\n",
            "epoch 1396| loss: 0.96435 | train_accuracy: 0.51704 | val_accuracy: 0.51499 |  1:05:09s\n",
            "epoch 1397| loss: 0.96547 | train_accuracy: 0.51646 | val_accuracy: 0.511   |  1:05:12s\n",
            "epoch 1398| loss: 0.96463 | train_accuracy: 0.51668 | val_accuracy: 0.51499 |  1:05:15s\n",
            "epoch 1399| loss: 0.96474 | train_accuracy: 0.51437 | val_accuracy: 0.51419 |  1:05:17s\n",
            "epoch 1400| loss: 0.96422 | train_accuracy: 0.51602 | val_accuracy: 0.5102  |  1:05:20s\n",
            "epoch 1401| loss: 0.96554 | train_accuracy: 0.51655 | val_accuracy: 0.51699 |  1:05:23s\n",
            "epoch 1402| loss: 0.96557 | train_accuracy: 0.5165  | val_accuracy: 0.51739 |  1:05:26s\n",
            "epoch 1403| loss: 0.96436 | train_accuracy: 0.51859 | val_accuracy: 0.51899 |  1:05:28s\n",
            "epoch 1404| loss: 0.96373 | train_accuracy: 0.51722 | val_accuracy: 0.5094  |  1:05:31s\n",
            "epoch 1405| loss: 0.96347 | train_accuracy: 0.51446 | val_accuracy: 0.505   |  1:05:34s\n",
            "epoch 1406| loss: 0.96679 | train_accuracy: 0.51677 | val_accuracy: 0.52099 |  1:05:37s\n",
            "epoch 1407| loss: 0.96835 | train_accuracy: 0.51695 | val_accuracy: 0.52259 |  1:05:39s\n",
            "epoch 1408| loss: 0.96656 | train_accuracy: 0.51526 | val_accuracy: 0.51419 |  1:05:42s\n",
            "epoch 1409| loss: 0.96705 | train_accuracy: 0.51717 | val_accuracy: 0.51699 |  1:05:45s\n",
            "epoch 1410| loss: 0.96764 | train_accuracy: 0.51841 | val_accuracy: 0.51499 |  1:05:47s\n",
            "epoch 1411| loss: 0.96524 | train_accuracy: 0.51806 | val_accuracy: 0.51419 |  1:05:50s\n",
            "epoch 1412| loss: 0.96429 | train_accuracy: 0.51833 | val_accuracy: 0.52059 |  1:05:53s\n",
            "epoch 1413| loss: 0.96723 | train_accuracy: 0.5181  | val_accuracy: 0.51939 |  1:05:56s\n",
            "epoch 1414| loss: 0.96508 | train_accuracy: 0.51859 | val_accuracy: 0.51739 |  1:05:58s\n",
            "epoch 1415| loss: 0.96524 | train_accuracy: 0.5177  | val_accuracy: 0.51459 |  1:06:01s\n",
            "epoch 1416| loss: 0.96359 | train_accuracy: 0.51921 | val_accuracy: 0.52099 |  1:06:04s\n",
            "epoch 1417| loss: 0.96416 | train_accuracy: 0.5189  | val_accuracy: 0.51499 |  1:06:07s\n",
            "epoch 1418| loss: 0.96504 | train_accuracy: 0.51939 | val_accuracy: 0.5114  |  1:06:09s\n",
            "epoch 1419| loss: 0.96486 | train_accuracy: 0.51988 | val_accuracy: 0.51619 |  1:06:12s\n",
            "epoch 1420| loss: 0.96435 | train_accuracy: 0.52024 | val_accuracy: 0.5098  |  1:06:15s\n",
            "epoch 1421| loss: 0.96322 | train_accuracy: 0.52037 | val_accuracy: 0.5086  |  1:06:18s\n",
            "epoch 1422| loss: 0.96205 | train_accuracy: 0.5201  | val_accuracy: 0.5114  |  1:06:20s\n",
            "epoch 1423| loss: 0.96433 | train_accuracy: 0.52112 | val_accuracy: 0.5106  |  1:06:23s\n",
            "epoch 1424| loss: 0.96116 | train_accuracy: 0.52272 | val_accuracy: 0.511   |  1:06:26s\n",
            "epoch 1425| loss: 0.96496 | train_accuracy: 0.52157 | val_accuracy: 0.5106  |  1:06:29s\n",
            "epoch 1426| loss: 0.96068 | train_accuracy: 0.52019 | val_accuracy: 0.51579 |  1:06:31s\n",
            "epoch 1427| loss: 0.96417 | train_accuracy: 0.52073 | val_accuracy: 0.51339 |  1:06:34s\n",
            "epoch 1428| loss: 0.96321 | train_accuracy: 0.52068 | val_accuracy: 0.51619 |  1:06:37s\n",
            "epoch 1429| loss: 0.96203 | train_accuracy: 0.52073 | val_accuracy: 0.51379 |  1:06:39s\n",
            "epoch 1430| loss: 0.96555 | train_accuracy: 0.51953 | val_accuracy: 0.5086  |  1:06:42s\n",
            "epoch 1431| loss: 0.96231 | train_accuracy: 0.52001 | val_accuracy: 0.51259 |  1:06:45s\n",
            "epoch 1432| loss: 0.96221 | train_accuracy: 0.52241 | val_accuracy: 0.51499 |  1:06:48s\n",
            "epoch 1433| loss: 0.9619  | train_accuracy: 0.52215 | val_accuracy: 0.51459 |  1:06:50s\n",
            "epoch 1434| loss: 0.96358 | train_accuracy: 0.52277 | val_accuracy: 0.5122  |  1:06:53s\n",
            "epoch 1435| loss: 0.95912 | train_accuracy: 0.52024 | val_accuracy: 0.52379 |  1:06:56s\n",
            "epoch 1436| loss: 0.96076 | train_accuracy: 0.5193  | val_accuracy: 0.52419 |  1:06:58s\n",
            "epoch 1437| loss: 0.95834 | train_accuracy: 0.5201  | val_accuracy: 0.51699 |  1:07:01s\n",
            "epoch 1438| loss: 0.96245 | train_accuracy: 0.52224 | val_accuracy: 0.51979 |  1:07:04s\n",
            "epoch 1439| loss: 0.96081 | train_accuracy: 0.52192 | val_accuracy: 0.52339 |  1:07:07s\n",
            "epoch 1440| loss: 0.95944 | train_accuracy: 0.52108 | val_accuracy: 0.51899 |  1:07:09s\n",
            "epoch 1441| loss: 0.96357 | train_accuracy: 0.52366 | val_accuracy: 0.5066  |  1:07:12s\n",
            "epoch 1442| loss: 0.96245 | train_accuracy: 0.52264 | val_accuracy: 0.51419 |  1:07:15s\n",
            "epoch 1443| loss: 0.95963 | train_accuracy: 0.52112 | val_accuracy: 0.51899 |  1:07:17s\n",
            "epoch 1444| loss: 0.96141 | train_accuracy: 0.52281 | val_accuracy: 0.51979 |  1:07:20s\n",
            "epoch 1445| loss: 0.9602  | train_accuracy: 0.52326 | val_accuracy: 0.52139 |  1:07:23s\n",
            "epoch 1446| loss: 0.96219 | train_accuracy: 0.52317 | val_accuracy: 0.51979 |  1:07:25s\n",
            "epoch 1447| loss: 0.95988 | train_accuracy: 0.52277 | val_accuracy: 0.51299 |  1:07:28s\n",
            "epoch 1448| loss: 0.96118 | train_accuracy: 0.52317 | val_accuracy: 0.51619 |  1:07:31s\n",
            "epoch 1449| loss: 0.96195 | train_accuracy: 0.52272 | val_accuracy: 0.51379 |  1:07:34s\n",
            "epoch 1450| loss: 0.96502 | train_accuracy: 0.5237  | val_accuracy: 0.51459 |  1:07:37s\n",
            "epoch 1451| loss: 0.96035 | train_accuracy: 0.5241  | val_accuracy: 0.51819 |  1:07:40s\n",
            "epoch 1452| loss: 0.96217 | train_accuracy: 0.52432 | val_accuracy: 0.51659 |  1:07:42s\n",
            "epoch 1453| loss: 0.96103 | train_accuracy: 0.52481 | val_accuracy: 0.51859 |  1:07:45s\n",
            "epoch 1454| loss: 0.96355 | train_accuracy: 0.52557 | val_accuracy: 0.52099 |  1:07:48s\n",
            "epoch 1455| loss: 0.96059 | train_accuracy: 0.52446 | val_accuracy: 0.51579 |  1:07:51s\n",
            "epoch 1456| loss: 0.96113 | train_accuracy: 0.52539 | val_accuracy: 0.51739 |  1:07:54s\n",
            "epoch 1457| loss: 0.96268 | train_accuracy: 0.5245  | val_accuracy: 0.51979 |  1:07:56s\n",
            "epoch 1458| loss: 0.96282 | train_accuracy: 0.52401 | val_accuracy: 0.51339 |  1:07:59s\n",
            "epoch 1459| loss: 0.96106 | train_accuracy: 0.52539 | val_accuracy: 0.52219 |  1:08:02s\n",
            "epoch 1460| loss: 0.96029 | train_accuracy: 0.52606 | val_accuracy: 0.52259 |  1:08:05s\n",
            "epoch 1461| loss: 0.96112 | train_accuracy: 0.5241  | val_accuracy: 0.5118  |  1:08:07s\n",
            "epoch 1462| loss: 0.96339 | train_accuracy: 0.52295 | val_accuracy: 0.51539 |  1:08:10s\n",
            "epoch 1463| loss: 0.96148 | train_accuracy: 0.52557 | val_accuracy: 0.52539 |  1:08:13s\n",
            "epoch 1464| loss: 0.96164 | train_accuracy: 0.52295 | val_accuracy: 0.52459 |  1:08:16s\n",
            "epoch 1465| loss: 0.95959 | train_accuracy: 0.52401 | val_accuracy: 0.51459 |  1:08:19s\n",
            "epoch 1466| loss: 0.95925 | train_accuracy: 0.52557 | val_accuracy: 0.51779 |  1:08:22s\n",
            "epoch 1467| loss: 0.96044 | train_accuracy: 0.52557 | val_accuracy: 0.51699 |  1:08:24s\n",
            "epoch 1468| loss: 0.95951 | train_accuracy: 0.52566 | val_accuracy: 0.51619 |  1:08:27s\n",
            "epoch 1469| loss: 0.96148 | train_accuracy: 0.52548 | val_accuracy: 0.51939 |  1:08:30s\n",
            "epoch 1470| loss: 0.95542 | train_accuracy: 0.52463 | val_accuracy: 0.51259 |  1:08:33s\n",
            "epoch 1471| loss: 0.95984 | train_accuracy: 0.52575 | val_accuracy: 0.51259 |  1:08:36s\n",
            "epoch 1472| loss: 0.96095 | train_accuracy: 0.52517 | val_accuracy: 0.5102  |  1:08:38s\n",
            "epoch 1473| loss: 0.95903 | train_accuracy: 0.52588 | val_accuracy: 0.5086  |  1:08:41s\n",
            "epoch 1474| loss: 0.95713 | train_accuracy: 0.52499 | val_accuracy: 0.5038  |  1:08:44s\n",
            "epoch 1475| loss: 0.96141 | train_accuracy: 0.52654 | val_accuracy: 0.5066  |  1:08:47s\n",
            "epoch 1476| loss: 0.96252 | train_accuracy: 0.52552 | val_accuracy: 0.51339 |  1:08:49s\n",
            "epoch 1477| loss: 0.9576  | train_accuracy: 0.52526 | val_accuracy: 0.511   |  1:08:52s\n",
            "epoch 1478| loss: 0.95747 | train_accuracy: 0.52632 | val_accuracy: 0.5106  |  1:08:55s\n",
            "epoch 1479| loss: 0.95978 | train_accuracy: 0.52517 | val_accuracy: 0.5018  |  1:08:58s\n",
            "epoch 1480| loss: 0.95888 | train_accuracy: 0.52521 | val_accuracy: 0.5026  |  1:09:01s\n",
            "epoch 1481| loss: 0.96325 | train_accuracy: 0.52566 | val_accuracy: 0.5082  |  1:09:03s\n",
            "epoch 1482| loss: 0.96156 | train_accuracy: 0.5261  | val_accuracy: 0.5034  |  1:09:06s\n",
            "epoch 1483| loss: 0.95888 | train_accuracy: 0.5257  | val_accuracy: 0.5054  |  1:09:09s\n",
            "epoch 1484| loss: 0.96164 | train_accuracy: 0.52601 | val_accuracy: 0.507   |  1:09:12s\n",
            "epoch 1485| loss: 0.96097 | train_accuracy: 0.52672 | val_accuracy: 0.5066  |  1:09:14s\n",
            "epoch 1486| loss: 0.95924 | train_accuracy: 0.52654 | val_accuracy: 0.5082  |  1:09:17s\n",
            "epoch 1487| loss: 0.96124 | train_accuracy: 0.5277  | val_accuracy: 0.509   |  1:09:20s\n",
            "epoch 1488| loss: 0.95977 | train_accuracy: 0.52583 | val_accuracy: 0.5074  |  1:09:23s\n",
            "epoch 1489| loss: 0.96007 | train_accuracy: 0.52734 | val_accuracy: 0.5074  |  1:09:25s\n",
            "epoch 1490| loss: 0.95957 | train_accuracy: 0.5265  | val_accuracy: 0.5098  |  1:09:28s\n",
            "epoch 1491| loss: 0.96151 | train_accuracy: 0.52739 | val_accuracy: 0.507   |  1:09:31s\n",
            "epoch 1492| loss: 0.95998 | train_accuracy: 0.52552 | val_accuracy: 0.5062  |  1:09:34s\n",
            "epoch 1493| loss: 0.95849 | train_accuracy: 0.52637 | val_accuracy: 0.5026  |  1:09:36s\n",
            "epoch 1494| loss: 0.95756 | train_accuracy: 0.52437 | val_accuracy: 0.5022  |  1:09:39s\n",
            "epoch 1495| loss: 0.96074 | train_accuracy: 0.52748 | val_accuracy: 0.507   |  1:09:42s\n",
            "epoch 1496| loss: 0.95651 | train_accuracy: 0.52863 | val_accuracy: 0.511   |  1:09:45s\n",
            "epoch 1497| loss: 0.959   | train_accuracy: 0.52654 | val_accuracy: 0.51259 |  1:09:47s\n",
            "epoch 1498| loss: 0.95735 | train_accuracy: 0.52708 | val_accuracy: 0.5014  |  1:09:50s\n",
            "epoch 1499| loss: 0.95896 | train_accuracy: 0.52588 | val_accuracy: 0.5026  |  1:09:53s\n",
            "epoch 1500| loss: 0.9602  | train_accuracy: 0.5269  | val_accuracy: 0.5054  |  1:09:56s\n",
            "epoch 1501| loss: 0.96009 | train_accuracy: 0.52495 | val_accuracy: 0.5078  |  1:09:58s\n",
            "epoch 1502| loss: 0.95969 | train_accuracy: 0.52623 | val_accuracy: 0.5106  |  1:10:01s\n",
            "epoch 1503| loss: 0.96131 | train_accuracy: 0.52601 | val_accuracy: 0.5082  |  1:10:04s\n",
            "epoch 1504| loss: 0.95964 | train_accuracy: 0.52348 | val_accuracy: 0.5066  |  1:10:06s\n",
            "epoch 1505| loss: 0.96238 | train_accuracy: 0.52357 | val_accuracy: 0.5102  |  1:10:09s\n",
            "epoch 1506| loss: 0.96181 | train_accuracy: 0.52401 | val_accuracy: 0.5066  |  1:10:12s\n",
            "epoch 1507| loss: 0.96119 | train_accuracy: 0.52463 | val_accuracy: 0.5106  |  1:10:15s\n",
            "epoch 1508| loss: 0.96308 | train_accuracy: 0.52312 | val_accuracy: 0.51339 |  1:10:17s\n",
            "epoch 1509| loss: 0.9588  | train_accuracy: 0.52521 | val_accuracy: 0.51339 |  1:10:20s\n",
            "epoch 1510| loss: 0.96105 | train_accuracy: 0.52428 | val_accuracy: 0.5114  |  1:10:23s\n",
            "epoch 1511| loss: 0.96229 | train_accuracy: 0.5249  | val_accuracy: 0.5042  |  1:10:26s\n",
            "epoch 1512| loss: 0.96259 | train_accuracy: 0.52272 | val_accuracy: 0.5098  |  1:10:29s\n",
            "epoch 1513| loss: 0.96141 | train_accuracy: 0.5233  | val_accuracy: 0.5078  |  1:10:31s\n",
            "epoch 1514| loss: 0.95878 | train_accuracy: 0.52383 | val_accuracy: 0.505   |  1:10:34s\n",
            "epoch 1515| loss: 0.95706 | train_accuracy: 0.52592 | val_accuracy: 0.507   |  1:10:37s\n",
            "epoch 1516| loss: 0.96296 | train_accuracy: 0.52575 | val_accuracy: 0.4966  |  1:10:40s\n",
            "epoch 1517| loss: 0.96222 | train_accuracy: 0.5265  | val_accuracy: 0.4966  |  1:10:42s\n",
            "epoch 1518| loss: 0.95711 | train_accuracy: 0.52628 | val_accuracy: 0.5074  |  1:10:45s\n",
            "epoch 1519| loss: 0.96309 | train_accuracy: 0.52535 | val_accuracy: 0.5058  |  1:10:48s\n",
            "epoch 1520| loss: 0.95926 | train_accuracy: 0.52317 | val_accuracy: 0.4998  |  1:10:51s\n",
            "epoch 1521| loss: 0.9597  | train_accuracy: 0.52472 | val_accuracy: 0.51339 |  1:10:54s\n",
            "epoch 1522| loss: 0.95984 | train_accuracy: 0.5229  | val_accuracy: 0.5086  |  1:10:56s\n",
            "epoch 1523| loss: 0.96034 | train_accuracy: 0.52237 | val_accuracy: 0.507   |  1:10:59s\n",
            "epoch 1524| loss: 0.96077 | train_accuracy: 0.52281 | val_accuracy: 0.5066  |  1:11:02s\n",
            "epoch 1525| loss: 0.9611  | train_accuracy: 0.5233  | val_accuracy: 0.51339 |  1:11:05s\n",
            "epoch 1526| loss: 0.96091 | train_accuracy: 0.52357 | val_accuracy: 0.5102  |  1:11:07s\n",
            "epoch 1527| loss: 0.95922 | train_accuracy: 0.52503 | val_accuracy: 0.5066  |  1:11:10s\n",
            "epoch 1528| loss: 0.96155 | train_accuracy: 0.52486 | val_accuracy: 0.5074  |  1:11:13s\n",
            "epoch 1529| loss: 0.96004 | train_accuracy: 0.5265  | val_accuracy: 0.5098  |  1:11:16s\n",
            "epoch 1530| loss: 0.95771 | train_accuracy: 0.52472 | val_accuracy: 0.501   |  1:11:18s\n",
            "epoch 1531| loss: 0.96118 | train_accuracy: 0.52681 | val_accuracy: 0.5006  |  1:11:21s\n",
            "epoch 1532| loss: 0.95795 | train_accuracy: 0.52588 | val_accuracy: 0.4946  |  1:11:24s\n",
            "epoch 1533| loss: 0.95832 | train_accuracy: 0.52441 | val_accuracy: 0.4914  |  1:11:26s\n",
            "epoch 1534| loss: 0.96006 | train_accuracy: 0.52615 | val_accuracy: 0.4974  |  1:11:29s\n",
            "epoch 1535| loss: 0.96056 | train_accuracy: 0.52486 | val_accuracy: 0.4938  |  1:11:32s\n",
            "epoch 1536| loss: 0.96005 | train_accuracy: 0.52344 | val_accuracy: 0.4946  |  1:11:35s\n",
            "epoch 1537| loss: 0.96007 | train_accuracy: 0.52281 | val_accuracy: 0.4998  |  1:11:37s\n",
            "epoch 1538| loss: 0.96166 | train_accuracy: 0.52232 | val_accuracy: 0.4962  |  1:11:40s\n",
            "epoch 1539| loss: 0.96281 | train_accuracy: 0.52437 | val_accuracy: 0.4918  |  1:11:43s\n",
            "epoch 1540| loss: 0.9582  | train_accuracy: 0.52348 | val_accuracy: 0.495   |  1:11:46s\n",
            "epoch 1541| loss: 0.96244 | train_accuracy: 0.52299 | val_accuracy: 0.497   |  1:11:48s\n",
            "epoch 1542| loss: 0.96009 | train_accuracy: 0.52486 | val_accuracy: 0.4978  |  1:11:51s\n",
            "epoch 1543| loss: 0.95652 | train_accuracy: 0.52481 | val_accuracy: 0.5002  |  1:11:54s\n",
            "epoch 1544| loss: 0.95994 | train_accuracy: 0.52437 | val_accuracy: 0.5002  |  1:11:57s\n",
            "epoch 1545| loss: 0.95835 | train_accuracy: 0.52472 | val_accuracy: 0.497   |  1:11:59s\n",
            "epoch 1546| loss: 0.96078 | train_accuracy: 0.52459 | val_accuracy: 0.5022  |  1:12:02s\n",
            "epoch 1547| loss: 0.95737 | train_accuracy: 0.52592 | val_accuracy: 0.5022  |  1:12:05s\n",
            "epoch 1548| loss: 0.95874 | train_accuracy: 0.52548 | val_accuracy: 0.4966  |  1:12:07s\n",
            "epoch 1549| loss: 0.96142 | train_accuracy: 0.5249  | val_accuracy: 0.4954  |  1:12:10s\n",
            "epoch 1550| loss: 0.95947 | train_accuracy: 0.52406 | val_accuracy: 0.4974  |  1:12:13s\n",
            "epoch 1551| loss: 0.95773 | train_accuracy: 0.52406 | val_accuracy: 0.499   |  1:12:16s\n",
            "epoch 1552| loss: 0.9609  | train_accuracy: 0.52268 | val_accuracy: 0.4954  |  1:12:18s\n",
            "epoch 1553| loss: 0.95703 | train_accuracy: 0.52295 | val_accuracy: 0.5014  |  1:12:21s\n",
            "epoch 1554| loss: 0.95899 | train_accuracy: 0.52179 | val_accuracy: 0.4982  |  1:12:24s\n",
            "epoch 1555| loss: 0.95997 | train_accuracy: 0.52175 | val_accuracy: 0.4966  |  1:12:27s\n",
            "epoch 1556| loss: 0.96056 | train_accuracy: 0.52232 | val_accuracy: 0.4974  |  1:12:30s\n",
            "epoch 1557| loss: 0.95994 | train_accuracy: 0.52272 | val_accuracy: 0.5002  |  1:12:33s\n",
            "epoch 1558| loss: 0.95852 | train_accuracy: 0.52232 | val_accuracy: 0.4982  |  1:12:35s\n",
            "epoch 1559| loss: 0.96275 | train_accuracy: 0.52215 | val_accuracy: 0.4966  |  1:12:38s\n",
            "epoch 1560| loss: 0.95837 | train_accuracy: 0.52237 | val_accuracy: 0.5034  |  1:12:41s\n",
            "epoch 1561| loss: 0.95784 | train_accuracy: 0.52264 | val_accuracy: 0.5018  |  1:12:43s\n",
            "epoch 1562| loss: 0.9623  | train_accuracy: 0.5233  | val_accuracy: 0.497   |  1:12:46s\n",
            "epoch 1563| loss: 0.95811 | train_accuracy: 0.52383 | val_accuracy: 0.5002  |  1:12:49s\n",
            "epoch 1564| loss: 0.96052 | train_accuracy: 0.52406 | val_accuracy: 0.4942  |  1:12:52s\n",
            "epoch 1565| loss: 0.95791 | train_accuracy: 0.52379 | val_accuracy: 0.4958  |  1:12:54s\n",
            "epoch 1566| loss: 0.95885 | train_accuracy: 0.5253  | val_accuracy: 0.499   |  1:12:57s\n",
            "epoch 1567| loss: 0.95758 | train_accuracy: 0.52477 | val_accuracy: 0.4978  |  1:13:00s\n",
            "epoch 1568| loss: 0.95845 | train_accuracy: 0.52503 | val_accuracy: 0.4938  |  1:13:02s\n",
            "epoch 1569| loss: 0.95812 | train_accuracy: 0.52401 | val_accuracy: 0.4918  |  1:13:05s\n",
            "epoch 1570| loss: 0.95621 | train_accuracy: 0.52654 | val_accuracy: 0.5006  |  1:13:08s\n",
            "epoch 1571| loss: 0.95769 | train_accuracy: 0.52659 | val_accuracy: 0.4958  |  1:13:11s\n",
            "epoch 1572| loss: 0.95443 | train_accuracy: 0.5249  | val_accuracy: 0.4938  |  1:13:14s\n",
            "epoch 1573| loss: 0.95718 | train_accuracy: 0.52423 | val_accuracy: 0.4954  |  1:13:16s\n",
            "epoch 1574| loss: 0.95719 | train_accuracy: 0.52184 | val_accuracy: 0.493   |  1:13:19s\n",
            "epoch 1575| loss: 0.95948 | train_accuracy: 0.52623 | val_accuracy: 0.4994  |  1:13:22s\n",
            "epoch 1576| loss: 0.96236 | train_accuracy: 0.5241  | val_accuracy: 0.497   |  1:13:24s\n",
            "epoch 1577| loss: 0.95739 | train_accuracy: 0.52321 | val_accuracy: 0.4986  |  1:13:27s\n",
            "epoch 1578| loss: 0.95896 | train_accuracy: 0.52575 | val_accuracy: 0.5034  |  1:13:30s\n",
            "epoch 1579| loss: 0.95836 | train_accuracy: 0.52526 | val_accuracy: 0.4974  |  1:13:33s\n",
            "epoch 1580| loss: 0.95589 | train_accuracy: 0.52477 | val_accuracy: 0.5026  |  1:13:35s\n",
            "epoch 1581| loss: 0.96036 | train_accuracy: 0.52552 | val_accuracy: 0.5066  |  1:13:38s\n",
            "epoch 1582| loss: 0.95383 | train_accuracy: 0.52663 | val_accuracy: 0.497   |  1:13:41s\n",
            "epoch 1583| loss: 0.95392 | train_accuracy: 0.52415 | val_accuracy: 0.4986  |  1:13:44s\n",
            "epoch 1584| loss: 0.95903 | train_accuracy: 0.52357 | val_accuracy: 0.5018  |  1:13:47s\n",
            "epoch 1585| loss: 0.95796 | train_accuracy: 0.52628 | val_accuracy: 0.5026  |  1:13:49s\n",
            "epoch 1586| loss: 0.9574  | train_accuracy: 0.52615 | val_accuracy: 0.4946  |  1:13:52s\n",
            "epoch 1587| loss: 0.95648 | train_accuracy: 0.52575 | val_accuracy: 0.5002  |  1:13:55s\n",
            "epoch 1588| loss: 0.95466 | train_accuracy: 0.52686 | val_accuracy: 0.4994  |  1:13:58s\n",
            "epoch 1589| loss: 0.95856 | train_accuracy: 0.52646 | val_accuracy: 0.5022  |  1:14:00s\n",
            "epoch 1590| loss: 0.95636 | train_accuracy: 0.52766 | val_accuracy: 0.495   |  1:14:03s\n",
            "epoch 1591| loss: 0.9576  | train_accuracy: 0.52615 | val_accuracy: 0.495   |  1:14:06s\n",
            "epoch 1592| loss: 0.95766 | train_accuracy: 0.52397 | val_accuracy: 0.4942  |  1:14:09s\n",
            "epoch 1593| loss: 0.95962 | train_accuracy: 0.52419 | val_accuracy: 0.4954  |  1:14:11s\n",
            "epoch 1594| loss: 0.96041 | train_accuracy: 0.52521 | val_accuracy: 0.5046  |  1:14:14s\n",
            "epoch 1595| loss: 0.96188 | train_accuracy: 0.52361 | val_accuracy: 0.4954  |  1:14:17s\n",
            "epoch 1596| loss: 0.96502 | train_accuracy: 0.51935 | val_accuracy: 0.501   |  1:14:20s\n",
            "epoch 1597| loss: 0.96421 | train_accuracy: 0.52108 | val_accuracy: 0.5054  |  1:14:22s\n",
            "epoch 1598| loss: 0.96082 | train_accuracy: 0.51904 | val_accuracy: 0.4986  |  1:14:25s\n",
            "epoch 1599| loss: 0.96528 | train_accuracy: 0.52224 | val_accuracy: 0.5042  |  1:14:28s\n",
            "epoch 1600| loss: 0.95901 | train_accuracy: 0.52335 | val_accuracy: 0.4974  |  1:14:31s\n",
            "epoch 1601| loss: 0.96105 | train_accuracy: 0.52477 | val_accuracy: 0.4974  |  1:14:33s\n",
            "epoch 1602| loss: 0.96156 | train_accuracy: 0.52486 | val_accuracy: 0.4966  |  1:14:36s\n",
            "epoch 1603| loss: 0.95963 | train_accuracy: 0.52686 | val_accuracy: 0.5014  |  1:14:39s\n",
            "epoch 1604| loss: 0.95841 | train_accuracy: 0.52623 | val_accuracy: 0.5054  |  1:14:42s\n",
            "epoch 1605| loss: 0.96123 | train_accuracy: 0.5249  | val_accuracy: 0.5002  |  1:14:48s\n",
            "epoch 1606| loss: 0.96048 | train_accuracy: 0.52677 | val_accuracy: 0.5054  |  1:14:52s\n",
            "epoch 1607| loss: 0.96031 | train_accuracy: 0.52686 | val_accuracy: 0.507   |  1:14:55s\n",
            "epoch 1608| loss: 0.96246 | train_accuracy: 0.5217  | val_accuracy: 0.5022  |  1:14:58s\n",
            "epoch 1609| loss: 0.96789 | train_accuracy: 0.51495 | val_accuracy: 0.497   |  1:15:00s\n",
            "epoch 1610| loss: 0.96674 | train_accuracy: 0.51526 | val_accuracy: 0.4998  |  1:15:03s\n",
            "epoch 1611| loss: 0.96639 | train_accuracy: 0.51779 | val_accuracy: 0.5034  |  1:15:06s\n",
            "epoch 1612| loss: 0.96186 | train_accuracy: 0.52215 | val_accuracy: 0.5022  |  1:15:09s\n",
            "epoch 1613| loss: 0.95929 | train_accuracy: 0.52086 | val_accuracy: 0.5098  |  1:15:11s\n",
            "epoch 1614| loss: 0.96221 | train_accuracy: 0.52224 | val_accuracy: 0.511   |  1:15:14s\n",
            "epoch 1615| loss: 0.96512 | train_accuracy: 0.52037 | val_accuracy: 0.5082  |  1:15:17s\n",
            "epoch 1616| loss: 0.96227 | train_accuracy: 0.52112 | val_accuracy: 0.507   |  1:15:20s\n",
            "epoch 1617| loss: 0.96275 | train_accuracy: 0.52246 | val_accuracy: 0.51379 |  1:15:23s\n",
            "epoch 1618| loss: 0.96487 | train_accuracy: 0.52126 | val_accuracy: 0.4998  |  1:15:25s\n",
            "epoch 1619| loss: 0.96407 | train_accuracy: 0.52232 | val_accuracy: 0.5122  |  1:15:28s\n",
            "epoch 1620| loss: 0.96103 | train_accuracy: 0.52161 | val_accuracy: 0.5046  |  1:15:31s\n",
            "epoch 1621| loss: 0.96486 | train_accuracy: 0.51713 | val_accuracy: 0.507   |  1:15:34s\n",
            "epoch 1622| loss: 0.96238 | train_accuracy: 0.51757 | val_accuracy: 0.5062  |  1:15:36s\n",
            "epoch 1623| loss: 0.96442 | train_accuracy: 0.51913 | val_accuracy: 0.4974  |  1:15:39s\n",
            "epoch 1624| loss: 0.96524 | train_accuracy: 0.51824 | val_accuracy: 0.4998  |  1:15:42s\n",
            "epoch 1625| loss: 0.96383 | train_accuracy: 0.51762 | val_accuracy: 0.4938  |  1:15:45s\n",
            "epoch 1626| loss: 0.96695 | train_accuracy: 0.51433 | val_accuracy: 0.491   |  1:15:47s\n",
            "epoch 1627| loss: 0.96586 | train_accuracy: 0.51446 | val_accuracy: 0.4986  |  1:15:50s\n",
            "epoch 1628| loss: 0.96212 | train_accuracy: 0.51659 | val_accuracy: 0.4966  |  1:15:53s\n",
            "epoch 1629| loss: 0.96632 | train_accuracy: 0.51615 | val_accuracy: 0.5014  |  1:15:56s\n",
            "epoch 1630| loss: 0.96734 | train_accuracy: 0.51588 | val_accuracy: 0.4914  |  1:15:59s\n",
            "epoch 1631| loss: 0.96384 | train_accuracy: 0.51797 | val_accuracy: 0.5002  |  1:16:01s\n",
            "epoch 1632| loss: 0.96722 | train_accuracy: 0.5165  | val_accuracy: 0.5022  |  1:16:04s\n",
            "epoch 1633| loss: 0.96301 | train_accuracy: 0.51593 | val_accuracy: 0.505   |  1:16:07s\n",
            "epoch 1634| loss: 0.9645  | train_accuracy: 0.51588 | val_accuracy: 0.5006  |  1:16:10s\n",
            "epoch 1635| loss: 0.96696 | train_accuracy: 0.51588 | val_accuracy: 0.4994  |  1:16:12s\n",
            "epoch 1636| loss: 0.96799 | train_accuracy: 0.51379 | val_accuracy: 0.499   |  1:16:15s\n",
            "epoch 1637| loss: 0.96908 | train_accuracy: 0.51482 | val_accuracy: 0.5014  |  1:16:18s\n",
            "epoch 1638| loss: 0.96786 | train_accuracy: 0.51637 | val_accuracy: 0.5022  |  1:16:21s\n",
            "epoch 1639| loss: 0.96732 | train_accuracy: 0.51713 | val_accuracy: 0.5026  |  1:16:23s\n",
            "epoch 1640| loss: 0.96611 | train_accuracy: 0.51899 | val_accuracy: 0.503   |  1:16:26s\n",
            "epoch 1641| loss: 0.96802 | train_accuracy: 0.51824 | val_accuracy: 0.5038  |  1:16:29s\n",
            "epoch 1642| loss: 0.96783 | train_accuracy: 0.51553 | val_accuracy: 0.5046  |  1:16:32s\n",
            "epoch 1643| loss: 0.96519 | train_accuracy: 0.51646 | val_accuracy: 0.4982  |  1:16:35s\n",
            "epoch 1644| loss: 0.9673  | train_accuracy: 0.5165  | val_accuracy: 0.5066  |  1:16:38s\n",
            "epoch 1645| loss: 0.96675 | train_accuracy: 0.51819 | val_accuracy: 0.4962  |  1:16:41s\n",
            "epoch 1646| loss: 0.96471 | train_accuracy: 0.52015 | val_accuracy: 0.4898  |  1:16:43s\n",
            "epoch 1647| loss: 0.96542 | train_accuracy: 0.51566 | val_accuracy: 0.4994  |  1:16:46s\n",
            "epoch 1648| loss: 0.96653 | train_accuracy: 0.51637 | val_accuracy: 0.4922  |  1:16:49s\n",
            "epoch 1649| loss: 0.96541 | train_accuracy: 0.5181  | val_accuracy: 0.48741 |  1:16:52s\n",
            "epoch 1650| loss: 0.96641 | train_accuracy: 0.51637 | val_accuracy: 0.4994  |  1:16:54s\n",
            "epoch 1651| loss: 0.96836 | train_accuracy: 0.51619 | val_accuracy: 0.4986  |  1:16:57s\n",
            "epoch 1652| loss: 0.96827 | train_accuracy: 0.51704 | val_accuracy: 0.4974  |  1:17:00s\n",
            "epoch 1653| loss: 0.9653  | train_accuracy: 0.52006 | val_accuracy: 0.5026  |  1:17:03s\n",
            "epoch 1654| loss: 0.9666  | train_accuracy: 0.51802 | val_accuracy: 0.51419 |  1:17:06s\n",
            "epoch 1655| loss: 0.96592 | train_accuracy: 0.52015 | val_accuracy: 0.505   |  1:17:09s\n",
            "epoch 1656| loss: 0.96155 | train_accuracy: 0.52033 | val_accuracy: 0.5026  |  1:17:11s\n",
            "epoch 1657| loss: 0.95992 | train_accuracy: 0.52024 | val_accuracy: 0.5094  |  1:17:14s\n",
            "epoch 1658| loss: 0.96392 | train_accuracy: 0.51997 | val_accuracy: 0.5094  |  1:17:17s\n",
            "epoch 1659| loss: 0.96441 | train_accuracy: 0.52104 | val_accuracy: 0.5114  |  1:17:20s\n",
            "epoch 1660| loss: 0.96589 | train_accuracy: 0.52112 | val_accuracy: 0.5014  |  1:17:22s\n",
            "epoch 1661| loss: 0.96442 | train_accuracy: 0.51895 | val_accuracy: 0.497   |  1:17:25s\n",
            "epoch 1662| loss: 0.96406 | train_accuracy: 0.51997 | val_accuracy: 0.4982  |  1:17:28s\n",
            "epoch 1663| loss: 0.96343 | train_accuracy: 0.52037 | val_accuracy: 0.5018  |  1:17:32s\n",
            "epoch 1664| loss: 0.96672 | train_accuracy: 0.51944 | val_accuracy: 0.4942  |  1:17:36s\n",
            "epoch 1665| loss: 0.96251 | train_accuracy: 0.52006 | val_accuracy: 0.497   |  1:17:39s\n",
            "epoch 1666| loss: 0.96542 | train_accuracy: 0.52033 | val_accuracy: 0.4922  |  1:17:42s\n",
            "epoch 1667| loss: 0.9625  | train_accuracy: 0.5197  | val_accuracy: 0.4946  |  1:17:45s\n",
            "epoch 1668| loss: 0.96859 | train_accuracy: 0.51917 | val_accuracy: 0.4994  |  1:17:47s\n",
            "epoch 1669| loss: 0.9657  | train_accuracy: 0.51819 | val_accuracy: 0.5002  |  1:17:50s\n",
            "epoch 1670| loss: 0.96588 | train_accuracy: 0.5201  | val_accuracy: 0.5038  |  1:17:53s\n",
            "epoch 1671| loss: 0.96536 | train_accuracy: 0.51921 | val_accuracy: 0.5022  |  1:17:56s\n",
            "epoch 1672| loss: 0.96197 | train_accuracy: 0.52108 | val_accuracy: 0.4942  |  1:17:59s\n",
            "epoch 1673| loss: 0.96382 | train_accuracy: 0.52108 | val_accuracy: 0.4954  |  1:18:01s\n",
            "epoch 1674| loss: 0.9654  | train_accuracy: 0.52041 | val_accuracy: 0.4878  |  1:18:04s\n",
            "epoch 1675| loss: 0.96587 | train_accuracy: 0.51984 | val_accuracy: 0.4958  |  1:18:07s\n",
            "epoch 1676| loss: 0.96203 | train_accuracy: 0.52059 | val_accuracy: 0.5006  |  1:18:09s\n",
            "epoch 1677| loss: 0.96376 | train_accuracy: 0.51881 | val_accuracy: 0.495   |  1:18:12s\n",
            "epoch 1678| loss: 0.96751 | train_accuracy: 0.51713 | val_accuracy: 0.4986  |  1:18:15s\n",
            "epoch 1679| loss: 0.96609 | train_accuracy: 0.52152 | val_accuracy: 0.4954  |  1:18:18s\n",
            "epoch 1680| loss: 0.96313 | train_accuracy: 0.52068 | val_accuracy: 0.5026  |  1:18:20s\n",
            "epoch 1681| loss: 0.96366 | train_accuracy: 0.51841 | val_accuracy: 0.4966  |  1:18:23s\n",
            "epoch 1682| loss: 0.96402 | train_accuracy: 0.51664 | val_accuracy: 0.4898  |  1:18:26s\n",
            "epoch 1683| loss: 0.9671  | train_accuracy: 0.51828 | val_accuracy: 0.4982  |  1:18:29s\n",
            "epoch 1684| loss: 0.96495 | train_accuracy: 0.51824 | val_accuracy: 0.5038  |  1:18:31s\n",
            "epoch 1685| loss: 0.96587 | train_accuracy: 0.51713 | val_accuracy: 0.5038  |  1:18:34s\n",
            "epoch 1686| loss: 0.9676  | train_accuracy: 0.51935 | val_accuracy: 0.4998  |  1:18:37s\n",
            "epoch 1687| loss: 0.96385 | train_accuracy: 0.51868 | val_accuracy: 0.499   |  1:18:40s\n",
            "epoch 1688| loss: 0.96639 | train_accuracy: 0.5185  | val_accuracy: 0.4978  |  1:18:42s\n",
            "epoch 1689| loss: 0.96719 | train_accuracy: 0.51868 | val_accuracy: 0.4962  |  1:18:45s\n",
            "epoch 1690| loss: 0.96451 | train_accuracy: 0.51904 | val_accuracy: 0.5014  |  1:18:48s\n",
            "epoch 1691| loss: 0.96606 | train_accuracy: 0.51824 | val_accuracy: 0.5022  |  1:18:51s\n",
            "epoch 1692| loss: 0.96533 | train_accuracy: 0.51775 | val_accuracy: 0.5014  |  1:18:53s\n",
            "epoch 1693| loss: 0.96609 | train_accuracy: 0.5185  | val_accuracy: 0.4982  |  1:18:56s\n",
            "epoch 1694| loss: 0.9641  | train_accuracy: 0.51722 | val_accuracy: 0.4974  |  1:18:59s\n",
            "epoch 1695| loss: 0.9684  | train_accuracy: 0.51788 | val_accuracy: 0.499   |  1:19:02s\n",
            "epoch 1696| loss: 0.96418 | train_accuracy: 0.51961 | val_accuracy: 0.4966  |  1:19:04s\n",
            "epoch 1697| loss: 0.9664  | train_accuracy: 0.51824 | val_accuracy: 0.4982  |  1:19:07s\n",
            "epoch 1698| loss: 0.96709 | train_accuracy: 0.5165  | val_accuracy: 0.503   |  1:19:10s\n",
            "epoch 1699| loss: 0.96843 | train_accuracy: 0.51566 | val_accuracy: 0.5046  |  1:19:13s\n",
            "epoch 1700| loss: 0.96906 | train_accuracy: 0.51375 | val_accuracy: 0.5022  |  1:19:15s\n",
            "epoch 1701| loss: 0.96679 | train_accuracy: 0.51433 | val_accuracy: 0.5038  |  1:19:18s\n",
            "epoch 1702| loss: 0.96942 | train_accuracy: 0.51637 | val_accuracy: 0.505   |  1:19:22s\n",
            "epoch 1703| loss: 0.9666  | train_accuracy: 0.51833 | val_accuracy: 0.507   |  1:19:24s\n",
            "epoch 1704| loss: 0.96828 | train_accuracy: 0.51522 | val_accuracy: 0.5042  |  1:19:27s\n",
            "epoch 1705| loss: 0.9673  | train_accuracy: 0.51677 | val_accuracy: 0.4982  |  1:19:30s\n",
            "epoch 1706| loss: 0.96797 | train_accuracy: 0.51615 | val_accuracy: 0.5022  |  1:19:33s\n",
            "epoch 1707| loss: 0.96545 | train_accuracy: 0.51526 | val_accuracy: 0.505   |  1:19:35s\n",
            "epoch 1708| loss: 0.96659 | train_accuracy: 0.51557 | val_accuracy: 0.5034  |  1:19:38s\n",
            "epoch 1709| loss: 0.96847 | train_accuracy: 0.51619 | val_accuracy: 0.5034  |  1:19:41s\n",
            "epoch 1710| loss: 0.9677  | train_accuracy: 0.51899 | val_accuracy: 0.503   |  1:19:44s\n",
            "epoch 1711| loss: 0.96757 | train_accuracy: 0.51837 | val_accuracy: 0.5042  |  1:19:46s\n",
            "epoch 1712| loss: 0.96587 | train_accuracy: 0.51939 | val_accuracy: 0.5026  |  1:19:49s\n",
            "epoch 1713| loss: 0.96893 | train_accuracy: 0.51895 | val_accuracy: 0.5022  |  1:19:52s\n",
            "epoch 1714| loss: 0.97145 | train_accuracy: 0.5209  | val_accuracy: 0.5074  |  1:19:55s\n",
            "epoch 1715| loss: 0.96531 | train_accuracy: 0.51824 | val_accuracy: 0.5062  |  1:19:57s\n",
            "epoch 1716| loss: 0.96553 | train_accuracy: 0.51984 | val_accuracy: 0.5082  |  1:20:00s\n",
            "epoch 1717| loss: 0.96823 | train_accuracy: 0.51895 | val_accuracy: 0.5062  |  1:20:03s\n",
            "epoch 1718| loss: 0.9716  | train_accuracy: 0.51868 | val_accuracy: 0.509   |  1:20:06s\n",
            "epoch 1719| loss: 0.96858 | train_accuracy: 0.51797 | val_accuracy: 0.5102  |  1:20:08s\n",
            "epoch 1720| loss: 0.96875 | train_accuracy: 0.51659 | val_accuracy: 0.5106  |  1:20:11s\n",
            "epoch 1721| loss: 0.97255 | train_accuracy: 0.51788 | val_accuracy: 0.5082  |  1:20:14s\n",
            "epoch 1722| loss: 0.97057 | train_accuracy: 0.51388 | val_accuracy: 0.5018  |  1:20:17s\n",
            "epoch 1723| loss: 0.97055 | train_accuracy: 0.51482 | val_accuracy: 0.5066  |  1:20:19s\n",
            "epoch 1724| loss: 0.97066 | train_accuracy: 0.51326 | val_accuracy: 0.5074  |  1:20:22s\n",
            "epoch 1725| loss: 0.97082 | train_accuracy: 0.51388 | val_accuracy: 0.51419 |  1:20:25s\n",
            "epoch 1726| loss: 0.97193 | train_accuracy: 0.50984 | val_accuracy: 0.5046  |  1:20:28s\n",
            "epoch 1727| loss: 0.97449 | train_accuracy: 0.50855 | val_accuracy: 0.509   |  1:20:31s\n",
            "epoch 1728| loss: 0.96996 | train_accuracy: 0.5098  | val_accuracy: 0.505   |  1:20:33s\n",
            "epoch 1729| loss: 0.96943 | train_accuracy: 0.51166 | val_accuracy: 0.5018  |  1:20:37s\n",
            "epoch 1730| loss: 0.97326 | train_accuracy: 0.51255 | val_accuracy: 0.5006  |  1:20:39s\n",
            "epoch 1731| loss: 0.97267 | train_accuracy: 0.51046 | val_accuracy: 0.497   |  1:20:42s\n",
            "epoch 1732| loss: 0.97545 | train_accuracy: 0.51393 | val_accuracy: 0.505   |  1:20:45s\n",
            "epoch 1733| loss: 0.97265 | train_accuracy: 0.51486 | val_accuracy: 0.5086  |  1:20:48s\n",
            "epoch 1734| loss: 0.9725  | train_accuracy: 0.51477 | val_accuracy: 0.5086  |  1:20:50s\n",
            "epoch 1735| loss: 0.9702  | train_accuracy: 0.51526 | val_accuracy: 0.503   |  1:20:53s\n",
            "epoch 1736| loss: 0.97115 | train_accuracy: 0.51695 | val_accuracy: 0.5082  |  1:20:56s\n",
            "epoch 1737| loss: 0.97274 | train_accuracy: 0.51948 | val_accuracy: 0.4974  |  1:20:59s\n",
            "epoch 1738| loss: 0.96859 | train_accuracy: 0.5193  | val_accuracy: 0.5006  |  1:21:01s\n",
            "epoch 1739| loss: 0.96922 | train_accuracy: 0.51824 | val_accuracy: 0.4986  |  1:21:04s\n",
            "epoch 1740| loss: 0.97    | train_accuracy: 0.5165  | val_accuracy: 0.4998  |  1:21:07s\n",
            "epoch 1741| loss: 0.97007 | train_accuracy: 0.51597 | val_accuracy: 0.501   |  1:21:09s\n",
            "epoch 1742| loss: 0.97411 | train_accuracy: 0.51277 | val_accuracy: 0.5038  |  1:21:12s\n",
            "epoch 1743| loss: 0.97346 | train_accuracy: 0.51162 | val_accuracy: 0.4986  |  1:21:15s\n",
            "epoch 1744| loss: 0.97226 | train_accuracy: 0.51162 | val_accuracy: 0.4978  |  1:21:18s\n",
            "epoch 1745| loss: 0.96911 | train_accuracy: 0.51353 | val_accuracy: 0.5058  |  1:21:20s\n",
            "epoch 1746| loss: 0.97146 | train_accuracy: 0.51264 | val_accuracy: 0.4978  |  1:21:23s\n",
            "epoch 1747| loss: 0.97246 | train_accuracy: 0.50971 | val_accuracy: 0.4906  |  1:21:26s\n",
            "epoch 1748| loss: 0.97302 | train_accuracy: 0.50864 | val_accuracy: 0.493   |  1:21:29s\n",
            "epoch 1749| loss: 0.97217 | train_accuracy: 0.51282 | val_accuracy: 0.4958  |  1:21:32s\n",
            "epoch 1750| loss: 0.96985 | train_accuracy: 0.51482 | val_accuracy: 0.4986  |  1:21:34s\n",
            "epoch 1751| loss: 0.97207 | train_accuracy: 0.51424 | val_accuracy: 0.495   |  1:21:38s\n",
            "epoch 1752| loss: 0.9698  | train_accuracy: 0.5098  | val_accuracy: 0.5018  |  1:21:40s\n",
            "epoch 1753| loss: 0.97325 | train_accuracy: 0.51428 | val_accuracy: 0.4986  |  1:21:43s\n",
            "epoch 1754| loss: 0.97128 | train_accuracy: 0.51193 | val_accuracy: 0.503   |  1:21:46s\n",
            "epoch 1755| loss: 0.97114 | train_accuracy: 0.51317 | val_accuracy: 0.5058  |  1:21:49s\n",
            "epoch 1756| loss: 0.97018 | train_accuracy: 0.51264 | val_accuracy: 0.4958  |  1:21:51s\n",
            "epoch 1757| loss: 0.97206 | train_accuracy: 0.51526 | val_accuracy: 0.4966  |  1:21:54s\n",
            "epoch 1758| loss: 0.96858 | train_accuracy: 0.51308 | val_accuracy: 0.4966  |  1:21:57s\n",
            "epoch 1759| loss: 0.97622 | train_accuracy: 0.51597 | val_accuracy: 0.4966  |  1:22:00s\n",
            "epoch 1760| loss: 0.97092 | train_accuracy: 0.51655 | val_accuracy: 0.5014  |  1:22:02s\n",
            "epoch 1761| loss: 0.96838 | train_accuracy: 0.5157  | val_accuracy: 0.5002  |  1:22:05s\n",
            "epoch 1762| loss: 0.97242 | train_accuracy: 0.51362 | val_accuracy: 0.5058  |  1:22:08s\n",
            "epoch 1763| loss: 0.97385 | train_accuracy: 0.51628 | val_accuracy: 0.505   |  1:22:11s\n",
            "epoch 1764| loss: 0.96854 | train_accuracy: 0.51402 | val_accuracy: 0.4962  |  1:22:13s\n",
            "epoch 1765| loss: 0.96961 | train_accuracy: 0.51597 | val_accuracy: 0.5014  |  1:22:16s\n",
            "epoch 1766| loss: 0.97074 | train_accuracy: 0.51553 | val_accuracy: 0.5022  |  1:22:19s\n",
            "epoch 1767| loss: 0.97048 | train_accuracy: 0.51491 | val_accuracy: 0.5038  |  1:22:22s\n",
            "epoch 1768| loss: 0.97091 | train_accuracy: 0.51624 | val_accuracy: 0.5026  |  1:22:24s\n",
            "epoch 1769| loss: 0.97129 | train_accuracy: 0.51517 | val_accuracy: 0.5038  |  1:22:27s\n",
            "epoch 1770| loss: 0.96792 | train_accuracy: 0.51335 | val_accuracy: 0.4994  |  1:22:30s\n",
            "epoch 1771| loss: 0.96845 | train_accuracy: 0.51495 | val_accuracy: 0.4978  |  1:22:33s\n",
            "epoch 1772| loss: 0.96901 | train_accuracy: 0.51344 | val_accuracy: 0.4978  |  1:22:36s\n",
            "epoch 1773| loss: 0.96965 | train_accuracy: 0.51482 | val_accuracy: 0.499   |  1:22:38s\n",
            "epoch 1774| loss: 0.96946 | train_accuracy: 0.51602 | val_accuracy: 0.4978  |  1:22:41s\n",
            "epoch 1775| loss: 0.96941 | train_accuracy: 0.51277 | val_accuracy: 0.4958  |  1:22:44s\n",
            "epoch 1776| loss: 0.97225 | train_accuracy: 0.51166 | val_accuracy: 0.4898  |  1:22:47s\n",
            "epoch 1777| loss: 0.97037 | train_accuracy: 0.51259 | val_accuracy: 0.4954  |  1:22:50s\n",
            "epoch 1778| loss: 0.97063 | train_accuracy: 0.51242 | val_accuracy: 0.4926  |  1:22:52s\n",
            "epoch 1779| loss: 0.97138 | train_accuracy: 0.51064 | val_accuracy: 0.4938  |  1:22:55s\n",
            "epoch 1780| loss: 0.97084 | train_accuracy: 0.51291 | val_accuracy: 0.495   |  1:22:58s\n",
            "epoch 1781| loss: 0.96899 | train_accuracy: 0.51357 | val_accuracy: 0.4942  |  1:23:01s\n",
            "epoch 1782| loss: 0.97055 | train_accuracy: 0.51326 | val_accuracy: 0.495   |  1:23:04s\n",
            "epoch 1783| loss: 0.96983 | train_accuracy: 0.51335 | val_accuracy: 0.503   |  1:23:06s\n",
            "epoch 1784| loss: 0.97291 | train_accuracy: 0.51339 | val_accuracy: 0.5062  |  1:23:09s\n",
            "epoch 1785| loss: 0.97128 | train_accuracy: 0.51339 | val_accuracy: 0.5058  |  1:23:12s\n",
            "epoch 1786| loss: 0.9678  | train_accuracy: 0.51344 | val_accuracy: 0.5094  |  1:23:15s\n",
            "epoch 1787| loss: 0.96852 | train_accuracy: 0.51455 | val_accuracy: 0.5022  |  1:23:18s\n",
            "epoch 1788| loss: 0.9675  | train_accuracy: 0.51366 | val_accuracy: 0.5026  |  1:23:21s\n",
            "epoch 1789| loss: 0.96835 | train_accuracy: 0.51375 | val_accuracy: 0.503   |  1:23:24s\n",
            "epoch 1790| loss: 0.96954 | train_accuracy: 0.51246 | val_accuracy: 0.5038  |  1:23:26s\n",
            "epoch 1791| loss: 0.96757 | train_accuracy: 0.51295 | val_accuracy: 0.5034  |  1:23:29s\n",
            "epoch 1792| loss: 0.96627 | train_accuracy: 0.51468 | val_accuracy: 0.5058  |  1:23:32s\n",
            "epoch 1793| loss: 0.96894 | train_accuracy: 0.51455 | val_accuracy: 0.5018  |  1:23:35s\n",
            "epoch 1794| loss: 0.96876 | train_accuracy: 0.51522 | val_accuracy: 0.4962  |  1:23:38s\n",
            "epoch 1795| loss: 0.96892 | train_accuracy: 0.51593 | val_accuracy: 0.4914  |  1:23:41s\n",
            "epoch 1796| loss: 0.97042 | train_accuracy: 0.51606 | val_accuracy: 0.4886  |  1:23:44s\n",
            "epoch 1797| loss: 0.96754 | train_accuracy: 0.51579 | val_accuracy: 0.489   |  1:23:47s\n",
            "epoch 1798| loss: 0.96929 | train_accuracy: 0.51468 | val_accuracy: 0.4902  |  1:23:49s\n",
            "epoch 1799| loss: 0.96753 | train_accuracy: 0.51602 | val_accuracy: 0.48701 |  1:23:52s\n",
            "epoch 1800| loss: 0.96591 | train_accuracy: 0.5173  | val_accuracy: 0.4922  |  1:23:55s\n",
            "epoch 1801| loss: 0.96728 | train_accuracy: 0.51722 | val_accuracy: 0.4966  |  1:23:58s\n",
            "epoch 1802| loss: 0.96829 | train_accuracy: 0.51699 | val_accuracy: 0.4922  |  1:24:01s\n",
            "epoch 1803| loss: 0.96692 | train_accuracy: 0.51579 | val_accuracy: 0.4878  |  1:24:03s\n",
            "epoch 1804| loss: 0.97015 | train_accuracy: 0.51557 | val_accuracy: 0.48301 |  1:24:06s\n",
            "epoch 1805| loss: 0.96407 | train_accuracy: 0.51526 | val_accuracy: 0.48741 |  1:24:09s\n",
            "epoch 1806| loss: 0.96944 | train_accuracy: 0.51402 | val_accuracy: 0.48261 |  1:24:12s\n",
            "epoch 1807| loss: 0.96853 | train_accuracy: 0.51451 | val_accuracy: 0.4898  |  1:24:15s\n",
            "epoch 1808| loss: 0.96603 | train_accuracy: 0.51628 | val_accuracy: 0.4918  |  1:24:17s\n",
            "epoch 1809| loss: 0.96678 | train_accuracy: 0.51477 | val_accuracy: 0.4918  |  1:24:20s\n",
            "epoch 1810| loss: 0.96864 | train_accuracy: 0.51566 | val_accuracy: 0.497   |  1:24:23s\n",
            "epoch 1811| loss: 0.97021 | train_accuracy: 0.51455 | val_accuracy: 0.4986  |  1:24:26s\n",
            "epoch 1812| loss: 0.9676  | train_accuracy: 0.51299 | val_accuracy: 0.5002  |  1:24:29s\n",
            "epoch 1813| loss: 0.96887 | train_accuracy: 0.51508 | val_accuracy: 0.4922  |  1:24:31s\n",
            "epoch 1814| loss: 0.97074 | train_accuracy: 0.51535 | val_accuracy: 0.5002  |  1:24:34s\n",
            "epoch 1815| loss: 0.96748 | train_accuracy: 0.51277 | val_accuracy: 0.4954  |  1:24:37s\n",
            "epoch 1816| loss: 0.96702 | train_accuracy: 0.51406 | val_accuracy: 0.4962  |  1:24:40s\n",
            "epoch 1817| loss: 0.9694  | train_accuracy: 0.51331 | val_accuracy: 0.4986  |  1:24:42s\n",
            "epoch 1818| loss: 0.96973 | train_accuracy: 0.51166 | val_accuracy: 0.4958  |  1:24:45s\n",
            "epoch 1819| loss: 0.96653 | train_accuracy: 0.51135 | val_accuracy: 0.499   |  1:24:48s\n",
            "epoch 1820| loss: 0.96806 | train_accuracy: 0.51153 | val_accuracy: 0.4938  |  1:24:51s\n",
            "epoch 1821| loss: 0.97018 | train_accuracy: 0.51246 | val_accuracy: 0.4906  |  1:24:53s\n",
            "epoch 1822| loss: 0.96451 | train_accuracy: 0.51188 | val_accuracy: 0.491   |  1:24:56s\n",
            "epoch 1823| loss: 0.96885 | train_accuracy: 0.51171 | val_accuracy: 0.491   |  1:24:59s\n",
            "epoch 1824| loss: 0.96766 | train_accuracy: 0.51197 | val_accuracy: 0.4958  |  1:25:02s\n",
            "epoch 1825| loss: 0.96831 | train_accuracy: 0.51144 | val_accuracy: 0.4986  |  1:25:05s\n",
            "epoch 1826| loss: 0.96403 | train_accuracy: 0.51144 | val_accuracy: 0.4926  |  1:25:07s\n",
            "epoch 1827| loss: 0.96845 | train_accuracy: 0.5114  | val_accuracy: 0.4918  |  1:25:10s\n",
            "epoch 1828| loss: 0.96805 | train_accuracy: 0.51055 | val_accuracy: 0.4942  |  1:25:13s\n",
            "epoch 1829| loss: 0.9672  | train_accuracy: 0.51259 | val_accuracy: 0.4942  |  1:25:16s\n",
            "epoch 1830| loss: 0.96794 | train_accuracy: 0.51379 | val_accuracy: 0.4962  |  1:25:18s\n",
            "epoch 1831| loss: 0.96678 | train_accuracy: 0.51437 | val_accuracy: 0.4942  |  1:25:21s\n",
            "epoch 1832| loss: 0.965   | train_accuracy: 0.51348 | val_accuracy: 0.4938  |  1:25:24s\n",
            "epoch 1833| loss: 0.96637 | train_accuracy: 0.51411 | val_accuracy: 0.4962  |  1:25:27s\n",
            "epoch 1834| loss: 0.96822 | train_accuracy: 0.51242 | val_accuracy: 0.4918  |  1:25:30s\n",
            "epoch 1835| loss: 0.96715 | train_accuracy: 0.51557 | val_accuracy: 0.5002  |  1:25:32s\n",
            "epoch 1836| loss: 0.96932 | train_accuracy: 0.51455 | val_accuracy: 0.5042  |  1:25:35s\n",
            "epoch 1837| loss: 0.96523 | train_accuracy: 0.51451 | val_accuracy: 0.4942  |  1:25:38s\n",
            "epoch 1838| loss: 0.96686 | train_accuracy: 0.51433 | val_accuracy: 0.4898  |  1:25:41s\n",
            "epoch 1839| loss: 0.96781 | train_accuracy: 0.5153  | val_accuracy: 0.4954  |  1:25:43s\n",
            "epoch 1840| loss: 0.9626  | train_accuracy: 0.5153  | val_accuracy: 0.4998  |  1:25:46s\n",
            "epoch 1841| loss: 0.96671 | train_accuracy: 0.51299 | val_accuracy: 0.4922  |  1:25:49s\n",
            "epoch 1842| loss: 0.96536 | train_accuracy: 0.51246 | val_accuracy: 0.491   |  1:25:52s\n",
            "epoch 1843| loss: 0.96401 | train_accuracy: 0.51384 | val_accuracy: 0.4894  |  1:25:54s\n",
            "epoch 1844| loss: 0.96677 | train_accuracy: 0.51491 | val_accuracy: 0.4938  |  1:25:57s\n",
            "epoch 1845| loss: 0.96714 | train_accuracy: 0.51513 | val_accuracy: 0.4978  |  1:26:00s\n",
            "epoch 1846| loss: 0.96667 | train_accuracy: 0.51628 | val_accuracy: 0.4962  |  1:26:03s\n",
            "epoch 1847| loss: 0.96357 | train_accuracy: 0.51606 | val_accuracy: 0.4994  |  1:26:06s\n",
            "epoch 1848| loss: 0.96398 | train_accuracy: 0.51459 | val_accuracy: 0.499   |  1:26:08s\n",
            "epoch 1849| loss: 0.96981 | train_accuracy: 0.50975 | val_accuracy: 0.4962  |  1:26:11s\n",
            "epoch 1850| loss: 0.96725 | train_accuracy: 0.50962 | val_accuracy: 0.4962  |  1:26:14s\n",
            "epoch 1851| loss: 0.96739 | train_accuracy: 0.51268 | val_accuracy: 0.5022  |  1:26:17s\n",
            "epoch 1852| loss: 0.96706 | train_accuracy: 0.51086 | val_accuracy: 0.499   |  1:26:20s\n",
            "epoch 1853| loss: 0.96904 | train_accuracy: 0.51051 | val_accuracy: 0.5018  |  1:26:23s\n",
            "epoch 1854| loss: 0.96997 | train_accuracy: 0.51317 | val_accuracy: 0.505   |  1:26:25s\n",
            "epoch 1855| loss: 0.96825 | train_accuracy: 0.51331 | val_accuracy: 0.5034  |  1:26:28s\n",
            "epoch 1856| loss: 0.96678 | train_accuracy: 0.51259 | val_accuracy: 0.5022  |  1:26:31s\n",
            "epoch 1857| loss: 0.96745 | train_accuracy: 0.51304 | val_accuracy: 0.503   |  1:26:34s\n",
            "epoch 1858| loss: 0.9667  | train_accuracy: 0.51295 | val_accuracy: 0.505   |  1:26:36s\n",
            "epoch 1859| loss: 0.96755 | train_accuracy: 0.51348 | val_accuracy: 0.5038  |  1:26:39s\n",
            "epoch 1860| loss: 0.96396 | train_accuracy: 0.51295 | val_accuracy: 0.5002  |  1:26:42s\n",
            "epoch 1861| loss: 0.96887 | train_accuracy: 0.51304 | val_accuracy: 0.4986  |  1:26:45s\n",
            "epoch 1862| loss: 0.96611 | train_accuracy: 0.51459 | val_accuracy: 0.4998  |  1:26:47s\n",
            "epoch 1863| loss: 0.9677  | train_accuracy: 0.51459 | val_accuracy: 0.507   |  1:26:50s\n",
            "epoch 1864| loss: 0.96469 | train_accuracy: 0.51637 | val_accuracy: 0.5082  |  1:26:53s\n",
            "epoch 1865| loss: 0.96854 | train_accuracy: 0.51713 | val_accuracy: 0.5058  |  1:26:56s\n",
            "epoch 1866| loss: 0.96651 | train_accuracy: 0.5173  | val_accuracy: 0.507   |  1:26:58s\n",
            "epoch 1867| loss: 0.96817 | train_accuracy: 0.51468 | val_accuracy: 0.5042  |  1:27:01s\n",
            "epoch 1868| loss: 0.96636 | train_accuracy: 0.51339 | val_accuracy: 0.4974  |  1:27:04s\n",
            "epoch 1869| loss: 0.96911 | train_accuracy: 0.51362 | val_accuracy: 0.4986  |  1:27:06s\n",
            "epoch 1870| loss: 0.96409 | train_accuracy: 0.51255 | val_accuracy: 0.503   |  1:27:09s\n",
            "epoch 1871| loss: 0.96786 | train_accuracy: 0.51371 | val_accuracy: 0.5038  |  1:27:12s\n",
            "epoch 1872| loss: 0.96402 | train_accuracy: 0.51242 | val_accuracy: 0.5098  |  1:27:15s\n",
            "epoch 1873| loss: 0.96713 | train_accuracy: 0.51455 | val_accuracy: 0.5014  |  1:27:17s\n",
            "epoch 1874| loss: 0.96743 | train_accuracy: 0.51428 | val_accuracy: 0.5062  |  1:27:20s\n",
            "epoch 1875| loss: 0.96684 | train_accuracy: 0.51224 | val_accuracy: 0.5022  |  1:27:23s\n",
            "epoch 1876| loss: 0.96509 | train_accuracy: 0.51193 | val_accuracy: 0.5046  |  1:27:26s\n",
            "epoch 1877| loss: 0.96676 | train_accuracy: 0.51606 | val_accuracy: 0.5054  |  1:27:28s\n",
            "epoch 1878| loss: 0.96788 | train_accuracy: 0.51491 | val_accuracy: 0.503   |  1:27:31s\n",
            "epoch 1879| loss: 0.96742 | train_accuracy: 0.51362 | val_accuracy: 0.5042  |  1:27:34s\n",
            "epoch 1880| loss: 0.96867 | train_accuracy: 0.51473 | val_accuracy: 0.5018  |  1:27:37s\n",
            "epoch 1881| loss: 0.96588 | train_accuracy: 0.51433 | val_accuracy: 0.4982  |  1:27:39s\n",
            "epoch 1882| loss: 0.96711 | train_accuracy: 0.51508 | val_accuracy: 0.5026  |  1:27:42s\n",
            "epoch 1883| loss: 0.96393 | train_accuracy: 0.51495 | val_accuracy: 0.5082  |  1:27:45s\n",
            "epoch 1884| loss: 0.9677  | train_accuracy: 0.51344 | val_accuracy: 0.507   |  1:27:48s\n",
            "epoch 1885| loss: 0.96552 | train_accuracy: 0.51451 | val_accuracy: 0.505   |  1:27:50s\n",
            "epoch 1886| loss: 0.96841 | train_accuracy: 0.51575 | val_accuracy: 0.5058  |  1:27:53s\n",
            "epoch 1887| loss: 0.96858 | train_accuracy: 0.51357 | val_accuracy: 0.4994  |  1:27:56s\n",
            "epoch 1888| loss: 0.96338 | train_accuracy: 0.51486 | val_accuracy: 0.4998  |  1:27:59s\n",
            "epoch 1889| loss: 0.96806 | train_accuracy: 0.51739 | val_accuracy: 0.5034  |  1:28:01s\n",
            "epoch 1890| loss: 0.96826 | train_accuracy: 0.51717 | val_accuracy: 0.5034  |  1:28:04s\n",
            "epoch 1891| loss: 0.96707 | train_accuracy: 0.51713 | val_accuracy: 0.5078  |  1:28:07s\n",
            "epoch 1892| loss: 0.96328 | train_accuracy: 0.51713 | val_accuracy: 0.5054  |  1:28:09s\n",
            "epoch 1893| loss: 0.96737 | train_accuracy: 0.5173  | val_accuracy: 0.5074  |  1:28:12s\n",
            "epoch 1894| loss: 0.96515 | train_accuracy: 0.51664 | val_accuracy: 0.5026  |  1:28:15s\n",
            "epoch 1895| loss: 0.96446 | train_accuracy: 0.51517 | val_accuracy: 0.5066  |  1:28:18s\n",
            "epoch 1896| loss: 0.96704 | train_accuracy: 0.51406 | val_accuracy: 0.5026  |  1:28:20s\n",
            "epoch 1897| loss: 0.96444 | train_accuracy: 0.51384 | val_accuracy: 0.5014  |  1:28:23s\n",
            "epoch 1898| loss: 0.96505 | train_accuracy: 0.51375 | val_accuracy: 0.5002  |  1:28:26s\n",
            "epoch 1899| loss: 0.9681  | train_accuracy: 0.51504 | val_accuracy: 0.5022  |  1:28:29s\n",
            "epoch 1900| loss: 0.96758 | train_accuracy: 0.51677 | val_accuracy: 0.5042  |  1:28:31s\n",
            "epoch 1901| loss: 0.96767 | train_accuracy: 0.51437 | val_accuracy: 0.503   |  1:28:34s\n",
            "epoch 1902| loss: 0.96688 | train_accuracy: 0.51615 | val_accuracy: 0.5054  |  1:28:37s\n",
            "epoch 1903| loss: 0.96817 | train_accuracy: 0.51508 | val_accuracy: 0.5018  |  1:28:40s\n",
            "epoch 1904| loss: 0.96546 | train_accuracy: 0.51473 | val_accuracy: 0.505   |  1:28:42s\n",
            "epoch 1905| loss: 0.96452 | train_accuracy: 0.51593 | val_accuracy: 0.505   |  1:28:45s\n",
            "epoch 1906| loss: 0.96661 | train_accuracy: 0.51575 | val_accuracy: 0.503   |  1:28:48s\n",
            "epoch 1907| loss: 0.96836 | train_accuracy: 0.51455 | val_accuracy: 0.5022  |  1:28:51s\n",
            "epoch 1908| loss: 0.96607 | train_accuracy: 0.51606 | val_accuracy: 0.4962  |  1:28:53s\n",
            "epoch 1909| loss: 0.96671 | train_accuracy: 0.51699 | val_accuracy: 0.5034  |  1:28:56s\n",
            "epoch 1910| loss: 0.96432 | train_accuracy: 0.51695 | val_accuracy: 0.501   |  1:28:59s\n",
            "epoch 1911| loss: 0.96562 | train_accuracy: 0.51815 | val_accuracy: 0.5058  |  1:29:02s\n",
            "epoch 1912| loss: 0.96457 | train_accuracy: 0.51899 | val_accuracy: 0.507   |  1:29:04s\n",
            "epoch 1913| loss: 0.96416 | train_accuracy: 0.51841 | val_accuracy: 0.503   |  1:29:07s\n",
            "epoch 1914| loss: 0.96326 | train_accuracy: 0.51841 | val_accuracy: 0.5026  |  1:29:10s\n",
            "epoch 1915| loss: 0.96602 | train_accuracy: 0.51873 | val_accuracy: 0.5058  |  1:29:12s\n",
            "epoch 1916| loss: 0.96627 | train_accuracy: 0.51833 | val_accuracy: 0.5054  |  1:29:15s\n",
            "epoch 1917| loss: 0.96666 | train_accuracy: 0.51921 | val_accuracy: 0.5018  |  1:29:18s\n",
            "epoch 1918| loss: 0.96635 | train_accuracy: 0.5173  | val_accuracy: 0.5034  |  1:29:21s\n",
            "epoch 1919| loss: 0.96677 | train_accuracy: 0.51824 | val_accuracy: 0.5014  |  1:29:23s\n",
            "epoch 1920| loss: 0.96538 | train_accuracy: 0.51833 | val_accuracy: 0.5002  |  1:29:26s\n",
            "epoch 1921| loss: 0.96604 | train_accuracy: 0.51806 | val_accuracy: 0.499   |  1:29:29s\n",
            "epoch 1922| loss: 0.96202 | train_accuracy: 0.51682 | val_accuracy: 0.4986  |  1:29:32s\n",
            "epoch 1923| loss: 0.96367 | train_accuracy: 0.5177  | val_accuracy: 0.4966  |  1:29:34s\n",
            "epoch 1924| loss: 0.96471 | train_accuracy: 0.51788 | val_accuracy: 0.5018  |  1:29:37s\n",
            "epoch 1925| loss: 0.96322 | train_accuracy: 0.51704 | val_accuracy: 0.5026  |  1:29:40s\n",
            "epoch 1926| loss: 0.96635 | train_accuracy: 0.51606 | val_accuracy: 0.5014  |  1:29:43s\n",
            "epoch 1927| loss: 0.9666  | train_accuracy: 0.51722 | val_accuracy: 0.497   |  1:29:45s\n",
            "epoch 1928| loss: 0.96615 | train_accuracy: 0.51428 | val_accuracy: 0.4966  |  1:29:48s\n",
            "epoch 1929| loss: 0.96686 | train_accuracy: 0.51406 | val_accuracy: 0.497   |  1:29:51s\n",
            "epoch 1930| loss: 0.96443 | train_accuracy: 0.51397 | val_accuracy: 0.4934  |  1:29:54s\n",
            "epoch 1931| loss: 0.96726 | train_accuracy: 0.51379 | val_accuracy: 0.4934  |  1:29:57s\n",
            "epoch 1932| loss: 0.96787 | train_accuracy: 0.51433 | val_accuracy: 0.4902  |  1:29:59s\n",
            "epoch 1933| loss: 0.96681 | train_accuracy: 0.51468 | val_accuracy: 0.493   |  1:30:02s\n",
            "epoch 1934| loss: 0.96538 | train_accuracy: 0.51504 | val_accuracy: 0.491   |  1:30:05s\n",
            "epoch 1935| loss: 0.96542 | train_accuracy: 0.51375 | val_accuracy: 0.5014  |  1:30:07s\n",
            "epoch 1936| loss: 0.96522 | train_accuracy: 0.51526 | val_accuracy: 0.5002  |  1:30:10s\n",
            "epoch 1937| loss: 0.96619 | train_accuracy: 0.51366 | val_accuracy: 0.4966  |  1:30:13s\n",
            "epoch 1938| loss: 0.97029 | train_accuracy: 0.51437 | val_accuracy: 0.4942  |  1:30:16s\n",
            "epoch 1939| loss: 0.96659 | train_accuracy: 0.51317 | val_accuracy: 0.499   |  1:30:18s\n",
            "epoch 1940| loss: 0.96896 | train_accuracy: 0.51362 | val_accuracy: 0.495   |  1:30:22s\n",
            "epoch 1941| loss: 0.97024 | train_accuracy: 0.51246 | val_accuracy: 0.4986  |  1:30:27s\n",
            "epoch 1942| loss: 0.96911 | train_accuracy: 0.51442 | val_accuracy: 0.4962  |  1:30:30s\n",
            "epoch 1943| loss: 0.96616 | train_accuracy: 0.51388 | val_accuracy: 0.499   |  1:30:33s\n",
            "epoch 1944| loss: 0.96793 | train_accuracy: 0.51442 | val_accuracy: 0.5046  |  1:30:36s\n",
            "epoch 1945| loss: 0.96859 | train_accuracy: 0.51313 | val_accuracy: 0.5082  |  1:30:38s\n",
            "epoch 1946| loss: 0.96615 | train_accuracy: 0.51273 | val_accuracy: 0.5078  |  1:30:41s\n",
            "epoch 1947| loss: 0.96666 | train_accuracy: 0.51251 | val_accuracy: 0.505   |  1:30:44s\n",
            "epoch 1948| loss: 0.96591 | train_accuracy: 0.51113 | val_accuracy: 0.5042  |  1:30:46s\n",
            "epoch 1949| loss: 0.96742 | train_accuracy: 0.51068 | val_accuracy: 0.501   |  1:30:50s\n",
            "epoch 1950| loss: 0.96735 | train_accuracy: 0.5106  | val_accuracy: 0.4986  |  1:30:53s\n",
            "epoch 1951| loss: 0.96803 | train_accuracy: 0.50957 | val_accuracy: 0.5026  |  1:30:55s\n",
            "epoch 1952| loss: 0.96833 | train_accuracy: 0.5122  | val_accuracy: 0.5022  |  1:30:58s\n",
            "epoch 1953| loss: 0.96684 | train_accuracy: 0.51251 | val_accuracy: 0.4962  |  1:31:01s\n",
            "epoch 1954| loss: 0.9716  | train_accuracy: 0.51108 | val_accuracy: 0.4946  |  1:31:03s\n",
            "epoch 1955| loss: 0.96708 | train_accuracy: 0.51331 | val_accuracy: 0.4946  |  1:31:06s\n",
            "epoch 1956| loss: 0.96563 | train_accuracy: 0.51282 | val_accuracy: 0.5002  |  1:31:09s\n",
            "epoch 1957| loss: 0.9668  | train_accuracy: 0.51193 | val_accuracy: 0.5062  |  1:31:12s\n",
            "epoch 1958| loss: 0.96692 | train_accuracy: 0.51486 | val_accuracy: 0.5026  |  1:31:14s\n",
            "epoch 1959| loss: 0.96498 | train_accuracy: 0.5153  | val_accuracy: 0.5018  |  1:31:17s\n",
            "epoch 1960| loss: 0.96415 | train_accuracy: 0.51442 | val_accuracy: 0.5014  |  1:31:20s\n",
            "epoch 1961| loss: 0.96534 | train_accuracy: 0.51468 | val_accuracy: 0.4982  |  1:31:23s\n",
            "epoch 1962| loss: 0.96497 | train_accuracy: 0.51499 | val_accuracy: 0.4994  |  1:31:25s\n",
            "epoch 1963| loss: 0.96753 | train_accuracy: 0.51379 | val_accuracy: 0.4966  |  1:31:28s\n",
            "epoch 1964| loss: 0.96771 | train_accuracy: 0.51615 | val_accuracy: 0.5014  |  1:31:31s\n",
            "epoch 1965| loss: 0.96572 | train_accuracy: 0.51331 | val_accuracy: 0.5094  |  1:31:33s\n",
            "epoch 1966| loss: 0.96851 | train_accuracy: 0.51242 | val_accuracy: 0.5082  |  1:31:36s\n",
            "epoch 1967| loss: 0.96322 | train_accuracy: 0.51366 | val_accuracy: 0.5102  |  1:31:39s\n",
            "epoch 1968| loss: 0.96857 | train_accuracy: 0.5157  | val_accuracy: 0.51579 |  1:31:42s\n",
            "epoch 1969| loss: 0.96733 | train_accuracy: 0.51473 | val_accuracy: 0.5082  |  1:31:44s\n",
            "epoch 1970| loss: 0.96937 | train_accuracy: 0.51584 | val_accuracy: 0.5082  |  1:31:47s\n",
            "epoch 1971| loss: 0.96619 | train_accuracy: 0.51722 | val_accuracy: 0.51419 |  1:31:50s\n",
            "epoch 1972| loss: 0.96709 | train_accuracy: 0.51828 | val_accuracy: 0.5074  |  1:31:53s\n",
            "epoch 1973| loss: 0.96653 | train_accuracy: 0.51806 | val_accuracy: 0.5038  |  1:31:58s\n",
            "epoch 1974| loss: 0.96637 | train_accuracy: 0.51646 | val_accuracy: 0.5042  |  1:32:01s\n",
            "epoch 1975| loss: 0.96686 | train_accuracy: 0.51695 | val_accuracy: 0.5094  |  1:32:03s\n",
            "epoch 1976| loss: 0.96309 | train_accuracy: 0.51739 | val_accuracy: 0.5062  |  1:32:06s\n",
            "epoch 1977| loss: 0.96615 | train_accuracy: 0.51433 | val_accuracy: 0.509   |  1:32:09s\n",
            "epoch 1978| loss: 0.96807 | train_accuracy: 0.51504 | val_accuracy: 0.5114  |  1:32:12s\n",
            "epoch 1979| loss: 0.96822 | train_accuracy: 0.51304 | val_accuracy: 0.5082  |  1:32:14s\n",
            "epoch 1980| loss: 0.967   | train_accuracy: 0.51459 | val_accuracy: 0.5098  |  1:32:17s\n",
            "epoch 1981| loss: 0.96738 | train_accuracy: 0.51317 | val_accuracy: 0.5034  |  1:32:20s\n",
            "epoch 1982| loss: 0.96306 | train_accuracy: 0.51291 | val_accuracy: 0.497   |  1:32:23s\n",
            "epoch 1983| loss: 0.96974 | train_accuracy: 0.51144 | val_accuracy: 0.5042  |  1:32:25s\n",
            "epoch 1984| loss: 0.96649 | train_accuracy: 0.51366 | val_accuracy: 0.5106  |  1:32:28s\n",
            "epoch 1985| loss: 0.96814 | train_accuracy: 0.51246 | val_accuracy: 0.5054  |  1:32:31s\n",
            "epoch 1986| loss: 0.96644 | train_accuracy: 0.51237 | val_accuracy: 0.4966  |  1:32:34s\n",
            "epoch 1987| loss: 0.96617 | train_accuracy: 0.51415 | val_accuracy: 0.4974  |  1:32:36s\n",
            "epoch 1988| loss: 0.97003 | train_accuracy: 0.51291 | val_accuracy: 0.4994  |  1:32:39s\n",
            "epoch 1989| loss: 0.96916 | train_accuracy: 0.51126 | val_accuracy: 0.503   |  1:32:42s\n",
            "epoch 1990| loss: 0.96675 | train_accuracy: 0.51202 | val_accuracy: 0.4998  |  1:32:45s\n",
            "epoch 1991| loss: 0.96523 | train_accuracy: 0.51406 | val_accuracy: 0.4986  |  1:32:47s\n",
            "epoch 1992| loss: 0.96708 | train_accuracy: 0.51362 | val_accuracy: 0.5038  |  1:32:50s\n",
            "epoch 1993| loss: 0.96463 | train_accuracy: 0.51486 | val_accuracy: 0.507   |  1:32:53s\n",
            "epoch 1994| loss: 0.96654 | train_accuracy: 0.51415 | val_accuracy: 0.5086  |  1:32:55s\n",
            "epoch 1995| loss: 0.96773 | train_accuracy: 0.51371 | val_accuracy: 0.5086  |  1:32:58s\n",
            "epoch 1996| loss: 0.96829 | train_accuracy: 0.51384 | val_accuracy: 0.5046  |  1:33:01s\n",
            "epoch 1997| loss: 0.96665 | train_accuracy: 0.51313 | val_accuracy: 0.5034  |  1:33:04s\n",
            "epoch 1998| loss: 0.96879 | train_accuracy: 0.51299 | val_accuracy: 0.505   |  1:33:06s\n",
            "epoch 1999| loss: 0.96483 | train_accuracy: 0.51273 | val_accuracy: 0.5082  |  1:33:09s\n",
            "epoch 2000| loss: 0.96851 | train_accuracy: 0.51428 | val_accuracy: 0.51339 |  1:33:12s\n",
            "epoch 2001| loss: 0.96832 | train_accuracy: 0.5153  | val_accuracy: 0.51339 |  1:33:15s\n",
            "epoch 2002| loss: 0.96462 | train_accuracy: 0.51566 | val_accuracy: 0.5094  |  1:33:17s\n",
            "epoch 2003| loss: 0.9669  | train_accuracy: 0.51477 | val_accuracy: 0.507   |  1:33:20s\n",
            "epoch 2004| loss: 0.96648 | train_accuracy: 0.51464 | val_accuracy: 0.5078  |  1:33:23s\n",
            "epoch 2005| loss: 0.9664  | train_accuracy: 0.51446 | val_accuracy: 0.5086  |  1:33:25s\n",
            "epoch 2006| loss: 0.96704 | train_accuracy: 0.51517 | val_accuracy: 0.5062  |  1:33:28s\n",
            "epoch 2007| loss: 0.96615 | train_accuracy: 0.51459 | val_accuracy: 0.5094  |  1:33:31s\n",
            "epoch 2008| loss: 0.96634 | train_accuracy: 0.51526 | val_accuracy: 0.5038  |  1:33:34s\n",
            "epoch 2009| loss: 0.96521 | train_accuracy: 0.51304 | val_accuracy: 0.5018  |  1:33:36s\n",
            "epoch 2010| loss: 0.96811 | train_accuracy: 0.51415 | val_accuracy: 0.4998  |  1:33:39s\n",
            "epoch 2011| loss: 0.96708 | train_accuracy: 0.51037 | val_accuracy: 0.4978  |  1:33:42s\n",
            "epoch 2012| loss: 0.9685  | train_accuracy: 0.51068 | val_accuracy: 0.4914  |  1:33:44s\n",
            "epoch 2013| loss: 0.96704 | train_accuracy: 0.51202 | val_accuracy: 0.4954  |  1:33:47s\n",
            "epoch 2014| loss: 0.9679  | train_accuracy: 0.51215 | val_accuracy: 0.499   |  1:33:50s\n",
            "epoch 2015| loss: 0.96806 | train_accuracy: 0.51477 | val_accuracy: 0.5038  |  1:33:53s\n",
            "epoch 2016| loss: 0.96764 | train_accuracy: 0.51415 | val_accuracy: 0.5018  |  1:33:55s\n",
            "epoch 2017| loss: 0.96778 | train_accuracy: 0.51193 | val_accuracy: 0.5034  |  1:33:58s\n",
            "epoch 2018| loss: 0.96629 | train_accuracy: 0.51051 | val_accuracy: 0.503   |  1:34:01s\n",
            "epoch 2019| loss: 0.9657  | train_accuracy: 0.50797 | val_accuracy: 0.5046  |  1:34:04s\n",
            "epoch 2020| loss: 0.96723 | train_accuracy: 0.51131 | val_accuracy: 0.509   |  1:34:06s\n",
            "epoch 2021| loss: 0.967   | train_accuracy: 0.50837 | val_accuracy: 0.503   |  1:34:09s\n",
            "epoch 2022| loss: 0.96734 | train_accuracy: 0.51055 | val_accuracy: 0.5018  |  1:34:12s\n",
            "epoch 2023| loss: 0.96662 | train_accuracy: 0.51073 | val_accuracy: 0.5046  |  1:34:15s\n",
            "epoch 2024| loss: 0.96826 | train_accuracy: 0.51037 | val_accuracy: 0.5014  |  1:34:17s\n",
            "epoch 2025| loss: 0.96511 | train_accuracy: 0.509   | val_accuracy: 0.5018  |  1:34:20s\n",
            "epoch 2026| loss: 0.96718 | train_accuracy: 0.51153 | val_accuracy: 0.503   |  1:34:23s\n",
            "epoch 2027| loss: 0.96408 | train_accuracy: 0.51086 | val_accuracy: 0.5062  |  1:34:26s\n",
            "epoch 2028| loss: 0.96473 | train_accuracy: 0.51024 | val_accuracy: 0.5058  |  1:34:28s\n",
            "epoch 2029| loss: 0.96574 | train_accuracy: 0.51117 | val_accuracy: 0.5082  |  1:34:31s\n",
            "epoch 2030| loss: 0.96779 | train_accuracy: 0.51215 | val_accuracy: 0.5086  |  1:34:34s\n",
            "epoch 2031| loss: 0.96756 | train_accuracy: 0.51091 | val_accuracy: 0.5038  |  1:34:37s\n",
            "epoch 2032| loss: 0.96427 | train_accuracy: 0.51237 | val_accuracy: 0.5062  |  1:34:39s\n",
            "epoch 2033| loss: 0.96877 | train_accuracy: 0.51202 | val_accuracy: 0.5082  |  1:34:42s\n",
            "epoch 2034| loss: 0.96544 | train_accuracy: 0.51108 | val_accuracy: 0.5082  |  1:34:45s\n",
            "epoch 2035| loss: 0.96858 | train_accuracy: 0.51117 | val_accuracy: 0.5102  |  1:34:48s\n",
            "epoch 2036| loss: 0.96758 | train_accuracy: 0.51202 | val_accuracy: 0.509   |  1:34:50s\n",
            "epoch 2037| loss: 0.96661 | train_accuracy: 0.51148 | val_accuracy: 0.5098  |  1:34:53s\n",
            "epoch 2038| loss: 0.96698 | train_accuracy: 0.51206 | val_accuracy: 0.5086  |  1:34:56s\n",
            "epoch 2039| loss: 0.96595 | train_accuracy: 0.51037 | val_accuracy: 0.5034  |  1:34:58s\n",
            "epoch 2040| loss: 0.96554 | train_accuracy: 0.51246 | val_accuracy: 0.5046  |  1:35:01s\n",
            "epoch 2041| loss: 0.96908 | train_accuracy: 0.51237 | val_accuracy: 0.5018  |  1:35:04s\n",
            "epoch 2042| loss: 0.96624 | train_accuracy: 0.51211 | val_accuracy: 0.5078  |  1:35:07s\n",
            "epoch 2043| loss: 0.9658  | train_accuracy: 0.51077 | val_accuracy: 0.5082  |  1:35:09s\n",
            "epoch 2044| loss: 0.96715 | train_accuracy: 0.51011 | val_accuracy: 0.5018  |  1:35:12s\n",
            "epoch 2045| loss: 0.96919 | train_accuracy: 0.51166 | val_accuracy: 0.5042  |  1:35:15s\n",
            "epoch 2046| loss: 0.9663  | train_accuracy: 0.51202 | val_accuracy: 0.5042  |  1:35:18s\n",
            "epoch 2047| loss: 0.96897 | train_accuracy: 0.51224 | val_accuracy: 0.5082  |  1:35:20s\n",
            "epoch 2048| loss: 0.96392 | train_accuracy: 0.51206 | val_accuracy: 0.509   |  1:35:23s\n",
            "epoch 2049| loss: 0.96649 | train_accuracy: 0.50988 | val_accuracy: 0.5054  |  1:35:26s\n",
            "epoch 2050| loss: 0.96739 | train_accuracy: 0.5114  | val_accuracy: 0.501   |  1:35:29s\n",
            "epoch 2051| loss: 0.97001 | train_accuracy: 0.51282 | val_accuracy: 0.5022  |  1:35:32s\n",
            "epoch 2052| loss: 0.9665  | train_accuracy: 0.51362 | val_accuracy: 0.5018  |  1:35:35s\n",
            "epoch 2053| loss: 0.9652  | train_accuracy: 0.51384 | val_accuracy: 0.4954  |  1:35:38s\n",
            "epoch 2054| loss: 0.96587 | train_accuracy: 0.51282 | val_accuracy: 0.4978  |  1:35:40s\n",
            "epoch 2055| loss: 0.96814 | train_accuracy: 0.51255 | val_accuracy: 0.4998  |  1:35:43s\n",
            "epoch 2056| loss: 0.96519 | train_accuracy: 0.51468 | val_accuracy: 0.5038  |  1:35:46s\n",
            "epoch 2057| loss: 0.96757 | train_accuracy: 0.51473 | val_accuracy: 0.5006  |  1:35:49s\n",
            "epoch 2058| loss: 0.96639 | train_accuracy: 0.51308 | val_accuracy: 0.499   |  1:35:51s\n",
            "epoch 2059| loss: 0.96205 | train_accuracy: 0.51259 | val_accuracy: 0.5018  |  1:35:54s\n",
            "epoch 2060| loss: 0.9651  | train_accuracy: 0.51344 | val_accuracy: 0.5042  |  1:35:57s\n",
            "epoch 2061| loss: 0.96601 | train_accuracy: 0.51428 | val_accuracy: 0.5022  |  1:36:00s\n",
            "epoch 2062| loss: 0.96657 | train_accuracy: 0.51308 | val_accuracy: 0.5014  |  1:36:02s\n",
            "epoch 2063| loss: 0.96552 | train_accuracy: 0.51308 | val_accuracy: 0.501   |  1:36:05s\n",
            "epoch 2064| loss: 0.96521 | train_accuracy: 0.5114  | val_accuracy: 0.5002  |  1:36:08s\n",
            "epoch 2065| loss: 0.96019 | train_accuracy: 0.51228 | val_accuracy: 0.501   |  1:36:11s\n",
            "epoch 2066| loss: 0.97006 | train_accuracy: 0.51255 | val_accuracy: 0.5042  |  1:36:13s\n",
            "epoch 2067| loss: 0.96692 | train_accuracy: 0.51246 | val_accuracy: 0.501   |  1:36:16s\n",
            "epoch 2068| loss: 0.96574 | train_accuracy: 0.51308 | val_accuracy: 0.503   |  1:36:19s\n",
            "epoch 2069| loss: 0.96583 | train_accuracy: 0.51224 | val_accuracy: 0.507   |  1:36:22s\n",
            "epoch 2070| loss: 0.9643  | train_accuracy: 0.51144 | val_accuracy: 0.5054  |  1:36:24s\n",
            "epoch 2071| loss: 0.9671  | train_accuracy: 0.51433 | val_accuracy: 0.5042  |  1:36:27s\n",
            "epoch 2072| loss: 0.96506 | train_accuracy: 0.51415 | val_accuracy: 0.5118  |  1:36:30s\n",
            "epoch 2073| loss: 0.96232 | train_accuracy: 0.51535 | val_accuracy: 0.5106  |  1:36:33s\n",
            "epoch 2074| loss: 0.96567 | train_accuracy: 0.51588 | val_accuracy: 0.5122  |  1:36:35s\n",
            "epoch 2075| loss: 0.9686  | train_accuracy: 0.51615 | val_accuracy: 0.5066  |  1:36:38s\n",
            "epoch 2076| loss: 0.96757 | train_accuracy: 0.51535 | val_accuracy: 0.5002  |  1:36:41s\n",
            "epoch 2077| loss: 0.96609 | train_accuracy: 0.51646 | val_accuracy: 0.5058  |  1:36:44s\n",
            "epoch 2078| loss: 0.96094 | train_accuracy: 0.5173  | val_accuracy: 0.5038  |  1:36:46s\n",
            "epoch 2079| loss: 0.96689 | train_accuracy: 0.51437 | val_accuracy: 0.491   |  1:36:49s\n",
            "epoch 2080| loss: 0.96587 | train_accuracy: 0.51513 | val_accuracy: 0.4938  |  1:36:52s\n",
            "epoch 2081| loss: 0.96537 | train_accuracy: 0.51673 | val_accuracy: 0.499   |  1:36:55s\n",
            "epoch 2082| loss: 0.96516 | train_accuracy: 0.51491 | val_accuracy: 0.505   |  1:36:57s\n",
            "epoch 2083| loss: 0.96456 | train_accuracy: 0.51442 | val_accuracy: 0.503   |  1:37:00s\n",
            "epoch 2084| loss: 0.96235 | train_accuracy: 0.51491 | val_accuracy: 0.5042  |  1:37:03s\n",
            "epoch 2085| loss: 0.96528 | train_accuracy: 0.51717 | val_accuracy: 0.5098  |  1:37:05s\n",
            "epoch 2086| loss: 0.96196 | train_accuracy: 0.51722 | val_accuracy: 0.5118  |  1:37:08s\n",
            "epoch 2087| loss: 0.9623  | train_accuracy: 0.51539 | val_accuracy: 0.5066  |  1:37:11s\n",
            "epoch 2088| loss: 0.96431 | train_accuracy: 0.51397 | val_accuracy: 0.5018  |  1:37:14s\n",
            "epoch 2089| loss: 0.96249 | train_accuracy: 0.51393 | val_accuracy: 0.501   |  1:37:16s\n",
            "epoch 2090| loss: 0.96532 | train_accuracy: 0.51486 | val_accuracy: 0.5102  |  1:37:19s\n",
            "epoch 2091| loss: 0.96631 | train_accuracy: 0.51268 | val_accuracy: 0.509   |  1:37:22s\n",
            "epoch 2092| loss: 0.96416 | train_accuracy: 0.51215 | val_accuracy: 0.5034  |  1:37:25s\n",
            "epoch 2093| loss: 0.96693 | train_accuracy: 0.51126 | val_accuracy: 0.5078  |  1:37:27s\n",
            "epoch 2094| loss: 0.96671 | train_accuracy: 0.51366 | val_accuracy: 0.5106  |  1:37:30s\n",
            "epoch 2095| loss: 0.96777 | train_accuracy: 0.51313 | val_accuracy: 0.5094  |  1:37:33s\n",
            "epoch 2096| loss: 0.96282 | train_accuracy: 0.51184 | val_accuracy: 0.501   |  1:37:36s\n",
            "epoch 2097| loss: 0.96399 | train_accuracy: 0.51126 | val_accuracy: 0.5014  |  1:37:38s\n",
            "epoch 2098| loss: 0.96749 | train_accuracy: 0.51246 | val_accuracy: 0.5018  |  1:37:41s\n",
            "epoch 2099| loss: 0.9658  | train_accuracy: 0.51246 | val_accuracy: 0.5038  |  1:37:44s\n",
            "epoch 2100| loss: 0.96711 | train_accuracy: 0.51335 | val_accuracy: 0.5034  |  1:37:47s\n",
            "epoch 2101| loss: 0.96826 | train_accuracy: 0.51562 | val_accuracy: 0.5066  |  1:37:49s\n",
            "epoch 2102| loss: 0.96305 | train_accuracy: 0.51624 | val_accuracy: 0.505   |  1:37:52s\n",
            "epoch 2103| loss: 0.96573 | train_accuracy: 0.51477 | val_accuracy: 0.5114  |  1:37:55s\n",
            "epoch 2104| loss: 0.96172 | train_accuracy: 0.51406 | val_accuracy: 0.51499 |  1:37:58s\n",
            "epoch 2105| loss: 0.96828 | train_accuracy: 0.51206 | val_accuracy: 0.5102  |  1:38:01s\n",
            "epoch 2106| loss: 0.9664  | train_accuracy: 0.51277 | val_accuracy: 0.5066  |  1:38:03s\n",
            "epoch 2107| loss: 0.96499 | train_accuracy: 0.51211 | val_accuracy: 0.5046  |  1:38:06s\n",
            "epoch 2108| loss: 0.96635 | train_accuracy: 0.51197 | val_accuracy: 0.5058  |  1:38:09s\n",
            "epoch 2109| loss: 0.96511 | train_accuracy: 0.51113 | val_accuracy: 0.5022  |  1:38:12s\n",
            "epoch 2110| loss: 0.96647 | train_accuracy: 0.5122  | val_accuracy: 0.5042  |  1:38:15s\n",
            "epoch 2111| loss: 0.96369 | train_accuracy: 0.51242 | val_accuracy: 0.503   |  1:38:18s\n",
            "epoch 2112| loss: 0.967   | train_accuracy: 0.51282 | val_accuracy: 0.5034  |  1:38:20s\n",
            "epoch 2113| loss: 0.96649 | train_accuracy: 0.5106  | val_accuracy: 0.5066  |  1:38:23s\n",
            "epoch 2114| loss: 0.9657  | train_accuracy: 0.51237 | val_accuracy: 0.505   |  1:38:26s\n",
            "epoch 2115| loss: 0.96439 | train_accuracy: 0.51379 | val_accuracy: 0.5034  |  1:38:29s\n",
            "epoch 2116| loss: 0.96661 | train_accuracy: 0.51264 | val_accuracy: 0.5018  |  1:38:32s\n",
            "epoch 2117| loss: 0.96313 | train_accuracy: 0.51308 | val_accuracy: 0.5038  |  1:38:35s\n",
            "epoch 2118| loss: 0.96696 | train_accuracy: 0.51335 | val_accuracy: 0.5054  |  1:38:38s\n",
            "epoch 2119| loss: 0.96353 | train_accuracy: 0.51451 | val_accuracy: 0.5058  |  1:38:40s\n",
            "epoch 2120| loss: 0.96383 | train_accuracy: 0.51548 | val_accuracy: 0.5094  |  1:38:43s\n",
            "epoch 2121| loss: 0.96324 | train_accuracy: 0.51419 | val_accuracy: 0.5066  |  1:38:46s\n",
            "epoch 2122| loss: 0.96481 | train_accuracy: 0.51211 | val_accuracy: 0.5078  |  1:38:49s\n",
            "epoch 2123| loss: 0.96264 | train_accuracy: 0.51193 | val_accuracy: 0.5098  |  1:38:52s\n",
            "epoch 2124| loss: 0.96377 | train_accuracy: 0.51491 | val_accuracy: 0.509   |  1:38:54s\n",
            "epoch 2125| loss: 0.96752 | train_accuracy: 0.51517 | val_accuracy: 0.5078  |  1:38:57s\n",
            "epoch 2126| loss: 0.96729 | train_accuracy: 0.51313 | val_accuracy: 0.509   |  1:39:00s\n",
            "epoch 2127| loss: 0.96425 | train_accuracy: 0.51331 | val_accuracy: 0.5046  |  1:39:03s\n",
            "epoch 2128| loss: 0.9638  | train_accuracy: 0.51362 | val_accuracy: 0.5098  |  1:39:06s\n",
            "epoch 2129| loss: 0.96732 | train_accuracy: 0.51242 | val_accuracy: 0.5086  |  1:39:08s\n",
            "epoch 2130| loss: 0.96454 | train_accuracy: 0.51295 | val_accuracy: 0.5102  |  1:39:11s\n",
            "epoch 2131| loss: 0.96507 | train_accuracy: 0.51344 | val_accuracy: 0.503   |  1:39:14s\n",
            "epoch 2132| loss: 0.96387 | train_accuracy: 0.51313 | val_accuracy: 0.5042  |  1:39:17s\n",
            "epoch 2133| loss: 0.96524 | train_accuracy: 0.51375 | val_accuracy: 0.5018  |  1:39:19s\n",
            "epoch 2134| loss: 0.96534 | train_accuracy: 0.51371 | val_accuracy: 0.5018  |  1:39:22s\n",
            "epoch 2135| loss: 0.96541 | train_accuracy: 0.51357 | val_accuracy: 0.5006  |  1:39:25s\n",
            "epoch 2136| loss: 0.965   | train_accuracy: 0.51277 | val_accuracy: 0.51339 |  1:39:28s\n",
            "epoch 2137| loss: 0.96876 | train_accuracy: 0.51295 | val_accuracy: 0.5046  |  1:39:31s\n",
            "epoch 2138| loss: 0.96787 | train_accuracy: 0.51273 | val_accuracy: 0.5078  |  1:39:33s\n",
            "epoch 2139| loss: 0.96703 | train_accuracy: 0.51215 | val_accuracy: 0.51259 |  1:39:36s\n",
            "epoch 2140| loss: 0.96402 | train_accuracy: 0.51268 | val_accuracy: 0.5098  |  1:39:39s\n",
            "epoch 2141| loss: 0.96887 | train_accuracy: 0.51193 | val_accuracy: 0.505   |  1:39:42s\n",
            "epoch 2142| loss: 0.96675 | train_accuracy: 0.51006 | val_accuracy: 0.503   |  1:39:45s\n",
            "epoch 2143| loss: 0.9697  | train_accuracy: 0.51086 | val_accuracy: 0.501   |  1:39:47s\n",
            "epoch 2144| loss: 0.96736 | train_accuracy: 0.51117 | val_accuracy: 0.503   |  1:39:50s\n",
            "epoch 2145| loss: 0.96895 | train_accuracy: 0.51135 | val_accuracy: 0.5054  |  1:39:53s\n",
            "epoch 2146| loss: 0.96228 | train_accuracy: 0.51215 | val_accuracy: 0.5086  |  1:39:56s\n",
            "epoch 2147| loss: 0.96626 | train_accuracy: 0.51299 | val_accuracy: 0.5034  |  1:39:59s\n",
            "epoch 2148| loss: 0.96507 | train_accuracy: 0.51126 | val_accuracy: 0.5034  |  1:40:02s\n",
            "epoch 2149| loss: 0.96905 | train_accuracy: 0.51326 | val_accuracy: 0.507   |  1:40:04s\n",
            "epoch 2150| loss: 0.96778 | train_accuracy: 0.5114  | val_accuracy: 0.5082  |  1:40:07s\n",
            "epoch 2151| loss: 0.96603 | train_accuracy: 0.51242 | val_accuracy: 0.511   |  1:40:10s\n",
            "epoch 2152| loss: 0.96657 | train_accuracy: 0.51286 | val_accuracy: 0.51459 |  1:40:13s\n",
            "epoch 2153| loss: 0.96837 | train_accuracy: 0.51175 | val_accuracy: 0.51259 |  1:40:16s\n",
            "epoch 2154| loss: 0.96526 | train_accuracy: 0.51366 | val_accuracy: 0.51699 |  1:40:19s\n",
            "epoch 2155| loss: 0.96529 | train_accuracy: 0.51397 | val_accuracy: 0.511   |  1:40:22s\n",
            "epoch 2156| loss: 0.96635 | train_accuracy: 0.51499 | val_accuracy: 0.5102  |  1:40:24s\n",
            "epoch 2157| loss: 0.96653 | train_accuracy: 0.51206 | val_accuracy: 0.51499 |  1:40:27s\n",
            "epoch 2158| loss: 0.9644  | train_accuracy: 0.511   | val_accuracy: 0.51499 |  1:40:30s\n",
            "epoch 2159| loss: 0.966   | train_accuracy: 0.51291 | val_accuracy: 0.5098  |  1:40:33s\n",
            "epoch 2160| loss: 0.96818 | train_accuracy: 0.51242 | val_accuracy: 0.507   |  1:40:36s\n",
            "epoch 2161| loss: 0.96614 | train_accuracy: 0.51291 | val_accuracy: 0.5066  |  1:40:39s\n",
            "epoch 2162| loss: 0.96656 | train_accuracy: 0.51384 | val_accuracy: 0.5066  |  1:40:41s\n",
            "epoch 2163| loss: 0.96784 | train_accuracy: 0.51282 | val_accuracy: 0.507   |  1:40:44s\n",
            "epoch 2164| loss: 0.96471 | train_accuracy: 0.51317 | val_accuracy: 0.5066  |  1:40:47s\n",
            "epoch 2165| loss: 0.96374 | train_accuracy: 0.51188 | val_accuracy: 0.5058  |  1:40:50s\n",
            "epoch 2166| loss: 0.96363 | train_accuracy: 0.51002 | val_accuracy: 0.5054  |  1:40:53s\n",
            "epoch 2167| loss: 0.96347 | train_accuracy: 0.5098  | val_accuracy: 0.5062  |  1:40:55s\n",
            "epoch 2168| loss: 0.96527 | train_accuracy: 0.51077 | val_accuracy: 0.5062  |  1:40:58s\n",
            "epoch 2169| loss: 0.96532 | train_accuracy: 0.51162 | val_accuracy: 0.5058  |  1:41:01s\n",
            "epoch 2170| loss: 0.96493 | train_accuracy: 0.51091 | val_accuracy: 0.5022  |  1:41:04s\n",
            "epoch 2171| loss: 0.96364 | train_accuracy: 0.51171 | val_accuracy: 0.5014  |  1:41:06s\n",
            "epoch 2172| loss: 0.96418 | train_accuracy: 0.51086 | val_accuracy: 0.5038  |  1:41:09s\n",
            "epoch 2173| loss: 0.96435 | train_accuracy: 0.51255 | val_accuracy: 0.5122  |  1:41:12s\n",
            "epoch 2174| loss: 0.96644 | train_accuracy: 0.51184 | val_accuracy: 0.51459 |  1:41:15s\n",
            "epoch 2175| loss: 0.9636  | train_accuracy: 0.51397 | val_accuracy: 0.51659 |  1:41:18s\n",
            "epoch 2176| loss: 0.96386 | train_accuracy: 0.51211 | val_accuracy: 0.5102  |  1:41:20s\n",
            "epoch 2177| loss: 0.96507 | train_accuracy: 0.51042 | val_accuracy: 0.5054  |  1:41:23s\n",
            "epoch 2178| loss: 0.96636 | train_accuracy: 0.50966 | val_accuracy: 0.5098  |  1:41:26s\n",
            "epoch 2179| loss: 0.96563 | train_accuracy: 0.51015 | val_accuracy: 0.5086  |  1:41:29s\n",
            "epoch 2180| loss: 0.96457 | train_accuracy: 0.51144 | val_accuracy: 0.5094  |  1:41:31s\n",
            "epoch 2181| loss: 0.96388 | train_accuracy: 0.50931 | val_accuracy: 0.51299 |  1:41:34s\n",
            "epoch 2182| loss: 0.9654  | train_accuracy: 0.51091 | val_accuracy: 0.511   |  1:41:37s\n",
            "epoch 2183| loss: 0.96778 | train_accuracy: 0.51171 | val_accuracy: 0.51539 |  1:41:40s\n",
            "epoch 2184| loss: 0.96413 | train_accuracy: 0.51335 | val_accuracy: 0.5074  |  1:41:42s\n",
            "epoch 2185| loss: 0.96664 | train_accuracy: 0.51304 | val_accuracy: 0.51459 |  1:41:45s\n",
            "epoch 2186| loss: 0.96428 | train_accuracy: 0.51406 | val_accuracy: 0.51379 |  1:41:48s\n",
            "epoch 2187| loss: 0.96546 | train_accuracy: 0.51264 | val_accuracy: 0.51339 |  1:41:51s\n",
            "epoch 2188| loss: 0.96646 | train_accuracy: 0.51295 | val_accuracy: 0.5042  |  1:41:53s\n",
            "epoch 2189| loss: 0.96489 | train_accuracy: 0.51437 | val_accuracy: 0.5062  |  1:41:56s\n",
            "epoch 2190| loss: 0.96578 | train_accuracy: 0.51575 | val_accuracy: 0.5082  |  1:41:59s\n",
            "epoch 2191| loss: 0.96739 | train_accuracy: 0.51619 | val_accuracy: 0.5098  |  1:42:02s\n",
            "epoch 2192| loss: 0.96282 | train_accuracy: 0.51584 | val_accuracy: 0.51259 |  1:42:04s\n",
            "epoch 2193| loss: 0.96488 | train_accuracy: 0.51633 | val_accuracy: 0.5094  |  1:42:07s\n",
            "epoch 2194| loss: 0.96175 | train_accuracy: 0.51695 | val_accuracy: 0.51779 |  1:42:10s\n",
            "epoch 2195| loss: 0.96173 | train_accuracy: 0.51713 | val_accuracy: 0.51619 |  1:42:13s\n",
            "epoch 2196| loss: 0.96561 | train_accuracy: 0.51744 | val_accuracy: 0.5062  |  1:42:16s\n",
            "epoch 2197| loss: 0.96247 | train_accuracy: 0.51722 | val_accuracy: 0.51379 |  1:42:18s\n",
            "epoch 2198| loss: 0.96017 | train_accuracy: 0.51757 | val_accuracy: 0.51539 |  1:42:21s\n",
            "epoch 2199| loss: 0.96711 | train_accuracy: 0.51508 | val_accuracy: 0.51259 |  1:42:24s\n",
            "epoch 2200| loss: 0.96605 | train_accuracy: 0.5161  | val_accuracy: 0.5114  |  1:42:27s\n",
            "epoch 2201| loss: 0.96258 | train_accuracy: 0.51495 | val_accuracy: 0.5082  |  1:42:29s\n",
            "epoch 2202| loss: 0.96241 | train_accuracy: 0.51477 | val_accuracy: 0.5066  |  1:42:32s\n",
            "epoch 2203| loss: 0.96368 | train_accuracy: 0.51499 | val_accuracy: 0.51259 |  1:42:35s\n",
            "epoch 2204| loss: 0.96364 | train_accuracy: 0.51686 | val_accuracy: 0.5054  |  1:42:38s\n",
            "epoch 2205| loss: 0.9627  | train_accuracy: 0.51802 | val_accuracy: 0.5078  |  1:42:40s\n",
            "epoch 2206| loss: 0.96334 | train_accuracy: 0.51726 | val_accuracy: 0.5058  |  1:42:43s\n",
            "epoch 2207| loss: 0.95915 | train_accuracy: 0.51699 | val_accuracy: 0.5042  |  1:42:46s\n",
            "epoch 2208| loss: 0.9615  | train_accuracy: 0.51615 | val_accuracy: 0.5038  |  1:42:49s\n",
            "epoch 2209| loss: 0.96388 | train_accuracy: 0.51628 | val_accuracy: 0.4998  |  1:42:51s\n",
            "epoch 2210| loss: 0.96261 | train_accuracy: 0.51695 | val_accuracy: 0.501   |  1:42:54s\n",
            "epoch 2211| loss: 0.96543 | train_accuracy: 0.51522 | val_accuracy: 0.5066  |  1:42:57s\n",
            "epoch 2212| loss: 0.9639  | train_accuracy: 0.51859 | val_accuracy: 0.503   |  1:42:59s\n",
            "epoch 2213| loss: 0.96448 | train_accuracy: 0.5173  | val_accuracy: 0.5018  |  1:43:02s\n",
            "epoch 2214| loss: 0.96594 | train_accuracy: 0.5177  | val_accuracy: 0.5034  |  1:43:05s\n",
            "epoch 2215| loss: 0.96258 | train_accuracy: 0.5177  | val_accuracy: 0.4998  |  1:43:08s\n",
            "epoch 2216| loss: 0.96143 | train_accuracy: 0.51682 | val_accuracy: 0.5014  |  1:43:10s\n",
            "epoch 2217| loss: 0.96062 | train_accuracy: 0.51722 | val_accuracy: 0.5002  |  1:43:13s\n",
            "epoch 2218| loss: 0.96279 | train_accuracy: 0.5173  | val_accuracy: 0.5018  |  1:43:16s\n",
            "epoch 2219| loss: 0.9615  | train_accuracy: 0.51588 | val_accuracy: 0.4986  |  1:43:19s\n",
            "epoch 2220| loss: 0.96152 | train_accuracy: 0.51673 | val_accuracy: 0.4994  |  1:43:22s\n",
            "epoch 2221| loss: 0.96044 | train_accuracy: 0.51757 | val_accuracy: 0.4994  |  1:43:24s\n",
            "epoch 2222| loss: 0.96402 | train_accuracy: 0.5177  | val_accuracy: 0.5034  |  1:43:27s\n",
            "epoch 2223| loss: 0.9628  | train_accuracy: 0.51548 | val_accuracy: 0.5098  |  1:43:30s\n",
            "epoch 2224| loss: 0.96337 | train_accuracy: 0.51619 | val_accuracy: 0.5046  |  1:43:33s\n",
            "epoch 2225| loss: 0.96388 | train_accuracy: 0.51562 | val_accuracy: 0.51259 |  1:43:35s\n",
            "epoch 2226| loss: 0.96264 | train_accuracy: 0.51522 | val_accuracy: 0.5062  |  1:43:38s\n",
            "epoch 2227| loss: 0.96371 | train_accuracy: 0.5169  | val_accuracy: 0.503   |  1:43:41s\n",
            "epoch 2228| loss: 0.96242 | train_accuracy: 0.51735 | val_accuracy: 0.509   |  1:43:43s\n",
            "epoch 2229| loss: 0.96304 | train_accuracy: 0.51793 | val_accuracy: 0.5046  |  1:43:46s\n",
            "epoch 2230| loss: 0.96558 | train_accuracy: 0.51788 | val_accuracy: 0.5042  |  1:43:49s\n",
            "epoch 2231| loss: 0.96176 | train_accuracy: 0.5181  | val_accuracy: 0.5086  |  1:43:52s\n",
            "epoch 2232| loss: 0.96588 | train_accuracy: 0.52019 | val_accuracy: 0.5042  |  1:43:54s\n",
            "epoch 2233| loss: 0.96132 | train_accuracy: 0.5197  | val_accuracy: 0.5034  |  1:43:57s\n",
            "epoch 2234| loss: 0.96221 | train_accuracy: 0.51873 | val_accuracy: 0.5046  |  1:44:00s\n",
            "epoch 2235| loss: 0.96267 | train_accuracy: 0.52015 | val_accuracy: 0.5046  |  1:44:03s\n",
            "epoch 2236| loss: 0.96432 | train_accuracy: 0.51668 | val_accuracy: 0.505   |  1:44:05s\n",
            "epoch 2237| loss: 0.96335 | train_accuracy: 0.51735 | val_accuracy: 0.5054  |  1:44:08s\n",
            "epoch 2238| loss: 0.96125 | train_accuracy: 0.52135 | val_accuracy: 0.507   |  1:44:11s\n",
            "epoch 2239| loss: 0.96237 | train_accuracy: 0.52041 | val_accuracy: 0.509   |  1:44:14s\n",
            "epoch 2240| loss: 0.96157 | train_accuracy: 0.5197  | val_accuracy: 0.5058  |  1:44:16s\n",
            "epoch 2241| loss: 0.95982 | train_accuracy: 0.51682 | val_accuracy: 0.5054  |  1:44:19s\n",
            "epoch 2242| loss: 0.96155 | train_accuracy: 0.5181  | val_accuracy: 0.5078  |  1:44:22s\n",
            "epoch 2243| loss: 0.96319 | train_accuracy: 0.5173  | val_accuracy: 0.5074  |  1:44:25s\n",
            "epoch 2244| loss: 0.96185 | train_accuracy: 0.51508 | val_accuracy: 0.5034  |  1:44:27s\n",
            "epoch 2245| loss: 0.96163 | train_accuracy: 0.51722 | val_accuracy: 0.5022  |  1:44:30s\n",
            "epoch 2246| loss: 0.96079 | train_accuracy: 0.51619 | val_accuracy: 0.5046  |  1:44:33s\n",
            "epoch 2247| loss: 0.96315 | train_accuracy: 0.51753 | val_accuracy: 0.5066  |  1:44:36s\n",
            "epoch 2248| loss: 0.96123 | train_accuracy: 0.51766 | val_accuracy: 0.5018  |  1:44:38s\n",
            "epoch 2249| loss: 0.96404 | train_accuracy: 0.51944 | val_accuracy: 0.5018  |  1:44:41s\n",
            "epoch 2250| loss: 0.95999 | train_accuracy: 0.51739 | val_accuracy: 0.4978  |  1:44:44s\n",
            "epoch 2251| loss: 0.95897 | train_accuracy: 0.51961 | val_accuracy: 0.5014  |  1:44:47s\n",
            "epoch 2252| loss: 0.96066 | train_accuracy: 0.51966 | val_accuracy: 0.5018  |  1:44:49s\n",
            "epoch 2253| loss: 0.96403 | train_accuracy: 0.5209  | val_accuracy: 0.5062  |  1:44:53s\n",
            "epoch 2254| loss: 0.96099 | train_accuracy: 0.51859 | val_accuracy: 0.5034  |  1:44:55s\n",
            "epoch 2255| loss: 0.96068 | train_accuracy: 0.51828 | val_accuracy: 0.5054  |  1:44:58s\n",
            "epoch 2256| loss: 0.96315 | train_accuracy: 0.51802 | val_accuracy: 0.5042  |  1:45:01s\n",
            "epoch 2257| loss: 0.96025 | train_accuracy: 0.51757 | val_accuracy: 0.505   |  1:45:04s\n",
            "epoch 2258| loss: 0.96294 | train_accuracy: 0.51686 | val_accuracy: 0.503   |  1:45:06s\n",
            "epoch 2259| loss: 0.96015 | train_accuracy: 0.51824 | val_accuracy: 0.503   |  1:45:09s\n",
            "epoch 2260| loss: 0.9649  | train_accuracy: 0.51557 | val_accuracy: 0.5058  |  1:45:12s\n",
            "epoch 2261| loss: 0.96442 | train_accuracy: 0.51668 | val_accuracy: 0.5082  |  1:45:15s\n",
            "epoch 2262| loss: 0.96131 | train_accuracy: 0.51664 | val_accuracy: 0.5098  |  1:45:17s\n",
            "epoch 2263| loss: 0.96513 | train_accuracy: 0.5177  | val_accuracy: 0.5114  |  1:45:20s\n",
            "epoch 2264| loss: 0.96101 | train_accuracy: 0.5177  | val_accuracy: 0.509   |  1:45:23s\n",
            "epoch 2265| loss: 0.96015 | train_accuracy: 0.51846 | val_accuracy: 0.511   |  1:45:25s\n",
            "epoch 2266| loss: 0.95938 | train_accuracy: 0.51766 | val_accuracy: 0.51379 |  1:45:28s\n",
            "epoch 2267| loss: 0.95984 | train_accuracy: 0.51766 | val_accuracy: 0.5034  |  1:45:31s\n",
            "epoch 2268| loss: 0.96241 | train_accuracy: 0.52001 | val_accuracy: 0.507   |  1:45:34s\n",
            "epoch 2269| loss: 0.96446 | train_accuracy: 0.51815 | val_accuracy: 0.4974  |  1:45:36s\n",
            "epoch 2270| loss: 0.96174 | train_accuracy: 0.51562 | val_accuracy: 0.4962  |  1:45:39s\n",
            "epoch 2271| loss: 0.96422 | train_accuracy: 0.5189  | val_accuracy: 0.5022  |  1:45:42s\n",
            "epoch 2272| loss: 0.96148 | train_accuracy: 0.5197  | val_accuracy: 0.5014  |  1:45:45s\n",
            "epoch 2273| loss: 0.96302 | train_accuracy: 0.51624 | val_accuracy: 0.4974  |  1:45:47s\n",
            "epoch 2274| loss: 0.96162 | train_accuracy: 0.51482 | val_accuracy: 0.495   |  1:45:50s\n",
            "epoch 2275| loss: 0.96443 | train_accuracy: 0.51628 | val_accuracy: 0.5002  |  1:45:53s\n",
            "epoch 2276| loss: 0.96225 | train_accuracy: 0.51446 | val_accuracy: 0.4994  |  1:45:56s\n",
            "epoch 2277| loss: 0.9635  | train_accuracy: 0.51588 | val_accuracy: 0.4954  |  1:45:58s\n",
            "epoch 2278| loss: 0.96403 | train_accuracy: 0.51526 | val_accuracy: 0.4954  |  1:46:01s\n",
            "epoch 2279| loss: 0.96667 | train_accuracy: 0.51428 | val_accuracy: 0.4958  |  1:46:04s\n",
            "epoch 2280| loss: 0.96588 | train_accuracy: 0.51455 | val_accuracy: 0.4946  |  1:46:07s\n",
            "epoch 2281| loss: 0.96124 | train_accuracy: 0.51495 | val_accuracy: 0.495   |  1:46:10s\n",
            "epoch 2282| loss: 0.96456 | train_accuracy: 0.51588 | val_accuracy: 0.5002  |  1:46:12s\n",
            "epoch 2283| loss: 0.96109 | train_accuracy: 0.51704 | val_accuracy: 0.5034  |  1:46:15s\n",
            "epoch 2284| loss: 0.96471 | train_accuracy: 0.51686 | val_accuracy: 0.5026  |  1:46:18s\n",
            "epoch 2285| loss: 0.96123 | train_accuracy: 0.51766 | val_accuracy: 0.5058  |  1:46:20s\n",
            "epoch 2286| loss: 0.96286 | train_accuracy: 0.51793 | val_accuracy: 0.5078  |  1:46:23s\n",
            "epoch 2287| loss: 0.95951 | train_accuracy: 0.5177  | val_accuracy: 0.5062  |  1:46:26s\n",
            "epoch 2288| loss: 0.96206 | train_accuracy: 0.51779 | val_accuracy: 0.503   |  1:46:29s\n",
            "epoch 2289| loss: 0.96191 | train_accuracy: 0.51815 | val_accuracy: 0.509   |  1:46:31s\n",
            "epoch 2290| loss: 0.96236 | train_accuracy: 0.51677 | val_accuracy: 0.509   |  1:46:34s\n",
            "epoch 2291| loss: 0.96197 | train_accuracy: 0.51566 | val_accuracy: 0.509   |  1:46:37s\n",
            "epoch 2292| loss: 0.96393 | train_accuracy: 0.51433 | val_accuracy: 0.501   |  1:46:40s\n",
            "epoch 2293| loss: 0.96503 | train_accuracy: 0.51491 | val_accuracy: 0.501   |  1:46:42s\n",
            "epoch 2294| loss: 0.96496 | train_accuracy: 0.51499 | val_accuracy: 0.4994  |  1:46:45s\n",
            "epoch 2295| loss: 0.9644  | train_accuracy: 0.51619 | val_accuracy: 0.4994  |  1:46:48s\n",
            "epoch 2296| loss: 0.96257 | train_accuracy: 0.51673 | val_accuracy: 0.5018  |  1:46:50s\n",
            "epoch 2297| loss: 0.96501 | train_accuracy: 0.51566 | val_accuracy: 0.5022  |  1:46:53s\n",
            "epoch 2298| loss: 0.96352 | train_accuracy: 0.5161  | val_accuracy: 0.5042  |  1:46:56s\n",
            "epoch 2299| loss: 0.96483 | train_accuracy: 0.51797 | val_accuracy: 0.5086  |  1:46:59s\n",
            "epoch 2300| loss: 0.96202 | train_accuracy: 0.51757 | val_accuracy: 0.505   |  1:47:01s\n",
            "epoch 2301| loss: 0.96149 | train_accuracy: 0.51868 | val_accuracy: 0.5066  |  1:47:04s\n",
            "epoch 2302| loss: 0.96498 | train_accuracy: 0.51739 | val_accuracy: 0.5074  |  1:47:07s\n",
            "epoch 2303| loss: 0.96156 | train_accuracy: 0.51699 | val_accuracy: 0.5086  |  1:47:10s\n",
            "epoch 2304| loss: 0.9624  | train_accuracy: 0.51637 | val_accuracy: 0.5042  |  1:47:12s\n",
            "epoch 2305| loss: 0.96288 | train_accuracy: 0.51726 | val_accuracy: 0.5062  |  1:47:15s\n",
            "epoch 2306| loss: 0.96103 | train_accuracy: 0.51619 | val_accuracy: 0.5062  |  1:47:18s\n",
            "epoch 2307| loss: 0.96144 | train_accuracy: 0.51646 | val_accuracy: 0.5054  |  1:47:21s\n",
            "epoch 2308| loss: 0.96107 | train_accuracy: 0.5157  | val_accuracy: 0.505   |  1:47:23s\n",
            "epoch 2309| loss: 0.96402 | train_accuracy: 0.51619 | val_accuracy: 0.5038  |  1:47:26s\n",
            "epoch 2310| loss: 0.96319 | train_accuracy: 0.51682 | val_accuracy: 0.5042  |  1:47:29s\n",
            "epoch 2311| loss: 0.95993 | train_accuracy: 0.51642 | val_accuracy: 0.5034  |  1:47:32s\n",
            "epoch 2312| loss: 0.96178 | train_accuracy: 0.51673 | val_accuracy: 0.5018  |  1:47:34s\n",
            "epoch 2313| loss: 0.96687 | train_accuracy: 0.51686 | val_accuracy: 0.5018  |  1:47:37s\n",
            "epoch 2314| loss: 0.96189 | train_accuracy: 0.51859 | val_accuracy: 0.5018  |  1:47:40s\n",
            "epoch 2315| loss: 0.96288 | train_accuracy: 0.51993 | val_accuracy: 0.5102  |  1:47:42s\n",
            "epoch 2316| loss: 0.96422 | train_accuracy: 0.51935 | val_accuracy: 0.5054  |  1:47:45s\n",
            "epoch 2317| loss: 0.96601 | train_accuracy: 0.51859 | val_accuracy: 0.5062  |  1:47:48s\n",
            "epoch 2318| loss: 0.96295 | train_accuracy: 0.51841 | val_accuracy: 0.5074  |  1:47:51s\n",
            "epoch 2319| loss: 0.96175 | train_accuracy: 0.51682 | val_accuracy: 0.5026  |  1:47:53s\n",
            "epoch 2320| loss: 0.9626  | train_accuracy: 0.5161  | val_accuracy: 0.5074  |  1:47:56s\n",
            "epoch 2321| loss: 0.96396 | train_accuracy: 0.51495 | val_accuracy: 0.51299 |  1:47:59s\n",
            "epoch 2322| loss: 0.96193 | train_accuracy: 0.51699 | val_accuracy: 0.51259 |  1:48:02s\n",
            "epoch 2323| loss: 0.96293 | train_accuracy: 0.51584 | val_accuracy: 0.5122  |  1:48:04s\n",
            "epoch 2324| loss: 0.96426 | train_accuracy: 0.51539 | val_accuracy: 0.51379 |  1:48:07s\n",
            "epoch 2325| loss: 0.96733 | train_accuracy: 0.51566 | val_accuracy: 0.507   |  1:48:10s\n",
            "epoch 2326| loss: 0.96267 | train_accuracy: 0.51726 | val_accuracy: 0.5082  |  1:48:13s\n",
            "epoch 2327| loss: 0.96558 | train_accuracy: 0.51797 | val_accuracy: 0.507   |  1:48:15s\n",
            "epoch 2328| loss: 0.96325 | train_accuracy: 0.51748 | val_accuracy: 0.51499 |  1:48:18s\n",
            "epoch 2329| loss: 0.9632  | train_accuracy: 0.51766 | val_accuracy: 0.51339 |  1:48:21s\n",
            "epoch 2330| loss: 0.966   | train_accuracy: 0.51824 | val_accuracy: 0.51259 |  1:48:24s\n",
            "epoch 2331| loss: 0.96171 | train_accuracy: 0.5165  | val_accuracy: 0.5066  |  1:48:26s\n",
            "epoch 2332| loss: 0.96308 | train_accuracy: 0.51637 | val_accuracy: 0.5038  |  1:48:29s\n",
            "epoch 2333| loss: 0.96197 | train_accuracy: 0.51873 | val_accuracy: 0.507   |  1:48:32s\n",
            "epoch 2334| loss: 0.96518 | train_accuracy: 0.51837 | val_accuracy: 0.5046  |  1:48:35s\n",
            "epoch 2335| loss: 0.96246 | train_accuracy: 0.51633 | val_accuracy: 0.5098  |  1:48:37s\n",
            "epoch 2336| loss: 0.96456 | train_accuracy: 0.51597 | val_accuracy: 0.509   |  1:48:40s\n",
            "epoch 2337| loss: 0.96497 | train_accuracy: 0.51535 | val_accuracy: 0.5034  |  1:48:43s\n",
            "epoch 2338| loss: 0.96277 | train_accuracy: 0.51539 | val_accuracy: 0.5018  |  1:48:46s\n",
            "epoch 2339| loss: 0.96018 | train_accuracy: 0.51562 | val_accuracy: 0.5038  |  1:48:48s\n",
            "epoch 2340| loss: 0.96173 | train_accuracy: 0.51553 | val_accuracy: 0.5002  |  1:48:51s\n",
            "epoch 2341| loss: 0.96693 | train_accuracy: 0.51495 | val_accuracy: 0.5014  |  1:48:54s\n",
            "epoch 2342| loss: 0.9591  | train_accuracy: 0.51411 | val_accuracy: 0.499   |  1:48:57s\n",
            "epoch 2343| loss: 0.95935 | train_accuracy: 0.51499 | val_accuracy: 0.5034  |  1:48:59s\n",
            "epoch 2344| loss: 0.9621  | train_accuracy: 0.51326 | val_accuracy: 0.509   |  1:49:02s\n",
            "epoch 2345| loss: 0.96372 | train_accuracy: 0.51277 | val_accuracy: 0.5042  |  1:49:05s\n",
            "epoch 2346| loss: 0.96218 | train_accuracy: 0.51313 | val_accuracy: 0.5062  |  1:49:07s\n",
            "epoch 2347| loss: 0.9589  | train_accuracy: 0.51375 | val_accuracy: 0.5046  |  1:49:10s\n",
            "epoch 2348| loss: 0.96447 | train_accuracy: 0.51419 | val_accuracy: 0.5014  |  1:49:13s\n",
            "epoch 2349| loss: 0.96347 | train_accuracy: 0.51459 | val_accuracy: 0.5038  |  1:49:16s\n",
            "epoch 2350| loss: 0.96489 | train_accuracy: 0.51455 | val_accuracy: 0.5046  |  1:49:18s\n",
            "epoch 2351| loss: 0.96244 | train_accuracy: 0.51393 | val_accuracy: 0.5018  |  1:49:21s\n",
            "epoch 2352| loss: 0.96446 | train_accuracy: 0.51255 | val_accuracy: 0.5046  |  1:49:24s\n",
            "epoch 2353| loss: 0.96406 | train_accuracy: 0.51468 | val_accuracy: 0.4998  |  1:49:27s\n",
            "epoch 2354| loss: 0.96327 | train_accuracy: 0.51379 | val_accuracy: 0.5042  |  1:49:30s\n",
            "epoch 2355| loss: 0.96204 | train_accuracy: 0.51495 | val_accuracy: 0.5042  |  1:49:32s\n",
            "epoch 2356| loss: 0.96194 | train_accuracy: 0.51375 | val_accuracy: 0.5058  |  1:49:35s\n",
            "epoch 2357| loss: 0.96806 | train_accuracy: 0.51291 | val_accuracy: 0.5046  |  1:49:38s\n",
            "epoch 2358| loss: 0.96805 | train_accuracy: 0.51175 | val_accuracy: 0.5022  |  1:49:41s\n",
            "epoch 2359| loss: 0.96231 | train_accuracy: 0.51233 | val_accuracy: 0.501   |  1:49:44s\n",
            "epoch 2360| loss: 0.96583 | train_accuracy: 0.51068 | val_accuracy: 0.4994  |  1:49:47s\n",
            "epoch 2361| loss: 0.96244 | train_accuracy: 0.51353 | val_accuracy: 0.5038  |  1:49:50s\n",
            "epoch 2362| loss: 0.96527 | train_accuracy: 0.51384 | val_accuracy: 0.5078  |  1:49:52s\n",
            "epoch 2363| loss: 0.96455 | train_accuracy: 0.51375 | val_accuracy: 0.5102  |  1:49:55s\n",
            "epoch 2364| loss: 0.96339 | train_accuracy: 0.51357 | val_accuracy: 0.5074  |  1:49:58s\n",
            "epoch 2365| loss: 0.96099 | train_accuracy: 0.51304 | val_accuracy: 0.5102  |  1:50:01s\n",
            "epoch 2366| loss: 0.96254 | train_accuracy: 0.51424 | val_accuracy: 0.5082  |  1:50:03s\n",
            "epoch 2367| loss: 0.9657  | train_accuracy: 0.51286 | val_accuracy: 0.5026  |  1:50:06s\n",
            "epoch 2368| loss: 0.96111 | train_accuracy: 0.51393 | val_accuracy: 0.5026  |  1:50:09s\n",
            "epoch 2369| loss: 0.96525 | train_accuracy: 0.51051 | val_accuracy: 0.503   |  1:50:12s\n",
            "epoch 2370| loss: 0.96682 | train_accuracy: 0.51042 | val_accuracy: 0.5062  |  1:50:14s\n",
            "epoch 2371| loss: 0.96179 | train_accuracy: 0.51086 | val_accuracy: 0.5094  |  1:50:17s\n",
            "epoch 2372| loss: 0.9649  | train_accuracy: 0.51073 | val_accuracy: 0.505   |  1:50:20s\n",
            "epoch 2373| loss: 0.96435 | train_accuracy: 0.51286 | val_accuracy: 0.5002  |  1:50:23s\n",
            "epoch 2374| loss: 0.96642 | train_accuracy: 0.51233 | val_accuracy: 0.4998  |  1:50:26s\n",
            "epoch 2375| loss: 0.96006 | train_accuracy: 0.51344 | val_accuracy: 0.495   |  1:50:28s\n",
            "epoch 2376| loss: 0.96374 | train_accuracy: 0.51224 | val_accuracy: 0.4954  |  1:50:31s\n",
            "epoch 2377| loss: 0.96452 | train_accuracy: 0.51277 | val_accuracy: 0.501   |  1:50:34s\n",
            "epoch 2378| loss: 0.96564 | train_accuracy: 0.51277 | val_accuracy: 0.503   |  1:50:36s\n",
            "epoch 2379| loss: 0.96141 | train_accuracy: 0.51331 | val_accuracy: 0.505   |  1:50:39s\n",
            "epoch 2380| loss: 0.96157 | train_accuracy: 0.51451 | val_accuracy: 0.5066  |  1:50:42s\n",
            "epoch 2381| loss: 0.9617  | train_accuracy: 0.51557 | val_accuracy: 0.5014  |  1:50:45s\n",
            "epoch 2382| loss: 0.96346 | train_accuracy: 0.51544 | val_accuracy: 0.501   |  1:50:48s\n",
            "epoch 2383| loss: 0.96177 | train_accuracy: 0.51459 | val_accuracy: 0.495   |  1:50:51s\n",
            "epoch 2384| loss: 0.9638  | train_accuracy: 0.51628 | val_accuracy: 0.4994  |  1:50:54s\n",
            "epoch 2385| loss: 0.96337 | train_accuracy: 0.5165  | val_accuracy: 0.501   |  1:50:57s\n",
            "epoch 2386| loss: 0.96232 | train_accuracy: 0.51744 | val_accuracy: 0.5042  |  1:51:00s\n",
            "epoch 2387| loss: 0.96233 | train_accuracy: 0.51833 | val_accuracy: 0.5006  |  1:51:03s\n",
            "epoch 2388| loss: 0.9623  | train_accuracy: 0.51779 | val_accuracy: 0.4998  |  1:51:05s\n",
            "epoch 2389| loss: 0.96055 | train_accuracy: 0.51508 | val_accuracy: 0.5038  |  1:51:08s\n",
            "epoch 2390| loss: 0.96359 | train_accuracy: 0.51579 | val_accuracy: 0.5042  |  1:51:11s\n",
            "epoch 2391| loss: 0.96486 | train_accuracy: 0.51628 | val_accuracy: 0.5006  |  1:51:14s\n",
            "epoch 2392| loss: 0.9612  | train_accuracy: 0.51659 | val_accuracy: 0.5042  |  1:51:16s\n",
            "epoch 2393| loss: 0.96129 | train_accuracy: 0.51646 | val_accuracy: 0.505   |  1:51:19s\n",
            "epoch 2394| loss: 0.95931 | train_accuracy: 0.51708 | val_accuracy: 0.505   |  1:51:22s\n",
            "epoch 2395| loss: 0.95844 | train_accuracy: 0.51446 | val_accuracy: 0.5026  |  1:51:25s\n",
            "epoch 2396| loss: 0.96222 | train_accuracy: 0.51406 | val_accuracy: 0.5002  |  1:51:27s\n",
            "epoch 2397| loss: 0.9596  | train_accuracy: 0.51455 | val_accuracy: 0.5042  |  1:51:30s\n",
            "epoch 2398| loss: 0.96194 | train_accuracy: 0.51428 | val_accuracy: 0.5014  |  1:51:33s\n",
            "epoch 2399| loss: 0.95967 | train_accuracy: 0.51602 | val_accuracy: 0.4986  |  1:51:36s\n",
            "epoch 2400| loss: 0.96132 | train_accuracy: 0.51348 | val_accuracy: 0.4978  |  1:51:39s\n",
            "epoch 2401| loss: 0.96461 | train_accuracy: 0.51384 | val_accuracy: 0.4994  |  1:51:41s\n",
            "epoch 2402| loss: 0.96477 | train_accuracy: 0.51326 | val_accuracy: 0.4998  |  1:51:44s\n",
            "epoch 2403| loss: 0.96335 | train_accuracy: 0.51424 | val_accuracy: 0.5026  |  1:51:47s\n",
            "epoch 2404| loss: 0.9613  | train_accuracy: 0.51482 | val_accuracy: 0.5022  |  1:51:50s\n",
            "epoch 2405| loss: 0.96105 | train_accuracy: 0.51504 | val_accuracy: 0.5002  |  1:51:52s\n",
            "epoch 2406| loss: 0.9635  | train_accuracy: 0.51517 | val_accuracy: 0.5018  |  1:51:55s\n",
            "epoch 2407| loss: 0.96114 | train_accuracy: 0.5157  | val_accuracy: 0.5046  |  1:51:58s\n",
            "epoch 2408| loss: 0.96522 | train_accuracy: 0.51522 | val_accuracy: 0.5022  |  1:52:01s\n",
            "epoch 2409| loss: 0.96527 | train_accuracy: 0.51499 | val_accuracy: 0.5026  |  1:52:03s\n",
            "epoch 2410| loss: 0.96325 | train_accuracy: 0.51517 | val_accuracy: 0.5046  |  1:52:06s\n",
            "epoch 2411| loss: 0.96285 | train_accuracy: 0.51642 | val_accuracy: 0.5034  |  1:52:09s\n",
            "epoch 2412| loss: 0.96426 | train_accuracy: 0.51513 | val_accuracy: 0.503   |  1:52:12s\n",
            "epoch 2413| loss: 0.96334 | train_accuracy: 0.51499 | val_accuracy: 0.5082  |  1:52:15s\n",
            "epoch 2414| loss: 0.9647  | train_accuracy: 0.51459 | val_accuracy: 0.5082  |  1:52:17s\n",
            "epoch 2415| loss: 0.96228 | train_accuracy: 0.51539 | val_accuracy: 0.5062  |  1:52:20s\n",
            "epoch 2416| loss: 0.96231 | train_accuracy: 0.51406 | val_accuracy: 0.501   |  1:52:23s\n",
            "epoch 2417| loss: 0.96295 | train_accuracy: 0.51375 | val_accuracy: 0.5042  |  1:52:26s\n",
            "epoch 2418| loss: 0.96332 | train_accuracy: 0.51411 | val_accuracy: 0.5046  |  1:52:28s\n",
            "epoch 2419| loss: 0.96141 | train_accuracy: 0.51575 | val_accuracy: 0.509   |  1:52:31s\n",
            "epoch 2420| loss: 0.9635  | train_accuracy: 0.51677 | val_accuracy: 0.5086  |  1:52:34s\n",
            "epoch 2421| loss: 0.96413 | train_accuracy: 0.51753 | val_accuracy: 0.5102  |  1:52:37s\n",
            "epoch 2422| loss: 0.96167 | train_accuracy: 0.51499 | val_accuracy: 0.5118  |  1:52:39s\n",
            "epoch 2423| loss: 0.95943 | train_accuracy: 0.51442 | val_accuracy: 0.505   |  1:52:42s\n",
            "epoch 2424| loss: 0.96132 | train_accuracy: 0.51557 | val_accuracy: 0.5054  |  1:52:45s\n",
            "epoch 2425| loss: 0.96123 | train_accuracy: 0.51606 | val_accuracy: 0.5018  |  1:52:48s\n",
            "epoch 2426| loss: 0.9629  | train_accuracy: 0.51562 | val_accuracy: 0.5046  |  1:52:50s\n",
            "epoch 2427| loss: 0.96389 | train_accuracy: 0.51655 | val_accuracy: 0.5086  |  1:52:53s\n",
            "epoch 2428| loss: 0.96037 | train_accuracy: 0.5177  | val_accuracy: 0.507   |  1:52:56s\n",
            "epoch 2429| loss: 0.96318 | train_accuracy: 0.51802 | val_accuracy: 0.5062  |  1:52:59s\n",
            "epoch 2430| loss: 0.96061 | train_accuracy: 0.51784 | val_accuracy: 0.5046  |  1:53:02s\n",
            "epoch 2431| loss: 0.96388 | train_accuracy: 0.51766 | val_accuracy: 0.511   |  1:53:04s\n",
            "epoch 2432| loss: 0.96419 | train_accuracy: 0.51779 | val_accuracy: 0.507   |  1:53:07s\n",
            "epoch 2433| loss: 0.9647  | train_accuracy: 0.51788 | val_accuracy: 0.5054  |  1:53:10s\n",
            "epoch 2434| loss: 0.96076 | train_accuracy: 0.51797 | val_accuracy: 0.5042  |  1:53:13s\n",
            "epoch 2435| loss: 0.9634  | train_accuracy: 0.51833 | val_accuracy: 0.5042  |  1:53:16s\n",
            "epoch 2436| loss: 0.96124 | train_accuracy: 0.52001 | val_accuracy: 0.5026  |  1:53:20s\n",
            "epoch 2437| loss: 0.95861 | train_accuracy: 0.51953 | val_accuracy: 0.5014  |  1:53:24s\n",
            "epoch 2438| loss: 0.96107 | train_accuracy: 0.5189  | val_accuracy: 0.5038  |  1:53:27s\n",
            "epoch 2439| loss: 0.9606  | train_accuracy: 0.51677 | val_accuracy: 0.5054  |  1:53:30s\n",
            "epoch 2440| loss: 0.96237 | train_accuracy: 0.51562 | val_accuracy: 0.5074  |  1:53:33s\n",
            "epoch 2441| loss: 0.9655  | train_accuracy: 0.51788 | val_accuracy: 0.5054  |  1:53:35s\n",
            "epoch 2442| loss: 0.96221 | train_accuracy: 0.51646 | val_accuracy: 0.5082  |  1:53:38s\n",
            "epoch 2443| loss: 0.96378 | train_accuracy: 0.51819 | val_accuracy: 0.5078  |  1:53:41s\n",
            "epoch 2444| loss: 0.96347 | train_accuracy: 0.51775 | val_accuracy: 0.5094  |  1:53:44s\n",
            "epoch 2445| loss: 0.96112 | train_accuracy: 0.51419 | val_accuracy: 0.5022  |  1:53:47s\n",
            "epoch 2446| loss: 0.96284 | train_accuracy: 0.51477 | val_accuracy: 0.5062  |  1:53:49s\n",
            "epoch 2447| loss: 0.96329 | train_accuracy: 0.51539 | val_accuracy: 0.505   |  1:53:52s\n",
            "epoch 2448| loss: 0.96095 | train_accuracy: 0.51473 | val_accuracy: 0.5022  |  1:53:55s\n",
            "epoch 2449| loss: 0.96065 | train_accuracy: 0.51424 | val_accuracy: 0.5042  |  1:53:58s\n",
            "epoch 2450| loss: 0.96486 | train_accuracy: 0.51424 | val_accuracy: 0.4998  |  1:54:01s\n",
            "epoch 2451| loss: 0.96257 | train_accuracy: 0.51402 | val_accuracy: 0.4974  |  1:54:03s\n",
            "epoch 2452| loss: 0.96426 | train_accuracy: 0.51424 | val_accuracy: 0.501   |  1:54:06s\n",
            "epoch 2453| loss: 0.96626 | train_accuracy: 0.51553 | val_accuracy: 0.4982  |  1:54:09s\n",
            "epoch 2454| loss: 0.96407 | train_accuracy: 0.51491 | val_accuracy: 0.5026  |  1:54:12s\n",
            "epoch 2455| loss: 0.96396 | train_accuracy: 0.51566 | val_accuracy: 0.5014  |  1:54:15s\n",
            "epoch 2456| loss: 0.96273 | train_accuracy: 0.51686 | val_accuracy: 0.5022  |  1:54:18s\n",
            "epoch 2457| loss: 0.96509 | train_accuracy: 0.51544 | val_accuracy: 0.505   |  1:54:20s\n",
            "epoch 2458| loss: 0.96192 | train_accuracy: 0.51664 | val_accuracy: 0.5074  |  1:54:24s\n",
            "epoch 2459| loss: 0.96244 | train_accuracy: 0.51584 | val_accuracy: 0.507   |  1:54:27s\n",
            "epoch 2460| loss: 0.96233 | train_accuracy: 0.51797 | val_accuracy: 0.5058  |  1:54:29s\n",
            "epoch 2461| loss: 0.96263 | train_accuracy: 0.51881 | val_accuracy: 0.5002  |  1:54:32s\n",
            "epoch 2462| loss: 0.96    | train_accuracy: 0.5193  | val_accuracy: 0.4982  |  1:54:35s\n",
            "epoch 2463| loss: 0.96149 | train_accuracy: 0.51806 | val_accuracy: 0.5018  |  1:54:38s\n",
            "\n",
            "Early stopping occurred at epoch 2463 with best_epoch = 1463 and best_val_accuracy = 0.52539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/callbacks.py:155: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(clf.history['loss'])"
      ],
      "metadata": {
        "id": "lKJV0b69YNNh",
        "outputId": "4fc091cc-0930-41d9-ca0d-240a4dd2fb4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa37072a310>]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot mse\n",
        "plt.plot(clf.history['train_accuracy'])\n",
        "plt.plot(clf.history['val_accuracy'])"
      ],
      "metadata": {
        "id": "PNp6Oo21YInI",
        "outputId": "4584a8cf-320d-4d46-8a73-f9600fb59c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fa3708851d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##N_a lớn"
      ],
      "metadata": {
        "id": "1mnhI2XLyK_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    n_d=16, n_a=512, n_steps=5,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=[3,12,3,12,3,12,3,12,3,12],\n",
        "    gamma=1.5, n_ind=2, n_shared=2,\n",
        "    lambda_sparse=1e-6, momentum=0.05, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 80},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGaUo15Ma_q1",
        "outputId": "4fa520d6-4f05-4973-e087-5540256c3c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name = ['train', 'val'],\n",
        "    max_epochs=3000, patience=3000,\n",
        "    batch_size=4096, vbs=1024 #, augmentations=aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DjV52yabBZh",
        "outputId": "b3fc1619-0528-43a3-9f41-c4e0244ca8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 2.38948 | train_accuracy: 0.48007 | val_accuracy: 0.46941 |  0:00:01s\n",
            "epoch 1  | loss: 1.27062 | train_accuracy: 0.49211 | val_accuracy: 0.47221 |  0:00:02s\n",
            "epoch 2  | loss: 1.13397 | train_accuracy: 0.48612 | val_accuracy: 0.4882  |  0:00:03s\n",
            "epoch 3  | loss: 1.06056 | train_accuracy: 0.4942  | val_accuracy: 0.489   |  0:00:04s\n",
            "epoch 4  | loss: 1.0196  | train_accuracy: 0.50255 | val_accuracy: 0.48181 |  0:00:06s\n",
            "epoch 5  | loss: 1.00637 | train_accuracy: 0.50389 | val_accuracy: 0.4934  |  0:00:07s\n",
            "epoch 6  | loss: 0.99254 | train_accuracy: 0.49709 | val_accuracy: 0.48541 |  0:00:08s\n",
            "epoch 7  | loss: 0.9861  | train_accuracy: 0.50957 | val_accuracy: 0.48301 |  0:00:10s\n",
            "epoch 8  | loss: 0.98161 | train_accuracy: 0.51157 | val_accuracy: 0.48101 |  0:00:11s\n",
            "epoch 9  | loss: 0.98038 | train_accuracy: 0.51126 | val_accuracy: 0.4898  |  0:00:12s\n",
            "epoch 10 | loss: 0.9776  | train_accuracy: 0.51215 | val_accuracy: 0.4938  |  0:00:13s\n",
            "epoch 11 | loss: 0.97893 | train_accuracy: 0.51451 | val_accuracy: 0.4978  |  0:00:14s\n",
            "epoch 12 | loss: 0.97319 | train_accuracy: 0.51317 | val_accuracy: 0.5038  |  0:00:16s\n",
            "epoch 13 | loss: 0.97371 | train_accuracy: 0.51459 | val_accuracy: 0.5002  |  0:00:17s\n",
            "epoch 14 | loss: 0.97006 | train_accuracy: 0.51757 | val_accuracy: 0.503   |  0:00:18s\n",
            "epoch 15 | loss: 0.96286 | train_accuracy: 0.52037 | val_accuracy: 0.5006  |  0:00:19s\n",
            "epoch 16 | loss: 0.96786 | train_accuracy: 0.52401 | val_accuracy: 0.4894  |  0:00:20s\n",
            "epoch 17 | loss: 0.96456 | train_accuracy: 0.52743 | val_accuracy: 0.503   |  0:00:22s\n",
            "epoch 18 | loss: 0.96448 | train_accuracy: 0.52712 | val_accuracy: 0.48421 |  0:00:23s\n",
            "epoch 19 | loss: 0.96038 | train_accuracy: 0.52632 | val_accuracy: 0.4946  |  0:00:24s\n",
            "epoch 20 | loss: 0.9578  | train_accuracy: 0.52734 | val_accuracy: 0.5062  |  0:00:25s\n",
            "epoch 21 | loss: 0.96196 | train_accuracy: 0.52423 | val_accuracy: 0.4958  |  0:00:26s\n",
            "epoch 22 | loss: 0.96306 | train_accuracy: 0.52232 | val_accuracy: 0.5018  |  0:00:27s\n",
            "epoch 23 | loss: 0.95949 | train_accuracy: 0.52699 | val_accuracy: 0.503   |  0:00:29s\n",
            "epoch 24 | loss: 0.95808 | train_accuracy: 0.52712 | val_accuracy: 0.4994  |  0:00:30s\n",
            "epoch 25 | loss: 0.95992 | train_accuracy: 0.52437 | val_accuracy: 0.4962  |  0:00:31s\n",
            "epoch 26 | loss: 0.9659  | train_accuracy: 0.52654 | val_accuracy: 0.4942  |  0:00:32s\n",
            "epoch 27 | loss: 0.96676 | train_accuracy: 0.52592 | val_accuracy: 0.5022  |  0:00:33s\n",
            "epoch 28 | loss: 0.96401 | train_accuracy: 0.51837 | val_accuracy: 0.51339 |  0:00:35s\n",
            "epoch 29 | loss: 0.96353 | train_accuracy: 0.52495 | val_accuracy: 0.51419 |  0:00:36s\n",
            "epoch 30 | loss: 0.96284 | train_accuracy: 0.52592 | val_accuracy: 0.493   |  0:00:37s\n",
            "epoch 31 | loss: 0.96075 | train_accuracy: 0.52579 | val_accuracy: 0.51419 |  0:00:38s\n",
            "epoch 32 | loss: 0.95887 | train_accuracy: 0.53152 | val_accuracy: 0.503   |  0:00:39s\n",
            "epoch 33 | loss: 0.96098 | train_accuracy: 0.53068 | val_accuracy: 0.4922  |  0:00:41s\n",
            "epoch 34 | loss: 0.95791 | train_accuracy: 0.52886 | val_accuracy: 0.4978  |  0:00:42s\n",
            "epoch 35 | loss: 0.95677 | train_accuracy: 0.53192 | val_accuracy: 0.5042  |  0:00:43s\n",
            "epoch 36 | loss: 0.95216 | train_accuracy: 0.5297  | val_accuracy: 0.4934  |  0:00:44s\n",
            "epoch 37 | loss: 0.95277 | train_accuracy: 0.53232 | val_accuracy: 0.5034  |  0:00:45s\n",
            "epoch 38 | loss: 0.95407 | train_accuracy: 0.53316 | val_accuracy: 0.5074  |  0:00:47s\n",
            "epoch 39 | loss: 0.9523  | train_accuracy: 0.52859 | val_accuracy: 0.4986  |  0:00:48s\n",
            "epoch 40 | loss: 0.95598 | train_accuracy: 0.5281  | val_accuracy: 0.4942  |  0:00:49s\n",
            "epoch 41 | loss: 0.95655 | train_accuracy: 0.52734 | val_accuracy: 0.5054  |  0:00:50s\n",
            "epoch 42 | loss: 0.95339 | train_accuracy: 0.52948 | val_accuracy: 0.5046  |  0:00:51s\n",
            "epoch 43 | loss: 0.95408 | train_accuracy: 0.53383 | val_accuracy: 0.5082  |  0:00:52s\n",
            "epoch 44 | loss: 0.95106 | train_accuracy: 0.53663 | val_accuracy: 0.51699 |  0:00:54s\n",
            "epoch 45 | loss: 0.94851 | train_accuracy: 0.53814 | val_accuracy: 0.505   |  0:00:55s\n",
            "epoch 46 | loss: 0.94781 | train_accuracy: 0.53863 | val_accuracy: 0.5014  |  0:00:56s\n",
            "epoch 47 | loss: 0.94701 | train_accuracy: 0.53836 | val_accuracy: 0.5026  |  0:00:57s\n",
            "epoch 48 | loss: 0.94545 | train_accuracy: 0.53752 | val_accuracy: 0.493   |  0:00:59s\n",
            "epoch 49 | loss: 0.94833 | train_accuracy: 0.53641 | val_accuracy: 0.4974  |  0:01:00s\n",
            "epoch 50 | loss: 0.94476 | train_accuracy: 0.53858 | val_accuracy: 0.4938  |  0:01:01s\n",
            "epoch 51 | loss: 0.94884 | train_accuracy: 0.53925 | val_accuracy: 0.4986  |  0:01:02s\n",
            "epoch 52 | loss: 0.94837 | train_accuracy: 0.53583 | val_accuracy: 0.5042  |  0:01:03s\n",
            "epoch 53 | loss: 0.95299 | train_accuracy: 0.54161 | val_accuracy: 0.4974  |  0:01:05s\n",
            "epoch 54 | loss: 0.95124 | train_accuracy: 0.53832 | val_accuracy: 0.4974  |  0:01:06s\n",
            "epoch 55 | loss: 0.95234 | train_accuracy: 0.53854 | val_accuracy: 0.5058  |  0:01:07s\n",
            "epoch 56 | loss: 0.95102 | train_accuracy: 0.53676 | val_accuracy: 0.5026  |  0:01:08s\n",
            "epoch 57 | loss: 0.95128 | train_accuracy: 0.53978 | val_accuracy: 0.5122  |  0:01:09s\n",
            "epoch 58 | loss: 0.95331 | train_accuracy: 0.53454 | val_accuracy: 0.5082  |  0:01:10s\n",
            "epoch 59 | loss: 0.95356 | train_accuracy: 0.53659 | val_accuracy: 0.5034  |  0:01:12s\n",
            "epoch 60 | loss: 0.95646 | train_accuracy: 0.53596 | val_accuracy: 0.5038  |  0:01:13s\n",
            "epoch 61 | loss: 0.95235 | train_accuracy: 0.5329  | val_accuracy: 0.497   |  0:01:14s\n",
            "epoch 62 | loss: 0.95246 | train_accuracy: 0.53414 | val_accuracy: 0.5062  |  0:01:15s\n",
            "epoch 63 | loss: 0.94818 | train_accuracy: 0.53445 | val_accuracy: 0.5094  |  0:01:16s\n",
            "epoch 64 | loss: 0.95233 | train_accuracy: 0.53898 | val_accuracy: 0.505   |  0:01:18s\n",
            "epoch 65 | loss: 0.95161 | train_accuracy: 0.53605 | val_accuracy: 0.5086  |  0:01:19s\n",
            "epoch 66 | loss: 0.95182 | train_accuracy: 0.53392 | val_accuracy: 0.5098  |  0:01:20s\n",
            "epoch 67 | loss: 0.95132 | train_accuracy: 0.53721 | val_accuracy: 0.4982  |  0:01:21s\n",
            "epoch 68 | loss: 0.95482 | train_accuracy: 0.53912 | val_accuracy: 0.495   |  0:01:22s\n",
            "epoch 69 | loss: 0.9462  | train_accuracy: 0.54307 | val_accuracy: 0.5002  |  0:01:24s\n",
            "epoch 70 | loss: 0.95005 | train_accuracy: 0.53654 | val_accuracy: 0.47861 |  0:01:25s\n",
            "epoch 71 | loss: 0.95006 | train_accuracy: 0.54041 | val_accuracy: 0.4934  |  0:01:26s\n",
            "epoch 72 | loss: 0.95023 | train_accuracy: 0.54112 | val_accuracy: 0.4894  |  0:01:28s\n",
            "epoch 73 | loss: 0.95008 | train_accuracy: 0.54161 | val_accuracy: 0.5054  |  0:01:29s\n",
            "epoch 74 | loss: 0.94948 | train_accuracy: 0.53832 | val_accuracy: 0.5102  |  0:01:30s\n",
            "epoch 75 | loss: 0.95438 | train_accuracy: 0.53401 | val_accuracy: 0.4998  |  0:01:31s\n",
            "epoch 76 | loss: 0.95247 | train_accuracy: 0.53539 | val_accuracy: 0.51339 |  0:01:32s\n",
            "epoch 77 | loss: 0.95292 | train_accuracy: 0.5373  | val_accuracy: 0.51419 |  0:01:34s\n",
            "epoch 78 | loss: 0.95082 | train_accuracy: 0.54081 | val_accuracy: 0.5098  |  0:01:35s\n",
            "epoch 79 | loss: 0.95237 | train_accuracy: 0.54103 | val_accuracy: 0.51859 |  0:01:36s\n",
            "epoch 80 | loss: 0.94497 | train_accuracy: 0.53925 | val_accuracy: 0.51979 |  0:01:37s\n",
            "epoch 81 | loss: 0.94593 | train_accuracy: 0.53912 | val_accuracy: 0.52179 |  0:01:38s\n",
            "epoch 82 | loss: 0.94534 | train_accuracy: 0.54218 | val_accuracy: 0.52379 |  0:01:40s\n",
            "epoch 83 | loss: 0.94613 | train_accuracy: 0.54249 | val_accuracy: 0.52419 |  0:01:41s\n",
            "epoch 84 | loss: 0.94442 | train_accuracy: 0.53934 | val_accuracy: 0.52619 |  0:01:42s\n",
            "epoch 85 | loss: 0.94538 | train_accuracy: 0.53832 | val_accuracy: 0.51459 |  0:01:43s\n",
            "epoch 86 | loss: 0.9455  | train_accuracy: 0.54143 | val_accuracy: 0.52339 |  0:01:44s\n",
            "epoch 87 | loss: 0.94714 | train_accuracy: 0.53703 | val_accuracy: 0.51379 |  0:01:46s\n",
            "epoch 88 | loss: 0.94986 | train_accuracy: 0.53423 | val_accuracy: 0.507   |  0:01:47s\n",
            "epoch 89 | loss: 0.95804 | train_accuracy: 0.53139 | val_accuracy: 0.51539 |  0:01:48s\n",
            "epoch 90 | loss: 0.95589 | train_accuracy: 0.53148 | val_accuracy: 0.5038  |  0:01:49s\n",
            "epoch 91 | loss: 0.95831 | train_accuracy: 0.52934 | val_accuracy: 0.5042  |  0:01:50s\n",
            "epoch 92 | loss: 0.96019 | train_accuracy: 0.53005 | val_accuracy: 0.51419 |  0:01:52s\n",
            "epoch 93 | loss: 0.95616 | train_accuracy: 0.53112 | val_accuracy: 0.51579 |  0:01:53s\n",
            "epoch 94 | loss: 0.95858 | train_accuracy: 0.5365  | val_accuracy: 0.5042  |  0:01:54s\n",
            "epoch 95 | loss: 0.95256 | train_accuracy: 0.53752 | val_accuracy: 0.5094  |  0:01:55s\n",
            "epoch 96 | loss: 0.95213 | train_accuracy: 0.5377  | val_accuracy: 0.5054  |  0:01:56s\n",
            "epoch 97 | loss: 0.94995 | train_accuracy: 0.5385  | val_accuracy: 0.51459 |  0:01:58s\n",
            "epoch 98 | loss: 0.95041 | train_accuracy: 0.53903 | val_accuracy: 0.5098  |  0:01:59s\n",
            "epoch 99 | loss: 0.94959 | train_accuracy: 0.53539 | val_accuracy: 0.5062  |  0:02:00s\n",
            "epoch 100| loss: 0.94731 | train_accuracy: 0.53818 | val_accuracy: 0.5102  |  0:02:01s\n",
            "epoch 101| loss: 0.9505  | train_accuracy: 0.53761 | val_accuracy: 0.5062  |  0:02:02s\n",
            "epoch 102| loss: 0.94723 | train_accuracy: 0.53912 | val_accuracy: 0.4914  |  0:02:04s\n",
            "epoch 103| loss: 0.95231 | train_accuracy: 0.53712 | val_accuracy: 0.51499 |  0:02:05s\n",
            "epoch 104| loss: 0.9485  | train_accuracy: 0.53574 | val_accuracy: 0.5062  |  0:02:06s\n",
            "epoch 105| loss: 0.94939 | train_accuracy: 0.53619 | val_accuracy: 0.51379 |  0:02:07s\n",
            "epoch 106| loss: 0.95101 | train_accuracy: 0.53539 | val_accuracy: 0.51419 |  0:02:08s\n",
            "epoch 107| loss: 0.95331 | train_accuracy: 0.5365  | val_accuracy: 0.5114  |  0:02:10s\n",
            "epoch 108| loss: 0.95148 | train_accuracy: 0.53885 | val_accuracy: 0.4938  |  0:02:11s\n",
            "epoch 109| loss: 0.95156 | train_accuracy: 0.53947 | val_accuracy: 0.505   |  0:02:12s\n",
            "epoch 110| loss: 0.95296 | train_accuracy: 0.53845 | val_accuracy: 0.5102  |  0:02:13s\n",
            "epoch 111| loss: 0.95324 | train_accuracy: 0.54032 | val_accuracy: 0.51819 |  0:02:14s\n",
            "epoch 112| loss: 0.95147 | train_accuracy: 0.53476 | val_accuracy: 0.52019 |  0:02:16s\n",
            "epoch 113| loss: 0.95152 | train_accuracy: 0.5361  | val_accuracy: 0.51339 |  0:02:17s\n",
            "epoch 114| loss: 0.95512 | train_accuracy: 0.53832 | val_accuracy: 0.5066  |  0:02:18s\n",
            "epoch 115| loss: 0.95451 | train_accuracy: 0.53645 | val_accuracy: 0.5102  |  0:02:19s\n",
            "epoch 116| loss: 0.95323 | train_accuracy: 0.52912 | val_accuracy: 0.5042  |  0:02:20s\n",
            "epoch 117| loss: 0.95466 | train_accuracy: 0.53148 | val_accuracy: 0.48741 |  0:02:22s\n",
            "epoch 118| loss: 0.95331 | train_accuracy: 0.53468 | val_accuracy: 0.499   |  0:02:23s\n",
            "epoch 119| loss: 0.95384 | train_accuracy: 0.53632 | val_accuracy: 0.499   |  0:02:24s\n",
            "epoch 120| loss: 0.94883 | train_accuracy: 0.53303 | val_accuracy: 0.507   |  0:02:25s\n",
            "epoch 121| loss: 0.95127 | train_accuracy: 0.5369  | val_accuracy: 0.503   |  0:02:26s\n",
            "epoch 122| loss: 0.95026 | train_accuracy: 0.53938 | val_accuracy: 0.497   |  0:02:28s\n",
            "epoch 123| loss: 0.94915 | train_accuracy: 0.53739 | val_accuracy: 0.5078  |  0:02:29s\n",
            "epoch 124| loss: 0.95118 | train_accuracy: 0.53707 | val_accuracy: 0.5046  |  0:02:30s\n",
            "epoch 125| loss: 0.95323 | train_accuracy: 0.52654 | val_accuracy: 0.4894  |  0:02:31s\n",
            "epoch 126| loss: 0.95683 | train_accuracy: 0.53041 | val_accuracy: 0.4982  |  0:02:32s\n",
            "epoch 127| loss: 0.95323 | train_accuracy: 0.52877 | val_accuracy: 0.5086  |  0:02:34s\n",
            "epoch 128| loss: 0.95422 | train_accuracy: 0.53054 | val_accuracy: 0.51459 |  0:02:35s\n",
            "epoch 129| loss: 0.95274 | train_accuracy: 0.5297  | val_accuracy: 0.5066  |  0:02:36s\n",
            "epoch 130| loss: 0.95406 | train_accuracy: 0.52899 | val_accuracy: 0.5042  |  0:02:37s\n",
            "epoch 131| loss: 0.95113 | train_accuracy: 0.5337  | val_accuracy: 0.5022  |  0:02:38s\n",
            "epoch 132| loss: 0.95323 | train_accuracy: 0.53503 | val_accuracy: 0.5062  |  0:02:40s\n",
            "epoch 133| loss: 0.94907 | train_accuracy: 0.53938 | val_accuracy: 0.5054  |  0:02:41s\n",
            "epoch 134| loss: 0.94593 | train_accuracy: 0.53752 | val_accuracy: 0.5094  |  0:02:42s\n",
            "epoch 135| loss: 0.94336 | train_accuracy: 0.53743 | val_accuracy: 0.5074  |  0:02:43s\n",
            "epoch 136| loss: 0.94499 | train_accuracy: 0.5385  | val_accuracy: 0.52219 |  0:02:44s\n",
            "epoch 137| loss: 0.94683 | train_accuracy: 0.54134 | val_accuracy: 0.51299 |  0:02:46s\n",
            "epoch 138| loss: 0.94407 | train_accuracy: 0.53938 | val_accuracy: 0.51619 |  0:02:47s\n",
            "epoch 139| loss: 0.94736 | train_accuracy: 0.53396 | val_accuracy: 0.51339 |  0:02:49s\n",
            "epoch 140| loss: 0.95249 | train_accuracy: 0.5297  | val_accuracy: 0.5074  |  0:02:50s\n",
            "epoch 141| loss: 0.95375 | train_accuracy: 0.53263 | val_accuracy: 0.51859 |  0:02:51s\n",
            "epoch 142| loss: 0.94916 | train_accuracy: 0.5333  | val_accuracy: 0.5098  |  0:02:52s\n",
            "epoch 143| loss: 0.95339 | train_accuracy: 0.53085 | val_accuracy: 0.5074  |  0:02:53s\n",
            "epoch 144| loss: 0.95909 | train_accuracy: 0.5297  | val_accuracy: 0.507   |  0:02:55s\n",
            "epoch 145| loss: 0.95626 | train_accuracy: 0.53214 | val_accuracy: 0.5002  |  0:02:56s\n",
            "epoch 146| loss: 0.95444 | train_accuracy: 0.52837 | val_accuracy: 0.4938  |  0:02:57s\n",
            "epoch 147| loss: 0.95189 | train_accuracy: 0.53281 | val_accuracy: 0.5014  |  0:02:58s\n",
            "epoch 148| loss: 0.9513  | train_accuracy: 0.53436 | val_accuracy: 0.503   |  0:02:59s\n",
            "epoch 149| loss: 0.94964 | train_accuracy: 0.53276 | val_accuracy: 0.5046  |  0:03:00s\n",
            "epoch 150| loss: 0.95335 | train_accuracy: 0.53117 | val_accuracy: 0.5066  |  0:03:02s\n",
            "epoch 151| loss: 0.9529  | train_accuracy: 0.53108 | val_accuracy: 0.5018  |  0:03:03s\n",
            "epoch 152| loss: 0.95234 | train_accuracy: 0.53676 | val_accuracy: 0.5122  |  0:03:04s\n",
            "epoch 153| loss: 0.95077 | train_accuracy: 0.53507 | val_accuracy: 0.5034  |  0:03:05s\n",
            "epoch 154| loss: 0.94722 | train_accuracy: 0.53739 | val_accuracy: 0.5054  |  0:03:06s\n",
            "epoch 155| loss: 0.95056 | train_accuracy: 0.5349  | val_accuracy: 0.5042  |  0:03:08s\n",
            "epoch 156| loss: 0.94488 | train_accuracy: 0.53974 | val_accuracy: 0.5022  |  0:03:09s\n",
            "epoch 157| loss: 0.94661 | train_accuracy: 0.53654 | val_accuracy: 0.505   |  0:03:10s\n",
            "epoch 158| loss: 0.94459 | train_accuracy: 0.53752 | val_accuracy: 0.5006  |  0:03:11s\n",
            "epoch 159| loss: 0.9461  | train_accuracy: 0.53956 | val_accuracy: 0.511   |  0:03:12s\n",
            "epoch 160| loss: 0.94569 | train_accuracy: 0.53747 | val_accuracy: 0.4978  |  0:03:14s\n",
            "epoch 161| loss: 0.94778 | train_accuracy: 0.53858 | val_accuracy: 0.51419 |  0:03:15s\n",
            "epoch 162| loss: 0.94912 | train_accuracy: 0.54005 | val_accuracy: 0.52059 |  0:03:16s\n",
            "epoch 163| loss: 0.94406 | train_accuracy: 0.5381  | val_accuracy: 0.5046  |  0:03:17s\n",
            "epoch 164| loss: 0.9437  | train_accuracy: 0.5373  | val_accuracy: 0.51779 |  0:03:18s\n",
            "epoch 165| loss: 0.94401 | train_accuracy: 0.54005 | val_accuracy: 0.5054  |  0:03:19s\n",
            "epoch 166| loss: 0.94489 | train_accuracy: 0.54174 | val_accuracy: 0.5054  |  0:03:21s\n",
            "epoch 167| loss: 0.94877 | train_accuracy: 0.54027 | val_accuracy: 0.4986  |  0:03:22s\n",
            "epoch 168| loss: 0.95139 | train_accuracy: 0.54081 | val_accuracy: 0.4962  |  0:03:23s\n",
            "epoch 169| loss: 0.94824 | train_accuracy: 0.53943 | val_accuracy: 0.4982  |  0:03:24s\n",
            "epoch 170| loss: 0.94507 | train_accuracy: 0.53938 | val_accuracy: 0.5058  |  0:03:25s\n",
            "epoch 171| loss: 0.94559 | train_accuracy: 0.54045 | val_accuracy: 0.507   |  0:03:27s\n",
            "epoch 172| loss: 0.94418 | train_accuracy: 0.54356 | val_accuracy: 0.5014  |  0:03:28s\n",
            "epoch 173| loss: 0.94391 | train_accuracy: 0.54085 | val_accuracy: 0.503   |  0:03:29s\n",
            "epoch 174| loss: 0.9471  | train_accuracy: 0.53707 | val_accuracy: 0.499   |  0:03:30s\n",
            "epoch 175| loss: 0.94796 | train_accuracy: 0.5349  | val_accuracy: 0.5094  |  0:03:31s\n",
            "epoch 176| loss: 0.9522  | train_accuracy: 0.53445 | val_accuracy: 0.4914  |  0:03:33s\n",
            "epoch 177| loss: 0.95347 | train_accuracy: 0.53756 | val_accuracy: 0.5042  |  0:03:34s\n",
            "epoch 178| loss: 0.94919 | train_accuracy: 0.53734 | val_accuracy: 0.4946  |  0:03:35s\n",
            "epoch 179| loss: 0.95053 | train_accuracy: 0.53881 | val_accuracy: 0.5014  |  0:03:36s\n",
            "epoch 180| loss: 0.94563 | train_accuracy: 0.53316 | val_accuracy: 0.4974  |  0:03:37s\n",
            "epoch 181| loss: 0.94752 | train_accuracy: 0.53525 | val_accuracy: 0.4934  |  0:03:39s\n",
            "epoch 182| loss: 0.95054 | train_accuracy: 0.53499 | val_accuracy: 0.497   |  0:03:40s\n",
            "epoch 183| loss: 0.95079 | train_accuracy: 0.53605 | val_accuracy: 0.499   |  0:03:41s\n",
            "epoch 184| loss: 0.947   | train_accuracy: 0.53308 | val_accuracy: 0.491   |  0:03:42s\n",
            "epoch 185| loss: 0.95088 | train_accuracy: 0.53574 | val_accuracy: 0.48661 |  0:03:43s\n",
            "epoch 186| loss: 0.95639 | train_accuracy: 0.53103 | val_accuracy: 0.497   |  0:03:44s\n",
            "epoch 187| loss: 0.95262 | train_accuracy: 0.53005 | val_accuracy: 0.505   |  0:03:46s\n",
            "epoch 188| loss: 0.95422 | train_accuracy: 0.53019 | val_accuracy: 0.4994  |  0:03:47s\n",
            "epoch 189| loss: 0.95518 | train_accuracy: 0.52881 | val_accuracy: 0.5058  |  0:03:48s\n",
            "epoch 190| loss: 0.95494 | train_accuracy: 0.53183 | val_accuracy: 0.5066  |  0:03:49s\n",
            "epoch 191| loss: 0.95916 | train_accuracy: 0.53014 | val_accuracy: 0.5034  |  0:03:50s\n",
            "epoch 192| loss: 0.9553  | train_accuracy: 0.52992 | val_accuracy: 0.5042  |  0:03:52s\n",
            "epoch 193| loss: 0.95813 | train_accuracy: 0.5269  | val_accuracy: 0.48501 |  0:03:53s\n",
            "epoch 194| loss: 0.95927 | train_accuracy: 0.52934 | val_accuracy: 0.4986  |  0:03:54s\n",
            "epoch 195| loss: 0.95853 | train_accuracy: 0.53099 | val_accuracy: 0.4966  |  0:03:55s\n",
            "epoch 196| loss: 0.95541 | train_accuracy: 0.53188 | val_accuracy: 0.497   |  0:03:56s\n",
            "epoch 197| loss: 0.95491 | train_accuracy: 0.53037 | val_accuracy: 0.501   |  0:03:58s\n",
            "epoch 198| loss: 0.95936 | train_accuracy: 0.52903 | val_accuracy: 0.4926  |  0:03:59s\n",
            "epoch 199| loss: 0.95844 | train_accuracy: 0.52766 | val_accuracy: 0.5062  |  0:04:00s\n",
            "epoch 200| loss: 0.96003 | train_accuracy: 0.52561 | val_accuracy: 0.5002  |  0:04:01s\n",
            "epoch 201| loss: 0.95955 | train_accuracy: 0.52521 | val_accuracy: 0.47701 |  0:04:02s\n",
            "epoch 202| loss: 0.96643 | train_accuracy: 0.52104 | val_accuracy: 0.48101 |  0:04:04s\n",
            "epoch 203| loss: 0.96469 | train_accuracy: 0.52108 | val_accuracy: 0.4902  |  0:04:05s\n",
            "epoch 204| loss: 0.9649  | train_accuracy: 0.52264 | val_accuracy: 0.491   |  0:04:06s\n",
            "epoch 205| loss: 0.9634  | train_accuracy: 0.52672 | val_accuracy: 0.493   |  0:04:07s\n",
            "epoch 206| loss: 0.96094 | train_accuracy: 0.5285  | val_accuracy: 0.497   |  0:04:08s\n",
            "epoch 207| loss: 0.95976 | train_accuracy: 0.52819 | val_accuracy: 0.5006  |  0:04:09s\n",
            "epoch 208| loss: 0.96225 | train_accuracy: 0.5325  | val_accuracy: 0.4958  |  0:04:11s\n",
            "epoch 209| loss: 0.95783 | train_accuracy: 0.53001 | val_accuracy: 0.48661 |  0:04:12s\n",
            "epoch 210| loss: 0.95789 | train_accuracy: 0.52659 | val_accuracy: 0.5026  |  0:04:13s\n",
            "epoch 211| loss: 0.95729 | train_accuracy: 0.52654 | val_accuracy: 0.499   |  0:04:14s\n",
            "epoch 212| loss: 0.95752 | train_accuracy: 0.52428 | val_accuracy: 0.4962  |  0:04:15s\n",
            "epoch 213| loss: 0.95713 | train_accuracy: 0.5265  | val_accuracy: 0.5034  |  0:04:17s\n",
            "epoch 214| loss: 0.95669 | train_accuracy: 0.52748 | val_accuracy: 0.4954  |  0:04:18s\n",
            "epoch 215| loss: 0.95765 | train_accuracy: 0.52712 | val_accuracy: 0.4922  |  0:04:19s\n",
            "epoch 216| loss: 0.95853 | train_accuracy: 0.5305  | val_accuracy: 0.4898  |  0:04:20s\n",
            "epoch 217| loss: 0.95702 | train_accuracy: 0.5293  | val_accuracy: 0.4942  |  0:04:21s\n",
            "epoch 218| loss: 0.95497 | train_accuracy: 0.53174 | val_accuracy: 0.4922  |  0:04:23s\n",
            "epoch 219| loss: 0.95256 | train_accuracy: 0.52654 | val_accuracy: 0.47381 |  0:04:24s\n",
            "epoch 220| loss: 0.95575 | train_accuracy: 0.52788 | val_accuracy: 0.4878  |  0:04:25s\n",
            "epoch 221| loss: 0.95564 | train_accuracy: 0.52846 | val_accuracy: 0.48141 |  0:04:26s\n",
            "epoch 222| loss: 0.95752 | train_accuracy: 0.52761 | val_accuracy: 0.4898  |  0:04:27s\n",
            "epoch 223| loss: 0.95995 | train_accuracy: 0.52828 | val_accuracy: 0.4902  |  0:04:28s\n",
            "epoch 224| loss: 0.95936 | train_accuracy: 0.5293  | val_accuracy: 0.4882  |  0:04:30s\n",
            "epoch 225| loss: 0.95802 | train_accuracy: 0.52957 | val_accuracy: 0.4886  |  0:04:31s\n",
            "epoch 226| loss: 0.96067 | train_accuracy: 0.5273  | val_accuracy: 0.47461 |  0:04:32s\n",
            "epoch 227| loss: 0.96265 | train_accuracy: 0.52859 | val_accuracy: 0.4986  |  0:04:33s\n",
            "epoch 228| loss: 0.95623 | train_accuracy: 0.53023 | val_accuracy: 0.4958  |  0:04:34s\n",
            "epoch 229| loss: 0.95781 | train_accuracy: 0.53112 | val_accuracy: 0.4934  |  0:04:36s\n",
            "epoch 230| loss: 0.96091 | train_accuracy: 0.52957 | val_accuracy: 0.4934  |  0:04:37s\n",
            "epoch 231| loss: 0.96128 | train_accuracy: 0.52561 | val_accuracy: 0.4882  |  0:04:38s\n",
            "epoch 232| loss: 0.95935 | train_accuracy: 0.52859 | val_accuracy: 0.4958  |  0:04:39s\n",
            "epoch 233| loss: 0.96297 | train_accuracy: 0.52943 | val_accuracy: 0.4978  |  0:04:40s\n",
            "epoch 234| loss: 0.95988 | train_accuracy: 0.5261  | val_accuracy: 0.4926  |  0:04:41s\n",
            "epoch 235| loss: 0.96189 | train_accuracy: 0.52699 | val_accuracy: 0.4994  |  0:04:43s\n",
            "epoch 236| loss: 0.95963 | train_accuracy: 0.52997 | val_accuracy: 0.48741 |  0:04:44s\n",
            "epoch 237| loss: 0.95749 | train_accuracy: 0.5269  | val_accuracy: 0.5002  |  0:04:45s\n",
            "epoch 238| loss: 0.95688 | train_accuracy: 0.53152 | val_accuracy: 0.5042  |  0:04:46s\n",
            "epoch 239| loss: 0.96054 | train_accuracy: 0.53152 | val_accuracy: 0.5058  |  0:04:47s\n",
            "epoch 240| loss: 0.96021 | train_accuracy: 0.52783 | val_accuracy: 0.4974  |  0:04:49s\n",
            "epoch 241| loss: 0.95834 | train_accuracy: 0.52686 | val_accuracy: 0.4966  |  0:04:50s\n",
            "epoch 242| loss: 0.95725 | train_accuracy: 0.52788 | val_accuracy: 0.4934  |  0:04:51s\n",
            "epoch 243| loss: 0.9557  | train_accuracy: 0.52575 | val_accuracy: 0.497   |  0:04:52s\n",
            "epoch 244| loss: 0.95718 | train_accuracy: 0.52694 | val_accuracy: 0.4938  |  0:04:53s\n",
            "epoch 245| loss: 0.95518 | train_accuracy: 0.52903 | val_accuracy: 0.5034  |  0:04:55s\n",
            "epoch 246| loss: 0.95532 | train_accuracy: 0.52965 | val_accuracy: 0.4922  |  0:04:56s\n",
            "epoch 247| loss: 0.95506 | train_accuracy: 0.52672 | val_accuracy: 0.4974  |  0:04:57s\n",
            "epoch 248| loss: 0.95467 | train_accuracy: 0.52677 | val_accuracy: 0.4958  |  0:04:58s\n",
            "epoch 249| loss: 0.95934 | train_accuracy: 0.52557 | val_accuracy: 0.4886  |  0:04:59s\n",
            "epoch 250| loss: 0.96003 | train_accuracy: 0.5237  | val_accuracy: 0.4902  |  0:05:00s\n",
            "epoch 251| loss: 0.96282 | train_accuracy: 0.52428 | val_accuracy: 0.48341 |  0:05:02s\n",
            "epoch 252| loss: 0.96137 | train_accuracy: 0.52623 | val_accuracy: 0.48141 |  0:05:03s\n",
            "epoch 253| loss: 0.96277 | train_accuracy: 0.52415 | val_accuracy: 0.48621 |  0:05:04s\n",
            "epoch 254| loss: 0.95661 | train_accuracy: 0.52686 | val_accuracy: 0.4894  |  0:05:05s\n",
            "epoch 255| loss: 0.95895 | train_accuracy: 0.52841 | val_accuracy: 0.5026  |  0:05:06s\n",
            "epoch 256| loss: 0.95627 | train_accuracy: 0.52637 | val_accuracy: 0.4946  |  0:05:08s\n",
            "epoch 257| loss: 0.95733 | train_accuracy: 0.52463 | val_accuracy: 0.4994  |  0:05:09s\n",
            "epoch 258| loss: 0.95732 | train_accuracy: 0.52699 | val_accuracy: 0.4918  |  0:05:10s\n",
            "epoch 259| loss: 0.95451 | train_accuracy: 0.52819 | val_accuracy: 0.5046  |  0:05:11s\n",
            "epoch 260| loss: 0.95452 | train_accuracy: 0.52992 | val_accuracy: 0.503   |  0:05:12s\n",
            "epoch 261| loss: 0.95601 | train_accuracy: 0.53019 | val_accuracy: 0.5122  |  0:05:14s\n",
            "epoch 262| loss: 0.95334 | train_accuracy: 0.5305  | val_accuracy: 0.4978  |  0:05:15s\n",
            "epoch 263| loss: 0.95293 | train_accuracy: 0.52886 | val_accuracy: 0.5042  |  0:05:16s\n",
            "epoch 264| loss: 0.95109 | train_accuracy: 0.52659 | val_accuracy: 0.4962  |  0:05:17s\n",
            "epoch 265| loss: 0.95173 | train_accuracy: 0.52677 | val_accuracy: 0.4906  |  0:05:18s\n",
            "epoch 266| loss: 0.95593 | train_accuracy: 0.5253  | val_accuracy: 0.4906  |  0:05:19s\n",
            "epoch 267| loss: 0.95872 | train_accuracy: 0.52566 | val_accuracy: 0.4946  |  0:05:21s\n",
            "epoch 268| loss: 0.95826 | train_accuracy: 0.52317 | val_accuracy: 0.489   |  0:05:22s\n",
            "epoch 269| loss: 0.95851 | train_accuracy: 0.52632 | val_accuracy: 0.5054  |  0:05:23s\n",
            "epoch 270| loss: 0.95652 | train_accuracy: 0.52601 | val_accuracy: 0.48621 |  0:05:24s\n",
            "epoch 271| loss: 0.95917 | train_accuracy: 0.52432 | val_accuracy: 0.4962  |  0:05:25s\n",
            "epoch 272| loss: 0.95642 | train_accuracy: 0.52575 | val_accuracy: 0.48701 |  0:05:27s\n",
            "epoch 273| loss: 0.95685 | train_accuracy: 0.52632 | val_accuracy: 0.5034  |  0:05:28s\n",
            "epoch 274| loss: 0.95438 | train_accuracy: 0.52748 | val_accuracy: 0.4898  |  0:05:29s\n",
            "epoch 275| loss: 0.95102 | train_accuracy: 0.53085 | val_accuracy: 0.48421 |  0:05:30s\n",
            "epoch 276| loss: 0.95222 | train_accuracy: 0.53165 | val_accuracy: 0.48181 |  0:05:31s\n",
            "epoch 277| loss: 0.95159 | train_accuracy: 0.5305  | val_accuracy: 0.48621 |  0:05:33s\n",
            "epoch 278| loss: 0.95457 | train_accuracy: 0.53303 | val_accuracy: 0.4922  |  0:05:34s\n",
            "epoch 279| loss: 0.94606 | train_accuracy: 0.52854 | val_accuracy: 0.4934  |  0:05:35s\n",
            "epoch 280| loss: 0.95289 | train_accuracy: 0.52708 | val_accuracy: 0.48301 |  0:05:36s\n",
            "epoch 281| loss: 0.95123 | train_accuracy: 0.52797 | val_accuracy: 0.48581 |  0:05:37s\n",
            "epoch 282| loss: 0.95013 | train_accuracy: 0.52903 | val_accuracy: 0.4946  |  0:05:39s\n",
            "epoch 283| loss: 0.95505 | train_accuracy: 0.52659 | val_accuracy: 0.4942  |  0:05:40s\n",
            "epoch 284| loss: 0.95657 | train_accuracy: 0.52379 | val_accuracy: 0.4954  |  0:05:41s\n",
            "epoch 285| loss: 0.95608 | train_accuracy: 0.52774 | val_accuracy: 0.505   |  0:05:42s\n",
            "epoch 286| loss: 0.95215 | train_accuracy: 0.52783 | val_accuracy: 0.51259 |  0:05:43s\n",
            "epoch 287| loss: 0.95378 | train_accuracy: 0.53014 | val_accuracy: 0.499   |  0:05:45s\n",
            "epoch 288| loss: 0.95463 | train_accuracy: 0.5289  | val_accuracy: 0.5026  |  0:05:46s\n",
            "epoch 289| loss: 0.95143 | train_accuracy: 0.52983 | val_accuracy: 0.493   |  0:05:47s\n",
            "epoch 290| loss: 0.95349 | train_accuracy: 0.53272 | val_accuracy: 0.5038  |  0:05:48s\n",
            "epoch 291| loss: 0.95276 | train_accuracy: 0.53339 | val_accuracy: 0.4938  |  0:05:49s\n",
            "epoch 292| loss: 0.94736 | train_accuracy: 0.53063 | val_accuracy: 0.48421 |  0:05:50s\n",
            "epoch 293| loss: 0.94599 | train_accuracy: 0.53232 | val_accuracy: 0.4962  |  0:05:52s\n",
            "epoch 294| loss: 0.94731 | train_accuracy: 0.53325 | val_accuracy: 0.4982  |  0:05:53s\n",
            "epoch 295| loss: 0.94503 | train_accuracy: 0.53125 | val_accuracy: 0.4978  |  0:05:54s\n",
            "epoch 296| loss: 0.95199 | train_accuracy: 0.52748 | val_accuracy: 0.499   |  0:05:55s\n",
            "epoch 297| loss: 0.94952 | train_accuracy: 0.52903 | val_accuracy: 0.4978  |  0:05:56s\n",
            "epoch 298| loss: 0.94914 | train_accuracy: 0.52992 | val_accuracy: 0.4954  |  0:05:58s\n",
            "epoch 299| loss: 0.94499 | train_accuracy: 0.53072 | val_accuracy: 0.51499 |  0:05:59s\n",
            "epoch 300| loss: 0.94676 | train_accuracy: 0.52912 | val_accuracy: 0.4994  |  0:06:00s\n",
            "epoch 301| loss: 0.94414 | train_accuracy: 0.53077 | val_accuracy: 0.5082  |  0:06:01s\n",
            "epoch 302| loss: 0.94657 | train_accuracy: 0.5317  | val_accuracy: 0.5014  |  0:06:02s\n",
            "epoch 303| loss: 0.94342 | train_accuracy: 0.53303 | val_accuracy: 0.5006  |  0:06:04s\n",
            "epoch 304| loss: 0.94762 | train_accuracy: 0.53143 | val_accuracy: 0.4998  |  0:06:05s\n",
            "epoch 305| loss: 0.94811 | train_accuracy: 0.53188 | val_accuracy: 0.5062  |  0:06:06s\n",
            "epoch 306| loss: 0.95218 | train_accuracy: 0.52463 | val_accuracy: 0.5026  |  0:06:07s\n",
            "epoch 307| loss: 0.94683 | train_accuracy: 0.53014 | val_accuracy: 0.5002  |  0:06:08s\n",
            "epoch 308| loss: 0.94936 | train_accuracy: 0.52703 | val_accuracy: 0.5006  |  0:06:09s\n",
            "epoch 309| loss: 0.94851 | train_accuracy: 0.52894 | val_accuracy: 0.4998  |  0:06:11s\n",
            "epoch 310| loss: 0.95043 | train_accuracy: 0.52877 | val_accuracy: 0.4962  |  0:06:12s\n",
            "epoch 311| loss: 0.94994 | train_accuracy: 0.52681 | val_accuracy: 0.5046  |  0:06:13s\n",
            "epoch 312| loss: 0.94959 | train_accuracy: 0.52934 | val_accuracy: 0.5106  |  0:06:14s\n",
            "epoch 313| loss: 0.95217 | train_accuracy: 0.53103 | val_accuracy: 0.5122  |  0:06:15s\n",
            "epoch 314| loss: 0.94716 | train_accuracy: 0.53192 | val_accuracy: 0.5038  |  0:06:17s\n",
            "epoch 315| loss: 0.95017 | train_accuracy: 0.53152 | val_accuracy: 0.4994  |  0:06:18s\n",
            "epoch 316| loss: 0.94916 | train_accuracy: 0.53223 | val_accuracy: 0.5086  |  0:06:19s\n",
            "epoch 317| loss: 0.94303 | train_accuracy: 0.53396 | val_accuracy: 0.5094  |  0:06:20s\n",
            "epoch 318| loss: 0.94659 | train_accuracy: 0.53205 | val_accuracy: 0.5098  |  0:06:21s\n",
            "epoch 319| loss: 0.94982 | train_accuracy: 0.52854 | val_accuracy: 0.503   |  0:06:22s\n",
            "epoch 320| loss: 0.94971 | train_accuracy: 0.52752 | val_accuracy: 0.5098  |  0:06:24s\n",
            "epoch 321| loss: 0.95054 | train_accuracy: 0.52908 | val_accuracy: 0.5118  |  0:06:25s\n",
            "epoch 322| loss: 0.94893 | train_accuracy: 0.5289  | val_accuracy: 0.51819 |  0:06:26s\n",
            "epoch 323| loss: 0.94999 | train_accuracy: 0.53281 | val_accuracy: 0.51979 |  0:06:27s\n",
            "epoch 324| loss: 0.94527 | train_accuracy: 0.53428 | val_accuracy: 0.51339 |  0:06:28s\n",
            "epoch 325| loss: 0.94446 | train_accuracy: 0.53365 | val_accuracy: 0.51459 |  0:06:30s\n",
            "epoch 326| loss: 0.94633 | train_accuracy: 0.53503 | val_accuracy: 0.51619 |  0:06:31s\n",
            "epoch 327| loss: 0.94525 | train_accuracy: 0.53379 | val_accuracy: 0.51579 |  0:06:32s\n",
            "epoch 328| loss: 0.94445 | train_accuracy: 0.53676 | val_accuracy: 0.51979 |  0:06:33s\n",
            "epoch 329| loss: 0.94238 | train_accuracy: 0.53547 | val_accuracy: 0.51499 |  0:06:34s\n",
            "epoch 330| loss: 0.94478 | train_accuracy: 0.5329  | val_accuracy: 0.51499 |  0:06:36s\n",
            "epoch 331| loss: 0.94369 | train_accuracy: 0.53641 | val_accuracy: 0.51539 |  0:06:37s\n",
            "epoch 332| loss: 0.94096 | train_accuracy: 0.53499 | val_accuracy: 0.51299 |  0:06:38s\n",
            "epoch 333| loss: 0.94061 | train_accuracy: 0.53841 | val_accuracy: 0.51379 |  0:06:39s\n",
            "epoch 334| loss: 0.94262 | train_accuracy: 0.53747 | val_accuracy: 0.51739 |  0:06:40s\n",
            "epoch 335| loss: 0.94021 | train_accuracy: 0.53539 | val_accuracy: 0.52299 |  0:06:41s\n",
            "epoch 336| loss: 0.94185 | train_accuracy: 0.53774 | val_accuracy: 0.52339 |  0:06:43s\n",
            "epoch 337| loss: 0.93739 | train_accuracy: 0.53432 | val_accuracy: 0.5098  |  0:06:44s\n",
            "epoch 338| loss: 0.93721 | train_accuracy: 0.53721 | val_accuracy: 0.52339 |  0:06:45s\n",
            "epoch 339| loss: 0.94263 | train_accuracy: 0.53503 | val_accuracy: 0.52139 |  0:06:46s\n",
            "epoch 340| loss: 0.94452 | train_accuracy: 0.53494 | val_accuracy: 0.52979 |  0:06:47s\n",
            "epoch 341| loss: 0.94513 | train_accuracy: 0.53836 | val_accuracy: 0.52979 |  0:06:49s\n",
            "epoch 342| loss: 0.94443 | train_accuracy: 0.53841 | val_accuracy: 0.53978 |  0:06:50s\n",
            "epoch 343| loss: 0.94507 | train_accuracy: 0.53739 | val_accuracy: 0.53778 |  0:06:51s\n",
            "epoch 344| loss: 0.94554 | train_accuracy: 0.53818 | val_accuracy: 0.53938 |  0:06:52s\n",
            "epoch 345| loss: 0.94321 | train_accuracy: 0.53805 | val_accuracy: 0.53379 |  0:06:53s\n",
            "epoch 346| loss: 0.9423  | train_accuracy: 0.53685 | val_accuracy: 0.53139 |  0:06:55s\n",
            "epoch 347| loss: 0.93867 | train_accuracy: 0.53956 | val_accuracy: 0.54018 |  0:06:56s\n",
            "epoch 348| loss: 0.9375  | train_accuracy: 0.53903 | val_accuracy: 0.53858 |  0:06:57s\n",
            "epoch 349| loss: 0.93659 | train_accuracy: 0.54267 | val_accuracy: 0.53858 |  0:06:58s\n",
            "epoch 350| loss: 0.93798 | train_accuracy: 0.54236 | val_accuracy: 0.53778 |  0:06:59s\n",
            "epoch 351| loss: 0.93801 | train_accuracy: 0.54018 | val_accuracy: 0.53978 |  0:07:01s\n",
            "epoch 352| loss: 0.93784 | train_accuracy: 0.54218 | val_accuracy: 0.53019 |  0:07:02s\n",
            "epoch 353| loss: 0.9348  | train_accuracy: 0.54285 | val_accuracy: 0.52859 |  0:07:03s\n",
            "epoch 354| loss: 0.93406 | train_accuracy: 0.54489 | val_accuracy: 0.52579 |  0:07:04s\n",
            "epoch 355| loss: 0.9372  | train_accuracy: 0.5444  | val_accuracy: 0.53379 |  0:07:05s\n",
            "epoch 356| loss: 0.93391 | train_accuracy: 0.54467 | val_accuracy: 0.52379 |  0:07:06s\n",
            "epoch 357| loss: 0.93532 | train_accuracy: 0.54489 | val_accuracy: 0.52539 |  0:07:08s\n",
            "epoch 358| loss: 0.93558 | train_accuracy: 0.53974 | val_accuracy: 0.5094  |  0:07:09s\n",
            "epoch 359| loss: 0.93524 | train_accuracy: 0.54232 | val_accuracy: 0.52939 |  0:07:10s\n",
            "epoch 360| loss: 0.93975 | train_accuracy: 0.54476 | val_accuracy: 0.51899 |  0:07:11s\n",
            "epoch 361| loss: 0.93355 | train_accuracy: 0.54281 | val_accuracy: 0.52699 |  0:07:12s\n",
            "epoch 362| loss: 0.93833 | train_accuracy: 0.54027 | val_accuracy: 0.52619 |  0:07:14s\n",
            "epoch 363| loss: 0.9383  | train_accuracy: 0.53832 | val_accuracy: 0.51899 |  0:07:15s\n",
            "epoch 364| loss: 0.94001 | train_accuracy: 0.53983 | val_accuracy: 0.52299 |  0:07:16s\n",
            "epoch 365| loss: 0.93968 | train_accuracy: 0.53721 | val_accuracy: 0.5106  |  0:07:17s\n",
            "epoch 366| loss: 0.94202 | train_accuracy: 0.53858 | val_accuracy: 0.52219 |  0:07:18s\n",
            "epoch 367| loss: 0.94302 | train_accuracy: 0.5377  | val_accuracy: 0.51259 |  0:07:20s\n",
            "epoch 368| loss: 0.94575 | train_accuracy: 0.53716 | val_accuracy: 0.51859 |  0:07:21s\n",
            "epoch 369| loss: 0.94486 | train_accuracy: 0.53521 | val_accuracy: 0.52419 |  0:07:22s\n",
            "epoch 370| loss: 0.94381 | train_accuracy: 0.53619 | val_accuracy: 0.51779 |  0:07:23s\n",
            "epoch 371| loss: 0.94364 | train_accuracy: 0.54041 | val_accuracy: 0.51659 |  0:07:24s\n",
            "epoch 372| loss: 0.94382 | train_accuracy: 0.53654 | val_accuracy: 0.51659 |  0:07:25s\n",
            "epoch 373| loss: 0.94488 | train_accuracy: 0.53468 | val_accuracy: 0.52219 |  0:07:27s\n",
            "epoch 374| loss: 0.94511 | train_accuracy: 0.53667 | val_accuracy: 0.51499 |  0:07:28s\n",
            "epoch 375| loss: 0.94499 | train_accuracy: 0.53627 | val_accuracy: 0.52019 |  0:07:29s\n",
            "epoch 376| loss: 0.9445  | train_accuracy: 0.53805 | val_accuracy: 0.51899 |  0:07:30s\n",
            "epoch 377| loss: 0.94021 | train_accuracy: 0.53476 | val_accuracy: 0.51299 |  0:07:31s\n",
            "epoch 378| loss: 0.94499 | train_accuracy: 0.53468 | val_accuracy: 0.5122  |  0:07:33s\n",
            "epoch 379| loss: 0.94299 | train_accuracy: 0.53303 | val_accuracy: 0.509   |  0:07:34s\n",
            "epoch 380| loss: 0.94268 | train_accuracy: 0.53441 | val_accuracy: 0.51699 |  0:07:35s\n",
            "epoch 381| loss: 0.94447 | train_accuracy: 0.53454 | val_accuracy: 0.511   |  0:07:36s\n",
            "epoch 382| loss: 0.94203 | train_accuracy: 0.53534 | val_accuracy: 0.5098  |  0:07:37s\n",
            "epoch 383| loss: 0.94323 | train_accuracy: 0.5321  | val_accuracy: 0.5118  |  0:07:39s\n",
            "epoch 384| loss: 0.94201 | train_accuracy: 0.53419 | val_accuracy: 0.5074  |  0:07:40s\n",
            "epoch 385| loss: 0.94531 | train_accuracy: 0.5337  | val_accuracy: 0.5094  |  0:07:41s\n",
            "epoch 386| loss: 0.94149 | train_accuracy: 0.53423 | val_accuracy: 0.505   |  0:07:42s\n",
            "epoch 387| loss: 0.94116 | train_accuracy: 0.53312 | val_accuracy: 0.5042  |  0:07:43s\n",
            "epoch 388| loss: 0.94678 | train_accuracy: 0.53587 | val_accuracy: 0.511   |  0:07:45s\n",
            "epoch 389| loss: 0.9423  | train_accuracy: 0.53401 | val_accuracy: 0.51299 |  0:07:46s\n",
            "epoch 390| loss: 0.94395 | train_accuracy: 0.53579 | val_accuracy: 0.51899 |  0:07:47s\n",
            "epoch 391| loss: 0.94439 | train_accuracy: 0.53441 | val_accuracy: 0.52059 |  0:07:48s\n",
            "epoch 392| loss: 0.94711 | train_accuracy: 0.53507 | val_accuracy: 0.52299 |  0:07:49s\n",
            "epoch 393| loss: 0.9455  | train_accuracy: 0.53587 | val_accuracy: 0.53179 |  0:07:50s\n",
            "epoch 394| loss: 0.94294 | train_accuracy: 0.5333  | val_accuracy: 0.51819 |  0:07:52s\n",
            "epoch 395| loss: 0.9439  | train_accuracy: 0.53574 | val_accuracy: 0.52379 |  0:07:53s\n",
            "epoch 396| loss: 0.94259 | train_accuracy: 0.53659 | val_accuracy: 0.51939 |  0:07:54s\n",
            "epoch 397| loss: 0.9459  | train_accuracy: 0.53676 | val_accuracy: 0.51379 |  0:07:55s\n",
            "epoch 398| loss: 0.94277 | train_accuracy: 0.53321 | val_accuracy: 0.5062  |  0:07:56s\n",
            "epoch 399| loss: 0.94213 | train_accuracy: 0.53334 | val_accuracy: 0.507   |  0:07:58s\n",
            "epoch 400| loss: 0.9452  | train_accuracy: 0.5357  | val_accuracy: 0.5114  |  0:07:59s\n",
            "epoch 401| loss: 0.94151 | train_accuracy: 0.53721 | val_accuracy: 0.52499 |  0:08:00s\n",
            "epoch 402| loss: 0.94236 | train_accuracy: 0.5361  | val_accuracy: 0.51779 |  0:08:01s\n",
            "epoch 403| loss: 0.94478 | train_accuracy: 0.53436 | val_accuracy: 0.52739 |  0:08:02s\n",
            "epoch 404| loss: 0.94248 | train_accuracy: 0.53459 | val_accuracy: 0.52019 |  0:08:04s\n",
            "epoch 405| loss: 0.94572 | train_accuracy: 0.53392 | val_accuracy: 0.51459 |  0:08:05s\n",
            "epoch 406| loss: 0.94371 | train_accuracy: 0.53503 | val_accuracy: 0.5078  |  0:08:06s\n",
            "epoch 407| loss: 0.9421  | train_accuracy: 0.53196 | val_accuracy: 0.51939 |  0:08:07s\n",
            "epoch 408| loss: 0.94609 | train_accuracy: 0.53205 | val_accuracy: 0.53019 |  0:08:08s\n",
            "epoch 409| loss: 0.94389 | train_accuracy: 0.53432 | val_accuracy: 0.51739 |  0:08:09s\n",
            "epoch 410| loss: 0.9413  | train_accuracy: 0.53339 | val_accuracy: 0.53059 |  0:08:11s\n",
            "epoch 411| loss: 0.94368 | train_accuracy: 0.53379 | val_accuracy: 0.52619 |  0:08:12s\n",
            "epoch 412| loss: 0.94546 | train_accuracy: 0.53228 | val_accuracy: 0.52499 |  0:08:13s\n",
            "epoch 413| loss: 0.94236 | train_accuracy: 0.53236 | val_accuracy: 0.52739 |  0:08:14s\n",
            "epoch 414| loss: 0.94434 | train_accuracy: 0.5305  | val_accuracy: 0.53419 |  0:08:15s\n",
            "epoch 415| loss: 0.9447  | train_accuracy: 0.53512 | val_accuracy: 0.52939 |  0:08:17s\n",
            "epoch 416| loss: 0.94415 | train_accuracy: 0.53592 | val_accuracy: 0.52259 |  0:08:18s\n",
            "epoch 417| loss: 0.94379 | train_accuracy: 0.53587 | val_accuracy: 0.52379 |  0:08:19s\n",
            "epoch 418| loss: 0.93782 | train_accuracy: 0.53294 | val_accuracy: 0.51739 |  0:08:20s\n",
            "epoch 419| loss: 0.94006 | train_accuracy: 0.53516 | val_accuracy: 0.51659 |  0:08:21s\n",
            "epoch 420| loss: 0.93986 | train_accuracy: 0.53605 | val_accuracy: 0.52939 |  0:08:22s\n",
            "epoch 421| loss: 0.94141 | train_accuracy: 0.5365  | val_accuracy: 0.52579 |  0:08:24s\n",
            "epoch 422| loss: 0.94088 | train_accuracy: 0.53667 | val_accuracy: 0.51699 |  0:08:25s\n",
            "epoch 423| loss: 0.9361  | train_accuracy: 0.53716 | val_accuracy: 0.54018 |  0:08:26s\n",
            "epoch 424| loss: 0.94193 | train_accuracy: 0.54156 | val_accuracy: 0.52259 |  0:08:27s\n",
            "epoch 425| loss: 0.93653 | train_accuracy: 0.54098 | val_accuracy: 0.52499 |  0:08:28s\n",
            "epoch 426| loss: 0.93846 | train_accuracy: 0.54005 | val_accuracy: 0.52859 |  0:08:30s\n",
            "epoch 427| loss: 0.93421 | train_accuracy: 0.53734 | val_accuracy: 0.52739 |  0:08:31s\n",
            "epoch 428| loss: 0.93906 | train_accuracy: 0.54169 | val_accuracy: 0.53139 |  0:08:32s\n",
            "epoch 429| loss: 0.93969 | train_accuracy: 0.54014 | val_accuracy: 0.52579 |  0:08:33s\n",
            "epoch 430| loss: 0.93742 | train_accuracy: 0.53894 | val_accuracy: 0.52539 |  0:08:34s\n",
            "epoch 431| loss: 0.94065 | train_accuracy: 0.53787 | val_accuracy: 0.52099 |  0:08:36s\n",
            "epoch 432| loss: 0.94014 | train_accuracy: 0.54112 | val_accuracy: 0.52139 |  0:08:37s\n",
            "epoch 433| loss: 0.94241 | train_accuracy: 0.5401  | val_accuracy: 0.51579 |  0:08:38s\n",
            "epoch 434| loss: 0.94433 | train_accuracy: 0.54072 | val_accuracy: 0.5122  |  0:08:39s\n",
            "epoch 435| loss: 0.95034 | train_accuracy: 0.53596 | val_accuracy: 0.51339 |  0:08:40s\n",
            "epoch 436| loss: 0.95255 | train_accuracy: 0.53445 | val_accuracy: 0.51659 |  0:08:42s\n",
            "epoch 437| loss: 0.95391 | train_accuracy: 0.53272 | val_accuracy: 0.51419 |  0:08:43s\n",
            "epoch 438| loss: 0.95004 | train_accuracy: 0.53321 | val_accuracy: 0.52219 |  0:08:44s\n",
            "epoch 439| loss: 0.94953 | train_accuracy: 0.53379 | val_accuracy: 0.509   |  0:08:45s\n",
            "epoch 440| loss: 0.94642 | train_accuracy: 0.54125 | val_accuracy: 0.51379 |  0:08:46s\n",
            "epoch 441| loss: 0.94685 | train_accuracy: 0.53703 | val_accuracy: 0.509   |  0:08:47s\n",
            "epoch 442| loss: 0.95013 | train_accuracy: 0.53059 | val_accuracy: 0.5006  |  0:08:49s\n",
            "epoch 443| loss: 0.95136 | train_accuracy: 0.5293  | val_accuracy: 0.5042  |  0:08:50s\n",
            "epoch 444| loss: 0.95022 | train_accuracy: 0.53587 | val_accuracy: 0.5122  |  0:08:51s\n",
            "epoch 445| loss: 0.94517 | train_accuracy: 0.5377  | val_accuracy: 0.5094  |  0:08:52s\n",
            "epoch 446| loss: 0.94303 | train_accuracy: 0.5373  | val_accuracy: 0.5098  |  0:08:53s\n",
            "epoch 447| loss: 0.94187 | train_accuracy: 0.54098 | val_accuracy: 0.5034  |  0:08:55s\n",
            "epoch 448| loss: 0.94374 | train_accuracy: 0.54152 | val_accuracy: 0.5098  |  0:08:56s\n",
            "epoch 449| loss: 0.94148 | train_accuracy: 0.54094 | val_accuracy: 0.51979 |  0:08:57s\n",
            "epoch 450| loss: 0.93619 | train_accuracy: 0.54169 | val_accuracy: 0.52699 |  0:08:58s\n",
            "epoch 451| loss: 0.94034 | train_accuracy: 0.53876 | val_accuracy: 0.5102  |  0:08:59s\n",
            "epoch 452| loss: 0.93747 | train_accuracy: 0.54134 | val_accuracy: 0.52339 |  0:09:01s\n",
            "epoch 453| loss: 0.93548 | train_accuracy: 0.54392 | val_accuracy: 0.52459 |  0:09:02s\n",
            "epoch 454| loss: 0.93744 | train_accuracy: 0.5452  | val_accuracy: 0.52139 |  0:09:03s\n",
            "epoch 455| loss: 0.93608 | train_accuracy: 0.544   | val_accuracy: 0.52139 |  0:09:04s\n",
            "epoch 456| loss: 0.93524 | train_accuracy: 0.5452  | val_accuracy: 0.52259 |  0:09:05s\n",
            "epoch 457| loss: 0.93145 | train_accuracy: 0.5452  | val_accuracy: 0.52699 |  0:09:07s\n",
            "epoch 458| loss: 0.93505 | train_accuracy: 0.5448  | val_accuracy: 0.52259 |  0:09:08s\n",
            "epoch 459| loss: 0.93825 | train_accuracy: 0.54685 | val_accuracy: 0.52739 |  0:09:09s\n",
            "epoch 460| loss: 0.93838 | train_accuracy: 0.54458 | val_accuracy: 0.52979 |  0:09:10s\n",
            "epoch 461| loss: 0.93359 | train_accuracy: 0.54578 | val_accuracy: 0.53539 |  0:09:11s\n",
            "epoch 462| loss: 0.92905 | train_accuracy: 0.54383 | val_accuracy: 0.52779 |  0:09:12s\n",
            "epoch 463| loss: 0.937   | train_accuracy: 0.54725 | val_accuracy: 0.52059 |  0:09:14s\n",
            "epoch 464| loss: 0.93532 | train_accuracy: 0.54183 | val_accuracy: 0.53139 |  0:09:15s\n",
            "epoch 465| loss: 0.93982 | train_accuracy: 0.53792 | val_accuracy: 0.52939 |  0:09:16s\n",
            "epoch 466| loss: 0.93983 | train_accuracy: 0.53987 | val_accuracy: 0.52099 |  0:09:17s\n",
            "epoch 467| loss: 0.93999 | train_accuracy: 0.54103 | val_accuracy: 0.51819 |  0:09:18s\n",
            "epoch 468| loss: 0.9354  | train_accuracy: 0.53978 | val_accuracy: 0.51619 |  0:09:20s\n",
            "epoch 469| loss: 0.93924 | train_accuracy: 0.54209 | val_accuracy: 0.51779 |  0:09:21s\n",
            "epoch 470| loss: 0.93944 | train_accuracy: 0.53921 | val_accuracy: 0.52579 |  0:09:22s\n",
            "epoch 471| loss: 0.94587 | train_accuracy: 0.53152 | val_accuracy: 0.52059 |  0:09:23s\n",
            "epoch 472| loss: 0.94524 | train_accuracy: 0.53401 | val_accuracy: 0.53339 |  0:09:24s\n",
            "epoch 473| loss: 0.94845 | train_accuracy: 0.53818 | val_accuracy: 0.53499 |  0:09:26s\n",
            "epoch 474| loss: 0.9412  | train_accuracy: 0.53072 | val_accuracy: 0.51779 |  0:09:27s\n",
            "epoch 475| loss: 0.9402  | train_accuracy: 0.53743 | val_accuracy: 0.53219 |  0:09:28s\n",
            "epoch 476| loss: 0.93986 | train_accuracy: 0.54098 | val_accuracy: 0.53019 |  0:09:29s\n",
            "epoch 477| loss: 0.93922 | train_accuracy: 0.54085 | val_accuracy: 0.54018 |  0:09:30s\n",
            "epoch 478| loss: 0.93991 | train_accuracy: 0.53872 | val_accuracy: 0.53858 |  0:09:31s\n",
            "epoch 479| loss: 0.93813 | train_accuracy: 0.53832 | val_accuracy: 0.52939 |  0:09:33s\n",
            "epoch 480| loss: 0.93909 | train_accuracy: 0.53907 | val_accuracy: 0.53579 |  0:09:34s\n",
            "epoch 481| loss: 0.93412 | train_accuracy: 0.54209 | val_accuracy: 0.53219 |  0:09:35s\n",
            "epoch 482| loss: 0.93531 | train_accuracy: 0.54103 | val_accuracy: 0.52619 |  0:09:36s\n",
            "epoch 483| loss: 0.93539 | train_accuracy: 0.5452  | val_accuracy: 0.52539 |  0:09:37s\n",
            "epoch 484| loss: 0.93595 | train_accuracy: 0.544   | val_accuracy: 0.53739 |  0:09:39s\n",
            "epoch 485| loss: 0.9331  | train_accuracy: 0.54409 | val_accuracy: 0.53179 |  0:09:40s\n",
            "epoch 486| loss: 0.93278 | train_accuracy: 0.54454 | val_accuracy: 0.53339 |  0:09:41s\n",
            "epoch 487| loss: 0.93479 | train_accuracy: 0.54125 | val_accuracy: 0.52859 |  0:09:42s\n",
            "epoch 488| loss: 0.93188 | train_accuracy: 0.54227 | val_accuracy: 0.53858 |  0:09:43s\n",
            "epoch 489| loss: 0.93945 | train_accuracy: 0.54405 | val_accuracy: 0.52299 |  0:09:45s\n",
            "epoch 490| loss: 0.93754 | train_accuracy: 0.54161 | val_accuracy: 0.52379 |  0:09:46s\n",
            "epoch 491| loss: 0.9346  | train_accuracy: 0.54436 | val_accuracy: 0.52619 |  0:09:47s\n",
            "epoch 492| loss: 0.9357  | train_accuracy: 0.54303 | val_accuracy: 0.53139 |  0:09:48s\n",
            "epoch 493| loss: 0.93454 | train_accuracy: 0.5448  | val_accuracy: 0.52179 |  0:09:49s\n",
            "epoch 494| loss: 0.93687 | train_accuracy: 0.54263 | val_accuracy: 0.52899 |  0:09:50s\n",
            "epoch 495| loss: 0.93681 | train_accuracy: 0.54089 | val_accuracy: 0.51539 |  0:09:52s\n",
            "epoch 496| loss: 0.93423 | train_accuracy: 0.54107 | val_accuracy: 0.52979 |  0:09:53s\n",
            "epoch 497| loss: 0.93353 | train_accuracy: 0.54312 | val_accuracy: 0.53099 |  0:09:54s\n",
            "epoch 498| loss: 0.93011 | train_accuracy: 0.54396 | val_accuracy: 0.51819 |  0:09:55s\n",
            "epoch 499| loss: 0.93188 | train_accuracy: 0.54281 | val_accuracy: 0.53579 |  0:09:56s\n",
            "epoch 500| loss: 0.93366 | train_accuracy: 0.54685 | val_accuracy: 0.52459 |  0:09:58s\n",
            "epoch 501| loss: 0.93279 | train_accuracy: 0.54423 | val_accuracy: 0.52899 |  0:09:59s\n",
            "epoch 502| loss: 0.93311 | train_accuracy: 0.54143 | val_accuracy: 0.52539 |  0:10:00s\n",
            "epoch 503| loss: 0.93382 | train_accuracy: 0.54281 | val_accuracy: 0.53659 |  0:10:01s\n",
            "epoch 504| loss: 0.93143 | train_accuracy: 0.54525 | val_accuracy: 0.52899 |  0:10:02s\n",
            "epoch 505| loss: 0.9317  | train_accuracy: 0.54152 | val_accuracy: 0.52419 |  0:10:03s\n",
            "epoch 506| loss: 0.93227 | train_accuracy: 0.54223 | val_accuracy: 0.52699 |  0:10:05s\n",
            "epoch 507| loss: 0.93208 | train_accuracy: 0.54018 | val_accuracy: 0.52019 |  0:10:06s\n",
            "epoch 508| loss: 0.93064 | train_accuracy: 0.54254 | val_accuracy: 0.52259 |  0:10:07s\n",
            "epoch 509| loss: 0.93246 | train_accuracy: 0.54525 | val_accuracy: 0.51859 |  0:10:08s\n",
            "epoch 510| loss: 0.93222 | train_accuracy: 0.54489 | val_accuracy: 0.51979 |  0:10:09s\n",
            "epoch 511| loss: 0.92901 | train_accuracy: 0.54854 | val_accuracy: 0.52339 |  0:10:11s\n",
            "epoch 512| loss: 0.92969 | train_accuracy: 0.54658 | val_accuracy: 0.53539 |  0:10:12s\n",
            "epoch 513| loss: 0.92849 | train_accuracy: 0.54929 | val_accuracy: 0.53419 |  0:10:13s\n",
            "epoch 514| loss: 0.92673 | train_accuracy: 0.5476  | val_accuracy: 0.53699 |  0:10:14s\n",
            "epoch 515| loss: 0.92734 | train_accuracy: 0.54836 | val_accuracy: 0.52379 |  0:10:16s\n",
            "epoch 516| loss: 0.929   | train_accuracy: 0.55409 | val_accuracy: 0.53499 |  0:10:17s\n",
            "epoch 517| loss: 0.92435 | train_accuracy: 0.55178 | val_accuracy: 0.53299 |  0:10:18s\n",
            "epoch 518| loss: 0.92827 | train_accuracy: 0.54907 | val_accuracy: 0.53339 |  0:10:19s\n",
            "epoch 519| loss: 0.92559 | train_accuracy: 0.54809 | val_accuracy: 0.51899 |  0:10:20s\n",
            "epoch 520| loss: 0.92908 | train_accuracy: 0.55187 | val_accuracy: 0.53179 |  0:10:22s\n",
            "epoch 521| loss: 0.92777 | train_accuracy: 0.55213 | val_accuracy: 0.52419 |  0:10:23s\n",
            "epoch 522| loss: 0.92431 | train_accuracy: 0.54694 | val_accuracy: 0.52459 |  0:10:24s\n",
            "epoch 523| loss: 0.93227 | train_accuracy: 0.54809 | val_accuracy: 0.52699 |  0:10:25s\n",
            "epoch 524| loss: 0.93067 | train_accuracy: 0.5464  | val_accuracy: 0.53339 |  0:10:26s\n",
            "epoch 525| loss: 0.9309  | train_accuracy: 0.54698 | val_accuracy: 0.51939 |  0:10:27s\n",
            "epoch 526| loss: 0.9303  | train_accuracy: 0.54885 | val_accuracy: 0.52979 |  0:10:29s\n",
            "epoch 527| loss: 0.92917 | train_accuracy: 0.5484  | val_accuracy: 0.53139 |  0:10:30s\n",
            "epoch 528| loss: 0.92834 | train_accuracy: 0.54867 | val_accuracy: 0.509   |  0:10:31s\n",
            "epoch 529| loss: 0.93246 | train_accuracy: 0.5508  | val_accuracy: 0.52659 |  0:10:32s\n",
            "epoch 530| loss: 0.9314  | train_accuracy: 0.54876 | val_accuracy: 0.52779 |  0:10:33s\n",
            "epoch 531| loss: 0.93063 | train_accuracy: 0.55142 | val_accuracy: 0.52379 |  0:10:34s\n",
            "epoch 532| loss: 0.9334  | train_accuracy: 0.54685 | val_accuracy: 0.51939 |  0:10:36s\n",
            "epoch 533| loss: 0.9371  | train_accuracy: 0.54281 | val_accuracy: 0.5066  |  0:10:37s\n",
            "epoch 534| loss: 0.93407 | train_accuracy: 0.54583 | val_accuracy: 0.53179 |  0:10:38s\n",
            "epoch 535| loss: 0.93408 | train_accuracy: 0.54818 | val_accuracy: 0.53019 |  0:10:39s\n",
            "epoch 536| loss: 0.93435 | train_accuracy: 0.54698 | val_accuracy: 0.53579 |  0:10:40s\n",
            "epoch 537| loss: 0.93592 | train_accuracy: 0.546   | val_accuracy: 0.53419 |  0:10:41s\n",
            "epoch 538| loss: 0.93434 | train_accuracy: 0.54676 | val_accuracy: 0.52819 |  0:10:43s\n",
            "epoch 539| loss: 0.93268 | train_accuracy: 0.54427 | val_accuracy: 0.51699 |  0:10:44s\n",
            "epoch 540| loss: 0.93664 | train_accuracy: 0.54578 | val_accuracy: 0.53579 |  0:10:45s\n",
            "epoch 541| loss: 0.93238 | train_accuracy: 0.54454 | val_accuracy: 0.53818 |  0:10:46s\n",
            "epoch 542| loss: 0.93079 | train_accuracy: 0.54587 | val_accuracy: 0.52219 |  0:10:47s\n",
            "epoch 543| loss: 0.93535 | train_accuracy: 0.54743 | val_accuracy: 0.53459 |  0:10:49s\n",
            "epoch 544| loss: 0.93107 | train_accuracy: 0.54765 | val_accuracy: 0.53898 |  0:10:50s\n",
            "epoch 545| loss: 0.93174 | train_accuracy: 0.54618 | val_accuracy: 0.51619 |  0:10:51s\n",
            "epoch 546| loss: 0.92914 | train_accuracy: 0.54836 | val_accuracy: 0.53379 |  0:10:52s\n",
            "epoch 547| loss: 0.92747 | train_accuracy: 0.54529 | val_accuracy: 0.54658 |  0:10:53s\n",
            "epoch 548| loss: 0.93045 | train_accuracy: 0.54627 | val_accuracy: 0.51979 |  0:10:54s\n",
            "epoch 549| loss: 0.93313 | train_accuracy: 0.54698 | val_accuracy: 0.53739 |  0:10:56s\n",
            "epoch 550| loss: 0.93123 | train_accuracy: 0.5496  | val_accuracy: 0.54098 |  0:10:57s\n",
            "epoch 551| loss: 0.93198 | train_accuracy: 0.546   | val_accuracy: 0.52459 |  0:10:58s\n",
            "epoch 552| loss: 0.93471 | train_accuracy: 0.54578 | val_accuracy: 0.53259 |  0:10:59s\n",
            "epoch 553| loss: 0.9336  | train_accuracy: 0.54814 | val_accuracy: 0.52859 |  0:11:00s\n",
            "epoch 554| loss: 0.92575 | train_accuracy: 0.54911 | val_accuracy: 0.53259 |  0:11:01s\n",
            "epoch 555| loss: 0.93225 | train_accuracy: 0.54449 | val_accuracy: 0.52939 |  0:11:03s\n",
            "epoch 556| loss: 0.93256 | train_accuracy: 0.54796 | val_accuracy: 0.52939 |  0:11:04s\n",
            "epoch 557| loss: 0.92997 | train_accuracy: 0.54605 | val_accuracy: 0.53099 |  0:11:05s\n",
            "epoch 558| loss: 0.93092 | train_accuracy: 0.54951 | val_accuracy: 0.52979 |  0:11:06s\n",
            "epoch 559| loss: 0.93245 | train_accuracy: 0.54823 | val_accuracy: 0.53699 |  0:11:07s\n",
            "epoch 560| loss: 0.93351 | train_accuracy: 0.54458 | val_accuracy: 0.51459 |  0:11:09s\n",
            "epoch 561| loss: 0.93554 | train_accuracy: 0.54414 | val_accuracy: 0.51939 |  0:11:10s\n",
            "epoch 562| loss: 0.93355 | train_accuracy: 0.53836 | val_accuracy: 0.52219 |  0:11:11s\n",
            "epoch 563| loss: 0.9321  | train_accuracy: 0.54281 | val_accuracy: 0.52339 |  0:11:12s\n",
            "epoch 564| loss: 0.93344 | train_accuracy: 0.54196 | val_accuracy: 0.51739 |  0:11:13s\n",
            "epoch 565| loss: 0.93537 | train_accuracy: 0.5444  | val_accuracy: 0.51899 |  0:11:15s\n",
            "epoch 566| loss: 0.93339 | train_accuracy: 0.54716 | val_accuracy: 0.52379 |  0:11:16s\n",
            "epoch 567| loss: 0.92924 | train_accuracy: 0.54369 | val_accuracy: 0.52779 |  0:11:17s\n",
            "epoch 568| loss: 0.93081 | train_accuracy: 0.54289 | val_accuracy: 0.52179 |  0:11:18s\n",
            "epoch 569| loss: 0.93274 | train_accuracy: 0.5448  | val_accuracy: 0.52379 |  0:11:19s\n",
            "epoch 570| loss: 0.93053 | train_accuracy: 0.54081 | val_accuracy: 0.51779 |  0:11:20s\n",
            "epoch 571| loss: 0.9288  | train_accuracy: 0.54538 | val_accuracy: 0.52379 |  0:11:22s\n",
            "epoch 572| loss: 0.93061 | train_accuracy: 0.54623 | val_accuracy: 0.52419 |  0:11:23s\n",
            "epoch 573| loss: 0.92779 | train_accuracy: 0.54543 | val_accuracy: 0.51539 |  0:11:24s\n",
            "epoch 574| loss: 0.93054 | train_accuracy: 0.54543 | val_accuracy: 0.52459 |  0:11:25s\n",
            "epoch 575| loss: 0.92837 | train_accuracy: 0.5468  | val_accuracy: 0.52499 |  0:11:26s\n",
            "epoch 576| loss: 0.92856 | train_accuracy: 0.54578 | val_accuracy: 0.51659 |  0:11:28s\n",
            "epoch 577| loss: 0.92879 | train_accuracy: 0.54694 | val_accuracy: 0.52699 |  0:11:29s\n",
            "epoch 578| loss: 0.92893 | train_accuracy: 0.54796 | val_accuracy: 0.53179 |  0:11:30s\n",
            "epoch 579| loss: 0.92597 | train_accuracy: 0.54694 | val_accuracy: 0.51459 |  0:11:31s\n",
            "epoch 580| loss: 0.92467 | train_accuracy: 0.54698 | val_accuracy: 0.52419 |  0:11:32s\n",
            "epoch 581| loss: 0.92317 | train_accuracy: 0.54982 | val_accuracy: 0.52659 |  0:11:34s\n",
            "epoch 582| loss: 0.92449 | train_accuracy: 0.54836 | val_accuracy: 0.53419 |  0:11:35s\n",
            "epoch 583| loss: 0.92397 | train_accuracy: 0.55129 | val_accuracy: 0.53539 |  0:11:36s\n",
            "epoch 584| loss: 0.92662 | train_accuracy: 0.54951 | val_accuracy: 0.53699 |  0:11:37s\n",
            "epoch 585| loss: 0.92655 | train_accuracy: 0.54489 | val_accuracy: 0.52699 |  0:11:38s\n",
            "epoch 586| loss: 0.92337 | train_accuracy: 0.54743 | val_accuracy: 0.53379 |  0:11:40s\n",
            "epoch 587| loss: 0.92561 | train_accuracy: 0.54516 | val_accuracy: 0.52739 |  0:11:41s\n",
            "epoch 588| loss: 0.92423 | train_accuracy: 0.54907 | val_accuracy: 0.52739 |  0:11:42s\n",
            "epoch 589| loss: 0.92504 | train_accuracy: 0.54969 | val_accuracy: 0.53139 |  0:11:43s\n",
            "epoch 590| loss: 0.92106 | train_accuracy: 0.54938 | val_accuracy: 0.52779 |  0:11:44s\n",
            "epoch 591| loss: 0.92213 | train_accuracy: 0.54885 | val_accuracy: 0.53139 |  0:11:45s\n",
            "epoch 592| loss: 0.92105 | train_accuracy: 0.55196 | val_accuracy: 0.53219 |  0:11:47s\n",
            "epoch 593| loss: 0.92124 | train_accuracy: 0.55222 | val_accuracy: 0.52659 |  0:11:48s\n",
            "epoch 594| loss: 0.92256 | train_accuracy: 0.55293 | val_accuracy: 0.52939 |  0:11:49s\n",
            "epoch 595| loss: 0.91797 | train_accuracy: 0.55293 | val_accuracy: 0.51259 |  0:11:50s\n",
            "epoch 596| loss: 0.92025 | train_accuracy: 0.55271 | val_accuracy: 0.52419 |  0:11:51s\n",
            "epoch 597| loss: 0.92192 | train_accuracy: 0.54889 | val_accuracy: 0.52139 |  0:11:52s\n",
            "epoch 598| loss: 0.92531 | train_accuracy: 0.55209 | val_accuracy: 0.52339 |  0:11:54s\n",
            "epoch 599| loss: 0.92757 | train_accuracy: 0.54947 | val_accuracy: 0.52859 |  0:11:55s\n",
            "epoch 600| loss: 0.92335 | train_accuracy: 0.54854 | val_accuracy: 0.53059 |  0:11:56s\n",
            "epoch 601| loss: 0.92705 | train_accuracy: 0.54836 | val_accuracy: 0.52179 |  0:11:57s\n",
            "epoch 602| loss: 0.92766 | train_accuracy: 0.54245 | val_accuracy: 0.52299 |  0:11:58s\n",
            "epoch 603| loss: 0.93021 | train_accuracy: 0.54894 | val_accuracy: 0.52179 |  0:11:59s\n",
            "epoch 604| loss: 0.9301  | train_accuracy: 0.54787 | val_accuracy: 0.51859 |  0:12:01s\n",
            "epoch 605| loss: 0.92697 | train_accuracy: 0.55062 | val_accuracy: 0.52259 |  0:12:02s\n",
            "epoch 606| loss: 0.9294  | train_accuracy: 0.55005 | val_accuracy: 0.53379 |  0:12:03s\n",
            "epoch 607| loss: 0.92891 | train_accuracy: 0.54858 | val_accuracy: 0.52059 |  0:12:04s\n",
            "epoch 608| loss: 0.93018 | train_accuracy: 0.54929 | val_accuracy: 0.52979 |  0:12:05s\n",
            "epoch 609| loss: 0.93195 | train_accuracy: 0.54241 | val_accuracy: 0.52059 |  0:12:06s\n",
            "epoch 610| loss: 0.93194 | train_accuracy: 0.54689 | val_accuracy: 0.52459 |  0:12:08s\n",
            "epoch 611| loss: 0.93202 | train_accuracy: 0.54911 | val_accuracy: 0.52499 |  0:12:09s\n",
            "epoch 612| loss: 0.92959 | train_accuracy: 0.54889 | val_accuracy: 0.51899 |  0:12:10s\n",
            "epoch 613| loss: 0.92754 | train_accuracy: 0.54996 | val_accuracy: 0.52419 |  0:12:11s\n",
            "epoch 614| loss: 0.92774 | train_accuracy: 0.55049 | val_accuracy: 0.52819 |  0:12:12s\n",
            "epoch 615| loss: 0.92371 | train_accuracy: 0.55022 | val_accuracy: 0.53379 |  0:12:14s\n",
            "epoch 616| loss: 0.92249 | train_accuracy: 0.55134 | val_accuracy: 0.52979 |  0:12:15s\n",
            "epoch 617| loss: 0.91991 | train_accuracy: 0.55151 | val_accuracy: 0.52459 |  0:12:16s\n",
            "epoch 618| loss: 0.92369 | train_accuracy: 0.55058 | val_accuracy: 0.52779 |  0:12:17s\n",
            "epoch 619| loss: 0.92731 | train_accuracy: 0.54627 | val_accuracy: 0.51339 |  0:12:18s\n",
            "epoch 620| loss: 0.92577 | train_accuracy: 0.55076 | val_accuracy: 0.53419 |  0:12:19s\n",
            "epoch 621| loss: 0.92413 | train_accuracy: 0.55031 | val_accuracy: 0.52419 |  0:12:21s\n",
            "epoch 622| loss: 0.92429 | train_accuracy: 0.55213 | val_accuracy: 0.53459 |  0:12:22s\n",
            "epoch 623| loss: 0.92103 | train_accuracy: 0.55356 | val_accuracy: 0.53139 |  0:12:23s\n",
            "epoch 624| loss: 0.91822 | train_accuracy: 0.55271 | val_accuracy: 0.52499 |  0:12:24s\n",
            "epoch 625| loss: 0.92077 | train_accuracy: 0.55076 | val_accuracy: 0.53019 |  0:12:25s\n",
            "epoch 626| loss: 0.92375 | train_accuracy: 0.54751 | val_accuracy: 0.53459 |  0:12:26s\n",
            "epoch 627| loss: 0.92504 | train_accuracy: 0.54934 | val_accuracy: 0.53818 |  0:12:28s\n",
            "epoch 628| loss: 0.925   | train_accuracy: 0.54823 | val_accuracy: 0.53059 |  0:12:29s\n",
            "epoch 629| loss: 0.92441 | train_accuracy: 0.5492  | val_accuracy: 0.53139 |  0:12:30s\n",
            "epoch 630| loss: 0.92448 | train_accuracy: 0.5488  | val_accuracy: 0.51699 |  0:12:31s\n",
            "epoch 631| loss: 0.92251 | train_accuracy: 0.55369 | val_accuracy: 0.53139 |  0:12:32s\n",
            "epoch 632| loss: 0.92197 | train_accuracy: 0.55222 | val_accuracy: 0.53259 |  0:12:34s\n",
            "epoch 633| loss: 0.92126 | train_accuracy: 0.55311 | val_accuracy: 0.52939 |  0:12:35s\n",
            "epoch 634| loss: 0.92086 | train_accuracy: 0.55022 | val_accuracy: 0.53099 |  0:12:36s\n",
            "epoch 635| loss: 0.92032 | train_accuracy: 0.55036 | val_accuracy: 0.52019 |  0:12:37s\n",
            "epoch 636| loss: 0.92352 | train_accuracy: 0.5532  | val_accuracy: 0.53339 |  0:12:38s\n",
            "epoch 637| loss: 0.92184 | train_accuracy: 0.55098 | val_accuracy: 0.53019 |  0:12:39s\n",
            "epoch 638| loss: 0.92051 | train_accuracy: 0.55391 | val_accuracy: 0.53659 |  0:12:41s\n",
            "epoch 639| loss: 0.91943 | train_accuracy: 0.55587 | val_accuracy: 0.53619 |  0:12:42s\n",
            "epoch 640| loss: 0.91788 | train_accuracy: 0.55671 | val_accuracy: 0.52899 |  0:12:43s\n",
            "epoch 641| loss: 0.91408 | train_accuracy: 0.55689 | val_accuracy: 0.53219 |  0:12:44s\n",
            "epoch 642| loss: 0.91625 | train_accuracy: 0.55493 | val_accuracy: 0.53898 |  0:12:45s\n",
            "epoch 643| loss: 0.91383 | train_accuracy: 0.55538 | val_accuracy: 0.53379 |  0:12:47s\n",
            "epoch 644| loss: 0.91338 | train_accuracy: 0.55689 | val_accuracy: 0.54218 |  0:12:48s\n",
            "epoch 645| loss: 0.91853 | train_accuracy: 0.55787 | val_accuracy: 0.52779 |  0:12:49s\n",
            "epoch 646| loss: 0.93586 | train_accuracy: 0.55165 | val_accuracy: 0.52139 |  0:12:50s\n",
            "epoch 647| loss: 0.92517 | train_accuracy: 0.55031 | val_accuracy: 0.52699 |  0:12:51s\n",
            "epoch 648| loss: 0.92545 | train_accuracy: 0.55373 | val_accuracy: 0.51779 |  0:12:53s\n",
            "epoch 649| loss: 0.92178 | train_accuracy: 0.55449 | val_accuracy: 0.51979 |  0:12:54s\n",
            "epoch 650| loss: 0.92544 | train_accuracy: 0.55351 | val_accuracy: 0.52179 |  0:12:55s\n",
            "epoch 651| loss: 0.92163 | train_accuracy: 0.55418 | val_accuracy: 0.53059 |  0:12:56s\n",
            "epoch 652| loss: 0.92551 | train_accuracy: 0.55165 | val_accuracy: 0.51899 |  0:12:57s\n",
            "epoch 653| loss: 0.92486 | train_accuracy: 0.55049 | val_accuracy: 0.51779 |  0:12:59s\n",
            "epoch 654| loss: 0.92399 | train_accuracy: 0.55365 | val_accuracy: 0.52339 |  0:13:00s\n",
            "epoch 655| loss: 0.92374 | train_accuracy: 0.55342 | val_accuracy: 0.52739 |  0:13:01s\n",
            "epoch 656| loss: 0.92216 | train_accuracy: 0.55476 | val_accuracy: 0.51819 |  0:13:02s\n",
            "epoch 657| loss: 0.918   | train_accuracy: 0.55365 | val_accuracy: 0.52899 |  0:13:03s\n",
            "epoch 658| loss: 0.91829 | train_accuracy: 0.5512  | val_accuracy: 0.51979 |  0:13:04s\n",
            "epoch 659| loss: 0.92008 | train_accuracy: 0.55396 | val_accuracy: 0.53419 |  0:13:06s\n",
            "epoch 660| loss: 0.91768 | train_accuracy: 0.55604 | val_accuracy: 0.52099 |  0:13:07s\n",
            "epoch 661| loss: 0.92246 | train_accuracy: 0.55231 | val_accuracy: 0.53219 |  0:13:08s\n",
            "epoch 662| loss: 0.92157 | train_accuracy: 0.55413 | val_accuracy: 0.52539 |  0:13:09s\n",
            "epoch 663| loss: 0.91995 | train_accuracy: 0.55533 | val_accuracy: 0.52459 |  0:13:10s\n",
            "epoch 664| loss: 0.92106 | train_accuracy: 0.55293 | val_accuracy: 0.52059 |  0:13:11s\n",
            "epoch 665| loss: 0.91914 | train_accuracy: 0.55333 | val_accuracy: 0.53379 |  0:13:13s\n",
            "epoch 666| loss: 0.92549 | train_accuracy: 0.55307 | val_accuracy: 0.53459 |  0:13:14s\n",
            "epoch 667| loss: 0.92606 | train_accuracy: 0.54987 | val_accuracy: 0.53659 |  0:13:15s\n",
            "epoch 668| loss: 0.9216  | train_accuracy: 0.55    | val_accuracy: 0.52939 |  0:13:16s\n",
            "epoch 669| loss: 0.92611 | train_accuracy: 0.54911 | val_accuracy: 0.53099 |  0:13:17s\n",
            "epoch 670| loss: 0.9271  | train_accuracy: 0.55022 | val_accuracy: 0.53459 |  0:13:18s\n",
            "epoch 671| loss: 0.92523 | train_accuracy: 0.55431 | val_accuracy: 0.53299 |  0:13:20s\n",
            "epoch 672| loss: 0.92657 | train_accuracy: 0.55076 | val_accuracy: 0.54098 |  0:13:21s\n",
            "epoch 673| loss: 0.92335 | train_accuracy: 0.55271 | val_accuracy: 0.51859 |  0:13:22s\n",
            "epoch 674| loss: 0.92266 | train_accuracy: 0.55222 | val_accuracy: 0.53099 |  0:13:23s\n",
            "epoch 675| loss: 0.92039 | train_accuracy: 0.55507 | val_accuracy: 0.53699 |  0:13:24s\n",
            "epoch 676| loss: 0.92073 | train_accuracy: 0.55538 | val_accuracy: 0.54218 |  0:13:26s\n",
            "epoch 677| loss: 0.91608 | train_accuracy: 0.55431 | val_accuracy: 0.53179 |  0:13:27s\n",
            "epoch 678| loss: 0.91797 | train_accuracy: 0.55489 | val_accuracy: 0.53059 |  0:13:28s\n",
            "epoch 679| loss: 0.91903 | train_accuracy: 0.55556 | val_accuracy: 0.53219 |  0:13:29s\n",
            "epoch 680| loss: 0.91934 | train_accuracy: 0.55778 | val_accuracy: 0.53699 |  0:13:30s\n",
            "epoch 681| loss: 0.91644 | train_accuracy: 0.55707 | val_accuracy: 0.53339 |  0:13:31s\n",
            "epoch 682| loss: 0.91658 | train_accuracy: 0.5584  | val_accuracy: 0.53339 |  0:13:33s\n",
            "epoch 683| loss: 0.91965 | train_accuracy: 0.55729 | val_accuracy: 0.53978 |  0:13:34s\n",
            "epoch 684| loss: 0.92139 | train_accuracy: 0.55649 | val_accuracy: 0.53059 |  0:13:35s\n",
            "epoch 685| loss: 0.92031 | train_accuracy: 0.55467 | val_accuracy: 0.54138 |  0:13:36s\n",
            "epoch 686| loss: 0.91919 | train_accuracy: 0.55502 | val_accuracy: 0.53259 |  0:13:37s\n",
            "epoch 687| loss: 0.92131 | train_accuracy: 0.554   | val_accuracy: 0.52819 |  0:13:38s\n",
            "epoch 688| loss: 0.92079 | train_accuracy: 0.55418 | val_accuracy: 0.52379 |  0:13:40s\n",
            "epoch 689| loss: 0.91946 | train_accuracy: 0.55698 | val_accuracy: 0.52499 |  0:13:41s\n",
            "epoch 690| loss: 0.91738 | train_accuracy: 0.55453 | val_accuracy: 0.53059 |  0:13:42s\n",
            "epoch 691| loss: 0.91968 | train_accuracy: 0.55533 | val_accuracy: 0.52459 |  0:13:43s\n",
            "epoch 692| loss: 0.92549 | train_accuracy: 0.55276 | val_accuracy: 0.53579 |  0:13:44s\n",
            "epoch 693| loss: 0.92354 | train_accuracy: 0.54809 | val_accuracy: 0.53699 |  0:13:45s\n",
            "epoch 694| loss: 0.92378 | train_accuracy: 0.55613 | val_accuracy: 0.53259 |  0:13:47s\n",
            "epoch 695| loss: 0.92384 | train_accuracy: 0.54667 | val_accuracy: 0.53379 |  0:13:48s\n",
            "epoch 696| loss: 0.94047 | train_accuracy: 0.53299 | val_accuracy: 0.53539 |  0:13:49s\n",
            "epoch 697| loss: 0.94966 | train_accuracy: 0.53023 | val_accuracy: 0.52699 |  0:13:50s\n",
            "epoch 698| loss: 0.94084 | train_accuracy: 0.53019 | val_accuracy: 0.52419 |  0:13:51s\n",
            "epoch 699| loss: 0.93852 | train_accuracy: 0.53468 | val_accuracy: 0.53019 |  0:13:53s\n",
            "epoch 700| loss: 0.93969 | train_accuracy: 0.5385  | val_accuracy: 0.53059 |  0:13:54s\n",
            "epoch 701| loss: 0.93401 | train_accuracy: 0.53854 | val_accuracy: 0.53699 |  0:13:55s\n",
            "epoch 702| loss: 0.93176 | train_accuracy: 0.54045 | val_accuracy: 0.52699 |  0:13:56s\n",
            "epoch 703| loss: 0.93917 | train_accuracy: 0.54134 | val_accuracy: 0.53459 |  0:13:57s\n",
            "epoch 704| loss: 0.93969 | train_accuracy: 0.53765 | val_accuracy: 0.52379 |  0:13:59s\n",
            "epoch 705| loss: 0.94398 | train_accuracy: 0.53667 | val_accuracy: 0.52299 |  0:14:00s\n",
            "epoch 706| loss: 0.9425  | train_accuracy: 0.53605 | val_accuracy: 0.52419 |  0:14:01s\n",
            "epoch 707| loss: 0.94012 | train_accuracy: 0.53672 | val_accuracy: 0.52019 |  0:14:02s\n",
            "epoch 708| loss: 0.94005 | train_accuracy: 0.53898 | val_accuracy: 0.52059 |  0:14:03s\n",
            "epoch 709| loss: 0.93808 | train_accuracy: 0.53867 | val_accuracy: 0.52179 |  0:14:04s\n",
            "epoch 710| loss: 0.9385  | train_accuracy: 0.5385  | val_accuracy: 0.51859 |  0:14:06s\n",
            "epoch 711| loss: 0.94071 | train_accuracy: 0.53952 | val_accuracy: 0.53379 |  0:14:07s\n",
            "epoch 712| loss: 0.93779 | train_accuracy: 0.53699 | val_accuracy: 0.52819 |  0:14:08s\n",
            "epoch 713| loss: 0.936   | train_accuracy: 0.54121 | val_accuracy: 0.53299 |  0:14:09s\n",
            "epoch 714| loss: 0.93413 | train_accuracy: 0.54307 | val_accuracy: 0.52779 |  0:14:10s\n",
            "epoch 715| loss: 0.93863 | train_accuracy: 0.54476 | val_accuracy: 0.54018 |  0:14:12s\n",
            "epoch 716| loss: 0.93207 | train_accuracy: 0.54258 | val_accuracy: 0.53459 |  0:14:13s\n",
            "epoch 717| loss: 0.93422 | train_accuracy: 0.54498 | val_accuracy: 0.53739 |  0:14:14s\n",
            "epoch 718| loss: 0.92915 | train_accuracy: 0.54507 | val_accuracy: 0.53459 |  0:14:15s\n",
            "epoch 719| loss: 0.92953 | train_accuracy: 0.54778 | val_accuracy: 0.53299 |  0:14:16s\n",
            "epoch 720| loss: 0.92844 | train_accuracy: 0.54463 | val_accuracy: 0.53179 |  0:14:18s\n",
            "epoch 721| loss: 0.93173 | train_accuracy: 0.54556 | val_accuracy: 0.53179 |  0:14:19s\n",
            "epoch 722| loss: 0.93346 | train_accuracy: 0.54027 | val_accuracy: 0.52179 |  0:14:20s\n",
            "epoch 723| loss: 0.93776 | train_accuracy: 0.54147 | val_accuracy: 0.52099 |  0:14:21s\n",
            "epoch 724| loss: 0.93609 | train_accuracy: 0.54489 | val_accuracy: 0.52539 |  0:14:22s\n",
            "epoch 725| loss: 0.93669 | train_accuracy: 0.54298 | val_accuracy: 0.52619 |  0:14:24s\n",
            "epoch 726| loss: 0.93553 | train_accuracy: 0.54534 | val_accuracy: 0.53938 |  0:14:25s\n",
            "epoch 727| loss: 0.93379 | train_accuracy: 0.54654 | val_accuracy: 0.53139 |  0:14:26s\n",
            "epoch 728| loss: 0.93559 | train_accuracy: 0.5432  | val_accuracy: 0.52899 |  0:14:27s\n",
            "epoch 729| loss: 0.93585 | train_accuracy: 0.54418 | val_accuracy: 0.54018 |  0:14:28s\n",
            "epoch 730| loss: 0.93697 | train_accuracy: 0.54294 | val_accuracy: 0.53339 |  0:14:29s\n",
            "epoch 731| loss: 0.93341 | train_accuracy: 0.54507 | val_accuracy: 0.52259 |  0:14:31s\n",
            "epoch 732| loss: 0.9325  | train_accuracy: 0.54329 | val_accuracy: 0.52499 |  0:14:32s\n",
            "epoch 733| loss: 0.9331  | train_accuracy: 0.54352 | val_accuracy: 0.52739 |  0:14:33s\n",
            "epoch 734| loss: 0.93371 | train_accuracy: 0.54098 | val_accuracy: 0.53699 |  0:14:34s\n",
            "epoch 735| loss: 0.93549 | train_accuracy: 0.53983 | val_accuracy: 0.53019 |  0:14:35s\n",
            "epoch 736| loss: 0.93304 | train_accuracy: 0.54067 | val_accuracy: 0.52659 |  0:14:36s\n",
            "epoch 737| loss: 0.93599 | train_accuracy: 0.54245 | val_accuracy: 0.53059 |  0:14:38s\n",
            "epoch 738| loss: 0.93559 | train_accuracy: 0.54325 | val_accuracy: 0.52259 |  0:14:39s\n",
            "epoch 739| loss: 0.93685 | train_accuracy: 0.54312 | val_accuracy: 0.53259 |  0:14:40s\n",
            "epoch 740| loss: 0.94137 | train_accuracy: 0.53841 | val_accuracy: 0.52379 |  0:14:41s\n",
            "epoch 741| loss: 0.94217 | train_accuracy: 0.53996 | val_accuracy: 0.52259 |  0:14:42s\n",
            "epoch 742| loss: 0.94912 | train_accuracy: 0.53614 | val_accuracy: 0.51259 |  0:14:44s\n",
            "epoch 743| loss: 0.95359 | train_accuracy: 0.53316 | val_accuracy: 0.52099 |  0:14:45s\n",
            "epoch 744| loss: 0.94882 | train_accuracy: 0.52997 | val_accuracy: 0.51979 |  0:14:46s\n",
            "epoch 745| loss: 0.95363 | train_accuracy: 0.52548 | val_accuracy: 0.5106  |  0:14:47s\n",
            "epoch 746| loss: 0.95215 | train_accuracy: 0.52774 | val_accuracy: 0.51739 |  0:14:48s\n",
            "epoch 747| loss: 0.95023 | train_accuracy: 0.5325  | val_accuracy: 0.52179 |  0:14:49s\n",
            "epoch 748| loss: 0.94954 | train_accuracy: 0.53285 | val_accuracy: 0.51699 |  0:14:51s\n",
            "epoch 749| loss: 0.94786 | train_accuracy: 0.53605 | val_accuracy: 0.52099 |  0:14:52s\n",
            "epoch 750| loss: 0.94582 | train_accuracy: 0.53876 | val_accuracy: 0.52499 |  0:14:53s\n",
            "epoch 751| loss: 0.93879 | train_accuracy: 0.53703 | val_accuracy: 0.51419 |  0:14:54s\n",
            "epoch 752| loss: 0.93987 | train_accuracy: 0.53405 | val_accuracy: 0.51899 |  0:14:55s\n",
            "epoch 753| loss: 0.9401  | train_accuracy: 0.53685 | val_accuracy: 0.51339 |  0:14:57s\n",
            "epoch 754| loss: 0.94524 | train_accuracy: 0.5321  | val_accuracy: 0.51579 |  0:14:58s\n",
            "epoch 755| loss: 0.93799 | train_accuracy: 0.53583 | val_accuracy: 0.51499 |  0:14:59s\n",
            "epoch 756| loss: 0.94234 | train_accuracy: 0.53734 | val_accuracy: 0.51899 |  0:15:00s\n",
            "epoch 757| loss: 0.93864 | train_accuracy: 0.53574 | val_accuracy: 0.51739 |  0:15:01s\n",
            "epoch 758| loss: 0.93913 | train_accuracy: 0.53676 | val_accuracy: 0.51459 |  0:15:03s\n",
            "epoch 759| loss: 0.93774 | train_accuracy: 0.54165 | val_accuracy: 0.51379 |  0:15:04s\n",
            "epoch 760| loss: 0.93741 | train_accuracy: 0.53952 | val_accuracy: 0.52139 |  0:15:05s\n",
            "epoch 761| loss: 0.93287 | train_accuracy: 0.54298 | val_accuracy: 0.52539 |  0:15:06s\n",
            "epoch 762| loss: 0.93376 | train_accuracy: 0.54374 | val_accuracy: 0.52259 |  0:15:07s\n",
            "epoch 763| loss: 0.93309 | train_accuracy: 0.54307 | val_accuracy: 0.51419 |  0:15:08s\n",
            "epoch 764| loss: 0.93462 | train_accuracy: 0.53978 | val_accuracy: 0.52139 |  0:15:10s\n",
            "epoch 765| loss: 0.93554 | train_accuracy: 0.54187 | val_accuracy: 0.52739 |  0:15:11s\n",
            "epoch 766| loss: 0.93468 | train_accuracy: 0.54174 | val_accuracy: 0.52619 |  0:15:12s\n",
            "epoch 767| loss: 0.93517 | train_accuracy: 0.53965 | val_accuracy: 0.52219 |  0:15:13s\n",
            "epoch 768| loss: 0.93315 | train_accuracy: 0.53987 | val_accuracy: 0.52659 |  0:15:14s\n",
            "epoch 769| loss: 0.93243 | train_accuracy: 0.53943 | val_accuracy: 0.52659 |  0:15:16s\n",
            "epoch 770| loss: 0.92863 | train_accuracy: 0.53867 | val_accuracy: 0.52859 |  0:15:17s\n",
            "epoch 771| loss: 0.93737 | train_accuracy: 0.53663 | val_accuracy: 0.51779 |  0:15:18s\n",
            "epoch 772| loss: 0.93334 | train_accuracy: 0.54023 | val_accuracy: 0.52739 |  0:15:19s\n",
            "epoch 773| loss: 0.93526 | train_accuracy: 0.5385  | val_accuracy: 0.52939 |  0:15:20s\n",
            "epoch 774| loss: 0.93772 | train_accuracy: 0.54254 | val_accuracy: 0.53219 |  0:15:22s\n",
            "epoch 775| loss: 0.93281 | train_accuracy: 0.5385  | val_accuracy: 0.53219 |  0:15:23s\n",
            "epoch 776| loss: 0.93386 | train_accuracy: 0.54294 | val_accuracy: 0.54498 |  0:15:24s\n",
            "epoch 777| loss: 0.93673 | train_accuracy: 0.54032 | val_accuracy: 0.53579 |  0:15:25s\n",
            "epoch 778| loss: 0.9335  | train_accuracy: 0.5452  | val_accuracy: 0.53898 |  0:15:26s\n",
            "epoch 779| loss: 0.93044 | train_accuracy: 0.54307 | val_accuracy: 0.53499 |  0:15:27s\n",
            "epoch 780| loss: 0.93279 | train_accuracy: 0.54045 | val_accuracy: 0.53579 |  0:15:29s\n",
            "epoch 781| loss: 0.93236 | train_accuracy: 0.54103 | val_accuracy: 0.54378 |  0:15:30s\n",
            "epoch 782| loss: 0.93322 | train_accuracy: 0.54463 | val_accuracy: 0.54218 |  0:15:31s\n",
            "epoch 783| loss: 0.93138 | train_accuracy: 0.54276 | val_accuracy: 0.53858 |  0:15:32s\n",
            "epoch 784| loss: 0.93382 | train_accuracy: 0.54552 | val_accuracy: 0.53858 |  0:15:33s\n",
            "epoch 785| loss: 0.93207 | train_accuracy: 0.54263 | val_accuracy: 0.52659 |  0:15:35s\n",
            "epoch 786| loss: 0.93099 | train_accuracy: 0.54609 | val_accuracy: 0.54018 |  0:15:36s\n",
            "epoch 787| loss: 0.93239 | train_accuracy: 0.54272 | val_accuracy: 0.52899 |  0:15:37s\n",
            "epoch 788| loss: 0.9296  | train_accuracy: 0.54423 | val_accuracy: 0.53619 |  0:15:38s\n",
            "epoch 789| loss: 0.92927 | train_accuracy: 0.54218 | val_accuracy: 0.53019 |  0:15:39s\n",
            "epoch 790| loss: 0.93066 | train_accuracy: 0.54449 | val_accuracy: 0.52019 |  0:15:41s\n",
            "epoch 791| loss: 0.9325  | train_accuracy: 0.54445 | val_accuracy: 0.53339 |  0:15:42s\n",
            "epoch 792| loss: 0.93027 | train_accuracy: 0.54289 | val_accuracy: 0.5122  |  0:15:43s\n",
            "epoch 793| loss: 0.9308  | train_accuracy: 0.54716 | val_accuracy: 0.52499 |  0:15:44s\n",
            "epoch 794| loss: 0.93015 | train_accuracy: 0.54925 | val_accuracy: 0.52779 |  0:15:45s\n",
            "epoch 795| loss: 0.93171 | train_accuracy: 0.54769 | val_accuracy: 0.53179 |  0:15:46s\n",
            "epoch 796| loss: 0.92735 | train_accuracy: 0.54609 | val_accuracy: 0.52939 |  0:15:48s\n",
            "epoch 797| loss: 0.92773 | train_accuracy: 0.54756 | val_accuracy: 0.51419 |  0:15:49s\n",
            "epoch 798| loss: 0.92419 | train_accuracy: 0.54436 | val_accuracy: 0.52299 |  0:15:50s\n",
            "epoch 799| loss: 0.92529 | train_accuracy: 0.54654 | val_accuracy: 0.52699 |  0:15:51s\n",
            "epoch 800| loss: 0.92798 | train_accuracy: 0.54587 | val_accuracy: 0.51459 |  0:15:52s\n",
            "epoch 801| loss: 0.92948 | train_accuracy: 0.54867 | val_accuracy: 0.52619 |  0:15:53s\n",
            "epoch 802| loss: 0.92826 | train_accuracy: 0.54503 | val_accuracy: 0.52379 |  0:15:55s\n",
            "epoch 803| loss: 0.92625 | train_accuracy: 0.54916 | val_accuracy: 0.52299 |  0:15:56s\n",
            "epoch 804| loss: 0.92294 | train_accuracy: 0.54969 | val_accuracy: 0.52219 |  0:15:57s\n",
            "epoch 805| loss: 0.92638 | train_accuracy: 0.54974 | val_accuracy: 0.52459 |  0:15:58s\n",
            "epoch 806| loss: 0.92527 | train_accuracy: 0.54849 | val_accuracy: 0.52179 |  0:15:59s\n",
            "epoch 807| loss: 0.92689 | train_accuracy: 0.54778 | val_accuracy: 0.53419 |  0:16:00s\n",
            "epoch 808| loss: 0.92342 | train_accuracy: 0.55129 | val_accuracy: 0.53339 |  0:16:02s\n",
            "epoch 809| loss: 0.92385 | train_accuracy: 0.55089 | val_accuracy: 0.54418 |  0:16:03s\n",
            "epoch 810| loss: 0.92192 | train_accuracy: 0.55276 | val_accuracy: 0.54258 |  0:16:04s\n",
            "epoch 811| loss: 0.92475 | train_accuracy: 0.55062 | val_accuracy: 0.53778 |  0:16:05s\n",
            "epoch 812| loss: 0.92344 | train_accuracy: 0.55138 | val_accuracy: 0.53099 |  0:16:06s\n",
            "epoch 813| loss: 0.92203 | train_accuracy: 0.54951 | val_accuracy: 0.52219 |  0:16:08s\n",
            "epoch 814| loss: 0.9202  | train_accuracy: 0.54809 | val_accuracy: 0.52619 |  0:16:09s\n",
            "epoch 815| loss: 0.92392 | train_accuracy: 0.55014 | val_accuracy: 0.52819 |  0:16:10s\n",
            "epoch 816| loss: 0.92564 | train_accuracy: 0.54996 | val_accuracy: 0.53179 |  0:16:11s\n",
            "epoch 817| loss: 0.92214 | train_accuracy: 0.55333 | val_accuracy: 0.52779 |  0:16:12s\n",
            "epoch 818| loss: 0.92678 | train_accuracy: 0.5472  | val_accuracy: 0.51739 |  0:16:13s\n",
            "epoch 819| loss: 0.92715 | train_accuracy: 0.54578 | val_accuracy: 0.52819 |  0:16:15s\n",
            "epoch 820| loss: 0.92963 | train_accuracy: 0.54871 | val_accuracy: 0.52499 |  0:16:16s\n",
            "epoch 821| loss: 0.92774 | train_accuracy: 0.54703 | val_accuracy: 0.53379 |  0:16:17s\n",
            "epoch 822| loss: 0.9305  | train_accuracy: 0.54658 | val_accuracy: 0.52219 |  0:16:18s\n",
            "epoch 823| loss: 0.92777 | train_accuracy: 0.54871 | val_accuracy: 0.53499 |  0:16:19s\n",
            "epoch 824| loss: 0.92677 | train_accuracy: 0.54774 | val_accuracy: 0.53459 |  0:16:20s\n",
            "epoch 825| loss: 0.92704 | train_accuracy: 0.54867 | val_accuracy: 0.52699 |  0:16:22s\n",
            "epoch 826| loss: 0.92685 | train_accuracy: 0.55187 | val_accuracy: 0.53259 |  0:16:23s\n",
            "epoch 827| loss: 0.92554 | train_accuracy: 0.55107 | val_accuracy: 0.52899 |  0:16:24s\n",
            "epoch 828| loss: 0.92432 | train_accuracy: 0.55156 | val_accuracy: 0.53459 |  0:16:25s\n",
            "epoch 829| loss: 0.92401 | train_accuracy: 0.55391 | val_accuracy: 0.52939 |  0:16:26s\n",
            "epoch 830| loss: 0.91925 | train_accuracy: 0.55462 | val_accuracy: 0.53579 |  0:16:27s\n",
            "epoch 831| loss: 0.91888 | train_accuracy: 0.55325 | val_accuracy: 0.52379 |  0:16:29s\n",
            "epoch 832| loss: 0.91956 | train_accuracy: 0.55209 | val_accuracy: 0.53619 |  0:16:30s\n",
            "epoch 833| loss: 0.92017 | train_accuracy: 0.55378 | val_accuracy: 0.53259 |  0:16:31s\n",
            "epoch 834| loss: 0.92081 | train_accuracy: 0.55751 | val_accuracy: 0.53499 |  0:16:32s\n",
            "epoch 835| loss: 0.91942 | train_accuracy: 0.55467 | val_accuracy: 0.53818 |  0:16:33s\n",
            "epoch 836| loss: 0.92097 | train_accuracy: 0.55258 | val_accuracy: 0.54098 |  0:16:35s\n",
            "epoch 837| loss: 0.91734 | train_accuracy: 0.55524 | val_accuracy: 0.54418 |  0:16:36s\n",
            "epoch 838| loss: 0.92026 | train_accuracy: 0.55649 | val_accuracy: 0.53499 |  0:16:37s\n",
            "epoch 839| loss: 0.91745 | train_accuracy: 0.55582 | val_accuracy: 0.53818 |  0:16:38s\n",
            "epoch 840| loss: 0.92095 | train_accuracy: 0.55493 | val_accuracy: 0.53778 |  0:16:39s\n",
            "epoch 841| loss: 0.92169 | train_accuracy: 0.55724 | val_accuracy: 0.54178 |  0:16:41s\n",
            "epoch 842| loss: 0.91669 | train_accuracy: 0.55818 | val_accuracy: 0.53978 |  0:16:42s\n",
            "epoch 843| loss: 0.91271 | train_accuracy: 0.55556 | val_accuracy: 0.52419 |  0:16:43s\n",
            "epoch 844| loss: 0.91218 | train_accuracy: 0.56026 | val_accuracy: 0.54258 |  0:16:44s\n",
            "epoch 845| loss: 0.91089 | train_accuracy: 0.55773 | val_accuracy: 0.53339 |  0:16:45s\n",
            "epoch 846| loss: 0.91155 | train_accuracy: 0.55356 | val_accuracy: 0.53499 |  0:16:46s\n",
            "epoch 847| loss: 0.92107 | train_accuracy: 0.55667 | val_accuracy: 0.52779 |  0:16:48s\n",
            "epoch 848| loss: 0.91995 | train_accuracy: 0.55582 | val_accuracy: 0.52899 |  0:16:49s\n",
            "epoch 849| loss: 0.91997 | train_accuracy: 0.55373 | val_accuracy: 0.53219 |  0:16:50s\n",
            "epoch 850| loss: 0.91908 | train_accuracy: 0.55298 | val_accuracy: 0.52939 |  0:16:51s\n",
            "epoch 851| loss: 0.91825 | train_accuracy: 0.55213 | val_accuracy: 0.53299 |  0:16:52s\n",
            "epoch 852| loss: 0.91968 | train_accuracy: 0.55333 | val_accuracy: 0.52859 |  0:16:54s\n",
            "epoch 853| loss: 0.91351 | train_accuracy: 0.55453 | val_accuracy: 0.52619 |  0:16:55s\n",
            "epoch 854| loss: 0.91796 | train_accuracy: 0.55484 | val_accuracy: 0.52659 |  0:16:56s\n",
            "epoch 855| loss: 0.91404 | train_accuracy: 0.55751 | val_accuracy: 0.53139 |  0:16:57s\n",
            "epoch 856| loss: 0.916   | train_accuracy: 0.55382 | val_accuracy: 0.5102  |  0:16:58s\n",
            "epoch 857| loss: 0.91368 | train_accuracy: 0.55729 | val_accuracy: 0.53579 |  0:17:00s\n",
            "epoch 858| loss: 0.91746 | train_accuracy: 0.55094 | val_accuracy: 0.51979 |  0:17:01s\n",
            "epoch 859| loss: 0.91859 | train_accuracy: 0.55089 | val_accuracy: 0.51459 |  0:17:02s\n",
            "epoch 860| loss: 0.92335 | train_accuracy: 0.55138 | val_accuracy: 0.51659 |  0:17:03s\n",
            "epoch 861| loss: 0.92879 | train_accuracy: 0.54734 | val_accuracy: 0.51619 |  0:17:04s\n",
            "epoch 862| loss: 0.92519 | train_accuracy: 0.55293 | val_accuracy: 0.52819 |  0:17:05s\n",
            "epoch 863| loss: 0.92014 | train_accuracy: 0.54942 | val_accuracy: 0.51379 |  0:17:07s\n",
            "epoch 864| loss: 0.92337 | train_accuracy: 0.54978 | val_accuracy: 0.51419 |  0:17:08s\n",
            "epoch 865| loss: 0.91987 | train_accuracy: 0.54978 | val_accuracy: 0.52299 |  0:17:09s\n",
            "epoch 866| loss: 0.91931 | train_accuracy: 0.55391 | val_accuracy: 0.52459 |  0:17:10s\n",
            "epoch 867| loss: 0.91601 | train_accuracy: 0.55182 | val_accuracy: 0.51939 |  0:17:11s\n",
            "epoch 868| loss: 0.91186 | train_accuracy: 0.55622 | val_accuracy: 0.52739 |  0:17:12s\n",
            "epoch 869| loss: 0.91257 | train_accuracy: 0.55609 | val_accuracy: 0.52139 |  0:17:14s\n",
            "epoch 870| loss: 0.90971 | train_accuracy: 0.55831 | val_accuracy: 0.53339 |  0:17:15s\n",
            "epoch 871| loss: 0.91693 | train_accuracy: 0.55622 | val_accuracy: 0.52099 |  0:17:16s\n",
            "epoch 872| loss: 0.91418 | train_accuracy: 0.55302 | val_accuracy: 0.52339 |  0:17:17s\n",
            "epoch 873| loss: 0.91761 | train_accuracy: 0.55022 | val_accuracy: 0.5074  |  0:17:18s\n",
            "epoch 874| loss: 0.91723 | train_accuracy: 0.55556 | val_accuracy: 0.52939 |  0:17:20s\n",
            "epoch 875| loss: 0.92013 | train_accuracy: 0.55298 | val_accuracy: 0.5118  |  0:17:21s\n",
            "epoch 876| loss: 0.91982 | train_accuracy: 0.55125 | val_accuracy: 0.5098  |  0:17:22s\n",
            "epoch 877| loss: 0.91778 | train_accuracy: 0.55218 | val_accuracy: 0.52819 |  0:17:23s\n",
            "epoch 878| loss: 0.91986 | train_accuracy: 0.55662 | val_accuracy: 0.51299 |  0:17:24s\n",
            "epoch 879| loss: 0.91769 | train_accuracy: 0.55849 | val_accuracy: 0.53019 |  0:17:25s\n",
            "epoch 880| loss: 0.91604 | train_accuracy: 0.55498 | val_accuracy: 0.52459 |  0:17:27s\n",
            "epoch 881| loss: 0.91336 | train_accuracy: 0.55947 | val_accuracy: 0.53299 |  0:17:28s\n",
            "epoch 882| loss: 0.91427 | train_accuracy: 0.55569 | val_accuracy: 0.52859 |  0:17:29s\n",
            "epoch 883| loss: 0.9117  | train_accuracy: 0.55729 | val_accuracy: 0.52499 |  0:17:30s\n",
            "epoch 884| loss: 0.91383 | train_accuracy: 0.55662 | val_accuracy: 0.52539 |  0:17:31s\n",
            "epoch 885| loss: 0.91698 | train_accuracy: 0.5568  | val_accuracy: 0.53099 |  0:17:32s\n",
            "epoch 886| loss: 0.91257 | train_accuracy: 0.55489 | val_accuracy: 0.52499 |  0:17:34s\n",
            "epoch 887| loss: 0.91256 | train_accuracy: 0.55671 | val_accuracy: 0.51779 |  0:17:35s\n",
            "epoch 888| loss: 0.91247 | train_accuracy: 0.55542 | val_accuracy: 0.52219 |  0:17:36s\n",
            "epoch 889| loss: 0.91203 | train_accuracy: 0.55333 | val_accuracy: 0.52059 |  0:17:37s\n",
            "epoch 890| loss: 0.91233 | train_accuracy: 0.55458 | val_accuracy: 0.51859 |  0:17:38s\n",
            "epoch 891| loss: 0.90884 | train_accuracy: 0.55582 | val_accuracy: 0.51739 |  0:17:39s\n",
            "epoch 892| loss: 0.90953 | train_accuracy: 0.55604 | val_accuracy: 0.51459 |  0:17:41s\n",
            "epoch 893| loss: 0.91023 | train_accuracy: 0.55742 | val_accuracy: 0.52059 |  0:17:42s\n",
            "epoch 894| loss: 0.90674 | train_accuracy: 0.55742 | val_accuracy: 0.52339 |  0:17:43s\n",
            "epoch 895| loss: 0.91171 | train_accuracy: 0.55742 | val_accuracy: 0.5122  |  0:17:44s\n",
            "epoch 896| loss: 0.91747 | train_accuracy: 0.55382 | val_accuracy: 0.53139 |  0:17:45s\n",
            "epoch 897| loss: 0.91538 | train_accuracy: 0.55631 | val_accuracy: 0.52699 |  0:17:46s\n",
            "epoch 898| loss: 0.91811 | train_accuracy: 0.55502 | val_accuracy: 0.51979 |  0:17:48s\n",
            "epoch 899| loss: 0.91617 | train_accuracy: 0.54965 | val_accuracy: 0.52419 |  0:17:49s\n",
            "epoch 900| loss: 0.91502 | train_accuracy: 0.55009 | val_accuracy: 0.53019 |  0:17:50s\n",
            "epoch 901| loss: 0.91496 | train_accuracy: 0.55245 | val_accuracy: 0.52579 |  0:17:51s\n",
            "epoch 902| loss: 0.9127  | train_accuracy: 0.55436 | val_accuracy: 0.52779 |  0:17:52s\n",
            "epoch 903| loss: 0.91329 | train_accuracy: 0.55502 | val_accuracy: 0.53179 |  0:17:54s\n",
            "epoch 904| loss: 0.91701 | train_accuracy: 0.55413 | val_accuracy: 0.53059 |  0:17:55s\n",
            "epoch 905| loss: 0.9149  | train_accuracy: 0.55387 | val_accuracy: 0.53219 |  0:17:56s\n",
            "epoch 906| loss: 0.90879 | train_accuracy: 0.55382 | val_accuracy: 0.53299 |  0:17:57s\n",
            "epoch 907| loss: 0.90708 | train_accuracy: 0.5552  | val_accuracy: 0.53139 |  0:17:58s\n",
            "epoch 908| loss: 0.90662 | train_accuracy: 0.55507 | val_accuracy: 0.52019 |  0:18:00s\n",
            "epoch 909| loss: 0.91055 | train_accuracy: 0.55702 | val_accuracy: 0.52539 |  0:18:01s\n",
            "epoch 910| loss: 0.91314 | train_accuracy: 0.55484 | val_accuracy: 0.52979 |  0:18:02s\n",
            "epoch 911| loss: 0.91158 | train_accuracy: 0.5544  | val_accuracy: 0.52259 |  0:18:03s\n",
            "epoch 912| loss: 0.91096 | train_accuracy: 0.5512  | val_accuracy: 0.52179 |  0:18:04s\n",
            "epoch 913| loss: 0.91071 | train_accuracy: 0.55449 | val_accuracy: 0.53579 |  0:18:05s\n",
            "epoch 914| loss: 0.90638 | train_accuracy: 0.55302 | val_accuracy: 0.51699 |  0:18:07s\n",
            "epoch 915| loss: 0.9121  | train_accuracy: 0.5576  | val_accuracy: 0.52539 |  0:18:08s\n",
            "epoch 916| loss: 0.90696 | train_accuracy: 0.55453 | val_accuracy: 0.52939 |  0:18:09s\n",
            "epoch 917| loss: 0.90955 | train_accuracy: 0.55791 | val_accuracy: 0.53499 |  0:18:10s\n",
            "epoch 918| loss: 0.90298 | train_accuracy: 0.554   | val_accuracy: 0.51779 |  0:18:11s\n",
            "epoch 919| loss: 0.90209 | train_accuracy: 0.55693 | val_accuracy: 0.52699 |  0:18:13s\n",
            "epoch 920| loss: 0.90611 | train_accuracy: 0.55862 | val_accuracy: 0.52859 |  0:18:14s\n",
            "epoch 921| loss: 0.9063  | train_accuracy: 0.55827 | val_accuracy: 0.51419 |  0:18:15s\n",
            "epoch 922| loss: 0.90047 | train_accuracy: 0.55889 | val_accuracy: 0.52059 |  0:18:16s\n",
            "epoch 923| loss: 0.90412 | train_accuracy: 0.55733 | val_accuracy: 0.52939 |  0:18:17s\n",
            "epoch 924| loss: 0.90461 | train_accuracy: 0.55755 | val_accuracy: 0.52139 |  0:18:19s\n",
            "epoch 925| loss: 0.90556 | train_accuracy: 0.5604  | val_accuracy: 0.52579 |  0:18:20s\n",
            "epoch 926| loss: 0.90485 | train_accuracy: 0.56151 | val_accuracy: 0.53579 |  0:18:21s\n",
            "epoch 927| loss: 0.90507 | train_accuracy: 0.55902 | val_accuracy: 0.52939 |  0:18:22s\n",
            "epoch 928| loss: 0.90262 | train_accuracy: 0.56138 | val_accuracy: 0.52779 |  0:18:23s\n",
            "epoch 929| loss: 0.90452 | train_accuracy: 0.56066 | val_accuracy: 0.53019 |  0:18:25s\n",
            "epoch 930| loss: 0.90728 | train_accuracy: 0.5616  | val_accuracy: 0.52219 |  0:18:26s\n",
            "epoch 931| loss: 0.90121 | train_accuracy: 0.56093 | val_accuracy: 0.52699 |  0:18:27s\n",
            "epoch 932| loss: 0.89784 | train_accuracy: 0.56435 | val_accuracy: 0.52899 |  0:18:28s\n",
            "epoch 933| loss: 0.89773 | train_accuracy: 0.56768 | val_accuracy: 0.52459 |  0:18:29s\n",
            "epoch 934| loss: 0.89622 | train_accuracy: 0.5648  | val_accuracy: 0.51259 |  0:18:30s\n",
            "epoch 935| loss: 0.89538 | train_accuracy: 0.56493 | val_accuracy: 0.52899 |  0:18:32s\n",
            "epoch 936| loss: 0.88833 | train_accuracy: 0.56466 | val_accuracy: 0.51379 |  0:18:33s\n",
            "epoch 937| loss: 0.89511 | train_accuracy: 0.56733 | val_accuracy: 0.52619 |  0:18:34s\n",
            "epoch 938| loss: 0.89612 | train_accuracy: 0.56702 | val_accuracy: 0.52459 |  0:18:35s\n",
            "epoch 939| loss: 0.89213 | train_accuracy: 0.57062 | val_accuracy: 0.52659 |  0:18:36s\n",
            "epoch 940| loss: 0.89287 | train_accuracy: 0.56973 | val_accuracy: 0.5118  |  0:18:37s\n",
            "epoch 941| loss: 0.89392 | train_accuracy: 0.56951 | val_accuracy: 0.51459 |  0:18:39s\n",
            "epoch 942| loss: 0.88894 | train_accuracy: 0.56853 | val_accuracy: 0.51579 |  0:18:40s\n",
            "epoch 943| loss: 0.89364 | train_accuracy: 0.57204 | val_accuracy: 0.52379 |  0:18:41s\n",
            "epoch 944| loss: 0.88724 | train_accuracy: 0.56871 | val_accuracy: 0.5094  |  0:18:42s\n",
            "epoch 945| loss: 0.8875  | train_accuracy: 0.57226 | val_accuracy: 0.52059 |  0:18:43s\n",
            "epoch 946| loss: 0.8878  | train_accuracy: 0.57142 | val_accuracy: 0.51619 |  0:18:44s\n",
            "epoch 947| loss: 0.89085 | train_accuracy: 0.56844 | val_accuracy: 0.51939 |  0:18:46s\n",
            "epoch 948| loss: 0.88935 | train_accuracy: 0.57168 | val_accuracy: 0.51699 |  0:18:47s\n",
            "epoch 949| loss: 0.88953 | train_accuracy: 0.57093 | val_accuracy: 0.51699 |  0:18:48s\n",
            "epoch 950| loss: 0.89295 | train_accuracy: 0.56942 | val_accuracy: 0.52219 |  0:18:49s\n",
            "epoch 951| loss: 0.89089 | train_accuracy: 0.57217 | val_accuracy: 0.52339 |  0:18:50s\n",
            "epoch 952| loss: 0.8882  | train_accuracy: 0.5711  | val_accuracy: 0.52059 |  0:18:52s\n",
            "epoch 953| loss: 0.88824 | train_accuracy: 0.57568 | val_accuracy: 0.52819 |  0:18:53s\n",
            "epoch 954| loss: 0.8825  | train_accuracy: 0.57448 | val_accuracy: 0.52539 |  0:18:54s\n",
            "epoch 955| loss: 0.88043 | train_accuracy: 0.56977 | val_accuracy: 0.52899 |  0:18:55s\n",
            "epoch 956| loss: 0.88488 | train_accuracy: 0.57244 | val_accuracy: 0.51419 |  0:18:56s\n",
            "epoch 957| loss: 0.87893 | train_accuracy: 0.5743  | val_accuracy: 0.52579 |  0:18:57s\n",
            "epoch 958| loss: 0.88253 | train_accuracy: 0.57466 | val_accuracy: 0.52819 |  0:18:59s\n",
            "epoch 959| loss: 0.87939 | train_accuracy: 0.56991 | val_accuracy: 0.53179 |  0:19:00s\n",
            "epoch 960| loss: 0.88606 | train_accuracy: 0.57302 | val_accuracy: 0.52139 |  0:19:01s\n",
            "epoch 961| loss: 0.88197 | train_accuracy: 0.57772 | val_accuracy: 0.52819 |  0:19:02s\n",
            "epoch 962| loss: 0.8809  | train_accuracy: 0.5783  | val_accuracy: 0.52699 |  0:19:03s\n",
            "epoch 963| loss: 0.8717  | train_accuracy: 0.5803  | val_accuracy: 0.53339 |  0:19:04s\n",
            "epoch 964| loss: 0.87438 | train_accuracy: 0.57835 | val_accuracy: 0.52019 |  0:19:06s\n",
            "epoch 965| loss: 0.87128 | train_accuracy: 0.58079 | val_accuracy: 0.52659 |  0:19:07s\n",
            "epoch 966| loss: 0.88078 | train_accuracy: 0.57706 | val_accuracy: 0.52299 |  0:19:08s\n",
            "epoch 967| loss: 0.88212 | train_accuracy: 0.5811  | val_accuracy: 0.52179 |  0:19:09s\n",
            "epoch 968| loss: 0.8782  | train_accuracy: 0.58057 | val_accuracy: 0.52979 |  0:19:10s\n",
            "epoch 969| loss: 0.87404 | train_accuracy: 0.57901 | val_accuracy: 0.52219 |  0:19:11s\n",
            "epoch 970| loss: 0.88059 | train_accuracy: 0.57173 | val_accuracy: 0.51939 |  0:19:13s\n",
            "epoch 971| loss: 0.88618 | train_accuracy: 0.57284 | val_accuracy: 0.52459 |  0:19:14s\n",
            "epoch 972| loss: 0.89238 | train_accuracy: 0.57035 | val_accuracy: 0.51819 |  0:19:15s\n",
            "epoch 973| loss: 0.88359 | train_accuracy: 0.57581 | val_accuracy: 0.52099 |  0:19:16s\n",
            "epoch 974| loss: 0.8817  | train_accuracy: 0.57541 | val_accuracy: 0.52139 |  0:19:17s\n",
            "epoch 975| loss: 0.87768 | train_accuracy: 0.58239 | val_accuracy: 0.53059 |  0:19:19s\n",
            "epoch 976| loss: 0.8721  | train_accuracy: 0.58159 | val_accuracy: 0.52859 |  0:19:20s\n",
            "epoch 977| loss: 0.87569 | train_accuracy: 0.57795 | val_accuracy: 0.52379 |  0:19:21s\n",
            "epoch 978| loss: 0.87655 | train_accuracy: 0.57852 | val_accuracy: 0.52419 |  0:19:22s\n",
            "epoch 979| loss: 0.87402 | train_accuracy: 0.58217 | val_accuracy: 0.53059 |  0:19:23s\n",
            "epoch 980| loss: 0.87657 | train_accuracy: 0.58083 | val_accuracy: 0.52259 |  0:19:24s\n",
            "epoch 981| loss: 0.8776  | train_accuracy: 0.58119 | val_accuracy: 0.52619 |  0:19:26s\n",
            "epoch 982| loss: 0.87024 | train_accuracy: 0.58092 | val_accuracy: 0.52539 |  0:19:27s\n",
            "epoch 983| loss: 0.86878 | train_accuracy: 0.5799  | val_accuracy: 0.53059 |  0:19:28s\n",
            "epoch 984| loss: 0.87096 | train_accuracy: 0.57923 | val_accuracy: 0.52659 |  0:19:29s\n",
            "epoch 985| loss: 0.86669 | train_accuracy: 0.57937 | val_accuracy: 0.51419 |  0:19:31s\n",
            "epoch 986| loss: 0.86965 | train_accuracy: 0.57848 | val_accuracy: 0.51899 |  0:19:32s\n",
            "epoch 987| loss: 0.87771 | train_accuracy: 0.5719  | val_accuracy: 0.51819 |  0:19:33s\n",
            "epoch 988| loss: 0.87726 | train_accuracy: 0.58243 | val_accuracy: 0.52179 |  0:19:34s\n",
            "epoch 989| loss: 0.87224 | train_accuracy: 0.58123 | val_accuracy: 0.53299 |  0:19:35s\n",
            "epoch 990| loss: 0.87501 | train_accuracy: 0.58346 | val_accuracy: 0.52819 |  0:19:37s\n",
            "epoch 991| loss: 0.86949 | train_accuracy: 0.58283 | val_accuracy: 0.53499 |  0:19:38s\n",
            "epoch 992| loss: 0.87443 | train_accuracy: 0.58199 | val_accuracy: 0.52379 |  0:19:39s\n",
            "epoch 993| loss: 0.87375 | train_accuracy: 0.57821 | val_accuracy: 0.52379 |  0:19:40s\n",
            "epoch 994| loss: 0.86855 | train_accuracy: 0.58181 | val_accuracy: 0.53739 |  0:19:41s\n",
            "epoch 995| loss: 0.86855 | train_accuracy: 0.58194 | val_accuracy: 0.52379 |  0:19:43s\n",
            "epoch 996| loss: 0.86691 | train_accuracy: 0.58825 | val_accuracy: 0.53099 |  0:19:44s\n",
            "epoch 997| loss: 0.86474 | train_accuracy: 0.58634 | val_accuracy: 0.52979 |  0:19:45s\n",
            "epoch 998| loss: 0.86445 | train_accuracy: 0.58568 | val_accuracy: 0.52019 |  0:19:46s\n",
            "epoch 999| loss: 0.86524 | train_accuracy: 0.58501 | val_accuracy: 0.53099 |  0:19:47s\n",
            "epoch 1000| loss: 0.86642 | train_accuracy: 0.59043 | val_accuracy: 0.52979 |  0:19:48s\n",
            "epoch 1001| loss: 0.86381 | train_accuracy: 0.58648 | val_accuracy: 0.53179 |  0:19:50s\n",
            "epoch 1002| loss: 0.86344 | train_accuracy: 0.5927  | val_accuracy: 0.52499 |  0:19:51s\n",
            "epoch 1003| loss: 0.85745 | train_accuracy: 0.5935  | val_accuracy: 0.52699 |  0:19:52s\n",
            "epoch 1004| loss: 0.85586 | train_accuracy: 0.58377 | val_accuracy: 0.5106  |  0:19:53s\n",
            "epoch 1005| loss: 0.85787 | train_accuracy: 0.58994 | val_accuracy: 0.51499 |  0:19:54s\n",
            "epoch 1006| loss: 0.86189 | train_accuracy: 0.58892 | val_accuracy: 0.51939 |  0:19:56s\n",
            "epoch 1007| loss: 0.86075 | train_accuracy: 0.5923  | val_accuracy: 0.5118  |  0:19:57s\n",
            "epoch 1008| loss: 0.855   | train_accuracy: 0.59087 | val_accuracy: 0.52259 |  0:19:58s\n",
            "epoch 1009| loss: 0.8576  | train_accuracy: 0.59074 | val_accuracy: 0.51819 |  0:19:59s\n",
            "epoch 1010| loss: 0.85667 | train_accuracy: 0.59136 | val_accuracy: 0.52339 |  0:20:00s\n",
            "epoch 1011| loss: 0.86171 | train_accuracy: 0.58723 | val_accuracy: 0.51499 |  0:20:01s\n",
            "epoch 1012| loss: 0.85633 | train_accuracy: 0.59541 | val_accuracy: 0.52539 |  0:20:03s\n",
            "epoch 1013| loss: 0.84877 | train_accuracy: 0.5923  | val_accuracy: 0.53059 |  0:20:04s\n",
            "epoch 1014| loss: 0.84444 | train_accuracy: 0.59709 | val_accuracy: 0.51739 |  0:20:05s\n",
            "epoch 1015| loss: 0.84727 | train_accuracy: 0.59341 | val_accuracy: 0.511   |  0:20:06s\n",
            "epoch 1016| loss: 0.85096 | train_accuracy: 0.59243 | val_accuracy: 0.51419 |  0:20:07s\n",
            "epoch 1017| loss: 0.85969 | train_accuracy: 0.59261 | val_accuracy: 0.52379 |  0:20:09s\n",
            "epoch 1018| loss: 0.85362 | train_accuracy: 0.58963 | val_accuracy: 0.5082  |  0:20:10s\n",
            "epoch 1019| loss: 0.84805 | train_accuracy: 0.59314 | val_accuracy: 0.51779 |  0:20:11s\n",
            "epoch 1020| loss: 0.85538 | train_accuracy: 0.59101 | val_accuracy: 0.52139 |  0:20:12s\n",
            "epoch 1021| loss: 0.85582 | train_accuracy: 0.59145 | val_accuracy: 0.52579 |  0:20:13s\n",
            "epoch 1022| loss: 0.85795 | train_accuracy: 0.58723 | val_accuracy: 0.5122  |  0:20:15s\n",
            "epoch 1023| loss: 0.85325 | train_accuracy: 0.58888 | val_accuracy: 0.53059 |  0:20:16s\n",
            "epoch 1024| loss: 0.85689 | train_accuracy: 0.58888 | val_accuracy: 0.51739 |  0:20:17s\n",
            "epoch 1025| loss: 0.85335 | train_accuracy: 0.59025 | val_accuracy: 0.52659 |  0:20:18s\n",
            "epoch 1026| loss: 0.84803 | train_accuracy: 0.59225 | val_accuracy: 0.51739 |  0:20:19s\n",
            "epoch 1027| loss: 0.84588 | train_accuracy: 0.59256 | val_accuracy: 0.52139 |  0:20:20s\n",
            "epoch 1028| loss: 0.84809 | train_accuracy: 0.59381 | val_accuracy: 0.52099 |  0:20:22s\n",
            "epoch 1029| loss: 0.84547 | train_accuracy: 0.59301 | val_accuracy: 0.52219 |  0:20:23s\n",
            "epoch 1030| loss: 0.84977 | train_accuracy: 0.5915  | val_accuracy: 0.51579 |  0:20:24s\n",
            "epoch 1031| loss: 0.84788 | train_accuracy: 0.59101 | val_accuracy: 0.511   |  0:20:25s\n",
            "epoch 1032| loss: 0.8524  | train_accuracy: 0.59136 | val_accuracy: 0.52219 |  0:20:26s\n",
            "epoch 1033| loss: 0.85114 | train_accuracy: 0.59527 | val_accuracy: 0.52699 |  0:20:28s\n",
            "epoch 1034| loss: 0.84881 | train_accuracy: 0.59798 | val_accuracy: 0.51779 |  0:20:29s\n",
            "epoch 1035| loss: 0.85031 | train_accuracy: 0.59812 | val_accuracy: 0.51819 |  0:20:30s\n",
            "epoch 1036| loss: 0.84813 | train_accuracy: 0.5883  | val_accuracy: 0.51979 |  0:20:31s\n",
            "epoch 1037| loss: 0.85392 | train_accuracy: 0.58892 | val_accuracy: 0.52219 |  0:20:32s\n",
            "epoch 1038| loss: 0.85038 | train_accuracy: 0.58976 | val_accuracy: 0.51939 |  0:20:34s\n",
            "epoch 1039| loss: 0.84528 | train_accuracy: 0.59358 | val_accuracy: 0.52019 |  0:20:35s\n",
            "epoch 1040| loss: 0.84222 | train_accuracy: 0.59785 | val_accuracy: 0.51379 |  0:20:36s\n",
            "epoch 1041| loss: 0.84317 | train_accuracy: 0.5994  | val_accuracy: 0.52619 |  0:20:37s\n",
            "epoch 1042| loss: 0.84471 | train_accuracy: 0.59621 | val_accuracy: 0.51899 |  0:20:38s\n",
            "epoch 1043| loss: 0.83952 | train_accuracy: 0.59669 | val_accuracy: 0.52299 |  0:20:39s\n",
            "epoch 1044| loss: 0.84703 | train_accuracy: 0.59816 | val_accuracy: 0.52819 |  0:20:41s\n",
            "epoch 1045| loss: 0.84363 | train_accuracy: 0.59883 | val_accuracy: 0.51619 |  0:20:42s\n",
            "epoch 1046| loss: 0.84422 | train_accuracy: 0.59558 | val_accuracy: 0.51539 |  0:20:43s\n",
            "epoch 1047| loss: 0.84161 | train_accuracy: 0.59678 | val_accuracy: 0.51699 |  0:20:44s\n",
            "epoch 1048| loss: 0.843   | train_accuracy: 0.59709 | val_accuracy: 0.5074  |  0:20:45s\n",
            "epoch 1049| loss: 0.84629 | train_accuracy: 0.59403 | val_accuracy: 0.51379 |  0:20:47s\n",
            "epoch 1050| loss: 0.83823 | train_accuracy: 0.59896 | val_accuracy: 0.52019 |  0:20:48s\n",
            "epoch 1051| loss: 0.84566 | train_accuracy: 0.60167 | val_accuracy: 0.51459 |  0:20:49s\n",
            "epoch 1052| loss: 0.84397 | train_accuracy: 0.59527 | val_accuracy: 0.53059 |  0:20:50s\n",
            "epoch 1053| loss: 0.84276 | train_accuracy: 0.59798 | val_accuracy: 0.5118  |  0:20:51s\n",
            "epoch 1054| loss: 0.84278 | train_accuracy: 0.60034 | val_accuracy: 0.51739 |  0:20:53s\n",
            "epoch 1055| loss: 0.84339 | train_accuracy: 0.59256 | val_accuracy: 0.5114  |  0:20:54s\n",
            "epoch 1056| loss: 0.84421 | train_accuracy: 0.5935  | val_accuracy: 0.51779 |  0:20:55s\n",
            "epoch 1057| loss: 0.84766 | train_accuracy: 0.59616 | val_accuracy: 0.51899 |  0:20:56s\n",
            "epoch 1058| loss: 0.85728 | train_accuracy: 0.59323 | val_accuracy: 0.52139 |  0:20:57s\n",
            "epoch 1059| loss: 0.84933 | train_accuracy: 0.59745 | val_accuracy: 0.51739 |  0:20:58s\n",
            "epoch 1060| loss: 0.83943 | train_accuracy: 0.5943  | val_accuracy: 0.52059 |  0:21:00s\n",
            "epoch 1061| loss: 0.84526 | train_accuracy: 0.59772 | val_accuracy: 0.5078  |  0:21:01s\n",
            "epoch 1062| loss: 0.83843 | train_accuracy: 0.60145 | val_accuracy: 0.503   |  0:21:02s\n",
            "epoch 1063| loss: 0.8351  | train_accuracy: 0.60189 | val_accuracy: 0.5082  |  0:21:03s\n",
            "epoch 1064| loss: 0.83079 | train_accuracy: 0.601   | val_accuracy: 0.5082  |  0:21:04s\n",
            "epoch 1065| loss: 0.84255 | train_accuracy: 0.59323 | val_accuracy: 0.5118  |  0:21:06s\n",
            "epoch 1066| loss: 0.84096 | train_accuracy: 0.5998  | val_accuracy: 0.51339 |  0:21:07s\n",
            "epoch 1067| loss: 0.83843 | train_accuracy: 0.60145 | val_accuracy: 0.52579 |  0:21:08s\n",
            "epoch 1068| loss: 0.83907 | train_accuracy: 0.59874 | val_accuracy: 0.51819 |  0:21:09s\n",
            "epoch 1069| loss: 0.83883 | train_accuracy: 0.59736 | val_accuracy: 0.52659 |  0:21:10s\n",
            "epoch 1070| loss: 0.84324 | train_accuracy: 0.59878 | val_accuracy: 0.51859 |  0:21:12s\n",
            "epoch 1071| loss: 0.83176 | train_accuracy: 0.601   | val_accuracy: 0.52019 |  0:21:13s\n",
            "epoch 1072| loss: 0.83002 | train_accuracy: 0.5994  | val_accuracy: 0.52139 |  0:21:15s\n",
            "epoch 1073| loss: 0.83897 | train_accuracy: 0.60074 | val_accuracy: 0.52179 |  0:21:16s\n",
            "epoch 1074| loss: 0.83037 | train_accuracy: 0.60665 | val_accuracy: 0.52179 |  0:21:18s\n",
            "epoch 1075| loss: 0.83091 | train_accuracy: 0.60602 | val_accuracy: 0.51979 |  0:21:19s\n",
            "epoch 1076| loss: 0.82628 | train_accuracy: 0.60389 | val_accuracy: 0.51819 |  0:21:20s\n",
            "epoch 1077| loss: 0.82653 | train_accuracy: 0.60851 | val_accuracy: 0.51379 |  0:21:22s\n",
            "epoch 1078| loss: 0.82313 | train_accuracy: 0.60482 | val_accuracy: 0.5098  |  0:21:23s\n",
            "epoch 1079| loss: 0.82643 | train_accuracy: 0.60585 | val_accuracy: 0.52699 |  0:21:24s\n",
            "epoch 1080| loss: 0.82643 | train_accuracy: 0.60625 | val_accuracy: 0.52339 |  0:21:25s\n",
            "epoch 1081| loss: 0.82863 | train_accuracy: 0.60269 | val_accuracy: 0.51819 |  0:21:26s\n",
            "epoch 1082| loss: 0.83057 | train_accuracy: 0.60003 | val_accuracy: 0.52259 |  0:21:28s\n",
            "epoch 1083| loss: 0.82817 | train_accuracy: 0.60451 | val_accuracy: 0.51939 |  0:21:29s\n",
            "epoch 1084| loss: 0.82585 | train_accuracy: 0.60851 | val_accuracy: 0.52459 |  0:21:30s\n",
            "epoch 1085| loss: 0.82377 | train_accuracy: 0.60456 | val_accuracy: 0.52179 |  0:21:31s\n",
            "epoch 1086| loss: 0.83171 | train_accuracy: 0.60123 | val_accuracy: 0.52219 |  0:21:32s\n",
            "epoch 1087| loss: 0.83421 | train_accuracy: 0.60376 | val_accuracy: 0.52019 |  0:21:33s\n",
            "epoch 1088| loss: 0.83292 | train_accuracy: 0.59972 | val_accuracy: 0.52299 |  0:21:35s\n",
            "epoch 1089| loss: 0.8378  | train_accuracy: 0.60598 | val_accuracy: 0.53019 |  0:21:36s\n",
            "epoch 1090| loss: 0.83889 | train_accuracy: 0.60491 | val_accuracy: 0.52699 |  0:21:37s\n",
            "epoch 1091| loss: 0.83106 | train_accuracy: 0.60283 | val_accuracy: 0.5122  |  0:21:38s\n",
            "epoch 1092| loss: 0.83617 | train_accuracy: 0.60016 | val_accuracy: 0.54378 |  0:21:39s\n",
            "epoch 1093| loss: 0.84056 | train_accuracy: 0.60665 | val_accuracy: 0.52139 |  0:21:41s\n",
            "epoch 1094| loss: 0.837   | train_accuracy: 0.60403 | val_accuracy: 0.52379 |  0:21:42s\n",
            "epoch 1095| loss: 0.83657 | train_accuracy: 0.60269 | val_accuracy: 0.52139 |  0:21:43s\n",
            "epoch 1096| loss: 0.8369  | train_accuracy: 0.59945 | val_accuracy: 0.51499 |  0:21:44s\n",
            "epoch 1097| loss: 0.83278 | train_accuracy: 0.60789 | val_accuracy: 0.52299 |  0:21:45s\n",
            "epoch 1098| loss: 0.83603 | train_accuracy: 0.60416 | val_accuracy: 0.5106  |  0:21:46s\n",
            "epoch 1099| loss: 0.83256 | train_accuracy: 0.59914 | val_accuracy: 0.51819 |  0:21:48s\n",
            "epoch 1100| loss: 0.82467 | train_accuracy: 0.60016 | val_accuracy: 0.51339 |  0:21:49s\n",
            "epoch 1101| loss: 0.8318  | train_accuracy: 0.60034 | val_accuracy: 0.52739 |  0:21:50s\n",
            "epoch 1102| loss: 0.83235 | train_accuracy: 0.60118 | val_accuracy: 0.5058  |  0:21:51s\n",
            "epoch 1103| loss: 0.83275 | train_accuracy: 0.6078  | val_accuracy: 0.52179 |  0:21:52s\n",
            "epoch 1104| loss: 0.83104 | train_accuracy: 0.60065 | val_accuracy: 0.5082  |  0:21:53s\n",
            "epoch 1105| loss: 0.83146 | train_accuracy: 0.60136 | val_accuracy: 0.52419 |  0:21:55s\n",
            "epoch 1106| loss: 0.83492 | train_accuracy: 0.60536 | val_accuracy: 0.52459 |  0:21:56s\n",
            "epoch 1107| loss: 0.82989 | train_accuracy: 0.60602 | val_accuracy: 0.52179 |  0:21:57s\n",
            "epoch 1108| loss: 0.82371 | train_accuracy: 0.60842 | val_accuracy: 0.51579 |  0:21:58s\n",
            "epoch 1109| loss: 0.82535 | train_accuracy: 0.60736 | val_accuracy: 0.51539 |  0:21:59s\n",
            "epoch 1110| loss: 0.82226 | train_accuracy: 0.60745 | val_accuracy: 0.52419 |  0:22:00s\n",
            "epoch 1111| loss: 0.81837 | train_accuracy: 0.6094  | val_accuracy: 0.53139 |  0:22:02s\n",
            "epoch 1112| loss: 0.83128 | train_accuracy: 0.60198 | val_accuracy: 0.53739 |  0:22:03s\n",
            "epoch 1113| loss: 0.83798 | train_accuracy: 0.60291 | val_accuracy: 0.52499 |  0:22:04s\n",
            "epoch 1114| loss: 0.8376  | train_accuracy: 0.60469 | val_accuracy: 0.52419 |  0:22:05s\n",
            "epoch 1115| loss: 0.82823 | train_accuracy: 0.60167 | val_accuracy: 0.53259 |  0:22:06s\n",
            "epoch 1116| loss: 0.8291  | train_accuracy: 0.60678 | val_accuracy: 0.53219 |  0:22:08s\n",
            "epoch 1117| loss: 0.81923 | train_accuracy: 0.61033 | val_accuracy: 0.53219 |  0:22:09s\n",
            "epoch 1118| loss: 0.82044 | train_accuracy: 0.61216 | val_accuracy: 0.53459 |  0:22:10s\n",
            "epoch 1119| loss: 0.81887 | train_accuracy: 0.61042 | val_accuracy: 0.54058 |  0:22:11s\n",
            "epoch 1120| loss: 0.81741 | train_accuracy: 0.61362 | val_accuracy: 0.52699 |  0:22:12s\n",
            "epoch 1121| loss: 0.8147  | train_accuracy: 0.60629 | val_accuracy: 0.52019 |  0:22:13s\n",
            "epoch 1122| loss: 0.81835 | train_accuracy: 0.61207 | val_accuracy: 0.53139 |  0:22:15s\n",
            "epoch 1123| loss: 0.81014 | train_accuracy: 0.61655 | val_accuracy: 0.53059 |  0:22:16s\n",
            "epoch 1124| loss: 0.81048 | train_accuracy: 0.61989 | val_accuracy: 0.53619 |  0:22:17s\n",
            "epoch 1125| loss: 0.80768 | train_accuracy: 0.61798 | val_accuracy: 0.52779 |  0:22:18s\n",
            "epoch 1126| loss: 0.80691 | train_accuracy: 0.61744 | val_accuracy: 0.54098 |  0:22:19s\n",
            "epoch 1127| loss: 0.80804 | train_accuracy: 0.61624 | val_accuracy: 0.52259 |  0:22:21s\n",
            "epoch 1128| loss: 0.80854 | train_accuracy: 0.61598 | val_accuracy: 0.53379 |  0:22:22s\n",
            "epoch 1129| loss: 0.81197 | train_accuracy: 0.607   | val_accuracy: 0.52139 |  0:22:23s\n",
            "epoch 1130| loss: 0.80882 | train_accuracy: 0.61469 | val_accuracy: 0.52899 |  0:22:24s\n",
            "epoch 1131| loss: 0.80778 | train_accuracy: 0.61304 | val_accuracy: 0.52139 |  0:22:25s\n",
            "epoch 1132| loss: 0.81543 | train_accuracy: 0.60918 | val_accuracy: 0.52099 |  0:22:27s\n",
            "epoch 1133| loss: 0.81409 | train_accuracy: 0.61544 | val_accuracy: 0.52299 |  0:22:28s\n",
            "epoch 1134| loss: 0.80696 | train_accuracy: 0.61393 | val_accuracy: 0.53499 |  0:22:29s\n",
            "epoch 1135| loss: 0.81194 | train_accuracy: 0.61233 | val_accuracy: 0.52739 |  0:22:30s\n",
            "epoch 1136| loss: 0.81516 | train_accuracy: 0.61251 | val_accuracy: 0.52379 |  0:22:31s\n",
            "epoch 1137| loss: 0.80691 | train_accuracy: 0.61038 | val_accuracy: 0.54418 |  0:22:32s\n",
            "epoch 1138| loss: 0.81244 | train_accuracy: 0.60989 | val_accuracy: 0.52419 |  0:22:34s\n",
            "epoch 1139| loss: 0.80892 | train_accuracy: 0.61855 | val_accuracy: 0.53539 |  0:22:35s\n",
            "epoch 1140| loss: 0.80465 | train_accuracy: 0.619   | val_accuracy: 0.52659 |  0:22:36s\n",
            "epoch 1141| loss: 0.80711 | train_accuracy: 0.61833 | val_accuracy: 0.53339 |  0:22:37s\n",
            "epoch 1142| loss: 0.81893 | train_accuracy: 0.61295 | val_accuracy: 0.52779 |  0:22:38s\n",
            "epoch 1143| loss: 0.81768 | train_accuracy: 0.60882 | val_accuracy: 0.52899 |  0:22:40s\n",
            "epoch 1144| loss: 0.81308 | train_accuracy: 0.61362 | val_accuracy: 0.53699 |  0:22:41s\n",
            "epoch 1145| loss: 0.80843 | train_accuracy: 0.619   | val_accuracy: 0.53858 |  0:22:42s\n",
            "epoch 1146| loss: 0.8103  | train_accuracy: 0.61291 | val_accuracy: 0.53459 |  0:22:43s\n",
            "epoch 1147| loss: 0.81545 | train_accuracy: 0.6102  | val_accuracy: 0.52659 |  0:22:44s\n",
            "epoch 1148| loss: 0.80522 | train_accuracy: 0.61842 | val_accuracy: 0.53858 |  0:22:46s\n",
            "epoch 1149| loss: 0.80617 | train_accuracy: 0.6218  | val_accuracy: 0.52699 |  0:22:47s\n",
            "epoch 1150| loss: 0.79921 | train_accuracy: 0.62069 | val_accuracy: 0.52659 |  0:22:48s\n",
            "epoch 1151| loss: 0.80076 | train_accuracy: 0.61722 | val_accuracy: 0.53099 |  0:22:49s\n",
            "epoch 1152| loss: 0.8007  | train_accuracy: 0.62126 | val_accuracy: 0.52579 |  0:22:50s\n",
            "epoch 1153| loss: 0.79933 | train_accuracy: 0.62388 | val_accuracy: 0.52339 |  0:22:51s\n",
            "epoch 1154| loss: 0.79243 | train_accuracy: 0.62011 | val_accuracy: 0.51739 |  0:22:53s\n",
            "epoch 1155| loss: 0.8006  | train_accuracy: 0.62375 | val_accuracy: 0.52699 |  0:22:54s\n",
            "epoch 1156| loss: 0.80111 | train_accuracy: 0.623   | val_accuracy: 0.53339 |  0:22:55s\n",
            "epoch 1157| loss: 0.79295 | train_accuracy: 0.62135 | val_accuracy: 0.53099 |  0:22:56s\n",
            "epoch 1158| loss: 0.79652 | train_accuracy: 0.62433 | val_accuracy: 0.53179 |  0:22:57s\n",
            "epoch 1159| loss: 0.79787 | train_accuracy: 0.62335 | val_accuracy: 0.52739 |  0:22:58s\n",
            "epoch 1160| loss: 0.80031 | train_accuracy: 0.62144 | val_accuracy: 0.52459 |  0:23:00s\n",
            "epoch 1161| loss: 0.80382 | train_accuracy: 0.61673 | val_accuracy: 0.53179 |  0:23:01s\n",
            "epoch 1162| loss: 0.80096 | train_accuracy: 0.62659 | val_accuracy: 0.52539 |  0:23:03s\n",
            "epoch 1163| loss: 0.79883 | train_accuracy: 0.6206  | val_accuracy: 0.53059 |  0:23:04s\n",
            "epoch 1164| loss: 0.80145 | train_accuracy: 0.61646 | val_accuracy: 0.52339 |  0:23:06s\n",
            "epoch 1165| loss: 0.80327 | train_accuracy: 0.60696 | val_accuracy: 0.52779 |  0:23:07s\n",
            "epoch 1166| loss: 0.8089  | train_accuracy: 0.613   | val_accuracy: 0.52259 |  0:23:08s\n",
            "epoch 1167| loss: 0.79651 | train_accuracy: 0.61584 | val_accuracy: 0.53179 |  0:23:09s\n",
            "epoch 1168| loss: 0.79629 | train_accuracy: 0.61793 | val_accuracy: 0.53059 |  0:23:10s\n",
            "epoch 1169| loss: 0.79615 | train_accuracy: 0.62344 | val_accuracy: 0.53019 |  0:23:11s\n",
            "epoch 1170| loss: 0.79339 | train_accuracy: 0.61753 | val_accuracy: 0.53019 |  0:23:13s\n",
            "epoch 1171| loss: 0.80954 | train_accuracy: 0.61438 | val_accuracy: 0.53699 |  0:23:14s\n",
            "epoch 1172| loss: 0.84625 | train_accuracy: 0.59656 | val_accuracy: 0.51299 |  0:23:15s\n",
            "epoch 1173| loss: 0.87326 | train_accuracy: 0.59354 | val_accuracy: 0.52939 |  0:23:16s\n",
            "epoch 1174| loss: 0.86101 | train_accuracy: 0.59025 | val_accuracy: 0.51899 |  0:23:17s\n",
            "epoch 1175| loss: 0.85625 | train_accuracy: 0.59354 | val_accuracy: 0.52659 |  0:23:18s\n",
            "epoch 1176| loss: 0.85495 | train_accuracy: 0.59461 | val_accuracy: 0.52019 |  0:23:20s\n",
            "epoch 1177| loss: 0.84394 | train_accuracy: 0.59816 | val_accuracy: 0.51299 |  0:23:21s\n",
            "epoch 1178| loss: 0.84403 | train_accuracy: 0.59376 | val_accuracy: 0.52699 |  0:23:22s\n",
            "epoch 1179| loss: 0.84135 | train_accuracy: 0.59474 | val_accuracy: 0.51459 |  0:23:23s\n",
            "epoch 1180| loss: 0.84264 | train_accuracy: 0.59661 | val_accuracy: 0.52659 |  0:23:24s\n",
            "epoch 1181| loss: 0.83972 | train_accuracy: 0.59367 | val_accuracy: 0.52059 |  0:23:25s\n",
            "epoch 1182| loss: 0.83429 | train_accuracy: 0.60562 | val_accuracy: 0.53419 |  0:23:27s\n",
            "epoch 1183| loss: 0.82997 | train_accuracy: 0.60713 | val_accuracy: 0.52499 |  0:23:28s\n",
            "epoch 1184| loss: 0.82032 | train_accuracy: 0.61051 | val_accuracy: 0.53818 |  0:23:29s\n",
            "epoch 1185| loss: 0.8251  | train_accuracy: 0.61091 | val_accuracy: 0.53699 |  0:23:30s\n",
            "epoch 1186| loss: 0.82262 | train_accuracy: 0.6122  | val_accuracy: 0.53299 |  0:23:31s\n",
            "epoch 1187| loss: 0.8213  | train_accuracy: 0.60851 | val_accuracy: 0.52219 |  0:23:33s\n",
            "epoch 1188| loss: 0.82183 | train_accuracy: 0.60958 | val_accuracy: 0.53619 |  0:23:34s\n",
            "epoch 1189| loss: 0.81837 | train_accuracy: 0.60638 | val_accuracy: 0.53099 |  0:23:35s\n",
            "epoch 1190| loss: 0.8188  | train_accuracy: 0.61064 | val_accuracy: 0.52939 |  0:23:36s\n",
            "epoch 1191| loss: 0.81886 | train_accuracy: 0.61611 | val_accuracy: 0.51739 |  0:23:37s\n",
            "epoch 1192| loss: 0.82125 | train_accuracy: 0.61264 | val_accuracy: 0.52419 |  0:23:39s\n",
            "epoch 1193| loss: 0.81889 | train_accuracy: 0.61211 | val_accuracy: 0.51459 |  0:23:40s\n",
            "epoch 1194| loss: 0.8162  | train_accuracy: 0.61109 | val_accuracy: 0.5114  |  0:23:41s\n",
            "epoch 1195| loss: 0.81668 | train_accuracy: 0.61589 | val_accuracy: 0.51699 |  0:23:42s\n",
            "epoch 1196| loss: 0.8147  | train_accuracy: 0.60984 | val_accuracy: 0.52299 |  0:23:43s\n",
            "epoch 1197| loss: 0.82329 | train_accuracy: 0.60776 | val_accuracy: 0.5102  |  0:23:44s\n",
            "epoch 1198| loss: 0.81979 | train_accuracy: 0.611   | val_accuracy: 0.52419 |  0:23:46s\n",
            "epoch 1199| loss: 0.82033 | train_accuracy: 0.60927 | val_accuracy: 0.51699 |  0:23:47s\n",
            "epoch 1200| loss: 0.82351 | train_accuracy: 0.61011 | val_accuracy: 0.51779 |  0:23:48s\n",
            "epoch 1201| loss: 0.81672 | train_accuracy: 0.60345 | val_accuracy: 0.52139 |  0:23:49s\n",
            "epoch 1202| loss: 0.8159  | train_accuracy: 0.61091 | val_accuracy: 0.51939 |  0:23:50s\n",
            "epoch 1203| loss: 0.8137  | train_accuracy: 0.61371 | val_accuracy: 0.52539 |  0:23:52s\n",
            "epoch 1204| loss: 0.80802 | train_accuracy: 0.61407 | val_accuracy: 0.53299 |  0:23:53s\n",
            "epoch 1205| loss: 0.80574 | train_accuracy: 0.61895 | val_accuracy: 0.52339 |  0:23:54s\n",
            "epoch 1206| loss: 0.80107 | train_accuracy: 0.62024 | val_accuracy: 0.52379 |  0:23:55s\n",
            "epoch 1207| loss: 0.80108 | train_accuracy: 0.6198  | val_accuracy: 0.52899 |  0:23:56s\n",
            "epoch 1208| loss: 0.80201 | train_accuracy: 0.61966 | val_accuracy: 0.52379 |  0:23:58s\n",
            "epoch 1209| loss: 0.80328 | train_accuracy: 0.61424 | val_accuracy: 0.51779 |  0:23:59s\n",
            "epoch 1210| loss: 0.80853 | train_accuracy: 0.61846 | val_accuracy: 0.52379 |  0:24:00s\n",
            "epoch 1211| loss: 0.81232 | train_accuracy: 0.617   | val_accuracy: 0.51819 |  0:24:01s\n",
            "epoch 1212| loss: 0.8182  | train_accuracy: 0.61638 | val_accuracy: 0.51579 |  0:24:02s\n",
            "epoch 1213| loss: 0.81582 | train_accuracy: 0.61487 | val_accuracy: 0.51379 |  0:24:03s\n",
            "epoch 1214| loss: 0.81196 | train_accuracy: 0.61127 | val_accuracy: 0.5122  |  0:24:05s\n",
            "epoch 1215| loss: 0.81546 | train_accuracy: 0.61873 | val_accuracy: 0.52379 |  0:24:06s\n",
            "epoch 1216| loss: 0.81279 | train_accuracy: 0.61829 | val_accuracy: 0.52099 |  0:24:07s\n",
            "epoch 1217| loss: 0.81148 | train_accuracy: 0.61904 | val_accuracy: 0.5082  |  0:24:08s\n",
            "epoch 1218| loss: 0.80707 | train_accuracy: 0.6154  | val_accuracy: 0.5034  |  0:24:10s\n",
            "epoch 1219| loss: 0.81077 | train_accuracy: 0.61882 | val_accuracy: 0.51299 |  0:24:11s\n",
            "epoch 1220| loss: 0.81996 | train_accuracy: 0.60896 | val_accuracy: 0.51299 |  0:24:12s\n",
            "epoch 1221| loss: 0.8173  | train_accuracy: 0.61389 | val_accuracy: 0.51459 |  0:24:13s\n",
            "epoch 1222| loss: 0.81161 | train_accuracy: 0.61713 | val_accuracy: 0.5118  |  0:24:14s\n",
            "epoch 1223| loss: 0.81714 | train_accuracy: 0.61455 | val_accuracy: 0.51699 |  0:24:16s\n",
            "epoch 1224| loss: 0.81583 | train_accuracy: 0.61944 | val_accuracy: 0.51659 |  0:24:17s\n",
            "epoch 1225| loss: 0.81123 | train_accuracy: 0.6166  | val_accuracy: 0.511   |  0:24:18s\n",
            "epoch 1226| loss: 0.81285 | train_accuracy: 0.61211 | val_accuracy: 0.51299 |  0:24:19s\n",
            "epoch 1227| loss: 0.81534 | train_accuracy: 0.61962 | val_accuracy: 0.51899 |  0:24:20s\n",
            "epoch 1228| loss: 0.80742 | train_accuracy: 0.61184 | val_accuracy: 0.52139 |  0:24:21s\n",
            "epoch 1229| loss: 0.81041 | train_accuracy: 0.61531 | val_accuracy: 0.52539 |  0:24:22s\n",
            "epoch 1230| loss: 0.80289 | train_accuracy: 0.61655 | val_accuracy: 0.52459 |  0:24:24s\n",
            "epoch 1231| loss: 0.7997  | train_accuracy: 0.61651 | val_accuracy: 0.52019 |  0:24:25s\n",
            "epoch 1232| loss: 0.80096 | train_accuracy: 0.61615 | val_accuracy: 0.53019 |  0:24:26s\n",
            "epoch 1233| loss: 0.80053 | train_accuracy: 0.61349 | val_accuracy: 0.52099 |  0:24:27s\n",
            "epoch 1234| loss: 0.79806 | train_accuracy: 0.62015 | val_accuracy: 0.52139 |  0:24:28s\n",
            "epoch 1235| loss: 0.80527 | train_accuracy: 0.61073 | val_accuracy: 0.51259 |  0:24:30s\n",
            "epoch 1236| loss: 0.79772 | train_accuracy: 0.62015 | val_accuracy: 0.52539 |  0:24:31s\n",
            "epoch 1237| loss: 0.79907 | train_accuracy: 0.61504 | val_accuracy: 0.52299 |  0:24:32s\n",
            "epoch 1238| loss: 0.79865 | train_accuracy: 0.61216 | val_accuracy: 0.52099 |  0:24:33s\n",
            "epoch 1239| loss: 0.79445 | train_accuracy: 0.61789 | val_accuracy: 0.52179 |  0:24:34s\n",
            "epoch 1240| loss: 0.79225 | train_accuracy: 0.61629 | val_accuracy: 0.5094  |  0:24:35s\n",
            "epoch 1241| loss: 0.79762 | train_accuracy: 0.62166 | val_accuracy: 0.52179 |  0:24:37s\n",
            "epoch 1242| loss: 0.79614 | train_accuracy: 0.61673 | val_accuracy: 0.53019 |  0:24:38s\n",
            "epoch 1243| loss: 0.79554 | train_accuracy: 0.61904 | val_accuracy: 0.52459 |  0:24:39s\n",
            "epoch 1244| loss: 0.80309 | train_accuracy: 0.61327 | val_accuracy: 0.52499 |  0:24:40s\n",
            "epoch 1245| loss: 0.79503 | train_accuracy: 0.61371 | val_accuracy: 0.51739 |  0:24:41s\n",
            "epoch 1246| loss: 0.7994  | train_accuracy: 0.61722 | val_accuracy: 0.52979 |  0:24:42s\n",
            "epoch 1247| loss: 0.79194 | train_accuracy: 0.62046 | val_accuracy: 0.51939 |  0:24:44s\n",
            "epoch 1248| loss: 0.79443 | train_accuracy: 0.62335 | val_accuracy: 0.51899 |  0:24:45s\n",
            "epoch 1249| loss: 0.79396 | train_accuracy: 0.62224 | val_accuracy: 0.51579 |  0:24:46s\n",
            "epoch 1250| loss: 0.78502 | train_accuracy: 0.62157 | val_accuracy: 0.52379 |  0:24:47s\n",
            "epoch 1251| loss: 0.79196 | train_accuracy: 0.62522 | val_accuracy: 0.52819 |  0:24:48s\n",
            "epoch 1252| loss: 0.79186 | train_accuracy: 0.61949 | val_accuracy: 0.51939 |  0:24:50s\n",
            "epoch 1253| loss: 0.78971 | train_accuracy: 0.6222  | val_accuracy: 0.52699 |  0:24:51s\n",
            "epoch 1254| loss: 0.78856 | train_accuracy: 0.62055 | val_accuracy: 0.53379 |  0:24:52s\n",
            "epoch 1255| loss: 0.78946 | train_accuracy: 0.62233 | val_accuracy: 0.53379 |  0:24:53s\n",
            "epoch 1256| loss: 0.79172 | train_accuracy: 0.6174  | val_accuracy: 0.53778 |  0:24:54s\n",
            "epoch 1257| loss: 0.79847 | train_accuracy: 0.62197 | val_accuracy: 0.52819 |  0:24:55s\n",
            "epoch 1258| loss: 0.78425 | train_accuracy: 0.62202 | val_accuracy: 0.52219 |  0:24:57s\n",
            "epoch 1259| loss: 0.79013 | train_accuracy: 0.62451 | val_accuracy: 0.52099 |  0:24:58s\n",
            "epoch 1260| loss: 0.79188 | train_accuracy: 0.61402 | val_accuracy: 0.51739 |  0:24:59s\n",
            "epoch 1261| loss: 0.79758 | train_accuracy: 0.61966 | val_accuracy: 0.52179 |  0:25:00s\n",
            "epoch 1262| loss: 0.79654 | train_accuracy: 0.61855 | val_accuracy: 0.52139 |  0:25:01s\n",
            "epoch 1263| loss: 0.79333 | train_accuracy: 0.60953 | val_accuracy: 0.52859 |  0:25:03s\n",
            "epoch 1264| loss: 0.79891 | train_accuracy: 0.61984 | val_accuracy: 0.53579 |  0:25:04s\n",
            "epoch 1265| loss: 0.79229 | train_accuracy: 0.61753 | val_accuracy: 0.53699 |  0:25:05s\n",
            "epoch 1266| loss: 0.79249 | train_accuracy: 0.61953 | val_accuracy: 0.53179 |  0:25:06s\n",
            "epoch 1267| loss: 0.78746 | train_accuracy: 0.62921 | val_accuracy: 0.53419 |  0:25:07s\n",
            "epoch 1268| loss: 0.78916 | train_accuracy: 0.62802 | val_accuracy: 0.53099 |  0:25:09s\n",
            "epoch 1269| loss: 0.78208 | train_accuracy: 0.62411 | val_accuracy: 0.53019 |  0:25:10s\n",
            "epoch 1270| loss: 0.78494 | train_accuracy: 0.62588 | val_accuracy: 0.53259 |  0:25:11s\n",
            "epoch 1271| loss: 0.78303 | train_accuracy: 0.62193 | val_accuracy: 0.52939 |  0:25:12s\n",
            "epoch 1272| loss: 0.78525 | train_accuracy: 0.62939 | val_accuracy: 0.52779 |  0:25:13s\n",
            "epoch 1273| loss: 0.78015 | train_accuracy: 0.62939 | val_accuracy: 0.52499 |  0:25:15s\n",
            "epoch 1274| loss: 0.78571 | train_accuracy: 0.6269  | val_accuracy: 0.53619 |  0:25:16s\n",
            "epoch 1275| loss: 0.78447 | train_accuracy: 0.62664 | val_accuracy: 0.53659 |  0:25:17s\n",
            "epoch 1276| loss: 0.78139 | train_accuracy: 0.62815 | val_accuracy: 0.54098 |  0:25:18s\n",
            "epoch 1277| loss: 0.7866  | train_accuracy: 0.6293  | val_accuracy: 0.52859 |  0:25:19s\n",
            "epoch 1278| loss: 0.78742 | train_accuracy: 0.63095 | val_accuracy: 0.52499 |  0:25:20s\n",
            "epoch 1279| loss: 0.78754 | train_accuracy: 0.62904 | val_accuracy: 0.53898 |  0:25:22s\n",
            "epoch 1280| loss: 0.78171 | train_accuracy: 0.62797 | val_accuracy: 0.53219 |  0:25:23s\n",
            "epoch 1281| loss: 0.77723 | train_accuracy: 0.63073 | val_accuracy: 0.53938 |  0:25:24s\n",
            "epoch 1282| loss: 0.78154 | train_accuracy: 0.62895 | val_accuracy: 0.53299 |  0:25:25s\n",
            "epoch 1283| loss: 0.78088 | train_accuracy: 0.63432 | val_accuracy: 0.54578 |  0:25:26s\n",
            "epoch 1284| loss: 0.77418 | train_accuracy: 0.63437 | val_accuracy: 0.53299 |  0:25:28s\n",
            "epoch 1285| loss: 0.7752  | train_accuracy: 0.63144 | val_accuracy: 0.53579 |  0:25:29s\n",
            "epoch 1286| loss: 0.77824 | train_accuracy: 0.63277 | val_accuracy: 0.53499 |  0:25:30s\n",
            "epoch 1287| loss: 0.77331 | train_accuracy: 0.63281 | val_accuracy: 0.53938 |  0:25:31s\n",
            "epoch 1288| loss: 0.77033 | train_accuracy: 0.63135 | val_accuracy: 0.53099 |  0:25:32s\n",
            "epoch 1289| loss: 0.77345 | train_accuracy: 0.63255 | val_accuracy: 0.53539 |  0:25:34s\n",
            "epoch 1290| loss: 0.77142 | train_accuracy: 0.63646 | val_accuracy: 0.52539 |  0:25:35s\n",
            "epoch 1291| loss: 0.77292 | train_accuracy: 0.63828 | val_accuracy: 0.54498 |  0:25:36s\n",
            "epoch 1292| loss: 0.76526 | train_accuracy: 0.63286 | val_accuracy: 0.53299 |  0:25:37s\n",
            "epoch 1293| loss: 0.77486 | train_accuracy: 0.6317  | val_accuracy: 0.52499 |  0:25:38s\n",
            "epoch 1294| loss: 0.78084 | train_accuracy: 0.63055 | val_accuracy: 0.53419 |  0:25:39s\n",
            "epoch 1295| loss: 0.77417 | train_accuracy: 0.63206 | val_accuracy: 0.52139 |  0:25:41s\n",
            "epoch 1296| loss: 0.77433 | train_accuracy: 0.63037 | val_accuracy: 0.53219 |  0:25:42s\n",
            "epoch 1297| loss: 0.77408 | train_accuracy: 0.62753 | val_accuracy: 0.53139 |  0:25:43s\n",
            "epoch 1298| loss: 0.7728  | train_accuracy: 0.63179 | val_accuracy: 0.54098 |  0:25:44s\n",
            "epoch 1299| loss: 0.76878 | train_accuracy: 0.62961 | val_accuracy: 0.52899 |  0:25:45s\n",
            "epoch 1300| loss: 0.77349 | train_accuracy: 0.63041 | val_accuracy: 0.53219 |  0:25:46s\n",
            "epoch 1301| loss: 0.77769 | train_accuracy: 0.62868 | val_accuracy: 0.52699 |  0:25:48s\n",
            "epoch 1302| loss: 0.77136 | train_accuracy: 0.63264 | val_accuracy: 0.53699 |  0:25:49s\n",
            "epoch 1303| loss: 0.77617 | train_accuracy: 0.63566 | val_accuracy: 0.54018 |  0:25:50s\n",
            "epoch 1304| loss: 0.77704 | train_accuracy: 0.63113 | val_accuracy: 0.53499 |  0:25:51s\n",
            "epoch 1305| loss: 0.78679 | train_accuracy: 0.62859 | val_accuracy: 0.53099 |  0:25:52s\n",
            "epoch 1306| loss: 0.7786  | train_accuracy: 0.62855 | val_accuracy: 0.52819 |  0:25:53s\n",
            "epoch 1307| loss: 0.77936 | train_accuracy: 0.6305  | val_accuracy: 0.53419 |  0:25:55s\n",
            "epoch 1308| loss: 0.77903 | train_accuracy: 0.62926 | val_accuracy: 0.52779 |  0:25:56s\n",
            "epoch 1309| loss: 0.78022 | train_accuracy: 0.62988 | val_accuracy: 0.53778 |  0:25:57s\n",
            "epoch 1310| loss: 0.77491 | train_accuracy: 0.63561 | val_accuracy: 0.53219 |  0:25:58s\n",
            "epoch 1311| loss: 0.76347 | train_accuracy: 0.63828 | val_accuracy: 0.53539 |  0:25:59s\n",
            "epoch 1312| loss: 0.76413 | train_accuracy: 0.63232 | val_accuracy: 0.52659 |  0:26:00s\n",
            "epoch 1313| loss: 0.76817 | train_accuracy: 0.63477 | val_accuracy: 0.52619 |  0:26:02s\n",
            "epoch 1314| loss: 0.7697  | train_accuracy: 0.63108 | val_accuracy: 0.52819 |  0:26:03s\n",
            "epoch 1315| loss: 0.76772 | train_accuracy: 0.63526 | val_accuracy: 0.53339 |  0:26:04s\n",
            "epoch 1316| loss: 0.77343 | train_accuracy: 0.63153 | val_accuracy: 0.52819 |  0:26:05s\n",
            "epoch 1317| loss: 0.77375 | train_accuracy: 0.62779 | val_accuracy: 0.53579 |  0:26:06s\n",
            "epoch 1318| loss: 0.78456 | train_accuracy: 0.62659 | val_accuracy: 0.53299 |  0:26:07s\n",
            "epoch 1319| loss: 0.77907 | train_accuracy: 0.63299 | val_accuracy: 0.53739 |  0:26:09s\n",
            "epoch 1320| loss: 0.77806 | train_accuracy: 0.63299 | val_accuracy: 0.53379 |  0:26:10s\n",
            "epoch 1321| loss: 0.7678  | train_accuracy: 0.64139 | val_accuracy: 0.53419 |  0:26:11s\n",
            "epoch 1322| loss: 0.76484 | train_accuracy: 0.63961 | val_accuracy: 0.52579 |  0:26:12s\n",
            "epoch 1323| loss: 0.76659 | train_accuracy: 0.63628 | val_accuracy: 0.53459 |  0:26:13s\n",
            "epoch 1324| loss: 0.76433 | train_accuracy: 0.64006 | val_accuracy: 0.53219 |  0:26:15s\n",
            "epoch 1325| loss: 0.76067 | train_accuracy: 0.63566 | val_accuracy: 0.53699 |  0:26:16s\n",
            "epoch 1326| loss: 0.76685 | train_accuracy: 0.62766 | val_accuracy: 0.53299 |  0:26:17s\n",
            "epoch 1327| loss: 0.77426 | train_accuracy: 0.63477 | val_accuracy: 0.54098 |  0:26:18s\n",
            "epoch 1328| loss: 0.76254 | train_accuracy: 0.63766 | val_accuracy: 0.52819 |  0:26:19s\n",
            "epoch 1329| loss: 0.76595 | train_accuracy: 0.63846 | val_accuracy: 0.53179 |  0:26:21s\n",
            "epoch 1330| loss: 0.77086 | train_accuracy: 0.6365  | val_accuracy: 0.53219 |  0:26:22s\n",
            "epoch 1331| loss: 0.77251 | train_accuracy: 0.63646 | val_accuracy: 0.52179 |  0:26:23s\n",
            "epoch 1332| loss: 0.76388 | train_accuracy: 0.63757 | val_accuracy: 0.52979 |  0:26:24s\n",
            "epoch 1333| loss: 0.77111 | train_accuracy: 0.63193 | val_accuracy: 0.52299 |  0:26:25s\n",
            "epoch 1334| loss: 0.77326 | train_accuracy: 0.63757 | val_accuracy: 0.52339 |  0:26:26s\n",
            "epoch 1335| loss: 0.76535 | train_accuracy: 0.63712 | val_accuracy: 0.52819 |  0:26:28s\n",
            "epoch 1336| loss: 0.76397 | train_accuracy: 0.63886 | val_accuracy: 0.53099 |  0:26:29s\n",
            "epoch 1337| loss: 0.76616 | train_accuracy: 0.63854 | val_accuracy: 0.52659 |  0:26:30s\n",
            "epoch 1338| loss: 0.75833 | train_accuracy: 0.6409  | val_accuracy: 0.53499 |  0:26:31s\n",
            "epoch 1339| loss: 0.76219 | train_accuracy: 0.63997 | val_accuracy: 0.53339 |  0:26:32s\n",
            "epoch 1340| loss: 0.76231 | train_accuracy: 0.63801 | val_accuracy: 0.53858 |  0:26:34s\n",
            "epoch 1341| loss: 0.76445 | train_accuracy: 0.63677 | val_accuracy: 0.53299 |  0:26:35s\n",
            "epoch 1342| loss: 0.765   | train_accuracy: 0.64094 | val_accuracy: 0.53858 |  0:26:36s\n",
            "epoch 1343| loss: 0.7649  | train_accuracy: 0.64032 | val_accuracy: 0.53419 |  0:26:37s\n",
            "epoch 1344| loss: 0.76762 | train_accuracy: 0.63979 | val_accuracy: 0.53898 |  0:26:38s\n",
            "epoch 1345| loss: 0.77365 | train_accuracy: 0.62859 | val_accuracy: 0.52979 |  0:26:39s\n",
            "epoch 1346| loss: 0.78208 | train_accuracy: 0.63646 | val_accuracy: 0.53739 |  0:26:41s\n",
            "epoch 1347| loss: 0.77753 | train_accuracy: 0.6405  | val_accuracy: 0.53699 |  0:26:42s\n",
            "epoch 1348| loss: 0.75975 | train_accuracy: 0.64272 | val_accuracy: 0.52859 |  0:26:43s\n",
            "epoch 1349| loss: 0.7598  | train_accuracy: 0.64396 | val_accuracy: 0.53898 |  0:26:44s\n",
            "epoch 1350| loss: 0.75486 | train_accuracy: 0.64512 | val_accuracy: 0.53379 |  0:26:45s\n",
            "epoch 1351| loss: 0.75665 | train_accuracy: 0.64108 | val_accuracy: 0.53778 |  0:26:47s\n",
            "epoch 1352| loss: 0.7534  | train_accuracy: 0.64583 | val_accuracy: 0.53579 |  0:26:48s\n",
            "epoch 1353| loss: 0.75616 | train_accuracy: 0.64281 | val_accuracy: 0.53699 |  0:26:49s\n",
            "epoch 1354| loss: 0.76274 | train_accuracy: 0.6417  | val_accuracy: 0.53259 |  0:26:50s\n",
            "epoch 1355| loss: 0.7578  | train_accuracy: 0.64303 | val_accuracy: 0.52499 |  0:26:51s\n",
            "epoch 1356| loss: 0.75244 | train_accuracy: 0.64179 | val_accuracy: 0.52579 |  0:26:53s\n",
            "epoch 1357| loss: 0.75469 | train_accuracy: 0.64352 | val_accuracy: 0.53299 |  0:26:54s\n",
            "epoch 1358| loss: 0.74875 | train_accuracy: 0.64734 | val_accuracy: 0.54298 |  0:26:55s\n",
            "epoch 1359| loss: 0.74903 | train_accuracy: 0.64707 | val_accuracy: 0.53539 |  0:26:56s\n",
            "epoch 1360| loss: 0.75165 | train_accuracy: 0.64476 | val_accuracy: 0.53219 |  0:26:57s\n",
            "epoch 1361| loss: 0.75144 | train_accuracy: 0.63988 | val_accuracy: 0.51779 |  0:26:58s\n",
            "epoch 1362| loss: 0.7501  | train_accuracy: 0.63948 | val_accuracy: 0.54138 |  0:27:00s\n",
            "epoch 1363| loss: 0.74922 | train_accuracy: 0.64468 | val_accuracy: 0.53379 |  0:27:01s\n",
            "epoch 1364| loss: 0.74314 | train_accuracy: 0.64365 | val_accuracy: 0.53059 |  0:27:02s\n",
            "epoch 1365| loss: 0.74462 | train_accuracy: 0.64365 | val_accuracy: 0.52539 |  0:27:03s\n",
            "epoch 1366| loss: 0.7454  | train_accuracy: 0.64574 | val_accuracy: 0.53259 |  0:27:04s\n",
            "epoch 1367| loss: 0.74692 | train_accuracy: 0.64512 | val_accuracy: 0.54098 |  0:27:06s\n",
            "epoch 1368| loss: 0.7483  | train_accuracy: 0.64636 | val_accuracy: 0.53099 |  0:27:07s\n",
            "epoch 1369| loss: 0.74869 | train_accuracy: 0.64383 | val_accuracy: 0.53339 |  0:27:08s\n",
            "epoch 1370| loss: 0.74514 | train_accuracy: 0.64636 | val_accuracy: 0.53299 |  0:27:09s\n",
            "epoch 1371| loss: 0.74567 | train_accuracy: 0.64165 | val_accuracy: 0.52819 |  0:27:10s\n",
            "epoch 1372| loss: 0.75061 | train_accuracy: 0.64499 | val_accuracy: 0.53858 |  0:27:11s\n",
            "epoch 1373| loss: 0.7522  | train_accuracy: 0.6437  | val_accuracy: 0.52779 |  0:27:13s\n",
            "epoch 1374| loss: 0.7551  | train_accuracy: 0.64343 | val_accuracy: 0.53659 |  0:27:14s\n",
            "epoch 1375| loss: 0.74844 | train_accuracy: 0.6389  | val_accuracy: 0.53539 |  0:27:15s\n",
            "epoch 1376| loss: 0.7558  | train_accuracy: 0.64032 | val_accuracy: 0.53259 |  0:27:16s\n",
            "epoch 1377| loss: 0.74748 | train_accuracy: 0.64356 | val_accuracy: 0.53778 |  0:27:17s\n",
            "epoch 1378| loss: 0.7517  | train_accuracy: 0.64277 | val_accuracy: 0.52379 |  0:27:18s\n",
            "epoch 1379| loss: 0.75244 | train_accuracy: 0.64308 | val_accuracy: 0.53619 |  0:27:20s\n",
            "epoch 1380| loss: 0.74776 | train_accuracy: 0.6441  | val_accuracy: 0.53339 |  0:27:21s\n",
            "epoch 1381| loss: 0.74401 | train_accuracy: 0.63863 | val_accuracy: 0.52979 |  0:27:22s\n",
            "epoch 1382| loss: 0.74816 | train_accuracy: 0.6373  | val_accuracy: 0.53898 |  0:27:23s\n",
            "epoch 1383| loss: 0.75709 | train_accuracy: 0.64277 | val_accuracy: 0.54258 |  0:27:24s\n",
            "epoch 1384| loss: 0.74459 | train_accuracy: 0.64321 | val_accuracy: 0.54178 |  0:27:25s\n",
            "epoch 1385| loss: 0.74687 | train_accuracy: 0.64308 | val_accuracy: 0.54018 |  0:27:27s\n",
            "epoch 1386| loss: 0.74746 | train_accuracy: 0.64165 | val_accuracy: 0.53699 |  0:27:28s\n",
            "epoch 1387| loss: 0.74555 | train_accuracy: 0.64277 | val_accuracy: 0.54178 |  0:27:29s\n",
            "epoch 1388| loss: 0.74302 | train_accuracy: 0.64525 | val_accuracy: 0.52779 |  0:27:30s\n",
            "epoch 1389| loss: 0.74201 | train_accuracy: 0.64281 | val_accuracy: 0.52499 |  0:27:31s\n",
            "epoch 1390| loss: 0.74407 | train_accuracy: 0.6453  | val_accuracy: 0.53858 |  0:27:33s\n",
            "epoch 1391| loss: 0.7448  | train_accuracy: 0.64499 | val_accuracy: 0.53499 |  0:27:34s\n",
            "epoch 1392| loss: 0.74366 | train_accuracy: 0.6421  | val_accuracy: 0.53219 |  0:27:35s\n",
            "epoch 1393| loss: 0.74796 | train_accuracy: 0.64237 | val_accuracy: 0.53019 |  0:27:36s\n",
            "epoch 1394| loss: 0.74762 | train_accuracy: 0.63899 | val_accuracy: 0.52099 |  0:27:37s\n",
            "epoch 1395| loss: 0.74735 | train_accuracy: 0.6433  | val_accuracy: 0.53299 |  0:27:38s\n",
            "epoch 1396| loss: 0.75072 | train_accuracy: 0.64641 | val_accuracy: 0.53579 |  0:27:40s\n",
            "epoch 1397| loss: 0.74376 | train_accuracy: 0.64472 | val_accuracy: 0.53219 |  0:27:41s\n",
            "epoch 1398| loss: 0.76535 | train_accuracy: 0.64117 | val_accuracy: 0.52459 |  0:27:42s\n",
            "epoch 1399| loss: 0.75299 | train_accuracy: 0.64494 | val_accuracy: 0.54258 |  0:27:43s\n",
            "epoch 1400| loss: 0.75546 | train_accuracy: 0.63646 | val_accuracy: 0.51339 |  0:27:44s\n",
            "epoch 1401| loss: 0.76436 | train_accuracy: 0.64117 | val_accuracy: 0.53379 |  0:27:46s\n",
            "epoch 1402| loss: 0.75418 | train_accuracy: 0.63659 | val_accuracy: 0.51619 |  0:27:47s\n",
            "epoch 1403| loss: 0.74864 | train_accuracy: 0.64579 | val_accuracy: 0.54338 |  0:27:48s\n",
            "epoch 1404| loss: 0.74669 | train_accuracy: 0.64108 | val_accuracy: 0.51739 |  0:27:49s\n",
            "epoch 1405| loss: 0.74629 | train_accuracy: 0.63974 | val_accuracy: 0.53139 |  0:27:50s\n",
            "epoch 1406| loss: 0.75033 | train_accuracy: 0.64277 | val_accuracy: 0.51459 |  0:27:52s\n",
            "epoch 1407| loss: 0.74434 | train_accuracy: 0.64356 | val_accuracy: 0.54138 |  0:27:53s\n",
            "epoch 1408| loss: 0.74531 | train_accuracy: 0.64205 | val_accuracy: 0.51739 |  0:27:54s\n",
            "epoch 1409| loss: 0.73905 | train_accuracy: 0.64339 | val_accuracy: 0.53259 |  0:27:55s\n",
            "epoch 1410| loss: 0.73829 | train_accuracy: 0.64641 | val_accuracy: 0.52619 |  0:27:56s\n",
            "epoch 1411| loss: 0.74533 | train_accuracy: 0.64259 | val_accuracy: 0.53858 |  0:27:57s\n",
            "epoch 1412| loss: 0.73668 | train_accuracy: 0.64787 | val_accuracy: 0.53019 |  0:27:59s\n",
            "epoch 1413| loss: 0.73713 | train_accuracy: 0.64614 | val_accuracy: 0.53259 |  0:28:00s\n",
            "epoch 1414| loss: 0.74544 | train_accuracy: 0.64099 | val_accuracy: 0.509   |  0:28:01s\n",
            "epoch 1415| loss: 0.74266 | train_accuracy: 0.64756 | val_accuracy: 0.53019 |  0:28:02s\n",
            "epoch 1416| loss: 0.74078 | train_accuracy: 0.64405 | val_accuracy: 0.52339 |  0:28:03s\n",
            "epoch 1417| loss: 0.73759 | train_accuracy: 0.6465  | val_accuracy: 0.52619 |  0:28:05s\n",
            "epoch 1418| loss: 0.74171 | train_accuracy: 0.64197 | val_accuracy: 0.52339 |  0:28:06s\n",
            "epoch 1419| loss: 0.74057 | train_accuracy: 0.64348 | val_accuracy: 0.52699 |  0:28:07s\n",
            "epoch 1420| loss: 0.74456 | train_accuracy: 0.64423 | val_accuracy: 0.51739 |  0:28:08s\n",
            "epoch 1421| loss: 0.74517 | train_accuracy: 0.64441 | val_accuracy: 0.53259 |  0:28:09s\n",
            "epoch 1422| loss: 0.74263 | train_accuracy: 0.64436 | val_accuracy: 0.5118  |  0:28:11s\n",
            "epoch 1423| loss: 0.74603 | train_accuracy: 0.64348 | val_accuracy: 0.53259 |  0:28:12s\n",
            "epoch 1424| loss: 0.74693 | train_accuracy: 0.6429  | val_accuracy: 0.52619 |  0:28:13s\n",
            "epoch 1425| loss: 0.74064 | train_accuracy: 0.64645 | val_accuracy: 0.53579 |  0:28:14s\n",
            "epoch 1426| loss: 0.75044 | train_accuracy: 0.64192 | val_accuracy: 0.52259 |  0:28:15s\n",
            "epoch 1427| loss: 0.75315 | train_accuracy: 0.64379 | val_accuracy: 0.52419 |  0:28:17s\n",
            "epoch 1428| loss: 0.75221 | train_accuracy: 0.64463 | val_accuracy: 0.53099 |  0:28:18s\n",
            "epoch 1429| loss: 0.74408 | train_accuracy: 0.64641 | val_accuracy: 0.53619 |  0:28:19s\n",
            "epoch 1430| loss: 0.74759 | train_accuracy: 0.64063 | val_accuracy: 0.52819 |  0:28:20s\n",
            "epoch 1431| loss: 0.74844 | train_accuracy: 0.64343 | val_accuracy: 0.52259 |  0:28:21s\n",
            "epoch 1432| loss: 0.73859 | train_accuracy: 0.64294 | val_accuracy: 0.52059 |  0:28:22s\n",
            "epoch 1433| loss: 0.75531 | train_accuracy: 0.64565 | val_accuracy: 0.51739 |  0:28:24s\n",
            "epoch 1434| loss: 0.76034 | train_accuracy: 0.64161 | val_accuracy: 0.51579 |  0:28:25s\n",
            "epoch 1435| loss: 0.75377 | train_accuracy: 0.6421  | val_accuracy: 0.52179 |  0:28:26s\n",
            "epoch 1436| loss: 0.75869 | train_accuracy: 0.6417  | val_accuracy: 0.5094  |  0:28:27s\n",
            "epoch 1437| loss: 0.74855 | train_accuracy: 0.64157 | val_accuracy: 0.51499 |  0:28:28s\n",
            "epoch 1438| loss: 0.75828 | train_accuracy: 0.6385  | val_accuracy: 0.52299 |  0:28:30s\n",
            "epoch 1439| loss: 0.76149 | train_accuracy: 0.63441 | val_accuracy: 0.51579 |  0:28:31s\n",
            "epoch 1440| loss: 0.76083 | train_accuracy: 0.6369  | val_accuracy: 0.52299 |  0:28:32s\n",
            "epoch 1441| loss: 0.75264 | train_accuracy: 0.63708 | val_accuracy: 0.51579 |  0:28:33s\n",
            "epoch 1442| loss: 0.75419 | train_accuracy: 0.6405  | val_accuracy: 0.52139 |  0:28:34s\n",
            "epoch 1443| loss: 0.75094 | train_accuracy: 0.6397  | val_accuracy: 0.52699 |  0:28:36s\n",
            "epoch 1444| loss: 0.75362 | train_accuracy: 0.63974 | val_accuracy: 0.51739 |  0:28:37s\n",
            "epoch 1445| loss: 0.75177 | train_accuracy: 0.64121 | val_accuracy: 0.52419 |  0:28:38s\n",
            "epoch 1446| loss: 0.75564 | train_accuracy: 0.63943 | val_accuracy: 0.52859 |  0:28:39s\n",
            "epoch 1447| loss: 0.75761 | train_accuracy: 0.63859 | val_accuracy: 0.52059 |  0:28:40s\n",
            "epoch 1448| loss: 0.74745 | train_accuracy: 0.6385  | val_accuracy: 0.52059 |  0:28:41s\n",
            "epoch 1449| loss: 0.7508  | train_accuracy: 0.64045 | val_accuracy: 0.51699 |  0:28:43s\n",
            "epoch 1450| loss: 0.75324 | train_accuracy: 0.63841 | val_accuracy: 0.51419 |  0:28:44s\n",
            "epoch 1451| loss: 0.75013 | train_accuracy: 0.64241 | val_accuracy: 0.53059 |  0:28:45s\n",
            "epoch 1452| loss: 0.74872 | train_accuracy: 0.64277 | val_accuracy: 0.51459 |  0:28:46s\n",
            "epoch 1453| loss: 0.74074 | train_accuracy: 0.64121 | val_accuracy: 0.5098  |  0:28:47s\n",
            "epoch 1454| loss: 0.74671 | train_accuracy: 0.64214 | val_accuracy: 0.51939 |  0:28:48s\n",
            "epoch 1455| loss: 0.74955 | train_accuracy: 0.64103 | val_accuracy: 0.53339 |  0:28:50s\n",
            "epoch 1456| loss: 0.75066 | train_accuracy: 0.63854 | val_accuracy: 0.52779 |  0:28:51s\n",
            "epoch 1457| loss: 0.75459 | train_accuracy: 0.64303 | val_accuracy: 0.52619 |  0:28:52s\n",
            "epoch 1458| loss: 0.7503  | train_accuracy: 0.64241 | val_accuracy: 0.52819 |  0:28:53s\n",
            "epoch 1459| loss: 0.75207 | train_accuracy: 0.64223 | val_accuracy: 0.51859 |  0:28:54s\n",
            "epoch 1460| loss: 0.74662 | train_accuracy: 0.63717 | val_accuracy: 0.52019 |  0:28:56s\n",
            "epoch 1461| loss: 0.7539  | train_accuracy: 0.63988 | val_accuracy: 0.52579 |  0:28:57s\n",
            "epoch 1462| loss: 0.75473 | train_accuracy: 0.6369  | val_accuracy: 0.5094  |  0:28:58s\n",
            "epoch 1463| loss: 0.75472 | train_accuracy: 0.63681 | val_accuracy: 0.51339 |  0:28:59s\n",
            "epoch 1464| loss: 0.75908 | train_accuracy: 0.63432 | val_accuracy: 0.507   |  0:29:00s\n",
            "epoch 1465| loss: 0.7631  | train_accuracy: 0.63299 | val_accuracy: 0.52699 |  0:29:01s\n",
            "epoch 1466| loss: 0.75601 | train_accuracy: 0.63357 | val_accuracy: 0.505   |  0:29:03s\n",
            "epoch 1467| loss: 0.75757 | train_accuracy: 0.63588 | val_accuracy: 0.51579 |  0:29:04s\n",
            "epoch 1468| loss: 0.75404 | train_accuracy: 0.63828 | val_accuracy: 0.5078  |  0:29:05s\n",
            "epoch 1469| loss: 0.75166 | train_accuracy: 0.63943 | val_accuracy: 0.51859 |  0:29:06s\n",
            "epoch 1470| loss: 0.74825 | train_accuracy: 0.63899 | val_accuracy: 0.5066  |  0:29:07s\n",
            "epoch 1471| loss: 0.75399 | train_accuracy: 0.63637 | val_accuracy: 0.52659 |  0:29:09s\n",
            "epoch 1472| loss: 0.75699 | train_accuracy: 0.63446 | val_accuracy: 0.51899 |  0:29:10s\n",
            "epoch 1473| loss: 0.75425 | train_accuracy: 0.63277 | val_accuracy: 0.52779 |  0:29:11s\n",
            "epoch 1474| loss: 0.74914 | train_accuracy: 0.63748 | val_accuracy: 0.52979 |  0:29:12s\n",
            "epoch 1475| loss: 0.74777 | train_accuracy: 0.63779 | val_accuracy: 0.51899 |  0:29:13s\n",
            "epoch 1476| loss: 0.75018 | train_accuracy: 0.63615 | val_accuracy: 0.52139 |  0:29:15s\n",
            "epoch 1477| loss: 0.75371 | train_accuracy: 0.63748 | val_accuracy: 0.52259 |  0:29:16s\n",
            "epoch 1478| loss: 0.74953 | train_accuracy: 0.63983 | val_accuracy: 0.52739 |  0:29:17s\n",
            "epoch 1479| loss: 0.75565 | train_accuracy: 0.63819 | val_accuracy: 0.52419 |  0:29:18s\n",
            "epoch 1480| loss: 0.75615 | train_accuracy: 0.63934 | val_accuracy: 0.51939 |  0:29:19s\n",
            "epoch 1481| loss: 0.75651 | train_accuracy: 0.63952 | val_accuracy: 0.52379 |  0:29:20s\n",
            "epoch 1482| loss: 0.75597 | train_accuracy: 0.6385  | val_accuracy: 0.52499 |  0:29:22s\n",
            "epoch 1483| loss: 0.75123 | train_accuracy: 0.63881 | val_accuracy: 0.51259 |  0:29:23s\n",
            "epoch 1484| loss: 0.75712 | train_accuracy: 0.63655 | val_accuracy: 0.52699 |  0:29:24s\n",
            "epoch 1485| loss: 0.75552 | train_accuracy: 0.63384 | val_accuracy: 0.52179 |  0:29:25s\n",
            "epoch 1486| loss: 0.75777 | train_accuracy: 0.63934 | val_accuracy: 0.52219 |  0:29:26s\n",
            "epoch 1487| loss: 0.75167 | train_accuracy: 0.63872 | val_accuracy: 0.52419 |  0:29:28s\n",
            "epoch 1488| loss: 0.74845 | train_accuracy: 0.64223 | val_accuracy: 0.52419 |  0:29:29s\n",
            "epoch 1489| loss: 0.75276 | train_accuracy: 0.64414 | val_accuracy: 0.53459 |  0:29:30s\n",
            "epoch 1490| loss: 0.74929 | train_accuracy: 0.63681 | val_accuracy: 0.52659 |  0:29:31s\n",
            "epoch 1491| loss: 0.75401 | train_accuracy: 0.63379 | val_accuracy: 0.53379 |  0:29:32s\n",
            "epoch 1492| loss: 0.75518 | train_accuracy: 0.63317 | val_accuracy: 0.53099 |  0:29:34s\n",
            "epoch 1493| loss: 0.75415 | train_accuracy: 0.62513 | val_accuracy: 0.511   |  0:29:35s\n",
            "epoch 1494| loss: 0.75827 | train_accuracy: 0.63139 | val_accuracy: 0.53099 |  0:29:36s\n",
            "epoch 1495| loss: 0.75414 | train_accuracy: 0.63837 | val_accuracy: 0.52139 |  0:29:37s\n",
            "epoch 1496| loss: 0.7514  | train_accuracy: 0.63877 | val_accuracy: 0.52899 |  0:29:38s\n",
            "epoch 1497| loss: 0.74908 | train_accuracy: 0.63899 | val_accuracy: 0.51859 |  0:29:39s\n",
            "epoch 1498| loss: 0.75109 | train_accuracy: 0.6405  | val_accuracy: 0.53579 |  0:29:41s\n",
            "epoch 1499| loss: 0.75344 | train_accuracy: 0.63814 | val_accuracy: 0.52139 |  0:29:42s\n",
            "epoch 1500| loss: 0.75338 | train_accuracy: 0.63894 | val_accuracy: 0.54378 |  0:29:43s\n",
            "epoch 1501| loss: 0.74928 | train_accuracy: 0.64121 | val_accuracy: 0.53579 |  0:29:44s\n",
            "epoch 1502| loss: 0.7561  | train_accuracy: 0.63832 | val_accuracy: 0.52779 |  0:29:45s\n",
            "epoch 1503| loss: 0.74724 | train_accuracy: 0.63886 | val_accuracy: 0.53778 |  0:29:46s\n",
            "epoch 1504| loss: 0.75051 | train_accuracy: 0.63592 | val_accuracy: 0.52859 |  0:29:48s\n",
            "epoch 1505| loss: 0.75642 | train_accuracy: 0.63561 | val_accuracy: 0.53739 |  0:29:49s\n",
            "epoch 1506| loss: 0.75849 | train_accuracy: 0.63677 | val_accuracy: 0.52139 |  0:29:50s\n",
            "epoch 1507| loss: 0.75347 | train_accuracy: 0.63774 | val_accuracy: 0.53219 |  0:29:51s\n",
            "epoch 1508| loss: 0.7529  | train_accuracy: 0.63552 | val_accuracy: 0.52859 |  0:29:52s\n",
            "epoch 1509| loss: 0.75429 | train_accuracy: 0.63357 | val_accuracy: 0.52419 |  0:29:53s\n",
            "epoch 1510| loss: 0.75632 | train_accuracy: 0.63521 | val_accuracy: 0.52739 |  0:29:55s\n",
            "epoch 1511| loss: 0.74927 | train_accuracy: 0.63752 | val_accuracy: 0.54778 |  0:29:56s\n",
            "epoch 1512| loss: 0.75169 | train_accuracy: 0.63917 | val_accuracy: 0.53139 |  0:29:57s\n",
            "epoch 1513| loss: 0.75158 | train_accuracy: 0.63974 | val_accuracy: 0.52979 |  0:29:58s\n",
            "epoch 1514| loss: 0.75152 | train_accuracy: 0.64072 | val_accuracy: 0.52299 |  0:29:59s\n",
            "epoch 1515| loss: 0.74419 | train_accuracy: 0.63988 | val_accuracy: 0.52979 |  0:30:01s\n",
            "epoch 1516| loss: 0.74929 | train_accuracy: 0.63868 | val_accuracy: 0.53219 |  0:30:02s\n",
            "epoch 1517| loss: 0.74975 | train_accuracy: 0.6357  | val_accuracy: 0.53419 |  0:30:03s\n",
            "epoch 1518| loss: 0.75355 | train_accuracy: 0.63388 | val_accuracy: 0.5098  |  0:30:04s\n",
            "epoch 1519| loss: 0.7482  | train_accuracy: 0.63557 | val_accuracy: 0.54018 |  0:30:05s\n",
            "epoch 1520| loss: 0.75528 | train_accuracy: 0.63432 | val_accuracy: 0.51939 |  0:30:06s\n",
            "epoch 1521| loss: 0.7524  | train_accuracy: 0.63814 | val_accuracy: 0.53579 |  0:30:08s\n",
            "epoch 1522| loss: 0.75569 | train_accuracy: 0.63659 | val_accuracy: 0.52779 |  0:30:09s\n",
            "epoch 1523| loss: 0.75049 | train_accuracy: 0.6401  | val_accuracy: 0.54098 |  0:30:10s\n",
            "epoch 1524| loss: 0.75187 | train_accuracy: 0.63926 | val_accuracy: 0.53099 |  0:30:11s\n",
            "epoch 1525| loss: 0.75038 | train_accuracy: 0.6377  | val_accuracy: 0.52859 |  0:30:12s\n",
            "epoch 1526| loss: 0.75367 | train_accuracy: 0.63797 | val_accuracy: 0.53299 |  0:30:13s\n",
            "epoch 1527| loss: 0.75309 | train_accuracy: 0.63894 | val_accuracy: 0.53699 |  0:30:15s\n",
            "epoch 1528| loss: 0.76443 | train_accuracy: 0.63264 | val_accuracy: 0.53019 |  0:30:16s\n",
            "epoch 1529| loss: 0.77074 | train_accuracy: 0.63623 | val_accuracy: 0.52339 |  0:30:17s\n",
            "epoch 1530| loss: 0.76583 | train_accuracy: 0.63543 | val_accuracy: 0.52259 |  0:30:18s\n",
            "epoch 1531| loss: 0.76596 | train_accuracy: 0.6333  | val_accuracy: 0.52499 |  0:30:19s\n",
            "epoch 1532| loss: 0.75917 | train_accuracy: 0.63468 | val_accuracy: 0.52499 |  0:30:21s\n",
            "epoch 1533| loss: 0.76096 | train_accuracy: 0.63543 | val_accuracy: 0.53419 |  0:30:22s\n",
            "epoch 1534| loss: 0.76649 | train_accuracy: 0.63512 | val_accuracy: 0.52579 |  0:30:23s\n",
            "epoch 1535| loss: 0.76494 | train_accuracy: 0.63717 | val_accuracy: 0.52819 |  0:30:24s\n",
            "epoch 1536| loss: 0.76407 | train_accuracy: 0.63046 | val_accuracy: 0.52699 |  0:30:25s\n",
            "epoch 1537| loss: 0.77147 | train_accuracy: 0.62859 | val_accuracy: 0.52499 |  0:30:27s\n",
            "epoch 1538| loss: 0.78894 | train_accuracy: 0.62864 | val_accuracy: 0.52299 |  0:30:28s\n",
            "epoch 1539| loss: 0.77928 | train_accuracy: 0.63033 | val_accuracy: 0.52179 |  0:30:29s\n",
            "epoch 1540| loss: 0.77035 | train_accuracy: 0.63326 | val_accuracy: 0.52739 |  0:30:30s\n",
            "epoch 1541| loss: 0.76662 | train_accuracy: 0.62828 | val_accuracy: 0.52779 |  0:30:31s\n",
            "epoch 1542| loss: 0.7741  | train_accuracy: 0.63015 | val_accuracy: 0.53019 |  0:30:32s\n",
            "epoch 1543| loss: 0.76892 | train_accuracy: 0.62966 | val_accuracy: 0.53379 |  0:30:34s\n",
            "epoch 1544| loss: 0.76797 | train_accuracy: 0.62739 | val_accuracy: 0.52779 |  0:30:35s\n",
            "epoch 1545| loss: 0.7735  | train_accuracy: 0.62504 | val_accuracy: 0.5118  |  0:30:36s\n",
            "epoch 1546| loss: 0.77064 | train_accuracy: 0.62882 | val_accuracy: 0.52059 |  0:30:37s\n",
            "epoch 1547| loss: 0.77154 | train_accuracy: 0.63046 | val_accuracy: 0.52299 |  0:30:38s\n",
            "epoch 1548| loss: 0.7639  | train_accuracy: 0.63059 | val_accuracy: 0.52979 |  0:30:40s\n",
            "epoch 1549| loss: 0.75706 | train_accuracy: 0.63068 | val_accuracy: 0.52899 |  0:30:41s\n",
            "epoch 1550| loss: 0.76477 | train_accuracy: 0.63059 | val_accuracy: 0.53299 |  0:30:42s\n",
            "epoch 1551| loss: 0.76507 | train_accuracy: 0.63268 | val_accuracy: 0.52339 |  0:30:43s\n",
            "epoch 1552| loss: 0.76244 | train_accuracy: 0.63419 | val_accuracy: 0.53259 |  0:30:44s\n",
            "epoch 1553| loss: 0.76521 | train_accuracy: 0.63481 | val_accuracy: 0.52179 |  0:30:46s\n",
            "epoch 1554| loss: 0.76185 | train_accuracy: 0.63153 | val_accuracy: 0.52819 |  0:30:47s\n",
            "epoch 1555| loss: 0.76181 | train_accuracy: 0.63201 | val_accuracy: 0.52139 |  0:30:48s\n",
            "epoch 1556| loss: 0.76137 | train_accuracy: 0.63339 | val_accuracy: 0.51899 |  0:30:49s\n",
            "epoch 1557| loss: 0.76208 | train_accuracy: 0.63379 | val_accuracy: 0.52899 |  0:30:50s\n",
            "epoch 1558| loss: 0.76836 | train_accuracy: 0.63268 | val_accuracy: 0.53459 |  0:30:52s\n",
            "epoch 1559| loss: 0.76854 | train_accuracy: 0.63121 | val_accuracy: 0.51819 |  0:30:53s\n",
            "epoch 1560| loss: 0.7611  | train_accuracy: 0.62957 | val_accuracy: 0.52459 |  0:30:54s\n",
            "epoch 1561| loss: 0.76156 | train_accuracy: 0.6353  | val_accuracy: 0.53219 |  0:30:55s\n",
            "epoch 1562| loss: 0.75849 | train_accuracy: 0.63397 | val_accuracy: 0.52699 |  0:30:56s\n",
            "epoch 1563| loss: 0.75461 | train_accuracy: 0.63503 | val_accuracy: 0.53539 |  0:30:57s\n",
            "epoch 1564| loss: 0.7606  | train_accuracy: 0.63477 | val_accuracy: 0.53139 |  0:30:59s\n",
            "epoch 1565| loss: 0.76301 | train_accuracy: 0.63166 | val_accuracy: 0.52459 |  0:31:00s\n",
            "epoch 1566| loss: 0.76757 | train_accuracy: 0.63361 | val_accuracy: 0.52219 |  0:31:01s\n",
            "epoch 1567| loss: 0.75657 | train_accuracy: 0.6341  | val_accuracy: 0.52339 |  0:31:02s\n",
            "epoch 1568| loss: 0.75754 | train_accuracy: 0.63575 | val_accuracy: 0.52299 |  0:31:03s\n",
            "epoch 1569| loss: 0.75985 | train_accuracy: 0.63388 | val_accuracy: 0.51419 |  0:31:04s\n",
            "epoch 1570| loss: 0.75632 | train_accuracy: 0.63406 | val_accuracy: 0.51979 |  0:31:06s\n",
            "epoch 1571| loss: 0.75609 | train_accuracy: 0.63832 | val_accuracy: 0.52859 |  0:31:07s\n",
            "epoch 1572| loss: 0.75416 | train_accuracy: 0.63339 | val_accuracy: 0.51659 |  0:31:08s\n",
            "epoch 1573| loss: 0.75136 | train_accuracy: 0.63686 | val_accuracy: 0.51979 |  0:31:09s\n",
            "epoch 1574| loss: 0.74995 | train_accuracy: 0.63588 | val_accuracy: 0.52819 |  0:31:10s\n",
            "epoch 1575| loss: 0.74891 | train_accuracy: 0.63415 | val_accuracy: 0.51659 |  0:31:11s\n",
            "epoch 1576| loss: 0.75658 | train_accuracy: 0.63561 | val_accuracy: 0.53059 |  0:31:13s\n",
            "epoch 1577| loss: 0.7513  | train_accuracy: 0.63459 | val_accuracy: 0.52859 |  0:31:14s\n",
            "epoch 1578| loss: 0.75031 | train_accuracy: 0.63619 | val_accuracy: 0.53299 |  0:31:15s\n",
            "epoch 1579| loss: 0.7522  | train_accuracy: 0.63837 | val_accuracy: 0.52579 |  0:31:16s\n",
            "epoch 1580| loss: 0.75459 | train_accuracy: 0.63863 | val_accuracy: 0.52339 |  0:31:17s\n",
            "epoch 1581| loss: 0.74771 | train_accuracy: 0.63988 | val_accuracy: 0.52419 |  0:31:18s\n",
            "epoch 1582| loss: 0.74784 | train_accuracy: 0.6377  | val_accuracy: 0.52579 |  0:31:20s\n",
            "epoch 1583| loss: 0.75363 | train_accuracy: 0.63712 | val_accuracy: 0.53179 |  0:31:21s\n",
            "epoch 1584| loss: 0.75156 | train_accuracy: 0.63846 | val_accuracy: 0.53379 |  0:31:22s\n",
            "epoch 1585| loss: 0.75403 | train_accuracy: 0.6369  | val_accuracy: 0.53379 |  0:31:23s\n",
            "epoch 1586| loss: 0.74967 | train_accuracy: 0.63788 | val_accuracy: 0.52979 |  0:31:24s\n",
            "epoch 1587| loss: 0.74896 | train_accuracy: 0.64028 | val_accuracy: 0.52539 |  0:31:26s\n",
            "epoch 1588| loss: 0.75072 | train_accuracy: 0.63894 | val_accuracy: 0.52379 |  0:31:27s\n",
            "epoch 1589| loss: 0.75055 | train_accuracy: 0.63917 | val_accuracy: 0.52419 |  0:31:28s\n",
            "epoch 1590| loss: 0.74646 | train_accuracy: 0.63846 | val_accuracy: 0.52379 |  0:31:29s\n",
            "epoch 1591| loss: 0.75188 | train_accuracy: 0.63872 | val_accuracy: 0.52339 |  0:31:30s\n",
            "epoch 1592| loss: 0.7535  | train_accuracy: 0.63823 | val_accuracy: 0.52939 |  0:31:31s\n",
            "epoch 1593| loss: 0.75103 | train_accuracy: 0.63628 | val_accuracy: 0.53938 |  0:31:33s\n",
            "epoch 1594| loss: 0.74634 | train_accuracy: 0.63877 | val_accuracy: 0.53619 |  0:31:34s\n",
            "epoch 1595| loss: 0.75098 | train_accuracy: 0.63646 | val_accuracy: 0.52819 |  0:31:35s\n",
            "epoch 1596| loss: 0.75258 | train_accuracy: 0.63659 | val_accuracy: 0.53419 |  0:31:36s\n",
            "epoch 1597| loss: 0.7497  | train_accuracy: 0.63579 | val_accuracy: 0.52139 |  0:31:37s\n",
            "epoch 1598| loss: 0.75219 | train_accuracy: 0.63717 | val_accuracy: 0.52819 |  0:31:38s\n",
            "epoch 1599| loss: 0.75605 | train_accuracy: 0.63881 | val_accuracy: 0.52859 |  0:31:40s\n",
            "epoch 1600| loss: 0.75679 | train_accuracy: 0.6349  | val_accuracy: 0.53219 |  0:31:41s\n",
            "epoch 1601| loss: 0.75492 | train_accuracy: 0.63814 | val_accuracy: 0.53499 |  0:31:42s\n",
            "epoch 1602| loss: 0.75313 | train_accuracy: 0.63699 | val_accuracy: 0.52939 |  0:31:43s\n",
            "epoch 1603| loss: 0.75228 | train_accuracy: 0.6341  | val_accuracy: 0.53579 |  0:31:44s\n",
            "epoch 1604| loss: 0.75443 | train_accuracy: 0.63575 | val_accuracy: 0.52939 |  0:31:46s\n",
            "epoch 1605| loss: 0.75485 | train_accuracy: 0.63077 | val_accuracy: 0.52219 |  0:31:47s\n",
            "epoch 1606| loss: 0.75377 | train_accuracy: 0.63317 | val_accuracy: 0.52059 |  0:31:48s\n",
            "epoch 1607| loss: 0.75564 | train_accuracy: 0.63632 | val_accuracy: 0.52979 |  0:31:49s\n",
            "epoch 1608| loss: 0.75026 | train_accuracy: 0.63321 | val_accuracy: 0.52099 |  0:31:50s\n",
            "epoch 1609| loss: 0.75357 | train_accuracy: 0.63357 | val_accuracy: 0.53059 |  0:31:52s\n",
            "epoch 1610| loss: 0.75367 | train_accuracy: 0.63677 | val_accuracy: 0.52539 |  0:31:53s\n",
            "epoch 1611| loss: 0.75113 | train_accuracy: 0.63597 | val_accuracy: 0.52299 |  0:31:54s\n",
            "epoch 1612| loss: 0.7465  | train_accuracy: 0.63819 | val_accuracy: 0.53059 |  0:31:55s\n",
            "epoch 1613| loss: 0.7537  | train_accuracy: 0.6373  | val_accuracy: 0.52659 |  0:31:56s\n",
            "epoch 1614| loss: 0.76332 | train_accuracy: 0.63766 | val_accuracy: 0.52299 |  0:31:58s\n",
            "epoch 1615| loss: 0.75297 | train_accuracy: 0.63464 | val_accuracy: 0.52059 |  0:31:59s\n",
            "epoch 1616| loss: 0.75646 | train_accuracy: 0.63535 | val_accuracy: 0.52619 |  0:32:00s\n",
            "epoch 1617| loss: 0.74956 | train_accuracy: 0.6369  | val_accuracy: 0.51579 |  0:32:01s\n",
            "epoch 1618| loss: 0.74519 | train_accuracy: 0.63957 | val_accuracy: 0.52859 |  0:32:02s\n",
            "epoch 1619| loss: 0.74367 | train_accuracy: 0.63379 | val_accuracy: 0.51339 |  0:32:03s\n",
            "epoch 1620| loss: 0.7461  | train_accuracy: 0.63983 | val_accuracy: 0.52259 |  0:32:05s\n",
            "epoch 1621| loss: 0.74496 | train_accuracy: 0.63957 | val_accuracy: 0.52219 |  0:32:06s\n",
            "epoch 1622| loss: 0.74624 | train_accuracy: 0.63934 | val_accuracy: 0.52379 |  0:32:07s\n",
            "epoch 1623| loss: 0.74669 | train_accuracy: 0.63903 | val_accuracy: 0.51619 |  0:32:08s\n",
            "epoch 1624| loss: 0.74108 | train_accuracy: 0.64179 | val_accuracy: 0.52539 |  0:32:09s\n",
            "epoch 1625| loss: 0.73919 | train_accuracy: 0.63814 | val_accuracy: 0.52299 |  0:32:11s\n",
            "epoch 1626| loss: 0.74507 | train_accuracy: 0.64108 | val_accuracy: 0.51939 |  0:32:12s\n",
            "epoch 1627| loss: 0.73548 | train_accuracy: 0.63894 | val_accuracy: 0.51339 |  0:32:13s\n",
            "epoch 1628| loss: 0.74249 | train_accuracy: 0.63837 | val_accuracy: 0.52419 |  0:32:14s\n",
            "epoch 1629| loss: 0.73858 | train_accuracy: 0.64054 | val_accuracy: 0.51859 |  0:32:15s\n",
            "epoch 1630| loss: 0.73981 | train_accuracy: 0.6437  | val_accuracy: 0.52779 |  0:32:17s\n",
            "epoch 1631| loss: 0.74261 | train_accuracy: 0.64028 | val_accuracy: 0.52459 |  0:32:18s\n",
            "epoch 1632| loss: 0.74275 | train_accuracy: 0.6421  | val_accuracy: 0.52099 |  0:32:19s\n",
            "epoch 1633| loss: 0.73962 | train_accuracy: 0.64352 | val_accuracy: 0.51259 |  0:32:20s\n",
            "epoch 1634| loss: 0.74295 | train_accuracy: 0.64459 | val_accuracy: 0.51339 |  0:32:21s\n",
            "epoch 1635| loss: 0.74454 | train_accuracy: 0.64268 | val_accuracy: 0.51859 |  0:32:22s\n",
            "epoch 1636| loss: 0.74037 | train_accuracy: 0.6421  | val_accuracy: 0.52419 |  0:32:24s\n",
            "epoch 1637| loss: 0.74193 | train_accuracy: 0.64112 | val_accuracy: 0.52259 |  0:32:25s\n",
            "epoch 1638| loss: 0.7391  | train_accuracy: 0.64294 | val_accuracy: 0.52139 |  0:32:26s\n",
            "epoch 1639| loss: 0.73725 | train_accuracy: 0.64081 | val_accuracy: 0.52019 |  0:32:27s\n",
            "epoch 1640| loss: 0.74142 | train_accuracy: 0.64201 | val_accuracy: 0.52099 |  0:32:28s\n",
            "epoch 1641| loss: 0.74688 | train_accuracy: 0.6401  | val_accuracy: 0.5074  |  0:32:30s\n",
            "epoch 1642| loss: 0.74406 | train_accuracy: 0.64023 | val_accuracy: 0.52779 |  0:32:31s\n",
            "epoch 1643| loss: 0.7398  | train_accuracy: 0.63681 | val_accuracy: 0.5102  |  0:32:32s\n",
            "epoch 1644| loss: 0.74028 | train_accuracy: 0.64134 | val_accuracy: 0.52019 |  0:32:33s\n",
            "epoch 1645| loss: 0.75285 | train_accuracy: 0.64032 | val_accuracy: 0.52139 |  0:32:34s\n",
            "epoch 1646| loss: 0.74535 | train_accuracy: 0.6421  | val_accuracy: 0.52299 |  0:32:35s\n",
            "epoch 1647| loss: 0.74254 | train_accuracy: 0.64219 | val_accuracy: 0.52779 |  0:32:37s\n",
            "epoch 1648| loss: 0.74722 | train_accuracy: 0.64099 | val_accuracy: 0.53259 |  0:32:38s\n",
            "epoch 1649| loss: 0.74682 | train_accuracy: 0.63997 | val_accuracy: 0.52179 |  0:32:39s\n",
            "epoch 1650| loss: 0.73805 | train_accuracy: 0.64108 | val_accuracy: 0.52299 |  0:32:40s\n",
            "epoch 1651| loss: 0.74156 | train_accuracy: 0.63908 | val_accuracy: 0.52219 |  0:32:41s\n",
            "epoch 1652| loss: 0.74246 | train_accuracy: 0.64103 | val_accuracy: 0.52979 |  0:32:43s\n",
            "epoch 1653| loss: 0.74309 | train_accuracy: 0.63712 | val_accuracy: 0.51819 |  0:32:44s\n",
            "epoch 1654| loss: 0.74701 | train_accuracy: 0.63832 | val_accuracy: 0.52699 |  0:32:45s\n",
            "epoch 1655| loss: 0.74337 | train_accuracy: 0.64045 | val_accuracy: 0.52179 |  0:32:46s\n",
            "epoch 1656| loss: 0.73739 | train_accuracy: 0.64254 | val_accuracy: 0.52299 |  0:32:47s\n",
            "epoch 1657| loss: 0.74194 | train_accuracy: 0.6421  | val_accuracy: 0.52259 |  0:32:49s\n",
            "epoch 1658| loss: 0.73879 | train_accuracy: 0.64157 | val_accuracy: 0.52619 |  0:32:50s\n",
            "epoch 1659| loss: 0.74314 | train_accuracy: 0.63655 | val_accuracy: 0.51619 |  0:32:51s\n",
            "epoch 1660| loss: 0.74568 | train_accuracy: 0.63597 | val_accuracy: 0.52059 |  0:32:52s\n",
            "epoch 1661| loss: 0.74698 | train_accuracy: 0.63948 | val_accuracy: 0.51579 |  0:32:53s\n",
            "epoch 1662| loss: 0.74149 | train_accuracy: 0.63948 | val_accuracy: 0.52499 |  0:32:55s\n",
            "epoch 1663| loss: 0.75038 | train_accuracy: 0.63814 | val_accuracy: 0.52979 |  0:32:56s\n",
            "epoch 1664| loss: 0.75887 | train_accuracy: 0.63788 | val_accuracy: 0.51819 |  0:32:57s\n",
            "epoch 1665| loss: 0.75382 | train_accuracy: 0.63703 | val_accuracy: 0.52739 |  0:32:58s\n",
            "epoch 1666| loss: 0.75265 | train_accuracy: 0.63659 | val_accuracy: 0.52259 |  0:32:59s\n",
            "epoch 1667| loss: 0.75083 | train_accuracy: 0.63672 | val_accuracy: 0.52459 |  0:33:00s\n",
            "epoch 1668| loss: 0.74547 | train_accuracy: 0.63806 | val_accuracy: 0.53139 |  0:33:02s\n",
            "epoch 1669| loss: 0.74639 | train_accuracy: 0.63997 | val_accuracy: 0.51299 |  0:33:03s\n",
            "epoch 1670| loss: 0.74798 | train_accuracy: 0.64023 | val_accuracy: 0.51859 |  0:33:04s\n",
            "epoch 1671| loss: 0.7447  | train_accuracy: 0.6397  | val_accuracy: 0.52339 |  0:33:05s\n",
            "epoch 1672| loss: 0.74491 | train_accuracy: 0.64254 | val_accuracy: 0.51819 |  0:33:06s\n",
            "epoch 1673| loss: 0.7446  | train_accuracy: 0.64476 | val_accuracy: 0.51859 |  0:33:08s\n",
            "epoch 1674| loss: 0.7415  | train_accuracy: 0.64587 | val_accuracy: 0.52139 |  0:33:09s\n",
            "epoch 1675| loss: 0.73704 | train_accuracy: 0.64716 | val_accuracy: 0.52019 |  0:33:10s\n",
            "epoch 1676| loss: 0.7386  | train_accuracy: 0.64641 | val_accuracy: 0.52059 |  0:33:11s\n",
            "epoch 1677| loss: 0.73766 | train_accuracy: 0.64654 | val_accuracy: 0.52299 |  0:33:12s\n",
            "epoch 1678| loss: 0.73231 | train_accuracy: 0.6449  | val_accuracy: 0.51779 |  0:33:13s\n",
            "epoch 1679| loss: 0.73647 | train_accuracy: 0.64894 | val_accuracy: 0.52059 |  0:33:15s\n",
            "epoch 1680| loss: 0.73541 | train_accuracy: 0.64676 | val_accuracy: 0.52499 |  0:33:16s\n",
            "epoch 1681| loss: 0.73167 | train_accuracy: 0.64561 | val_accuracy: 0.51859 |  0:33:17s\n",
            "epoch 1682| loss: 0.73601 | train_accuracy: 0.64392 | val_accuracy: 0.51899 |  0:33:18s\n",
            "epoch 1683| loss: 0.73946 | train_accuracy: 0.64268 | val_accuracy: 0.51659 |  0:33:19s\n",
            "epoch 1684| loss: 0.74005 | train_accuracy: 0.64365 | val_accuracy: 0.52259 |  0:33:21s\n",
            "epoch 1685| loss: 0.75024 | train_accuracy: 0.64254 | val_accuracy: 0.52219 |  0:33:22s\n",
            "epoch 1686| loss: 0.74879 | train_accuracy: 0.6421  | val_accuracy: 0.51619 |  0:33:23s\n",
            "epoch 1687| loss: 0.75329 | train_accuracy: 0.64108 | val_accuracy: 0.52179 |  0:33:24s\n",
            "epoch 1688| loss: 0.7563  | train_accuracy: 0.63846 | val_accuracy: 0.51499 |  0:33:25s\n",
            "epoch 1689| loss: 0.7491  | train_accuracy: 0.64165 | val_accuracy: 0.5118  |  0:33:27s\n",
            "epoch 1690| loss: 0.74707 | train_accuracy: 0.64316 | val_accuracy: 0.53059 |  0:33:28s\n",
            "epoch 1691| loss: 0.73701 | train_accuracy: 0.64312 | val_accuracy: 0.52219 |  0:33:29s\n",
            "epoch 1692| loss: 0.73883 | train_accuracy: 0.64192 | val_accuracy: 0.51699 |  0:33:30s\n",
            "epoch 1693| loss: 0.741   | train_accuracy: 0.64197 | val_accuracy: 0.51939 |  0:33:31s\n",
            "epoch 1694| loss: 0.74419 | train_accuracy: 0.64494 | val_accuracy: 0.52339 |  0:33:33s\n",
            "epoch 1695| loss: 0.73885 | train_accuracy: 0.64476 | val_accuracy: 0.52459 |  0:33:34s\n",
            "epoch 1696| loss: 0.73603 | train_accuracy: 0.64654 | val_accuracy: 0.51739 |  0:33:35s\n",
            "epoch 1697| loss: 0.73821 | train_accuracy: 0.64765 | val_accuracy: 0.51979 |  0:33:36s\n",
            "epoch 1698| loss: 0.74047 | train_accuracy: 0.64499 | val_accuracy: 0.51859 |  0:33:37s\n",
            "epoch 1699| loss: 0.73613 | train_accuracy: 0.64232 | val_accuracy: 0.52139 |  0:33:39s\n",
            "epoch 1700| loss: 0.73647 | train_accuracy: 0.64445 | val_accuracy: 0.52699 |  0:33:40s\n",
            "epoch 1701| loss: 0.74176 | train_accuracy: 0.6457  | val_accuracy: 0.51779 |  0:33:41s\n",
            "epoch 1702| loss: 0.73987 | train_accuracy: 0.64592 | val_accuracy: 0.52659 |  0:33:42s\n",
            "epoch 1703| loss: 0.73027 | train_accuracy: 0.64348 | val_accuracy: 0.52099 |  0:33:43s\n",
            "epoch 1704| loss: 0.7342  | train_accuracy: 0.64459 | val_accuracy: 0.52659 |  0:33:44s\n",
            "epoch 1705| loss: 0.73845 | train_accuracy: 0.64503 | val_accuracy: 0.52059 |  0:33:46s\n",
            "epoch 1706| loss: 0.74366 | train_accuracy: 0.64445 | val_accuracy: 0.52579 |  0:33:47s\n",
            "epoch 1707| loss: 0.75028 | train_accuracy: 0.63983 | val_accuracy: 0.51299 |  0:33:48s\n",
            "epoch 1708| loss: 0.74508 | train_accuracy: 0.6429  | val_accuracy: 0.52699 |  0:33:49s\n",
            "epoch 1709| loss: 0.74677 | train_accuracy: 0.64299 | val_accuracy: 0.52459 |  0:33:50s\n",
            "epoch 1710| loss: 0.74228 | train_accuracy: 0.64383 | val_accuracy: 0.52019 |  0:33:52s\n",
            "epoch 1711| loss: 0.73623 | train_accuracy: 0.64534 | val_accuracy: 0.52019 |  0:33:53s\n",
            "epoch 1712| loss: 0.73431 | train_accuracy: 0.64161 | val_accuracy: 0.52899 |  0:33:54s\n",
            "epoch 1713| loss: 0.73662 | train_accuracy: 0.64374 | val_accuracy: 0.51699 |  0:33:55s\n",
            "epoch 1714| loss: 0.73612 | train_accuracy: 0.6469  | val_accuracy: 0.52019 |  0:33:56s\n",
            "epoch 1715| loss: 0.73013 | train_accuracy: 0.64894 | val_accuracy: 0.52339 |  0:33:58s\n",
            "epoch 1716| loss: 0.72858 | train_accuracy: 0.64881 | val_accuracy: 0.52099 |  0:33:59s\n",
            "epoch 1717| loss: 0.73156 | train_accuracy: 0.64832 | val_accuracy: 0.51939 |  0:34:00s\n",
            "epoch 1718| loss: 0.72895 | train_accuracy: 0.6457  | val_accuracy: 0.51779 |  0:34:01s\n",
            "epoch 1719| loss: 0.73225 | train_accuracy: 0.64592 | val_accuracy: 0.52099 |  0:34:02s\n",
            "epoch 1720| loss: 0.736   | train_accuracy: 0.64574 | val_accuracy: 0.51779 |  0:34:04s\n",
            "epoch 1721| loss: 0.73064 | train_accuracy: 0.64445 | val_accuracy: 0.51979 |  0:34:05s\n",
            "epoch 1722| loss: 0.7313  | train_accuracy: 0.64339 | val_accuracy: 0.51819 |  0:34:06s\n",
            "epoch 1723| loss: 0.73341 | train_accuracy: 0.64272 | val_accuracy: 0.5078  |  0:34:07s\n",
            "epoch 1724| loss: 0.7345  | train_accuracy: 0.64561 | val_accuracy: 0.52539 |  0:34:08s\n",
            "epoch 1725| loss: 0.73691 | train_accuracy: 0.64361 | val_accuracy: 0.52419 |  0:34:10s\n",
            "epoch 1726| loss: 0.73684 | train_accuracy: 0.64165 | val_accuracy: 0.5114  |  0:34:11s\n",
            "epoch 1727| loss: 0.73218 | train_accuracy: 0.64343 | val_accuracy: 0.5114  |  0:34:12s\n",
            "epoch 1728| loss: 0.73113 | train_accuracy: 0.64636 | val_accuracy: 0.51379 |  0:34:13s\n",
            "epoch 1729| loss: 0.73397 | train_accuracy: 0.64765 | val_accuracy: 0.51979 |  0:34:14s\n",
            "epoch 1730| loss: 0.72979 | train_accuracy: 0.64712 | val_accuracy: 0.51579 |  0:34:16s\n",
            "epoch 1731| loss: 0.72953 | train_accuracy: 0.64494 | val_accuracy: 0.51659 |  0:34:17s\n",
            "epoch 1732| loss: 0.72964 | train_accuracy: 0.64454 | val_accuracy: 0.51579 |  0:34:18s\n",
            "epoch 1733| loss: 0.73007 | train_accuracy: 0.64476 | val_accuracy: 0.51779 |  0:34:19s\n",
            "epoch 1734| loss: 0.73457 | train_accuracy: 0.64676 | val_accuracy: 0.52379 |  0:34:20s\n",
            "epoch 1735| loss: 0.73567 | train_accuracy: 0.64392 | val_accuracy: 0.53179 |  0:34:21s\n",
            "epoch 1736| loss: 0.73142 | train_accuracy: 0.64556 | val_accuracy: 0.52779 |  0:34:23s\n",
            "epoch 1737| loss: 0.72646 | train_accuracy: 0.64663 | val_accuracy: 0.53299 |  0:34:24s\n",
            "epoch 1738| loss: 0.73205 | train_accuracy: 0.64685 | val_accuracy: 0.53139 |  0:34:25s\n",
            "epoch 1739| loss: 0.73063 | train_accuracy: 0.64592 | val_accuracy: 0.52699 |  0:34:26s\n",
            "epoch 1740| loss: 0.72455 | train_accuracy: 0.65014 | val_accuracy: 0.52859 |  0:34:27s\n",
            "epoch 1741| loss: 0.72858 | train_accuracy: 0.6489  | val_accuracy: 0.53179 |  0:34:29s\n",
            "epoch 1742| loss: 0.72811 | train_accuracy: 0.64938 | val_accuracy: 0.52259 |  0:34:30s\n",
            "epoch 1743| loss: 0.72396 | train_accuracy: 0.65143 | val_accuracy: 0.52379 |  0:34:31s\n",
            "epoch 1744| loss: 0.71919 | train_accuracy: 0.64832 | val_accuracy: 0.52139 |  0:34:32s\n",
            "epoch 1745| loss: 0.72867 | train_accuracy: 0.65032 | val_accuracy: 0.51499 |  0:34:33s\n",
            "epoch 1746| loss: 0.72595 | train_accuracy: 0.64703 | val_accuracy: 0.52099 |  0:34:35s\n",
            "epoch 1747| loss: 0.72781 | train_accuracy: 0.65085 | val_accuracy: 0.51899 |  0:34:36s\n",
            "epoch 1748| loss: 0.72346 | train_accuracy: 0.64961 | val_accuracy: 0.52859 |  0:34:37s\n",
            "epoch 1749| loss: 0.72845 | train_accuracy: 0.65156 | val_accuracy: 0.52419 |  0:34:38s\n",
            "epoch 1750| loss: 0.72642 | train_accuracy: 0.65352 | val_accuracy: 0.51539 |  0:34:39s\n",
            "epoch 1751| loss: 0.72137 | train_accuracy: 0.65392 | val_accuracy: 0.51739 |  0:34:40s\n",
            "epoch 1752| loss: 0.72419 | train_accuracy: 0.65076 | val_accuracy: 0.52539 |  0:34:42s\n",
            "epoch 1753| loss: 0.72117 | train_accuracy: 0.65463 | val_accuracy: 0.53219 |  0:34:43s\n",
            "epoch 1754| loss: 0.72339 | train_accuracy: 0.65365 | val_accuracy: 0.52539 |  0:34:44s\n",
            "epoch 1755| loss: 0.72065 | train_accuracy: 0.65303 | val_accuracy: 0.52059 |  0:34:45s\n",
            "epoch 1756| loss: 0.72141 | train_accuracy: 0.65347 | val_accuracy: 0.52019 |  0:34:46s\n",
            "epoch 1757| loss: 0.71936 | train_accuracy: 0.6493  | val_accuracy: 0.52339 |  0:34:47s\n",
            "epoch 1758| loss: 0.73006 | train_accuracy: 0.64605 | val_accuracy: 0.52019 |  0:34:49s\n",
            "epoch 1759| loss: 0.72599 | train_accuracy: 0.64743 | val_accuracy: 0.51659 |  0:34:50s\n",
            "epoch 1760| loss: 0.72384 | train_accuracy: 0.64779 | val_accuracy: 0.52339 |  0:34:51s\n",
            "epoch 1761| loss: 0.7289  | train_accuracy: 0.65001 | val_accuracy: 0.51459 |  0:34:52s\n",
            "epoch 1762| loss: 0.72467 | train_accuracy: 0.65125 | val_accuracy: 0.52459 |  0:34:53s\n",
            "epoch 1763| loss: 0.72739 | train_accuracy: 0.64436 | val_accuracy: 0.51979 |  0:34:55s\n",
            "epoch 1764| loss: 0.73408 | train_accuracy: 0.64476 | val_accuracy: 0.52579 |  0:34:56s\n",
            "epoch 1765| loss: 0.73552 | train_accuracy: 0.64525 | val_accuracy: 0.52419 |  0:34:57s\n",
            "epoch 1766| loss: 0.73655 | train_accuracy: 0.6425  | val_accuracy: 0.52459 |  0:34:58s\n",
            "epoch 1767| loss: 0.74126 | train_accuracy: 0.64028 | val_accuracy: 0.52419 |  0:34:59s\n",
            "epoch 1768| loss: 0.7405  | train_accuracy: 0.64139 | val_accuracy: 0.51499 |  0:35:00s\n",
            "epoch 1769| loss: 0.73687 | train_accuracy: 0.64396 | val_accuracy: 0.51579 |  0:35:02s\n",
            "epoch 1770| loss: 0.7377  | train_accuracy: 0.63948 | val_accuracy: 0.5086  |  0:35:03s\n",
            "epoch 1771| loss: 0.73718 | train_accuracy: 0.64379 | val_accuracy: 0.52139 |  0:35:04s\n",
            "epoch 1772| loss: 0.73767 | train_accuracy: 0.64259 | val_accuracy: 0.51699 |  0:35:05s\n",
            "epoch 1773| loss: 0.73767 | train_accuracy: 0.64627 | val_accuracy: 0.52019 |  0:35:06s\n",
            "epoch 1774| loss: 0.73379 | train_accuracy: 0.64334 | val_accuracy: 0.51819 |  0:35:07s\n",
            "epoch 1775| loss: 0.73415 | train_accuracy: 0.64916 | val_accuracy: 0.52299 |  0:35:09s\n",
            "epoch 1776| loss: 0.73406 | train_accuracy: 0.64521 | val_accuracy: 0.51979 |  0:35:10s\n",
            "epoch 1777| loss: 0.72844 | train_accuracy: 0.64912 | val_accuracy: 0.52259 |  0:35:11s\n",
            "epoch 1778| loss: 0.72691 | train_accuracy: 0.64725 | val_accuracy: 0.51899 |  0:35:12s\n",
            "epoch 1779| loss: 0.73011 | train_accuracy: 0.64952 | val_accuracy: 0.52659 |  0:35:13s\n",
            "epoch 1780| loss: 0.72497 | train_accuracy: 0.64801 | val_accuracy: 0.52019 |  0:35:15s\n",
            "epoch 1781| loss: 0.72526 | train_accuracy: 0.64956 | val_accuracy: 0.51779 |  0:35:16s\n",
            "epoch 1782| loss: 0.72332 | train_accuracy: 0.65063 | val_accuracy: 0.51859 |  0:35:17s\n",
            "epoch 1783| loss: 0.72433 | train_accuracy: 0.64916 | val_accuracy: 0.52019 |  0:35:18s\n",
            "epoch 1784| loss: 0.72497 | train_accuracy: 0.64872 | val_accuracy: 0.52139 |  0:35:19s\n",
            "epoch 1785| loss: 0.72348 | train_accuracy: 0.64739 | val_accuracy: 0.52379 |  0:35:21s\n",
            "epoch 1786| loss: 0.72389 | train_accuracy: 0.65014 | val_accuracy: 0.51939 |  0:35:22s\n",
            "epoch 1787| loss: 0.72201 | train_accuracy: 0.65169 | val_accuracy: 0.52539 |  0:35:23s\n",
            "epoch 1788| loss: 0.7252  | train_accuracy: 0.65098 | val_accuracy: 0.52459 |  0:35:24s\n",
            "epoch 1789| loss: 0.72229 | train_accuracy: 0.64801 | val_accuracy: 0.52299 |  0:35:25s\n",
            "epoch 1790| loss: 0.72573 | train_accuracy: 0.64836 | val_accuracy: 0.51979 |  0:35:27s\n",
            "epoch 1791| loss: 0.72476 | train_accuracy: 0.64934 | val_accuracy: 0.51859 |  0:35:28s\n",
            "epoch 1792| loss: 0.72907 | train_accuracy: 0.64388 | val_accuracy: 0.52179 |  0:35:29s\n",
            "epoch 1793| loss: 0.7257  | train_accuracy: 0.65085 | val_accuracy: 0.52379 |  0:35:30s\n",
            "epoch 1794| loss: 0.72381 | train_accuracy: 0.65236 | val_accuracy: 0.52339 |  0:35:31s\n",
            "epoch 1795| loss: 0.71733 | train_accuracy: 0.64987 | val_accuracy: 0.51699 |  0:35:32s\n",
            "epoch 1796| loss: 0.7228  | train_accuracy: 0.65045 | val_accuracy: 0.52339 |  0:35:34s\n",
            "epoch 1797| loss: 0.72192 | train_accuracy: 0.65227 | val_accuracy: 0.52419 |  0:35:35s\n",
            "epoch 1798| loss: 0.71794 | train_accuracy: 0.65156 | val_accuracy: 0.52499 |  0:35:36s\n",
            "epoch 1799| loss: 0.7232  | train_accuracy: 0.65121 | val_accuracy: 0.52619 |  0:35:37s\n",
            "epoch 1800| loss: 0.72179 | train_accuracy: 0.65143 | val_accuracy: 0.52179 |  0:35:38s\n",
            "epoch 1801| loss: 0.72219 | train_accuracy: 0.64956 | val_accuracy: 0.51819 |  0:35:40s\n",
            "epoch 1802| loss: 0.72758 | train_accuracy: 0.64992 | val_accuracy: 0.53059 |  0:35:41s\n",
            "epoch 1803| loss: 0.72374 | train_accuracy: 0.64952 | val_accuracy: 0.51979 |  0:35:42s\n",
            "epoch 1804| loss: 0.72674 | train_accuracy: 0.65085 | val_accuracy: 0.52659 |  0:35:43s\n",
            "epoch 1805| loss: 0.72735 | train_accuracy: 0.64859 | val_accuracy: 0.52899 |  0:35:44s\n",
            "epoch 1806| loss: 0.72422 | train_accuracy: 0.64725 | val_accuracy: 0.51859 |  0:35:46s\n",
            "epoch 1807| loss: 0.72262 | train_accuracy: 0.64845 | val_accuracy: 0.51739 |  0:35:47s\n",
            "epoch 1808| loss: 0.72754 | train_accuracy: 0.64996 | val_accuracy: 0.52299 |  0:35:48s\n",
            "epoch 1809| loss: 0.72234 | train_accuracy: 0.64752 | val_accuracy: 0.52139 |  0:35:49s\n",
            "epoch 1810| loss: 0.72653 | train_accuracy: 0.65107 | val_accuracy: 0.52739 |  0:35:50s\n",
            "epoch 1811| loss: 0.72272 | train_accuracy: 0.65374 | val_accuracy: 0.52139 |  0:35:52s\n",
            "epoch 1812| loss: 0.72781 | train_accuracy: 0.65023 | val_accuracy: 0.52939 |  0:35:53s\n",
            "epoch 1813| loss: 0.7256  | train_accuracy: 0.64912 | val_accuracy: 0.51899 |  0:35:54s\n",
            "epoch 1814| loss: 0.7318  | train_accuracy: 0.64534 | val_accuracy: 0.511   |  0:35:55s\n",
            "epoch 1815| loss: 0.72916 | train_accuracy: 0.64956 | val_accuracy: 0.51659 |  0:35:56s\n",
            "epoch 1816| loss: 0.72902 | train_accuracy: 0.64921 | val_accuracy: 0.51819 |  0:35:58s\n",
            "epoch 1817| loss: 0.72687 | train_accuracy: 0.65107 | val_accuracy: 0.51899 |  0:35:59s\n",
            "epoch 1818| loss: 0.7303  | train_accuracy: 0.65116 | val_accuracy: 0.51579 |  0:36:00s\n",
            "epoch 1819| loss: 0.72617 | train_accuracy: 0.64898 | val_accuracy: 0.51579 |  0:36:01s\n",
            "epoch 1820| loss: 0.72812 | train_accuracy: 0.65001 | val_accuracy: 0.52339 |  0:36:02s\n",
            "epoch 1821| loss: 0.73386 | train_accuracy: 0.64961 | val_accuracy: 0.51859 |  0:36:03s\n",
            "epoch 1822| loss: 0.7311  | train_accuracy: 0.64859 | val_accuracy: 0.52899 |  0:36:05s\n",
            "epoch 1823| loss: 0.73457 | train_accuracy: 0.6497  | val_accuracy: 0.52139 |  0:36:06s\n",
            "epoch 1824| loss: 0.73653 | train_accuracy: 0.64667 | val_accuracy: 0.51659 |  0:36:07s\n",
            "epoch 1825| loss: 0.72818 | train_accuracy: 0.65027 | val_accuracy: 0.51939 |  0:36:08s\n",
            "epoch 1826| loss: 0.72677 | train_accuracy: 0.65214 | val_accuracy: 0.52579 |  0:36:09s\n",
            "epoch 1827| loss: 0.7208  | train_accuracy: 0.65356 | val_accuracy: 0.52459 |  0:36:11s\n",
            "epoch 1828| loss: 0.72453 | train_accuracy: 0.65147 | val_accuracy: 0.52619 |  0:36:12s\n",
            "epoch 1829| loss: 0.72158 | train_accuracy: 0.65081 | val_accuracy: 0.52299 |  0:36:13s\n",
            "epoch 1830| loss: 0.71752 | train_accuracy: 0.65045 | val_accuracy: 0.52339 |  0:36:14s\n",
            "epoch 1831| loss: 0.7203  | train_accuracy: 0.65072 | val_accuracy: 0.52499 |  0:36:15s\n",
            "epoch 1832| loss: 0.72457 | train_accuracy: 0.64872 | val_accuracy: 0.51939 |  0:36:17s\n",
            "epoch 1833| loss: 0.72631 | train_accuracy: 0.65094 | val_accuracy: 0.52699 |  0:36:18s\n",
            "epoch 1834| loss: 0.7247  | train_accuracy: 0.65134 | val_accuracy: 0.52539 |  0:36:19s\n",
            "epoch 1835| loss: 0.7277  | train_accuracy: 0.65027 | val_accuracy: 0.52659 |  0:36:20s\n",
            "epoch 1836| loss: 0.72296 | train_accuracy: 0.64987 | val_accuracy: 0.52539 |  0:36:21s\n",
            "epoch 1837| loss: 0.72629 | train_accuracy: 0.65094 | val_accuracy: 0.52819 |  0:36:23s\n",
            "epoch 1838| loss: 0.72711 | train_accuracy: 0.64983 | val_accuracy: 0.52259 |  0:36:24s\n",
            "epoch 1839| loss: 0.7305  | train_accuracy: 0.65125 | val_accuracy: 0.51819 |  0:36:25s\n",
            "epoch 1840| loss: 0.73022 | train_accuracy: 0.65085 | val_accuracy: 0.52019 |  0:36:26s\n",
            "epoch 1841| loss: 0.72778 | train_accuracy: 0.65072 | val_accuracy: 0.52339 |  0:36:27s\n",
            "epoch 1842| loss: 0.72679 | train_accuracy: 0.65267 | val_accuracy: 0.52979 |  0:36:29s\n",
            "epoch 1843| loss: 0.72946 | train_accuracy: 0.65121 | val_accuracy: 0.52459 |  0:36:30s\n",
            "epoch 1844| loss: 0.7235  | train_accuracy: 0.65178 | val_accuracy: 0.52499 |  0:36:31s\n",
            "epoch 1845| loss: 0.72563 | train_accuracy: 0.6513  | val_accuracy: 0.51539 |  0:36:32s\n",
            "epoch 1846| loss: 0.73531 | train_accuracy: 0.64734 | val_accuracy: 0.52179 |  0:36:34s\n",
            "epoch 1847| loss: 0.73414 | train_accuracy: 0.64872 | val_accuracy: 0.52379 |  0:36:35s\n",
            "epoch 1848| loss: 0.72851 | train_accuracy: 0.64885 | val_accuracy: 0.52379 |  0:36:36s\n",
            "epoch 1849| loss: 0.72381 | train_accuracy: 0.65183 | val_accuracy: 0.51779 |  0:36:37s\n",
            "epoch 1850| loss: 0.72426 | train_accuracy: 0.65178 | val_accuracy: 0.51459 |  0:36:38s\n",
            "epoch 1851| loss: 0.72302 | train_accuracy: 0.65134 | val_accuracy: 0.5114  |  0:36:40s\n",
            "epoch 1852| loss: 0.72266 | train_accuracy: 0.65334 | val_accuracy: 0.51699 |  0:36:41s\n",
            "epoch 1853| loss: 0.7242  | train_accuracy: 0.65281 | val_accuracy: 0.51659 |  0:36:42s\n",
            "epoch 1854| loss: 0.71858 | train_accuracy: 0.65227 | val_accuracy: 0.52019 |  0:36:43s\n",
            "epoch 1855| loss: 0.71992 | train_accuracy: 0.65374 | val_accuracy: 0.51619 |  0:36:44s\n",
            "epoch 1856| loss: 0.71492 | train_accuracy: 0.65307 | val_accuracy: 0.51939 |  0:36:45s\n",
            "epoch 1857| loss: 0.71683 | train_accuracy: 0.65396 | val_accuracy: 0.51339 |  0:36:47s\n",
            "epoch 1858| loss: 0.71551 | train_accuracy: 0.65396 | val_accuracy: 0.51779 |  0:36:48s\n",
            "epoch 1859| loss: 0.71845 | train_accuracy: 0.65427 | val_accuracy: 0.51579 |  0:36:49s\n",
            "epoch 1860| loss: 0.71865 | train_accuracy: 0.65374 | val_accuracy: 0.52099 |  0:36:50s\n",
            "epoch 1861| loss: 0.71694 | train_accuracy: 0.65352 | val_accuracy: 0.52419 |  0:36:51s\n",
            "epoch 1862| loss: 0.71464 | train_accuracy: 0.65627 | val_accuracy: 0.52739 |  0:36:52s\n",
            "epoch 1863| loss: 0.71364 | train_accuracy: 0.65423 | val_accuracy: 0.51819 |  0:36:54s\n",
            "epoch 1864| loss: 0.71584 | train_accuracy: 0.65338 | val_accuracy: 0.5106  |  0:36:55s\n",
            "epoch 1865| loss: 0.71966 | train_accuracy: 0.65254 | val_accuracy: 0.52059 |  0:36:56s\n",
            "epoch 1866| loss: 0.72366 | train_accuracy: 0.65267 | val_accuracy: 0.52019 |  0:36:57s\n",
            "epoch 1867| loss: 0.72043 | train_accuracy: 0.65432 | val_accuracy: 0.52459 |  0:36:58s\n",
            "epoch 1868| loss: 0.72038 | train_accuracy: 0.65378 | val_accuracy: 0.52339 |  0:36:59s\n",
            "epoch 1869| loss: 0.71881 | train_accuracy: 0.65396 | val_accuracy: 0.52579 |  0:37:01s\n",
            "epoch 1870| loss: 0.72105 | train_accuracy: 0.65218 | val_accuracy: 0.51859 |  0:37:02s\n",
            "epoch 1871| loss: 0.72328 | train_accuracy: 0.65423 | val_accuracy: 0.51939 |  0:37:03s\n",
            "epoch 1872| loss: 0.72157 | train_accuracy: 0.65432 | val_accuracy: 0.52139 |  0:37:04s\n",
            "epoch 1873| loss: 0.71871 | train_accuracy: 0.65556 | val_accuracy: 0.52619 |  0:37:05s\n",
            "epoch 1874| loss: 0.72024 | train_accuracy: 0.65498 | val_accuracy: 0.52299 |  0:37:07s\n",
            "epoch 1875| loss: 0.72102 | train_accuracy: 0.65423 | val_accuracy: 0.51459 |  0:37:08s\n",
            "epoch 1876| loss: 0.72066 | train_accuracy: 0.65356 | val_accuracy: 0.52059 |  0:37:09s\n",
            "epoch 1877| loss: 0.71941 | train_accuracy: 0.65387 | val_accuracy: 0.51299 |  0:37:10s\n",
            "epoch 1878| loss: 0.71957 | train_accuracy: 0.65334 | val_accuracy: 0.51459 |  0:37:11s\n",
            "epoch 1879| loss: 0.71846 | train_accuracy: 0.65698 | val_accuracy: 0.51619 |  0:37:12s\n",
            "epoch 1880| loss: 0.7178  | train_accuracy: 0.65414 | val_accuracy: 0.51379 |  0:37:14s\n",
            "epoch 1881| loss: 0.71904 | train_accuracy: 0.65201 | val_accuracy: 0.51499 |  0:37:15s\n",
            "epoch 1882| loss: 0.71646 | train_accuracy: 0.65587 | val_accuracy: 0.51339 |  0:37:16s\n",
            "epoch 1883| loss: 0.72055 | train_accuracy: 0.65556 | val_accuracy: 0.51379 |  0:37:17s\n",
            "epoch 1884| loss: 0.72776 | train_accuracy: 0.65267 | val_accuracy: 0.51499 |  0:37:18s\n",
            "epoch 1885| loss: 0.72662 | train_accuracy: 0.65236 | val_accuracy: 0.51619 |  0:37:20s\n",
            "epoch 1886| loss: 0.72196 | train_accuracy: 0.65489 | val_accuracy: 0.51699 |  0:37:21s\n",
            "epoch 1887| loss: 0.71889 | train_accuracy: 0.65765 | val_accuracy: 0.5106  |  0:37:22s\n",
            "epoch 1888| loss: 0.71562 | train_accuracy: 0.65547 | val_accuracy: 0.5058  |  0:37:23s\n",
            "epoch 1889| loss: 0.72266 | train_accuracy: 0.65778 | val_accuracy: 0.5106  |  0:37:24s\n",
            "epoch 1890| loss: 0.72135 | train_accuracy: 0.65187 | val_accuracy: 0.5122  |  0:37:26s\n",
            "epoch 1891| loss: 0.71573 | train_accuracy: 0.65467 | val_accuracy: 0.51299 |  0:37:27s\n",
            "epoch 1892| loss: 0.71835 | train_accuracy: 0.65583 | val_accuracy: 0.52059 |  0:37:28s\n",
            "epoch 1893| loss: 0.7204  | train_accuracy: 0.6568  | val_accuracy: 0.51619 |  0:37:29s\n",
            "epoch 1894| loss: 0.72289 | train_accuracy: 0.65765 | val_accuracy: 0.51859 |  0:37:30s\n",
            "epoch 1895| loss: 0.71833 | train_accuracy: 0.65516 | val_accuracy: 0.51539 |  0:37:31s\n",
            "epoch 1896| loss: 0.71795 | train_accuracy: 0.658   | val_accuracy: 0.52659 |  0:37:33s\n",
            "epoch 1897| loss: 0.71739 | train_accuracy: 0.65867 | val_accuracy: 0.52459 |  0:37:34s\n",
            "epoch 1898| loss: 0.71669 | train_accuracy: 0.6576  | val_accuracy: 0.51859 |  0:37:35s\n",
            "epoch 1899| loss: 0.71212 | train_accuracy: 0.65996 | val_accuracy: 0.51619 |  0:37:36s\n",
            "epoch 1900| loss: 0.71227 | train_accuracy: 0.65729 | val_accuracy: 0.51659 |  0:37:37s\n",
            "epoch 1901| loss: 0.71634 | train_accuracy: 0.65409 | val_accuracy: 0.52339 |  0:37:39s\n",
            "epoch 1902| loss: 0.7119  | train_accuracy: 0.65454 | val_accuracy: 0.51579 |  0:37:40s\n",
            "epoch 1903| loss: 0.72137 | train_accuracy: 0.6564  | val_accuracy: 0.51979 |  0:37:41s\n",
            "epoch 1904| loss: 0.71697 | train_accuracy: 0.65623 | val_accuracy: 0.52019 |  0:37:42s\n",
            "epoch 1905| loss: 0.72369 | train_accuracy: 0.65667 | val_accuracy: 0.51819 |  0:37:43s\n",
            "epoch 1906| loss: 0.7164  | train_accuracy: 0.65458 | val_accuracy: 0.52259 |  0:37:45s\n",
            "epoch 1907| loss: 0.71587 | train_accuracy: 0.65294 | val_accuracy: 0.52019 |  0:37:46s\n",
            "epoch 1908| loss: 0.71271 | train_accuracy: 0.65809 | val_accuracy: 0.51859 |  0:37:47s\n",
            "epoch 1909| loss: 0.71561 | train_accuracy: 0.65609 | val_accuracy: 0.52259 |  0:37:48s\n",
            "epoch 1910| loss: 0.71227 | train_accuracy: 0.6588  | val_accuracy: 0.52139 |  0:37:49s\n",
            "epoch 1911| loss: 0.7104  | train_accuracy: 0.65831 | val_accuracy: 0.51899 |  0:37:51s\n",
            "epoch 1912| loss: 0.71518 | train_accuracy: 0.65667 | val_accuracy: 0.51979 |  0:37:52s\n",
            "epoch 1913| loss: 0.72435 | train_accuracy: 0.65831 | val_accuracy: 0.52499 |  0:37:53s\n",
            "epoch 1914| loss: 0.72326 | train_accuracy: 0.65685 | val_accuracy: 0.51819 |  0:37:54s\n",
            "epoch 1915| loss: 0.72191 | train_accuracy: 0.65574 | val_accuracy: 0.52459 |  0:37:55s\n",
            "epoch 1916| loss: 0.71876 | train_accuracy: 0.65547 | val_accuracy: 0.52499 |  0:37:57s\n",
            "epoch 1917| loss: 0.71857 | train_accuracy: 0.65889 | val_accuracy: 0.52459 |  0:37:58s\n",
            "epoch 1918| loss: 0.71689 | train_accuracy: 0.6596  | val_accuracy: 0.52059 |  0:37:59s\n",
            "epoch 1919| loss: 0.71693 | train_accuracy: 0.65867 | val_accuracy: 0.52099 |  0:38:00s\n",
            "epoch 1920| loss: 0.71841 | train_accuracy: 0.65774 | val_accuracy: 0.51859 |  0:38:01s\n",
            "epoch 1921| loss: 0.71818 | train_accuracy: 0.65823 | val_accuracy: 0.52059 |  0:38:03s\n",
            "epoch 1922| loss: 0.71736 | train_accuracy: 0.65951 | val_accuracy: 0.52339 |  0:38:04s\n",
            "epoch 1923| loss: 0.7154  | train_accuracy: 0.65898 | val_accuracy: 0.52179 |  0:38:05s\n",
            "epoch 1924| loss: 0.72072 | train_accuracy: 0.6544  | val_accuracy: 0.51779 |  0:38:06s\n",
            "epoch 1925| loss: 0.71448 | train_accuracy: 0.65858 | val_accuracy: 0.52099 |  0:38:07s\n",
            "epoch 1926| loss: 0.71564 | train_accuracy: 0.66049 | val_accuracy: 0.51899 |  0:38:09s\n",
            "epoch 1927| loss: 0.71632 | train_accuracy: 0.65711 | val_accuracy: 0.52419 |  0:38:10s\n",
            "epoch 1928| loss: 0.71524 | train_accuracy: 0.65996 | val_accuracy: 0.52419 |  0:38:11s\n",
            "epoch 1929| loss: 0.71478 | train_accuracy: 0.66071 | val_accuracy: 0.51859 |  0:38:12s\n",
            "epoch 1930| loss: 0.71398 | train_accuracy: 0.66031 | val_accuracy: 0.51579 |  0:38:14s\n",
            "epoch 1931| loss: 0.71229 | train_accuracy: 0.66329 | val_accuracy: 0.52939 |  0:38:15s\n",
            "epoch 1932| loss: 0.71082 | train_accuracy: 0.65938 | val_accuracy: 0.52499 |  0:38:16s\n",
            "epoch 1933| loss: 0.71592 | train_accuracy: 0.65845 | val_accuracy: 0.52659 |  0:38:17s\n",
            "epoch 1934| loss: 0.71105 | train_accuracy: 0.66111 | val_accuracy: 0.53379 |  0:38:18s\n",
            "epoch 1935| loss: 0.71733 | train_accuracy: 0.65982 | val_accuracy: 0.53139 |  0:38:19s\n",
            "epoch 1936| loss: 0.71543 | train_accuracy: 0.66022 | val_accuracy: 0.53219 |  0:38:21s\n",
            "epoch 1937| loss: 0.71085 | train_accuracy: 0.65885 | val_accuracy: 0.52699 |  0:38:22s\n",
            "epoch 1938| loss: 0.71127 | train_accuracy: 0.66058 | val_accuracy: 0.52299 |  0:38:23s\n",
            "epoch 1939| loss: 0.71067 | train_accuracy: 0.65858 | val_accuracy: 0.52019 |  0:38:24s\n",
            "epoch 1940| loss: 0.71184 | train_accuracy: 0.65898 | val_accuracy: 0.52579 |  0:38:25s\n",
            "epoch 1941| loss: 0.71141 | train_accuracy: 0.66151 | val_accuracy: 0.53059 |  0:38:27s\n",
            "epoch 1942| loss: 0.70951 | train_accuracy: 0.65911 | val_accuracy: 0.52579 |  0:38:28s\n",
            "epoch 1943| loss: 0.71288 | train_accuracy: 0.66373 | val_accuracy: 0.53259 |  0:38:29s\n",
            "epoch 1944| loss: 0.70962 | train_accuracy: 0.65854 | val_accuracy: 0.51979 |  0:38:30s\n",
            "epoch 1945| loss: 0.71686 | train_accuracy: 0.65987 | val_accuracy: 0.53259 |  0:38:31s\n",
            "epoch 1946| loss: 0.70861 | train_accuracy: 0.66134 | val_accuracy: 0.52019 |  0:38:33s\n",
            "epoch 1947| loss: 0.71421 | train_accuracy: 0.66094 | val_accuracy: 0.52179 |  0:38:34s\n",
            "epoch 1948| loss: 0.71292 | train_accuracy: 0.65871 | val_accuracy: 0.52539 |  0:38:35s\n",
            "epoch 1949| loss: 0.71804 | train_accuracy: 0.66005 | val_accuracy: 0.52099 |  0:38:36s\n",
            "epoch 1950| loss: 0.71145 | train_accuracy: 0.65996 | val_accuracy: 0.52859 |  0:38:37s\n",
            "epoch 1951| loss: 0.71955 | train_accuracy: 0.65663 | val_accuracy: 0.51699 |  0:38:39s\n",
            "epoch 1952| loss: 0.7162  | train_accuracy: 0.65516 | val_accuracy: 0.53059 |  0:38:40s\n",
            "epoch 1953| loss: 0.71422 | train_accuracy: 0.65738 | val_accuracy: 0.52179 |  0:38:41s\n",
            "epoch 1954| loss: 0.71364 | train_accuracy: 0.66125 | val_accuracy: 0.53499 |  0:38:42s\n",
            "epoch 1955| loss: 0.70939 | train_accuracy: 0.66102 | val_accuracy: 0.52739 |  0:38:43s\n",
            "epoch 1956| loss: 0.71198 | train_accuracy: 0.66187 | val_accuracy: 0.52739 |  0:38:45s\n",
            "epoch 1957| loss: 0.71268 | train_accuracy: 0.66089 | val_accuracy: 0.52579 |  0:38:46s\n",
            "epoch 1958| loss: 0.70786 | train_accuracy: 0.66347 | val_accuracy: 0.53379 |  0:38:47s\n",
            "epoch 1959| loss: 0.70829 | train_accuracy: 0.66089 | val_accuracy: 0.52859 |  0:38:48s\n",
            "epoch 1960| loss: 0.71613 | train_accuracy: 0.66245 | val_accuracy: 0.52939 |  0:38:49s\n",
            "epoch 1961| loss: 0.70604 | train_accuracy: 0.66111 | val_accuracy: 0.52939 |  0:38:51s\n",
            "epoch 1962| loss: 0.70841 | train_accuracy: 0.66205 | val_accuracy: 0.52579 |  0:38:52s\n",
            "epoch 1963| loss: 0.70748 | train_accuracy: 0.66182 | val_accuracy: 0.52939 |  0:38:53s\n",
            "epoch 1964| loss: 0.7104  | train_accuracy: 0.65987 | val_accuracy: 0.52779 |  0:38:54s\n",
            "epoch 1965| loss: 0.71325 | train_accuracy: 0.65889 | val_accuracy: 0.52819 |  0:38:55s\n",
            "epoch 1966| loss: 0.71071 | train_accuracy: 0.65711 | val_accuracy: 0.53139 |  0:38:56s\n",
            "epoch 1967| loss: 0.71788 | train_accuracy: 0.65747 | val_accuracy: 0.52339 |  0:38:58s\n",
            "epoch 1968| loss: 0.71884 | train_accuracy: 0.65854 | val_accuracy: 0.53259 |  0:38:59s\n",
            "epoch 1969| loss: 0.7202  | train_accuracy: 0.65534 | val_accuracy: 0.52539 |  0:39:00s\n",
            "epoch 1970| loss: 0.71578 | train_accuracy: 0.658   | val_accuracy: 0.52499 |  0:39:01s\n",
            "epoch 1971| loss: 0.71688 | train_accuracy: 0.65769 | val_accuracy: 0.52299 |  0:39:02s\n",
            "epoch 1972| loss: 0.71954 | train_accuracy: 0.65645 | val_accuracy: 0.52699 |  0:39:04s\n",
            "epoch 1973| loss: 0.71985 | train_accuracy: 0.65765 | val_accuracy: 0.52979 |  0:39:05s\n",
            "epoch 1974| loss: 0.71755 | train_accuracy: 0.65991 | val_accuracy: 0.52659 |  0:39:06s\n",
            "epoch 1975| loss: 0.71791 | train_accuracy: 0.65392 | val_accuracy: 0.52819 |  0:39:07s\n",
            "epoch 1976| loss: 0.7207  | train_accuracy: 0.65547 | val_accuracy: 0.52659 |  0:39:09s\n",
            "epoch 1977| loss: 0.7169  | train_accuracy: 0.65361 | val_accuracy: 0.52619 |  0:39:10s\n",
            "epoch 1978| loss: 0.7195  | train_accuracy: 0.65609 | val_accuracy: 0.53219 |  0:39:11s\n",
            "epoch 1979| loss: 0.71808 | train_accuracy: 0.65245 | val_accuracy: 0.52699 |  0:39:12s\n",
            "epoch 1980| loss: 0.71948 | train_accuracy: 0.65418 | val_accuracy: 0.52539 |  0:39:13s\n",
            "epoch 1981| loss: 0.72187 | train_accuracy: 0.65609 | val_accuracy: 0.52459 |  0:39:15s\n",
            "epoch 1982| loss: 0.71455 | train_accuracy: 0.65556 | val_accuracy: 0.52139 |  0:39:16s\n",
            "epoch 1983| loss: 0.7174  | train_accuracy: 0.65405 | val_accuracy: 0.51939 |  0:39:17s\n",
            "epoch 1984| loss: 0.71769 | train_accuracy: 0.65734 | val_accuracy: 0.51779 |  0:39:18s\n",
            "epoch 1985| loss: 0.71061 | train_accuracy: 0.65836 | val_accuracy: 0.52819 |  0:39:19s\n",
            "epoch 1986| loss: 0.71454 | train_accuracy: 0.65903 | val_accuracy: 0.52139 |  0:39:21s\n",
            "epoch 1987| loss: 0.71703 | train_accuracy: 0.65654 | val_accuracy: 0.52339 |  0:39:22s\n",
            "epoch 1988| loss: 0.71765 | train_accuracy: 0.65956 | val_accuracy: 0.52579 |  0:39:23s\n",
            "epoch 1989| loss: 0.71258 | train_accuracy: 0.65751 | val_accuracy: 0.52499 |  0:39:24s\n",
            "epoch 1990| loss: 0.71916 | train_accuracy: 0.65618 | val_accuracy: 0.53699 |  0:39:25s\n",
            "epoch 1991| loss: 0.71661 | train_accuracy: 0.65529 | val_accuracy: 0.53379 |  0:39:27s\n",
            "epoch 1992| loss: 0.71702 | train_accuracy: 0.65632 | val_accuracy: 0.53539 |  0:39:28s\n",
            "epoch 1993| loss: 0.71726 | train_accuracy: 0.65498 | val_accuracy: 0.53139 |  0:39:29s\n",
            "epoch 1994| loss: 0.72057 | train_accuracy: 0.65263 | val_accuracy: 0.53499 |  0:39:30s\n",
            "epoch 1995| loss: 0.71734 | train_accuracy: 0.65272 | val_accuracy: 0.53938 |  0:39:31s\n",
            "epoch 1996| loss: 0.75426 | train_accuracy: 0.65098 | val_accuracy: 0.53259 |  0:39:33s\n",
            "epoch 1997| loss: 0.77661 | train_accuracy: 0.65161 | val_accuracy: 0.53459 |  0:39:34s\n",
            "epoch 1998| loss: 0.75414 | train_accuracy: 0.65392 | val_accuracy: 0.52499 |  0:39:35s\n",
            "epoch 1999| loss: 0.74279 | train_accuracy: 0.65365 | val_accuracy: 0.52739 |  0:39:36s\n",
            "epoch 2000| loss: 0.73727 | train_accuracy: 0.65507 | val_accuracy: 0.52619 |  0:39:37s\n",
            "epoch 2001| loss: 0.73559 | train_accuracy: 0.65392 | val_accuracy: 0.52699 |  0:39:39s\n",
            "epoch 2002| loss: 0.73037 | train_accuracy: 0.65316 | val_accuracy: 0.53259 |  0:39:40s\n",
            "epoch 2003| loss: 0.72623 | train_accuracy: 0.65414 | val_accuracy: 0.52779 |  0:39:41s\n",
            "epoch 2004| loss: 0.72426 | train_accuracy: 0.65925 | val_accuracy: 0.53139 |  0:39:42s\n",
            "epoch 2005| loss: 0.72441 | train_accuracy: 0.65552 | val_accuracy: 0.52059 |  0:39:43s\n",
            "epoch 2006| loss: 0.72854 | train_accuracy: 0.65663 | val_accuracy: 0.52339 |  0:39:44s\n",
            "epoch 2007| loss: 0.72551 | train_accuracy: 0.65965 | val_accuracy: 0.52099 |  0:39:46s\n",
            "epoch 2008| loss: 0.72796 | train_accuracy: 0.65361 | val_accuracy: 0.52979 |  0:39:47s\n",
            "epoch 2009| loss: 0.72852 | train_accuracy: 0.6544  | val_accuracy: 0.52819 |  0:39:48s\n",
            "epoch 2010| loss: 0.72314 | train_accuracy: 0.65658 | val_accuracy: 0.53139 |  0:39:49s\n",
            "epoch 2011| loss: 0.73005 | train_accuracy: 0.64996 | val_accuracy: 0.53059 |  0:39:50s\n",
            "epoch 2012| loss: 0.73279 | train_accuracy: 0.65649 | val_accuracy: 0.52899 |  0:39:52s\n",
            "epoch 2013| loss: 0.72337 | train_accuracy: 0.65569 | val_accuracy: 0.52659 |  0:39:53s\n",
            "epoch 2014| loss: 0.71821 | train_accuracy: 0.65934 | val_accuracy: 0.52859 |  0:39:54s\n",
            "epoch 2015| loss: 0.7282  | train_accuracy: 0.65916 | val_accuracy: 0.52099 |  0:39:55s\n",
            "epoch 2016| loss: 0.72938 | train_accuracy: 0.65312 | val_accuracy: 0.52139 |  0:39:56s\n",
            "epoch 2017| loss: 0.72482 | train_accuracy: 0.65871 | val_accuracy: 0.52139 |  0:39:57s\n",
            "epoch 2018| loss: 0.72106 | train_accuracy: 0.65814 | val_accuracy: 0.52219 |  0:39:59s\n",
            "epoch 2019| loss: 0.71919 | train_accuracy: 0.6608  | val_accuracy: 0.51939 |  0:40:00s\n",
            "epoch 2020| loss: 0.71919 | train_accuracy: 0.66138 | val_accuracy: 0.51859 |  0:40:01s\n",
            "epoch 2021| loss: 0.72075 | train_accuracy: 0.65974 | val_accuracy: 0.52059 |  0:40:02s\n",
            "epoch 2022| loss: 0.72027 | train_accuracy: 0.65911 | val_accuracy: 0.52499 |  0:40:03s\n",
            "epoch 2023| loss: 0.72051 | train_accuracy: 0.66076 | val_accuracy: 0.51659 |  0:40:05s\n",
            "epoch 2024| loss: 0.71407 | train_accuracy: 0.65978 | val_accuracy: 0.51939 |  0:40:06s\n",
            "epoch 2025| loss: 0.70863 | train_accuracy: 0.66062 | val_accuracy: 0.51419 |  0:40:07s\n",
            "epoch 2026| loss: 0.71334 | train_accuracy: 0.66129 | val_accuracy: 0.51859 |  0:40:08s\n",
            "epoch 2027| loss: 0.71272 | train_accuracy: 0.66116 | val_accuracy: 0.51539 |  0:40:09s\n",
            "epoch 2028| loss: 0.70744 | train_accuracy: 0.66258 | val_accuracy: 0.51979 |  0:40:10s\n",
            "epoch 2029| loss: 0.72031 | train_accuracy: 0.65876 | val_accuracy: 0.52299 |  0:40:12s\n",
            "epoch 2030| loss: 0.71469 | train_accuracy: 0.66307 | val_accuracy: 0.52379 |  0:40:13s\n",
            "epoch 2031| loss: 0.71044 | train_accuracy: 0.66102 | val_accuracy: 0.52339 |  0:40:14s\n",
            "epoch 2032| loss: 0.70844 | train_accuracy: 0.66489 | val_accuracy: 0.53099 |  0:40:15s\n",
            "epoch 2033| loss: 0.70224 | train_accuracy: 0.66427 | val_accuracy: 0.52579 |  0:40:16s\n",
            "epoch 2034| loss: 0.70169 | train_accuracy: 0.66347 | val_accuracy: 0.52619 |  0:40:18s\n",
            "epoch 2035| loss: 0.70333 | train_accuracy: 0.66249 | val_accuracy: 0.52539 |  0:40:19s\n",
            "epoch 2036| loss: 0.70382 | train_accuracy: 0.666   | val_accuracy: 0.52939 |  0:40:20s\n",
            "epoch 2037| loss: 0.70175 | train_accuracy: 0.6632  | val_accuracy: 0.52259 |  0:40:21s\n",
            "epoch 2038| loss: 0.69557 | train_accuracy: 0.66684 | val_accuracy: 0.52379 |  0:40:22s\n",
            "epoch 2039| loss: 0.70184 | train_accuracy: 0.6652  | val_accuracy: 0.52339 |  0:40:24s\n",
            "epoch 2040| loss: 0.70085 | train_accuracy: 0.66769 | val_accuracy: 0.52179 |  0:40:25s\n",
            "epoch 2041| loss: 0.701   | train_accuracy: 0.6672  | val_accuracy: 0.52499 |  0:40:26s\n",
            "epoch 2042| loss: 0.69951 | train_accuracy: 0.66818 | val_accuracy: 0.51379 |  0:40:27s\n",
            "epoch 2043| loss: 0.70449 | train_accuracy: 0.66813 | val_accuracy: 0.51939 |  0:40:28s\n",
            "epoch 2044| loss: 0.6948  | train_accuracy: 0.66662 | val_accuracy: 0.52779 |  0:40:30s\n",
            "epoch 2045| loss: 0.70067 | train_accuracy: 0.66285 | val_accuracy: 0.52219 |  0:40:31s\n",
            "epoch 2046| loss: 0.70171 | train_accuracy: 0.66662 | val_accuracy: 0.52459 |  0:40:32s\n",
            "epoch 2047| loss: 0.69805 | train_accuracy: 0.66276 | val_accuracy: 0.51979 |  0:40:33s\n",
            "epoch 2048| loss: 0.69612 | train_accuracy: 0.66347 | val_accuracy: 0.52139 |  0:40:34s\n",
            "epoch 2049| loss: 0.6943  | train_accuracy: 0.66604 | val_accuracy: 0.52499 |  0:40:36s\n",
            "epoch 2050| loss: 0.69869 | train_accuracy: 0.66405 | val_accuracy: 0.51859 |  0:40:37s\n",
            "epoch 2051| loss: 0.69732 | train_accuracy: 0.66822 | val_accuracy: 0.52699 |  0:40:38s\n",
            "epoch 2052| loss: 0.69672 | train_accuracy: 0.66747 | val_accuracy: 0.52019 |  0:40:39s\n",
            "epoch 2053| loss: 0.69274 | train_accuracy: 0.66853 | val_accuracy: 0.52979 |  0:40:40s\n",
            "epoch 2054| loss: 0.69912 | train_accuracy: 0.668   | val_accuracy: 0.53219 |  0:40:42s\n",
            "epoch 2055| loss: 0.7004  | train_accuracy: 0.66756 | val_accuracy: 0.52939 |  0:40:43s\n",
            "epoch 2056| loss: 0.69946 | train_accuracy: 0.66649 | val_accuracy: 0.52779 |  0:40:44s\n",
            "epoch 2057| loss: 0.69978 | train_accuracy: 0.66498 | val_accuracy: 0.52979 |  0:40:45s\n",
            "epoch 2058| loss: 0.69747 | train_accuracy: 0.66409 | val_accuracy: 0.52579 |  0:40:46s\n",
            "epoch 2059| loss: 0.70011 | train_accuracy: 0.6664  | val_accuracy: 0.52299 |  0:40:48s\n",
            "epoch 2060| loss: 0.69974 | train_accuracy: 0.66538 | val_accuracy: 0.52539 |  0:40:49s\n",
            "epoch 2061| loss: 0.70149 | train_accuracy: 0.66325 | val_accuracy: 0.52379 |  0:40:50s\n",
            "epoch 2062| loss: 0.70705 | train_accuracy: 0.66102 | val_accuracy: 0.53299 |  0:40:51s\n",
            "epoch 2063| loss: 0.70673 | train_accuracy: 0.65787 | val_accuracy: 0.52659 |  0:40:52s\n",
            "epoch 2064| loss: 0.71143 | train_accuracy: 0.66187 | val_accuracy: 0.53099 |  0:40:53s\n",
            "epoch 2065| loss: 0.71044 | train_accuracy: 0.66489 | val_accuracy: 0.54138 |  0:40:55s\n",
            "epoch 2066| loss: 0.70664 | train_accuracy: 0.66485 | val_accuracy: 0.53539 |  0:40:56s\n",
            "epoch 2067| loss: 0.70684 | train_accuracy: 0.66502 | val_accuracy: 0.53619 |  0:40:57s\n",
            "epoch 2068| loss: 0.69977 | train_accuracy: 0.66702 | val_accuracy: 0.53778 |  0:40:58s\n",
            "epoch 2069| loss: 0.69428 | train_accuracy: 0.66907 | val_accuracy: 0.53219 |  0:40:59s\n",
            "epoch 2070| loss: 0.70065 | train_accuracy: 0.6668  | val_accuracy: 0.53219 |  0:41:01s\n",
            "epoch 2071| loss: 0.70244 | train_accuracy: 0.66684 | val_accuracy: 0.52579 |  0:41:02s\n",
            "epoch 2072| loss: 0.7041  | train_accuracy: 0.66591 | val_accuracy: 0.52739 |  0:41:03s\n",
            "epoch 2073| loss: 0.70355 | train_accuracy: 0.6672  | val_accuracy: 0.53219 |  0:41:04s\n",
            "epoch 2074| loss: 0.69981 | train_accuracy: 0.66867 | val_accuracy: 0.52659 |  0:41:05s\n",
            "epoch 2075| loss: 0.70074 | train_accuracy: 0.66436 | val_accuracy: 0.52579 |  0:41:06s\n",
            "epoch 2076| loss: 0.699   | train_accuracy: 0.66667 | val_accuracy: 0.52859 |  0:41:08s\n",
            "epoch 2077| loss: 0.69743 | train_accuracy: 0.66564 | val_accuracy: 0.53858 |  0:41:09s\n",
            "epoch 2078| loss: 0.70073 | train_accuracy: 0.66547 | val_accuracy: 0.52699 |  0:41:10s\n",
            "epoch 2079| loss: 0.71211 | train_accuracy: 0.66373 | val_accuracy: 0.52099 |  0:41:11s\n",
            "epoch 2080| loss: 0.70317 | train_accuracy: 0.668   | val_accuracy: 0.53019 |  0:41:12s\n",
            "epoch 2081| loss: 0.70199 | train_accuracy: 0.66769 | val_accuracy: 0.53099 |  0:41:13s\n",
            "epoch 2082| loss: 0.69951 | train_accuracy: 0.67013 | val_accuracy: 0.52979 |  0:41:15s\n",
            "epoch 2083| loss: 0.69744 | train_accuracy: 0.66787 | val_accuracy: 0.53339 |  0:41:16s\n",
            "epoch 2084| loss: 0.68983 | train_accuracy: 0.66782 | val_accuracy: 0.52619 |  0:41:17s\n",
            "epoch 2085| loss: 0.69547 | train_accuracy: 0.66938 | val_accuracy: 0.52699 |  0:41:18s\n",
            "epoch 2086| loss: 0.6944  | train_accuracy: 0.67164 | val_accuracy: 0.53099 |  0:41:19s\n",
            "epoch 2087| loss: 0.6936  | train_accuracy: 0.67071 | val_accuracy: 0.52939 |  0:41:20s\n",
            "epoch 2088| loss: 0.69693 | train_accuracy: 0.67013 | val_accuracy: 0.52579 |  0:41:22s\n",
            "epoch 2089| loss: 0.69304 | train_accuracy: 0.67102 | val_accuracy: 0.53619 |  0:41:23s\n",
            "epoch 2090| loss: 0.69507 | train_accuracy: 0.66898 | val_accuracy: 0.52579 |  0:41:24s\n",
            "epoch 2091| loss: 0.69368 | train_accuracy: 0.67191 | val_accuracy: 0.52499 |  0:41:25s\n",
            "epoch 2092| loss: 0.69043 | train_accuracy: 0.67231 | val_accuracy: 0.52979 |  0:41:26s\n",
            "epoch 2093| loss: 0.6898  | train_accuracy: 0.67204 | val_accuracy: 0.52139 |  0:41:28s\n",
            "epoch 2094| loss: 0.69128 | train_accuracy: 0.67315 | val_accuracy: 0.52299 |  0:41:29s\n",
            "epoch 2095| loss: 0.69152 | train_accuracy: 0.674   | val_accuracy: 0.52299 |  0:41:30s\n",
            "epoch 2096| loss: 0.69105 | train_accuracy: 0.67084 | val_accuracy: 0.52779 |  0:41:31s\n",
            "epoch 2097| loss: 0.70032 | train_accuracy: 0.67013 | val_accuracy: 0.51939 |  0:41:32s\n",
            "epoch 2098| loss: 0.69834 | train_accuracy: 0.67098 | val_accuracy: 0.52459 |  0:41:33s\n",
            "epoch 2099| loss: 0.70026 | train_accuracy: 0.67022 | val_accuracy: 0.52059 |  0:41:35s\n",
            "epoch 2100| loss: 0.69567 | train_accuracy: 0.67298 | val_accuracy: 0.52179 |  0:41:36s\n",
            "epoch 2101| loss: 0.69482 | train_accuracy: 0.6708  | val_accuracy: 0.52259 |  0:41:37s\n",
            "epoch 2102| loss: 0.6927  | train_accuracy: 0.67235 | val_accuracy: 0.52459 |  0:41:38s\n",
            "epoch 2103| loss: 0.68595 | train_accuracy: 0.67346 | val_accuracy: 0.52339 |  0:41:39s\n",
            "epoch 2104| loss: 0.69045 | train_accuracy: 0.6724  | val_accuracy: 0.51739 |  0:41:41s\n",
            "epoch 2105| loss: 0.69249 | train_accuracy: 0.67293 | val_accuracy: 0.51739 |  0:41:42s\n",
            "epoch 2106| loss: 0.69093 | train_accuracy: 0.67115 | val_accuracy: 0.52539 |  0:41:43s\n",
            "epoch 2107| loss: 0.69734 | train_accuracy: 0.6716  | val_accuracy: 0.52019 |  0:41:44s\n",
            "epoch 2108| loss: 0.70062 | train_accuracy: 0.66831 | val_accuracy: 0.52659 |  0:41:45s\n",
            "epoch 2109| loss: 0.69509 | train_accuracy: 0.66849 | val_accuracy: 0.53019 |  0:41:47s\n",
            "epoch 2110| loss: 0.69764 | train_accuracy: 0.67311 | val_accuracy: 0.53419 |  0:41:48s\n",
            "epoch 2111| loss: 0.70154 | train_accuracy: 0.67235 | val_accuracy: 0.53419 |  0:41:49s\n",
            "epoch 2112| loss: 0.70117 | train_accuracy: 0.67129 | val_accuracy: 0.53339 |  0:41:50s\n",
            "epoch 2113| loss: 0.69706 | train_accuracy: 0.67031 | val_accuracy: 0.53259 |  0:41:51s\n",
            "epoch 2114| loss: 0.68996 | train_accuracy: 0.67169 | val_accuracy: 0.53099 |  0:41:53s\n",
            "epoch 2115| loss: 0.69658 | train_accuracy: 0.67213 | val_accuracy: 0.52579 |  0:41:54s\n",
            "epoch 2116| loss: 0.69466 | train_accuracy: 0.67431 | val_accuracy: 0.52379 |  0:41:55s\n",
            "epoch 2117| loss: 0.69514 | train_accuracy: 0.67462 | val_accuracy: 0.52459 |  0:41:56s\n",
            "epoch 2118| loss: 0.69529 | train_accuracy: 0.67555 | val_accuracy: 0.52539 |  0:41:57s\n",
            "epoch 2119| loss: 0.69279 | train_accuracy: 0.67533 | val_accuracy: 0.52859 |  0:41:58s\n",
            "epoch 2120| loss: 0.69139 | train_accuracy: 0.67542 | val_accuracy: 0.52419 |  0:42:00s\n",
            "epoch 2121| loss: 0.69132 | train_accuracy: 0.67648 | val_accuracy: 0.52539 |  0:42:01s\n",
            "epoch 2122| loss: 0.6907  | train_accuracy: 0.67768 | val_accuracy: 0.52619 |  0:42:02s\n",
            "epoch 2123| loss: 0.68634 | train_accuracy: 0.67555 | val_accuracy: 0.53219 |  0:42:03s\n",
            "epoch 2124| loss: 0.68042 | train_accuracy: 0.67773 | val_accuracy: 0.52539 |  0:42:04s\n",
            "epoch 2125| loss: 0.68483 | train_accuracy: 0.67862 | val_accuracy: 0.52699 |  0:42:06s\n",
            "epoch 2126| loss: 0.68509 | train_accuracy: 0.67613 | val_accuracy: 0.52779 |  0:42:07s\n",
            "epoch 2127| loss: 0.69322 | train_accuracy: 0.67489 | val_accuracy: 0.52419 |  0:42:08s\n",
            "epoch 2128| loss: 0.68953 | train_accuracy: 0.67564 | val_accuracy: 0.52259 |  0:42:09s\n",
            "epoch 2129| loss: 0.68197 | train_accuracy: 0.6744  | val_accuracy: 0.51779 |  0:42:10s\n",
            "epoch 2130| loss: 0.68351 | train_accuracy: 0.67529 | val_accuracy: 0.52499 |  0:42:12s\n",
            "epoch 2131| loss: 0.68791 | train_accuracy: 0.67453 | val_accuracy: 0.52819 |  0:42:13s\n",
            "epoch 2132| loss: 0.68381 | train_accuracy: 0.6752  | val_accuracy: 0.53419 |  0:42:14s\n",
            "epoch 2133| loss: 0.68749 | train_accuracy: 0.67462 | val_accuracy: 0.53339 |  0:42:15s\n",
            "epoch 2134| loss: 0.68675 | train_accuracy: 0.67324 | val_accuracy: 0.53459 |  0:42:16s\n",
            "epoch 2135| loss: 0.68953 | train_accuracy: 0.67213 | val_accuracy: 0.52419 |  0:42:18s\n",
            "epoch 2136| loss: 0.68641 | train_accuracy: 0.67706 | val_accuracy: 0.52539 |  0:42:19s\n",
            "epoch 2137| loss: 0.68587 | train_accuracy: 0.67489 | val_accuracy: 0.53179 |  0:42:20s\n",
            "epoch 2138| loss: 0.68861 | train_accuracy: 0.67333 | val_accuracy: 0.52739 |  0:42:21s\n",
            "epoch 2139| loss: 0.68599 | train_accuracy: 0.67338 | val_accuracy: 0.52459 |  0:42:22s\n",
            "epoch 2140| loss: 0.68913 | train_accuracy: 0.67462 | val_accuracy: 0.52459 |  0:42:23s\n",
            "epoch 2141| loss: 0.68459 | train_accuracy: 0.67546 | val_accuracy: 0.52659 |  0:42:25s\n",
            "epoch 2142| loss: 0.68799 | train_accuracy: 0.6736  | val_accuracy: 0.53139 |  0:42:26s\n",
            "epoch 2143| loss: 0.68921 | train_accuracy: 0.67231 | val_accuracy: 0.52459 |  0:42:27s\n",
            "epoch 2144| loss: 0.69055 | train_accuracy: 0.6752  | val_accuracy: 0.52019 |  0:42:28s\n",
            "epoch 2145| loss: 0.69291 | train_accuracy: 0.6724  | val_accuracy: 0.52219 |  0:42:29s\n",
            "epoch 2146| loss: 0.68968 | train_accuracy: 0.67395 | val_accuracy: 0.51939 |  0:42:30s\n",
            "epoch 2147| loss: 0.68127 | train_accuracy: 0.67502 | val_accuracy: 0.52179 |  0:42:32s\n",
            "epoch 2148| loss: 0.68324 | train_accuracy: 0.6764  | val_accuracy: 0.52219 |  0:42:33s\n",
            "epoch 2149| loss: 0.68418 | train_accuracy: 0.67577 | val_accuracy: 0.51859 |  0:42:34s\n",
            "epoch 2150| loss: 0.67967 | train_accuracy: 0.67875 | val_accuracy: 0.52779 |  0:42:35s\n",
            "epoch 2151| loss: 0.68221 | train_accuracy: 0.67497 | val_accuracy: 0.52539 |  0:42:36s\n",
            "epoch 2152| loss: 0.68315 | train_accuracy: 0.67653 | val_accuracy: 0.52379 |  0:42:38s\n",
            "epoch 2153| loss: 0.68005 | train_accuracy: 0.6788  | val_accuracy: 0.52459 |  0:42:39s\n",
            "epoch 2154| loss: 0.68459 | train_accuracy: 0.6776  | val_accuracy: 0.52179 |  0:42:40s\n",
            "epoch 2155| loss: 0.67944 | train_accuracy: 0.67564 | val_accuracy: 0.52339 |  0:42:41s\n",
            "epoch 2156| loss: 0.68101 | train_accuracy: 0.67693 | val_accuracy: 0.52539 |  0:42:42s\n",
            "epoch 2157| loss: 0.67931 | train_accuracy: 0.6748  | val_accuracy: 0.52579 |  0:42:43s\n",
            "epoch 2158| loss: 0.68039 | train_accuracy: 0.67564 | val_accuracy: 0.52659 |  0:42:45s\n",
            "epoch 2159| loss: 0.68766 | train_accuracy: 0.67373 | val_accuracy: 0.52859 |  0:42:46s\n",
            "epoch 2160| loss: 0.68613 | train_accuracy: 0.67542 | val_accuracy: 0.52219 |  0:42:47s\n",
            "epoch 2161| loss: 0.68623 | train_accuracy: 0.67591 | val_accuracy: 0.53179 |  0:42:48s\n",
            "epoch 2162| loss: 0.68423 | train_accuracy: 0.672   | val_accuracy: 0.51379 |  0:42:49s\n",
            "epoch 2163| loss: 0.68789 | train_accuracy: 0.67191 | val_accuracy: 0.52379 |  0:42:50s\n",
            "epoch 2164| loss: 0.68441 | train_accuracy: 0.67457 | val_accuracy: 0.52099 |  0:42:52s\n",
            "epoch 2165| loss: 0.68144 | train_accuracy: 0.67466 | val_accuracy: 0.52339 |  0:42:53s\n",
            "epoch 2166| loss: 0.68714 | train_accuracy: 0.67888 | val_accuracy: 0.52779 |  0:42:54s\n",
            "epoch 2167| loss: 0.68114 | train_accuracy: 0.67609 | val_accuracy: 0.52619 |  0:42:55s\n",
            "epoch 2168| loss: 0.68255 | train_accuracy: 0.67058 | val_accuracy: 0.51779 |  0:42:56s\n",
            "epoch 2169| loss: 0.68006 | train_accuracy: 0.67298 | val_accuracy: 0.52459 |  0:42:58s\n",
            "epoch 2170| loss: 0.68569 | train_accuracy: 0.67035 | val_accuracy: 0.52059 |  0:42:59s\n",
            "epoch 2171| loss: 0.68728 | train_accuracy: 0.67204 | val_accuracy: 0.51659 |  0:43:00s\n",
            "epoch 2172| loss: 0.68909 | train_accuracy: 0.6736  | val_accuracy: 0.51899 |  0:43:01s\n",
            "epoch 2173| loss: 0.68344 | train_accuracy: 0.67377 | val_accuracy: 0.51659 |  0:43:03s\n",
            "epoch 2174| loss: 0.69051 | train_accuracy: 0.6736  | val_accuracy: 0.52179 |  0:43:04s\n",
            "epoch 2175| loss: 0.68783 | train_accuracy: 0.67311 | val_accuracy: 0.52339 |  0:43:05s\n",
            "epoch 2176| loss: 0.68581 | train_accuracy: 0.67213 | val_accuracy: 0.51739 |  0:43:06s\n",
            "epoch 2177| loss: 0.68935 | train_accuracy: 0.67542 | val_accuracy: 0.51539 |  0:43:07s\n",
            "epoch 2178| loss: 0.68653 | train_accuracy: 0.67511 | val_accuracy: 0.52379 |  0:43:09s\n",
            "epoch 2179| loss: 0.68892 | train_accuracy: 0.67284 | val_accuracy: 0.52099 |  0:43:10s\n",
            "epoch 2180| loss: 0.68473 | train_accuracy: 0.67364 | val_accuracy: 0.52179 |  0:43:11s\n",
            "epoch 2181| loss: 0.68954 | train_accuracy: 0.67209 | val_accuracy: 0.52139 |  0:43:12s\n",
            "epoch 2182| loss: 0.68771 | train_accuracy: 0.67049 | val_accuracy: 0.53019 |  0:43:13s\n",
            "epoch 2183| loss: 0.6938  | train_accuracy: 0.66849 | val_accuracy: 0.52899 |  0:43:15s\n",
            "epoch 2184| loss: 0.69625 | train_accuracy: 0.66782 | val_accuracy: 0.52459 |  0:43:16s\n",
            "epoch 2185| loss: 0.69519 | train_accuracy: 0.67062 | val_accuracy: 0.52459 |  0:43:17s\n",
            "epoch 2186| loss: 0.69454 | train_accuracy: 0.67027 | val_accuracy: 0.51979 |  0:43:18s\n",
            "epoch 2187| loss: 0.69419 | train_accuracy: 0.66902 | val_accuracy: 0.52539 |  0:43:19s\n",
            "epoch 2188| loss: 0.69589 | train_accuracy: 0.66933 | val_accuracy: 0.52499 |  0:43:21s\n",
            "epoch 2189| loss: 0.69466 | train_accuracy: 0.67089 | val_accuracy: 0.51699 |  0:43:22s\n",
            "epoch 2190| loss: 0.69025 | train_accuracy: 0.67222 | val_accuracy: 0.52059 |  0:43:23s\n",
            "epoch 2191| loss: 0.68947 | train_accuracy: 0.67222 | val_accuracy: 0.52059 |  0:43:24s\n",
            "epoch 2192| loss: 0.68611 | train_accuracy: 0.67067 | val_accuracy: 0.52459 |  0:43:25s\n",
            "epoch 2193| loss: 0.69536 | train_accuracy: 0.66991 | val_accuracy: 0.52899 |  0:43:26s\n",
            "epoch 2194| loss: 0.68898 | train_accuracy: 0.67129 | val_accuracy: 0.52979 |  0:43:28s\n",
            "epoch 2195| loss: 0.69351 | train_accuracy: 0.67204 | val_accuracy: 0.52619 |  0:43:29s\n",
            "epoch 2196| loss: 0.68765 | train_accuracy: 0.67204 | val_accuracy: 0.53019 |  0:43:30s\n",
            "epoch 2197| loss: 0.68606 | train_accuracy: 0.67346 | val_accuracy: 0.51939 |  0:43:32s\n",
            "epoch 2198| loss: 0.68512 | train_accuracy: 0.67218 | val_accuracy: 0.52779 |  0:43:34s\n",
            "epoch 2199| loss: 0.68148 | train_accuracy: 0.6736  | val_accuracy: 0.52179 |  0:43:35s\n",
            "epoch 2200| loss: 0.68347 | train_accuracy: 0.67484 | val_accuracy: 0.52579 |  0:43:37s\n",
            "epoch 2201| loss: 0.68345 | train_accuracy: 0.67377 | val_accuracy: 0.52339 |  0:43:39s\n",
            "epoch 2202| loss: 0.6845  | train_accuracy: 0.67564 | val_accuracy: 0.52499 |  0:43:40s\n",
            "epoch 2203| loss: 0.6816  | train_accuracy: 0.67422 | val_accuracy: 0.52779 |  0:43:41s\n",
            "epoch 2204| loss: 0.67958 | train_accuracy: 0.67258 | val_accuracy: 0.52339 |  0:43:42s\n",
            "epoch 2205| loss: 0.67969 | train_accuracy: 0.67457 | val_accuracy: 0.52859 |  0:43:44s\n",
            "epoch 2206| loss: 0.68128 | train_accuracy: 0.67564 | val_accuracy: 0.52619 |  0:43:45s\n",
            "epoch 2207| loss: 0.67985 | train_accuracy: 0.67431 | val_accuracy: 0.52619 |  0:43:46s\n",
            "epoch 2208| loss: 0.6818  | train_accuracy: 0.67471 | val_accuracy: 0.52619 |  0:43:47s\n",
            "epoch 2209| loss: 0.67835 | train_accuracy: 0.67444 | val_accuracy: 0.52179 |  0:43:48s\n",
            "epoch 2210| loss: 0.68362 | train_accuracy: 0.67351 | val_accuracy: 0.52139 |  0:43:49s\n",
            "epoch 2211| loss: 0.68112 | train_accuracy: 0.67529 | val_accuracy: 0.52699 |  0:43:51s\n",
            "epoch 2212| loss: 0.68191 | train_accuracy: 0.67449 | val_accuracy: 0.52179 |  0:43:52s\n",
            "epoch 2213| loss: 0.67888 | train_accuracy: 0.67613 | val_accuracy: 0.53419 |  0:43:53s\n",
            "epoch 2214| loss: 0.67962 | train_accuracy: 0.67653 | val_accuracy: 0.52619 |  0:43:54s\n",
            "epoch 2215| loss: 0.67683 | train_accuracy: 0.67306 | val_accuracy: 0.52579 |  0:43:55s\n",
            "epoch 2216| loss: 0.68495 | train_accuracy: 0.67555 | val_accuracy: 0.52699 |  0:43:57s\n",
            "epoch 2217| loss: 0.68112 | train_accuracy: 0.67484 | val_accuracy: 0.53339 |  0:43:58s\n",
            "epoch 2218| loss: 0.67829 | train_accuracy: 0.67506 | val_accuracy: 0.52859 |  0:43:59s\n",
            "epoch 2219| loss: 0.6755  | train_accuracy: 0.67409 | val_accuracy: 0.53499 |  0:44:00s\n",
            "epoch 2220| loss: 0.6811  | train_accuracy: 0.67586 | val_accuracy: 0.53059 |  0:44:01s\n",
            "epoch 2221| loss: 0.6816  | train_accuracy: 0.67506 | val_accuracy: 0.51779 |  0:44:02s\n",
            "epoch 2222| loss: 0.67934 | train_accuracy: 0.67489 | val_accuracy: 0.52979 |  0:44:04s\n",
            "epoch 2223| loss: 0.67842 | train_accuracy: 0.67484 | val_accuracy: 0.52779 |  0:44:05s\n",
            "epoch 2224| loss: 0.6784  | train_accuracy: 0.67382 | val_accuracy: 0.52939 |  0:44:06s\n",
            "epoch 2225| loss: 0.67828 | train_accuracy: 0.67417 | val_accuracy: 0.52499 |  0:44:07s\n",
            "epoch 2226| loss: 0.68186 | train_accuracy: 0.67733 | val_accuracy: 0.52899 |  0:44:08s\n",
            "epoch 2227| loss: 0.67908 | train_accuracy: 0.67635 | val_accuracy: 0.52459 |  0:44:09s\n",
            "epoch 2228| loss: 0.68425 | train_accuracy: 0.67209 | val_accuracy: 0.52819 |  0:44:11s\n",
            "epoch 2229| loss: 0.6817  | train_accuracy: 0.6736  | val_accuracy: 0.51419 |  0:44:12s\n",
            "epoch 2230| loss: 0.67838 | train_accuracy: 0.67573 | val_accuracy: 0.52579 |  0:44:13s\n",
            "epoch 2231| loss: 0.67725 | train_accuracy: 0.6772  | val_accuracy: 0.52139 |  0:44:14s\n",
            "epoch 2232| loss: 0.67895 | train_accuracy: 0.67591 | val_accuracy: 0.52699 |  0:44:15s\n",
            "epoch 2233| loss: 0.68103 | train_accuracy: 0.67706 | val_accuracy: 0.52899 |  0:44:16s\n",
            "epoch 2234| loss: 0.67649 | train_accuracy: 0.67613 | val_accuracy: 0.52699 |  0:44:18s\n",
            "epoch 2235| loss: 0.68101 | train_accuracy: 0.67369 | val_accuracy: 0.52699 |  0:44:19s\n",
            "epoch 2236| loss: 0.67951 | train_accuracy: 0.6736  | val_accuracy: 0.52299 |  0:44:20s\n",
            "epoch 2237| loss: 0.67993 | train_accuracy: 0.67275 | val_accuracy: 0.52339 |  0:44:21s\n",
            "epoch 2238| loss: 0.68265 | train_accuracy: 0.67231 | val_accuracy: 0.52379 |  0:44:22s\n",
            "epoch 2239| loss: 0.68057 | train_accuracy: 0.67391 | val_accuracy: 0.52779 |  0:44:24s\n",
            "epoch 2240| loss: 0.69288 | train_accuracy: 0.67093 | val_accuracy: 0.51459 |  0:44:25s\n",
            "epoch 2241| loss: 0.68386 | train_accuracy: 0.67226 | val_accuracy: 0.52179 |  0:44:26s\n",
            "epoch 2242| loss: 0.69041 | train_accuracy: 0.67164 | val_accuracy: 0.52819 |  0:44:27s\n",
            "epoch 2243| loss: 0.68283 | train_accuracy: 0.67338 | val_accuracy: 0.52019 |  0:44:28s\n",
            "epoch 2244| loss: 0.68315 | train_accuracy: 0.6712  | val_accuracy: 0.53059 |  0:44:30s\n",
            "epoch 2245| loss: 0.68625 | train_accuracy: 0.67329 | val_accuracy: 0.52619 |  0:44:31s\n",
            "epoch 2246| loss: 0.68217 | train_accuracy: 0.67333 | val_accuracy: 0.51979 |  0:44:32s\n",
            "epoch 2247| loss: 0.68586 | train_accuracy: 0.67213 | val_accuracy: 0.52499 |  0:44:33s\n",
            "epoch 2248| loss: 0.679   | train_accuracy: 0.6736  | val_accuracy: 0.51659 |  0:44:34s\n",
            "epoch 2249| loss: 0.68045 | train_accuracy: 0.67293 | val_accuracy: 0.52099 |  0:44:36s\n",
            "epoch 2250| loss: 0.67864 | train_accuracy: 0.672   | val_accuracy: 0.51499 |  0:44:37s\n",
            "epoch 2251| loss: 0.6799  | train_accuracy: 0.67253 | val_accuracy: 0.51339 |  0:44:38s\n",
            "epoch 2252| loss: 0.68969 | train_accuracy: 0.67271 | val_accuracy: 0.52339 |  0:44:39s\n",
            "epoch 2253| loss: 0.67952 | train_accuracy: 0.67422 | val_accuracy: 0.5098  |  0:44:40s\n",
            "epoch 2254| loss: 0.68159 | train_accuracy: 0.6724  | val_accuracy: 0.51579 |  0:44:42s\n",
            "epoch 2255| loss: 0.68418 | train_accuracy: 0.67431 | val_accuracy: 0.51859 |  0:44:43s\n",
            "epoch 2256| loss: 0.68092 | train_accuracy: 0.6756  | val_accuracy: 0.52019 |  0:44:44s\n",
            "epoch 2257| loss: 0.67746 | train_accuracy: 0.67635 | val_accuracy: 0.51899 |  0:44:45s\n",
            "epoch 2258| loss: 0.68342 | train_accuracy: 0.67582 | val_accuracy: 0.51339 |  0:44:46s\n",
            "epoch 2259| loss: 0.67449 | train_accuracy: 0.67306 | val_accuracy: 0.51859 |  0:44:48s\n",
            "epoch 2260| loss: 0.67962 | train_accuracy: 0.67609 | val_accuracy: 0.52539 |  0:44:49s\n",
            "epoch 2261| loss: 0.67555 | train_accuracy: 0.67529 | val_accuracy: 0.52139 |  0:44:50s\n",
            "epoch 2262| loss: 0.6773  | train_accuracy: 0.67417 | val_accuracy: 0.51659 |  0:44:51s\n",
            "epoch 2263| loss: 0.67493 | train_accuracy: 0.6748  | val_accuracy: 0.51779 |  0:44:52s\n",
            "epoch 2264| loss: 0.67544 | train_accuracy: 0.67604 | val_accuracy: 0.52499 |  0:44:54s\n",
            "epoch 2265| loss: 0.67504 | train_accuracy: 0.67662 | val_accuracy: 0.5114  |  0:44:55s\n",
            "epoch 2266| loss: 0.68109 | train_accuracy: 0.67462 | val_accuracy: 0.51819 |  0:44:56s\n",
            "epoch 2267| loss: 0.68093 | train_accuracy: 0.67391 | val_accuracy: 0.51739 |  0:44:57s\n",
            "epoch 2268| loss: 0.67782 | train_accuracy: 0.6764  | val_accuracy: 0.51979 |  0:44:58s\n",
            "epoch 2269| loss: 0.67718 | train_accuracy: 0.67595 | val_accuracy: 0.52299 |  0:45:00s\n",
            "epoch 2270| loss: 0.67759 | train_accuracy: 0.67742 | val_accuracy: 0.51779 |  0:45:01s\n",
            "epoch 2271| loss: 0.67578 | train_accuracy: 0.67586 | val_accuracy: 0.5122  |  0:45:02s\n",
            "epoch 2272| loss: 0.67594 | train_accuracy: 0.67657 | val_accuracy: 0.51899 |  0:45:03s\n",
            "epoch 2273| loss: 0.67513 | train_accuracy: 0.67426 | val_accuracy: 0.51499 |  0:45:04s\n",
            "epoch 2274| loss: 0.68234 | train_accuracy: 0.67466 | val_accuracy: 0.53179 |  0:45:06s\n",
            "epoch 2275| loss: 0.67713 | train_accuracy: 0.67693 | val_accuracy: 0.52459 |  0:45:07s\n",
            "epoch 2276| loss: 0.6799  | train_accuracy: 0.67586 | val_accuracy: 0.52379 |  0:45:08s\n",
            "epoch 2277| loss: 0.677   | train_accuracy: 0.6784  | val_accuracy: 0.51979 |  0:45:10s\n",
            "epoch 2278| loss: 0.67283 | train_accuracy: 0.67942 | val_accuracy: 0.51899 |  0:45:12s\n",
            "epoch 2279| loss: 0.67801 | train_accuracy: 0.67684 | val_accuracy: 0.52339 |  0:45:13s\n",
            "epoch 2280| loss: 0.68305 | train_accuracy: 0.67711 | val_accuracy: 0.5114  |  0:45:14s\n",
            "epoch 2281| loss: 0.67887 | train_accuracy: 0.67711 | val_accuracy: 0.51939 |  0:45:15s\n",
            "epoch 2282| loss: 0.67601 | train_accuracy: 0.67457 | val_accuracy: 0.51379 |  0:45:17s\n",
            "epoch 2283| loss: 0.68113 | train_accuracy: 0.67644 | val_accuracy: 0.52379 |  0:45:18s\n",
            "epoch 2284| loss: 0.67719 | train_accuracy: 0.67733 | val_accuracy: 0.509   |  0:45:19s\n",
            "epoch 2285| loss: 0.68277 | train_accuracy: 0.67595 | val_accuracy: 0.51419 |  0:45:20s\n",
            "epoch 2286| loss: 0.6778  | train_accuracy: 0.67604 | val_accuracy: 0.51459 |  0:45:21s\n",
            "epoch 2287| loss: 0.6785  | train_accuracy: 0.67315 | val_accuracy: 0.51659 |  0:45:23s\n",
            "epoch 2288| loss: 0.68295 | train_accuracy: 0.674   | val_accuracy: 0.51859 |  0:45:24s\n",
            "epoch 2289| loss: 0.68127 | train_accuracy: 0.67493 | val_accuracy: 0.51939 |  0:45:25s\n",
            "epoch 2290| loss: 0.68267 | train_accuracy: 0.67648 | val_accuracy: 0.51699 |  0:45:26s\n",
            "epoch 2291| loss: 0.67892 | train_accuracy: 0.67635 | val_accuracy: 0.51859 |  0:45:27s\n",
            "epoch 2292| loss: 0.67814 | train_accuracy: 0.67622 | val_accuracy: 0.52339 |  0:45:29s\n",
            "epoch 2293| loss: 0.67606 | train_accuracy: 0.67591 | val_accuracy: 0.52859 |  0:45:30s\n",
            "epoch 2294| loss: 0.67805 | train_accuracy: 0.6764  | val_accuracy: 0.52219 |  0:45:31s\n",
            "epoch 2295| loss: 0.68225 | train_accuracy: 0.67484 | val_accuracy: 0.52819 |  0:45:32s\n",
            "epoch 2296| loss: 0.67881 | train_accuracy: 0.67404 | val_accuracy: 0.51819 |  0:45:33s\n",
            "epoch 2297| loss: 0.68115 | train_accuracy: 0.67764 | val_accuracy: 0.52339 |  0:45:35s\n",
            "epoch 2298| loss: 0.68018 | train_accuracy: 0.67364 | val_accuracy: 0.52139 |  0:45:36s\n",
            "epoch 2299| loss: 0.67725 | train_accuracy: 0.67422 | val_accuracy: 0.52579 |  0:45:37s\n",
            "epoch 2300| loss: 0.67814 | train_accuracy: 0.67577 | val_accuracy: 0.52579 |  0:45:38s\n",
            "epoch 2301| loss: 0.67778 | train_accuracy: 0.67564 | val_accuracy: 0.52739 |  0:45:39s\n",
            "epoch 2302| loss: 0.67759 | train_accuracy: 0.67702 | val_accuracy: 0.52179 |  0:45:41s\n",
            "epoch 2303| loss: 0.67959 | train_accuracy: 0.67551 | val_accuracy: 0.52939 |  0:45:42s\n",
            "epoch 2304| loss: 0.6789  | train_accuracy: 0.67666 | val_accuracy: 0.52459 |  0:45:43s\n",
            "epoch 2305| loss: 0.67693 | train_accuracy: 0.67471 | val_accuracy: 0.51939 |  0:45:44s\n",
            "epoch 2306| loss: 0.68113 | train_accuracy: 0.67706 | val_accuracy: 0.52299 |  0:45:45s\n",
            "epoch 2307| loss: 0.67402 | train_accuracy: 0.67706 | val_accuracy: 0.52219 |  0:45:47s\n",
            "epoch 2308| loss: 0.67582 | train_accuracy: 0.67555 | val_accuracy: 0.52659 |  0:45:48s\n",
            "epoch 2309| loss: 0.67501 | train_accuracy: 0.67773 | val_accuracy: 0.51739 |  0:45:49s\n",
            "epoch 2310| loss: 0.67231 | train_accuracy: 0.67586 | val_accuracy: 0.52259 |  0:45:50s\n",
            "epoch 2311| loss: 0.67363 | train_accuracy: 0.67648 | val_accuracy: 0.51939 |  0:45:51s\n",
            "epoch 2312| loss: 0.67293 | train_accuracy: 0.67515 | val_accuracy: 0.52179 |  0:45:52s\n",
            "epoch 2313| loss: 0.67168 | train_accuracy: 0.67613 | val_accuracy: 0.52179 |  0:45:54s\n",
            "epoch 2314| loss: 0.67593 | train_accuracy: 0.6776  | val_accuracy: 0.52459 |  0:45:55s\n",
            "epoch 2315| loss: 0.67475 | train_accuracy: 0.67662 | val_accuracy: 0.52779 |  0:45:56s\n",
            "epoch 2316| loss: 0.67514 | train_accuracy: 0.67826 | val_accuracy: 0.52539 |  0:45:57s\n",
            "epoch 2317| loss: 0.67861 | train_accuracy: 0.67751 | val_accuracy: 0.52379 |  0:45:58s\n",
            "epoch 2318| loss: 0.67855 | train_accuracy: 0.6772  | val_accuracy: 0.52219 |  0:46:00s\n",
            "epoch 2319| loss: 0.67489 | train_accuracy: 0.67795 | val_accuracy: 0.52139 |  0:46:01s\n",
            "epoch 2320| loss: 0.68242 | train_accuracy: 0.67697 | val_accuracy: 0.52019 |  0:46:02s\n",
            "epoch 2321| loss: 0.67304 | train_accuracy: 0.67706 | val_accuracy: 0.52819 |  0:46:03s\n",
            "epoch 2322| loss: 0.676   | train_accuracy: 0.67671 | val_accuracy: 0.52179 |  0:46:04s\n",
            "epoch 2323| loss: 0.67642 | train_accuracy: 0.67582 | val_accuracy: 0.52499 |  0:46:06s\n",
            "epoch 2324| loss: 0.67451 | train_accuracy: 0.67484 | val_accuracy: 0.51779 |  0:46:07s\n",
            "epoch 2325| loss: 0.67931 | train_accuracy: 0.67515 | val_accuracy: 0.51619 |  0:46:08s\n",
            "epoch 2326| loss: 0.68161 | train_accuracy: 0.67497 | val_accuracy: 0.51739 |  0:46:09s\n",
            "epoch 2327| loss: 0.68217 | train_accuracy: 0.67466 | val_accuracy: 0.53219 |  0:46:10s\n",
            "epoch 2328| loss: 0.68021 | train_accuracy: 0.67409 | val_accuracy: 0.52579 |  0:46:12s\n",
            "epoch 2329| loss: 0.68421 | train_accuracy: 0.67302 | val_accuracy: 0.52059 |  0:46:13s\n",
            "epoch 2330| loss: 0.67825 | train_accuracy: 0.67613 | val_accuracy: 0.51859 |  0:46:14s\n",
            "epoch 2331| loss: 0.68396 | train_accuracy: 0.67506 | val_accuracy: 0.51859 |  0:46:15s\n",
            "epoch 2332| loss: 0.67625 | train_accuracy: 0.67591 | val_accuracy: 0.52139 |  0:46:16s\n",
            "epoch 2333| loss: 0.68103 | train_accuracy: 0.67466 | val_accuracy: 0.52419 |  0:46:18s\n",
            "epoch 2334| loss: 0.68431 | train_accuracy: 0.67413 | val_accuracy: 0.52259 |  0:46:19s\n",
            "epoch 2335| loss: 0.685   | train_accuracy: 0.67355 | val_accuracy: 0.52419 |  0:46:20s\n",
            "epoch 2336| loss: 0.6846  | train_accuracy: 0.67275 | val_accuracy: 0.52419 |  0:46:21s\n",
            "epoch 2337| loss: 0.68786 | train_accuracy: 0.67075 | val_accuracy: 0.51979 |  0:46:22s\n",
            "epoch 2338| loss: 0.68544 | train_accuracy: 0.66987 | val_accuracy: 0.52499 |  0:46:24s\n",
            "epoch 2339| loss: 0.6925  | train_accuracy: 0.6692  | val_accuracy: 0.51939 |  0:46:25s\n",
            "epoch 2340| loss: 0.68943 | train_accuracy: 0.66964 | val_accuracy: 0.52139 |  0:46:26s\n",
            "epoch 2341| loss: 0.69083 | train_accuracy: 0.67035 | val_accuracy: 0.52499 |  0:46:27s\n",
            "epoch 2342| loss: 0.68959 | train_accuracy: 0.67044 | val_accuracy: 0.52259 |  0:46:28s\n",
            "epoch 2343| loss: 0.68904 | train_accuracy: 0.67053 | val_accuracy: 0.52339 |  0:46:30s\n",
            "epoch 2344| loss: 0.69362 | train_accuracy: 0.67084 | val_accuracy: 0.52579 |  0:46:31s\n",
            "epoch 2345| loss: 0.68982 | train_accuracy: 0.67093 | val_accuracy: 0.52259 |  0:46:32s\n",
            "epoch 2346| loss: 0.68824 | train_accuracy: 0.67004 | val_accuracy: 0.52619 |  0:46:33s\n",
            "epoch 2347| loss: 0.68855 | train_accuracy: 0.67035 | val_accuracy: 0.52019 |  0:46:34s\n",
            "epoch 2348| loss: 0.68703 | train_accuracy: 0.66947 | val_accuracy: 0.52379 |  0:46:35s\n",
            "epoch 2349| loss: 0.69166 | train_accuracy: 0.66716 | val_accuracy: 0.51859 |  0:46:37s\n",
            "epoch 2350| loss: 0.68323 | train_accuracy: 0.6692  | val_accuracy: 0.52419 |  0:46:38s\n",
            "epoch 2351| loss: 0.6855  | train_accuracy: 0.67084 | val_accuracy: 0.52139 |  0:46:39s\n",
            "epoch 2352| loss: 0.68709 | train_accuracy: 0.67    | val_accuracy: 0.52779 |  0:46:40s\n",
            "epoch 2353| loss: 0.6936  | train_accuracy: 0.67173 | val_accuracy: 0.53059 |  0:46:41s\n",
            "epoch 2354| loss: 0.68029 | train_accuracy: 0.67093 | val_accuracy: 0.52099 |  0:46:43s\n",
            "epoch 2355| loss: 0.68512 | train_accuracy: 0.66924 | val_accuracy: 0.51859 |  0:46:44s\n",
            "epoch 2356| loss: 0.6815  | train_accuracy: 0.67133 | val_accuracy: 0.51979 |  0:46:45s\n",
            "epoch 2357| loss: 0.68429 | train_accuracy: 0.66907 | val_accuracy: 0.51979 |  0:46:46s\n",
            "epoch 2358| loss: 0.68101 | train_accuracy: 0.67191 | val_accuracy: 0.52099 |  0:46:47s\n",
            "epoch 2359| loss: 0.67947 | train_accuracy: 0.67244 | val_accuracy: 0.51979 |  0:46:48s\n",
            "epoch 2360| loss: 0.68293 | train_accuracy: 0.67124 | val_accuracy: 0.51979 |  0:46:50s\n",
            "epoch 2361| loss: 0.6865  | train_accuracy: 0.67155 | val_accuracy: 0.52259 |  0:46:51s\n",
            "epoch 2362| loss: 0.68192 | train_accuracy: 0.67164 | val_accuracy: 0.52059 |  0:46:52s\n",
            "epoch 2363| loss: 0.68448 | train_accuracy: 0.67284 | val_accuracy: 0.52699 |  0:46:53s\n",
            "epoch 2364| loss: 0.68331 | train_accuracy: 0.6704  | val_accuracy: 0.52539 |  0:46:54s\n",
            "epoch 2365| loss: 0.68555 | train_accuracy: 0.67191 | val_accuracy: 0.51859 |  0:46:56s\n",
            "epoch 2366| loss: 0.68677 | train_accuracy: 0.66947 | val_accuracy: 0.52459 |  0:46:57s\n",
            "epoch 2367| loss: 0.68258 | train_accuracy: 0.6696  | val_accuracy: 0.52259 |  0:46:58s\n",
            "epoch 2368| loss: 0.68067 | train_accuracy: 0.67004 | val_accuracy: 0.52339 |  0:46:59s\n",
            "epoch 2369| loss: 0.68508 | train_accuracy: 0.67027 | val_accuracy: 0.52699 |  0:47:00s\n",
            "epoch 2370| loss: 0.68927 | train_accuracy: 0.66987 | val_accuracy: 0.52499 |  0:47:01s\n",
            "epoch 2371| loss: 0.68869 | train_accuracy: 0.66782 | val_accuracy: 0.52499 |  0:47:03s\n",
            "epoch 2372| loss: 0.68832 | train_accuracy: 0.66915 | val_accuracy: 0.52339 |  0:47:04s\n",
            "epoch 2373| loss: 0.68496 | train_accuracy: 0.67111 | val_accuracy: 0.52059 |  0:47:05s\n",
            "epoch 2374| loss: 0.68661 | train_accuracy: 0.67204 | val_accuracy: 0.52659 |  0:47:06s\n",
            "epoch 2375| loss: 0.683   | train_accuracy: 0.67124 | val_accuracy: 0.52659 |  0:47:07s\n",
            "epoch 2376| loss: 0.68743 | train_accuracy: 0.6684  | val_accuracy: 0.51819 |  0:47:08s\n",
            "epoch 2377| loss: 0.68927 | train_accuracy: 0.66884 | val_accuracy: 0.52419 |  0:47:10s\n",
            "epoch 2378| loss: 0.69027 | train_accuracy: 0.66729 | val_accuracy: 0.52579 |  0:47:11s\n",
            "epoch 2379| loss: 0.69088 | train_accuracy: 0.66707 | val_accuracy: 0.51659 |  0:47:12s\n",
            "epoch 2380| loss: 0.68815 | train_accuracy: 0.66689 | val_accuracy: 0.52099 |  0:47:13s\n",
            "epoch 2381| loss: 0.68924 | train_accuracy: 0.66636 | val_accuracy: 0.51699 |  0:47:14s\n",
            "epoch 2382| loss: 0.68797 | train_accuracy: 0.66671 | val_accuracy: 0.52259 |  0:47:16s\n",
            "epoch 2383| loss: 0.69207 | train_accuracy: 0.66951 | val_accuracy: 0.52259 |  0:47:17s\n",
            "epoch 2384| loss: 0.69127 | train_accuracy: 0.66862 | val_accuracy: 0.52739 |  0:47:18s\n",
            "epoch 2385| loss: 0.68916 | train_accuracy: 0.66849 | val_accuracy: 0.52379 |  0:47:19s\n",
            "epoch 2386| loss: 0.68995 | train_accuracy: 0.67031 | val_accuracy: 0.52139 |  0:47:20s\n",
            "epoch 2387| loss: 0.69125 | train_accuracy: 0.66907 | val_accuracy: 0.52219 |  0:47:22s\n",
            "epoch 2388| loss: 0.68453 | train_accuracy: 0.66835 | val_accuracy: 0.52179 |  0:47:23s\n",
            "epoch 2389| loss: 0.68428 | train_accuracy: 0.66924 | val_accuracy: 0.52459 |  0:47:24s\n",
            "epoch 2390| loss: 0.68811 | train_accuracy: 0.67169 | val_accuracy: 0.52339 |  0:47:25s\n",
            "epoch 2391| loss: 0.68209 | train_accuracy: 0.66947 | val_accuracy: 0.51659 |  0:47:26s\n",
            "epoch 2392| loss: 0.68308 | train_accuracy: 0.66875 | val_accuracy: 0.52379 |  0:47:28s\n",
            "epoch 2393| loss: 0.68096 | train_accuracy: 0.67333 | val_accuracy: 0.51819 |  0:47:29s\n",
            "epoch 2394| loss: 0.67919 | train_accuracy: 0.67111 | val_accuracy: 0.51659 |  0:47:30s\n",
            "epoch 2395| loss: 0.68027 | train_accuracy: 0.67204 | val_accuracy: 0.51459 |  0:47:31s\n",
            "epoch 2396| loss: 0.68322 | train_accuracy: 0.6724  | val_accuracy: 0.51899 |  0:47:32s\n",
            "epoch 2397| loss: 0.68235 | train_accuracy: 0.67409 | val_accuracy: 0.52019 |  0:47:34s\n",
            "epoch 2398| loss: 0.68432 | train_accuracy: 0.67186 | val_accuracy: 0.51579 |  0:47:35s\n",
            "epoch 2399| loss: 0.68268 | train_accuracy: 0.67133 | val_accuracy: 0.51619 |  0:47:36s\n",
            "epoch 2400| loss: 0.68117 | train_accuracy: 0.67098 | val_accuracy: 0.51819 |  0:47:37s\n",
            "epoch 2401| loss: 0.6838  | train_accuracy: 0.67049 | val_accuracy: 0.51819 |  0:47:38s\n",
            "epoch 2402| loss: 0.69108 | train_accuracy: 0.67222 | val_accuracy: 0.51379 |  0:47:40s\n",
            "epoch 2403| loss: 0.67604 | train_accuracy: 0.67231 | val_accuracy: 0.51499 |  0:47:41s\n",
            "epoch 2404| loss: 0.67774 | train_accuracy: 0.67262 | val_accuracy: 0.51939 |  0:47:42s\n",
            "epoch 2405| loss: 0.67475 | train_accuracy: 0.67369 | val_accuracy: 0.52339 |  0:47:43s\n",
            "epoch 2406| loss: 0.67649 | train_accuracy: 0.67577 | val_accuracy: 0.52219 |  0:47:44s\n",
            "epoch 2407| loss: 0.67497 | train_accuracy: 0.67475 | val_accuracy: 0.51859 |  0:47:46s\n",
            "epoch 2408| loss: 0.6769  | train_accuracy: 0.67235 | val_accuracy: 0.51339 |  0:47:47s\n",
            "epoch 2409| loss: 0.67356 | train_accuracy: 0.67306 | val_accuracy: 0.51819 |  0:47:48s\n",
            "epoch 2410| loss: 0.67367 | train_accuracy: 0.67449 | val_accuracy: 0.51579 |  0:47:49s\n",
            "epoch 2411| loss: 0.67609 | train_accuracy: 0.67462 | val_accuracy: 0.51539 |  0:47:50s\n",
            "epoch 2412| loss: 0.682   | train_accuracy: 0.67671 | val_accuracy: 0.52339 |  0:47:52s\n",
            "epoch 2413| loss: 0.67699 | train_accuracy: 0.67231 | val_accuracy: 0.5118  |  0:47:53s\n",
            "epoch 2414| loss: 0.67699 | train_accuracy: 0.67409 | val_accuracy: 0.52219 |  0:47:54s\n",
            "epoch 2415| loss: 0.67409 | train_accuracy: 0.67457 | val_accuracy: 0.52179 |  0:47:55s\n",
            "epoch 2416| loss: 0.67287 | train_accuracy: 0.674   | val_accuracy: 0.51779 |  0:47:56s\n",
            "epoch 2417| loss: 0.67541 | train_accuracy: 0.67609 | val_accuracy: 0.5106  |  0:47:58s\n",
            "epoch 2418| loss: 0.6752  | train_accuracy: 0.67573 | val_accuracy: 0.52339 |  0:47:59s\n",
            "epoch 2419| loss: 0.67032 | train_accuracy: 0.67564 | val_accuracy: 0.52539 |  0:48:00s\n",
            "epoch 2420| loss: 0.66947 | train_accuracy: 0.67662 | val_accuracy: 0.52579 |  0:48:01s\n",
            "epoch 2421| loss: 0.66876 | train_accuracy: 0.67813 | val_accuracy: 0.52819 |  0:48:02s\n",
            "epoch 2422| loss: 0.67303 | train_accuracy: 0.67404 | val_accuracy: 0.51739 |  0:48:04s\n",
            "epoch 2423| loss: 0.6744  | train_accuracy: 0.67422 | val_accuracy: 0.51259 |  0:48:05s\n",
            "epoch 2424| loss: 0.67151 | train_accuracy: 0.67497 | val_accuracy: 0.51819 |  0:48:06s\n",
            "epoch 2425| loss: 0.67209 | train_accuracy: 0.67471 | val_accuracy: 0.52059 |  0:48:07s\n",
            "epoch 2426| loss: 0.67381 | train_accuracy: 0.67431 | val_accuracy: 0.52019 |  0:48:08s\n",
            "epoch 2427| loss: 0.67401 | train_accuracy: 0.67235 | val_accuracy: 0.51299 |  0:48:09s\n",
            "epoch 2428| loss: 0.67549 | train_accuracy: 0.67444 | val_accuracy: 0.52699 |  0:48:11s\n",
            "epoch 2429| loss: 0.67404 | train_accuracy: 0.67564 | val_accuracy: 0.51619 |  0:48:12s\n",
            "epoch 2430| loss: 0.6728  | train_accuracy: 0.67409 | val_accuracy: 0.51739 |  0:48:13s\n",
            "epoch 2431| loss: 0.67389 | train_accuracy: 0.67231 | val_accuracy: 0.51619 |  0:48:14s\n",
            "epoch 2432| loss: 0.67607 | train_accuracy: 0.67369 | val_accuracy: 0.51539 |  0:48:15s\n",
            "epoch 2433| loss: 0.67668 | train_accuracy: 0.67373 | val_accuracy: 0.52579 |  0:48:17s\n",
            "epoch 2434| loss: 0.67576 | train_accuracy: 0.67409 | val_accuracy: 0.51379 |  0:48:18s\n",
            "epoch 2435| loss: 0.67046 | train_accuracy: 0.67746 | val_accuracy: 0.52219 |  0:48:19s\n",
            "epoch 2436| loss: 0.67263 | train_accuracy: 0.67511 | val_accuracy: 0.51899 |  0:48:20s\n",
            "epoch 2437| loss: 0.67306 | train_accuracy: 0.67338 | val_accuracy: 0.52379 |  0:48:21s\n",
            "epoch 2438| loss: 0.67637 | train_accuracy: 0.67417 | val_accuracy: 0.52819 |  0:48:22s\n",
            "epoch 2439| loss: 0.67399 | train_accuracy: 0.67204 | val_accuracy: 0.52539 |  0:48:24s\n",
            "epoch 2440| loss: 0.67752 | train_accuracy: 0.67471 | val_accuracy: 0.52539 |  0:48:25s\n",
            "epoch 2441| loss: 0.67075 | train_accuracy: 0.6736  | val_accuracy: 0.52859 |  0:48:26s\n",
            "epoch 2442| loss: 0.66968 | train_accuracy: 0.67506 | val_accuracy: 0.52339 |  0:48:27s\n",
            "epoch 2443| loss: 0.66719 | train_accuracy: 0.67529 | val_accuracy: 0.52419 |  0:48:28s\n",
            "epoch 2444| loss: 0.66638 | train_accuracy: 0.67409 | val_accuracy: 0.52059 |  0:48:29s\n",
            "epoch 2445| loss: 0.66969 | train_accuracy: 0.67311 | val_accuracy: 0.52299 |  0:48:31s\n",
            "epoch 2446| loss: 0.67608 | train_accuracy: 0.6744  | val_accuracy: 0.53219 |  0:48:32s\n",
            "epoch 2447| loss: 0.67878 | train_accuracy: 0.67351 | val_accuracy: 0.52259 |  0:48:33s\n",
            "epoch 2448| loss: 0.67655 | train_accuracy: 0.67462 | val_accuracy: 0.52419 |  0:48:34s\n",
            "epoch 2449| loss: 0.6747  | train_accuracy: 0.67404 | val_accuracy: 0.52499 |  0:48:35s\n",
            "epoch 2450| loss: 0.67481 | train_accuracy: 0.67413 | val_accuracy: 0.51819 |  0:48:36s\n",
            "epoch 2451| loss: 0.67943 | train_accuracy: 0.67422 | val_accuracy: 0.52499 |  0:48:38s\n",
            "epoch 2452| loss: 0.67543 | train_accuracy: 0.67462 | val_accuracy: 0.52499 |  0:48:39s\n",
            "epoch 2453| loss: 0.6691  | train_accuracy: 0.67511 | val_accuracy: 0.52099 |  0:48:40s\n",
            "epoch 2454| loss: 0.66808 | train_accuracy: 0.67657 | val_accuracy: 0.52659 |  0:48:41s\n",
            "epoch 2455| loss: 0.67327 | train_accuracy: 0.67662 | val_accuracy: 0.52099 |  0:48:42s\n",
            "epoch 2456| loss: 0.67297 | train_accuracy: 0.67817 | val_accuracy: 0.52779 |  0:48:44s\n",
            "epoch 2457| loss: 0.67761 | train_accuracy: 0.67804 | val_accuracy: 0.52659 |  0:48:45s\n",
            "epoch 2458| loss: 0.67121 | train_accuracy: 0.67529 | val_accuracy: 0.52579 |  0:48:46s\n",
            "epoch 2459| loss: 0.67264 | train_accuracy: 0.6764  | val_accuracy: 0.52099 |  0:48:47s\n",
            "epoch 2460| loss: 0.67019 | train_accuracy: 0.67791 | val_accuracy: 0.51859 |  0:48:48s\n",
            "epoch 2461| loss: 0.67349 | train_accuracy: 0.67706 | val_accuracy: 0.52539 |  0:48:50s\n",
            "epoch 2462| loss: 0.67462 | train_accuracy: 0.67786 | val_accuracy: 0.51899 |  0:48:51s\n",
            "epoch 2463| loss: 0.6734  | train_accuracy: 0.6784  | val_accuracy: 0.52939 |  0:48:52s\n",
            "epoch 2464| loss: 0.67064 | train_accuracy: 0.67773 | val_accuracy: 0.52859 |  0:48:53s\n",
            "epoch 2465| loss: 0.67221 | train_accuracy: 0.67595 | val_accuracy: 0.52299 |  0:48:55s\n",
            "epoch 2466| loss: 0.67332 | train_accuracy: 0.6764  | val_accuracy: 0.53339 |  0:48:56s\n",
            "epoch 2467| loss: 0.67127 | train_accuracy: 0.67466 | val_accuracy: 0.51739 |  0:48:57s\n",
            "epoch 2468| loss: 0.67144 | train_accuracy: 0.67577 | val_accuracy: 0.52659 |  0:48:58s\n",
            "epoch 2469| loss: 0.66786 | train_accuracy: 0.6784  | val_accuracy: 0.52619 |  0:48:59s\n",
            "epoch 2470| loss: 0.67292 | train_accuracy: 0.67768 | val_accuracy: 0.52139 |  0:49:01s\n",
            "epoch 2471| loss: 0.66827 | train_accuracy: 0.67564 | val_accuracy: 0.51739 |  0:49:02s\n",
            "epoch 2472| loss: 0.67974 | train_accuracy: 0.67728 | val_accuracy: 0.53059 |  0:49:03s\n",
            "epoch 2473| loss: 0.67365 | train_accuracy: 0.67942 | val_accuracy: 0.52219 |  0:49:04s\n",
            "epoch 2474| loss: 0.67614 | train_accuracy: 0.67404 | val_accuracy: 0.52299 |  0:49:05s\n",
            "epoch 2475| loss: 0.6748  | train_accuracy: 0.67373 | val_accuracy: 0.52339 |  0:49:07s\n",
            "epoch 2476| loss: 0.67176 | train_accuracy: 0.67355 | val_accuracy: 0.52219 |  0:49:08s\n",
            "epoch 2477| loss: 0.67877 | train_accuracy: 0.67435 | val_accuracy: 0.52299 |  0:49:09s\n",
            "epoch 2478| loss: 0.67595 | train_accuracy: 0.67382 | val_accuracy: 0.52219 |  0:49:10s\n",
            "epoch 2479| loss: 0.67349 | train_accuracy: 0.67386 | val_accuracy: 0.51859 |  0:49:11s\n",
            "epoch 2480| loss: 0.66921 | train_accuracy: 0.67746 | val_accuracy: 0.51779 |  0:49:13s\n",
            "epoch 2481| loss: 0.67337 | train_accuracy: 0.67515 | val_accuracy: 0.52459 |  0:49:14s\n",
            "epoch 2482| loss: 0.67303 | train_accuracy: 0.67564 | val_accuracy: 0.51739 |  0:49:15s\n",
            "epoch 2483| loss: 0.67426 | train_accuracy: 0.67364 | val_accuracy: 0.52539 |  0:49:16s\n",
            "epoch 2484| loss: 0.67032 | train_accuracy: 0.67733 | val_accuracy: 0.51899 |  0:49:17s\n",
            "epoch 2485| loss: 0.66868 | train_accuracy: 0.67604 | val_accuracy: 0.52379 |  0:49:19s\n",
            "epoch 2486| loss: 0.67023 | train_accuracy: 0.67742 | val_accuracy: 0.52579 |  0:49:20s\n",
            "epoch 2487| loss: 0.6674  | train_accuracy: 0.67671 | val_accuracy: 0.51899 |  0:49:21s\n",
            "epoch 2488| loss: 0.66518 | train_accuracy: 0.67666 | val_accuracy: 0.52459 |  0:49:22s\n",
            "epoch 2489| loss: 0.67112 | train_accuracy: 0.6772  | val_accuracy: 0.52339 |  0:49:23s\n",
            "epoch 2490| loss: 0.67467 | train_accuracy: 0.67711 | val_accuracy: 0.51539 |  0:49:25s\n",
            "epoch 2491| loss: 0.67088 | train_accuracy: 0.67617 | val_accuracy: 0.52339 |  0:49:26s\n",
            "epoch 2492| loss: 0.67102 | train_accuracy: 0.67786 | val_accuracy: 0.52619 |  0:49:27s\n",
            "epoch 2493| loss: 0.66952 | train_accuracy: 0.67573 | val_accuracy: 0.53339 |  0:49:28s\n",
            "epoch 2494| loss: 0.67296 | train_accuracy: 0.67613 | val_accuracy: 0.52619 |  0:49:29s\n",
            "epoch 2495| loss: 0.67238 | train_accuracy: 0.67493 | val_accuracy: 0.52539 |  0:49:30s\n",
            "epoch 2496| loss: 0.66901 | train_accuracy: 0.67755 | val_accuracy: 0.52539 |  0:49:32s\n",
            "epoch 2497| loss: 0.66631 | train_accuracy: 0.67706 | val_accuracy: 0.52859 |  0:49:33s\n",
            "epoch 2498| loss: 0.67347 | train_accuracy: 0.67648 | val_accuracy: 0.52899 |  0:49:34s\n",
            "epoch 2499| loss: 0.66866 | train_accuracy: 0.67911 | val_accuracy: 0.53019 |  0:49:35s\n",
            "epoch 2500| loss: 0.66726 | train_accuracy: 0.67942 | val_accuracy: 0.53019 |  0:49:36s\n",
            "epoch 2501| loss: 0.66289 | train_accuracy: 0.67866 | val_accuracy: 0.53379 |  0:49:37s\n",
            "epoch 2502| loss: 0.66766 | train_accuracy: 0.67982 | val_accuracy: 0.53099 |  0:49:39s\n",
            "epoch 2503| loss: 0.66812 | train_accuracy: 0.67857 | val_accuracy: 0.52139 |  0:49:40s\n",
            "epoch 2504| loss: 0.66707 | train_accuracy: 0.67959 | val_accuracy: 0.53139 |  0:49:41s\n",
            "epoch 2505| loss: 0.66672 | train_accuracy: 0.67955 | val_accuracy: 0.52899 |  0:49:42s\n",
            "epoch 2506| loss: 0.66556 | train_accuracy: 0.68124 | val_accuracy: 0.52939 |  0:49:43s\n",
            "epoch 2507| loss: 0.66381 | train_accuracy: 0.68022 | val_accuracy: 0.53019 |  0:49:45s\n",
            "epoch 2508| loss: 0.66292 | train_accuracy: 0.67999 | val_accuracy: 0.52739 |  0:49:46s\n",
            "epoch 2509| loss: 0.66222 | train_accuracy: 0.68119 | val_accuracy: 0.54018 |  0:49:47s\n",
            "epoch 2510| loss: 0.66264 | train_accuracy: 0.68146 | val_accuracy: 0.53619 |  0:49:48s\n",
            "epoch 2511| loss: 0.66287 | train_accuracy: 0.68204 | val_accuracy: 0.53099 |  0:49:49s\n",
            "epoch 2512| loss: 0.66592 | train_accuracy: 0.68071 | val_accuracy: 0.53019 |  0:49:50s\n",
            "epoch 2513| loss: 0.66455 | train_accuracy: 0.68048 | val_accuracy: 0.52979 |  0:49:52s\n",
            "epoch 2514| loss: 0.66268 | train_accuracy: 0.68111 | val_accuracy: 0.53499 |  0:49:53s\n",
            "epoch 2515| loss: 0.66651 | train_accuracy: 0.68257 | val_accuracy: 0.52939 |  0:49:54s\n",
            "epoch 2516| loss: 0.66165 | train_accuracy: 0.68182 | val_accuracy: 0.53099 |  0:49:55s\n",
            "epoch 2517| loss: 0.66782 | train_accuracy: 0.68217 | val_accuracy: 0.54418 |  0:49:56s\n",
            "epoch 2518| loss: 0.66182 | train_accuracy: 0.68106 | val_accuracy: 0.53659 |  0:49:58s\n",
            "epoch 2519| loss: 0.6629  | train_accuracy: 0.68084 | val_accuracy: 0.53019 |  0:49:59s\n",
            "epoch 2520| loss: 0.66877 | train_accuracy: 0.68031 | val_accuracy: 0.54138 |  0:50:00s\n",
            "epoch 2521| loss: 0.66761 | train_accuracy: 0.68195 | val_accuracy: 0.52739 |  0:50:01s\n",
            "epoch 2522| loss: 0.66618 | train_accuracy: 0.68124 | val_accuracy: 0.52859 |  0:50:02s\n",
            "epoch 2523| loss: 0.66485 | train_accuracy: 0.68404 | val_accuracy: 0.53059 |  0:50:04s\n",
            "epoch 2524| loss: 0.66471 | train_accuracy: 0.68048 | val_accuracy: 0.52899 |  0:50:05s\n",
            "epoch 2525| loss: 0.66205 | train_accuracy: 0.68062 | val_accuracy: 0.53099 |  0:50:06s\n",
            "epoch 2526| loss: 0.66624 | train_accuracy: 0.68035 | val_accuracy: 0.52139 |  0:50:07s\n",
            "epoch 2527| loss: 0.66416 | train_accuracy: 0.67959 | val_accuracy: 0.52539 |  0:50:08s\n",
            "epoch 2528| loss: 0.66442 | train_accuracy: 0.6823  | val_accuracy: 0.53299 |  0:50:10s\n",
            "epoch 2529| loss: 0.66577 | train_accuracy: 0.68297 | val_accuracy: 0.53699 |  0:50:11s\n",
            "epoch 2530| loss: 0.66264 | train_accuracy: 0.68199 | val_accuracy: 0.53219 |  0:50:12s\n",
            "epoch 2531| loss: 0.66625 | train_accuracy: 0.67933 | val_accuracy: 0.52619 |  0:50:13s\n",
            "epoch 2532| loss: 0.66913 | train_accuracy: 0.67786 | val_accuracy: 0.52499 |  0:50:14s\n",
            "epoch 2533| loss: 0.66244 | train_accuracy: 0.67919 | val_accuracy: 0.53099 |  0:50:16s\n",
            "epoch 2534| loss: 0.66544 | train_accuracy: 0.6839  | val_accuracy: 0.52659 |  0:50:17s\n",
            "epoch 2535| loss: 0.66747 | train_accuracy: 0.68257 | val_accuracy: 0.53259 |  0:50:18s\n",
            "epoch 2536| loss: 0.66919 | train_accuracy: 0.68382 | val_accuracy: 0.53139 |  0:50:19s\n",
            "epoch 2537| loss: 0.66016 | train_accuracy: 0.68337 | val_accuracy: 0.53419 |  0:50:20s\n",
            "epoch 2538| loss: 0.66364 | train_accuracy: 0.68195 | val_accuracy: 0.53259 |  0:50:22s\n",
            "epoch 2539| loss: 0.66445 | train_accuracy: 0.68026 | val_accuracy: 0.52899 |  0:50:23s\n",
            "epoch 2540| loss: 0.6619  | train_accuracy: 0.68102 | val_accuracy: 0.52539 |  0:50:24s\n",
            "epoch 2541| loss: 0.66369 | train_accuracy: 0.68053 | val_accuracy: 0.52699 |  0:50:25s\n",
            "epoch 2542| loss: 0.66165 | train_accuracy: 0.68004 | val_accuracy: 0.53059 |  0:50:26s\n",
            "epoch 2543| loss: 0.66849 | train_accuracy: 0.68004 | val_accuracy: 0.52659 |  0:50:28s\n",
            "epoch 2544| loss: 0.6649  | train_accuracy: 0.6776  | val_accuracy: 0.52299 |  0:50:29s\n",
            "epoch 2545| loss: 0.66068 | train_accuracy: 0.67946 | val_accuracy: 0.52819 |  0:50:30s\n",
            "epoch 2546| loss: 0.66027 | train_accuracy: 0.68048 | val_accuracy: 0.53099 |  0:50:31s\n",
            "epoch 2547| loss: 0.66069 | train_accuracy: 0.67919 | val_accuracy: 0.53139 |  0:50:32s\n",
            "epoch 2548| loss: 0.66106 | train_accuracy: 0.68142 | val_accuracy: 0.52099 |  0:50:34s\n",
            "epoch 2549| loss: 0.66514 | train_accuracy: 0.68057 | val_accuracy: 0.51379 |  0:50:35s\n",
            "epoch 2550| loss: 0.65809 | train_accuracy: 0.68199 | val_accuracy: 0.52499 |  0:50:36s\n",
            "epoch 2551| loss: 0.66004 | train_accuracy: 0.68164 | val_accuracy: 0.51699 |  0:50:37s\n",
            "epoch 2552| loss: 0.66232 | train_accuracy: 0.68333 | val_accuracy: 0.51899 |  0:50:38s\n",
            "epoch 2553| loss: 0.6604  | train_accuracy: 0.68204 | val_accuracy: 0.52899 |  0:50:40s\n",
            "epoch 2554| loss: 0.66001 | train_accuracy: 0.68182 | val_accuracy: 0.52059 |  0:50:41s\n",
            "epoch 2555| loss: 0.65804 | train_accuracy: 0.68235 | val_accuracy: 0.52259 |  0:50:42s\n",
            "epoch 2556| loss: 0.6586  | train_accuracy: 0.67915 | val_accuracy: 0.52939 |  0:50:43s\n",
            "epoch 2557| loss: 0.66376 | train_accuracy: 0.68155 | val_accuracy: 0.52779 |  0:50:44s\n",
            "epoch 2558| loss: 0.66504 | train_accuracy: 0.68284 | val_accuracy: 0.52979 |  0:50:45s\n",
            "epoch 2559| loss: 0.6614  | train_accuracy: 0.68133 | val_accuracy: 0.53099 |  0:50:47s\n",
            "epoch 2560| loss: 0.65568 | train_accuracy: 0.68191 | val_accuracy: 0.53019 |  0:50:48s\n",
            "epoch 2561| loss: 0.65813 | train_accuracy: 0.68204 | val_accuracy: 0.53299 |  0:50:49s\n",
            "epoch 2562| loss: 0.6617  | train_accuracy: 0.6847  | val_accuracy: 0.52899 |  0:50:50s\n",
            "epoch 2563| loss: 0.65445 | train_accuracy: 0.6847  | val_accuracy: 0.53299 |  0:50:51s\n",
            "epoch 2564| loss: 0.65374 | train_accuracy: 0.68346 | val_accuracy: 0.52659 |  0:50:53s\n",
            "epoch 2565| loss: 0.65499 | train_accuracy: 0.68435 | val_accuracy: 0.53419 |  0:50:54s\n",
            "epoch 2566| loss: 0.65627 | train_accuracy: 0.68448 | val_accuracy: 0.53619 |  0:50:55s\n",
            "epoch 2567| loss: 0.65628 | train_accuracy: 0.68457 | val_accuracy: 0.52739 |  0:50:56s\n",
            "epoch 2568| loss: 0.6563  | train_accuracy: 0.68457 | val_accuracy: 0.52939 |  0:50:57s\n",
            "epoch 2569| loss: 0.65434 | train_accuracy: 0.68373 | val_accuracy: 0.52619 |  0:50:59s\n",
            "epoch 2570| loss: 0.65468 | train_accuracy: 0.68364 | val_accuracy: 0.53179 |  0:51:00s\n",
            "epoch 2571| loss: 0.65409 | train_accuracy: 0.68253 | val_accuracy: 0.53139 |  0:51:01s\n",
            "epoch 2572| loss: 0.65772 | train_accuracy: 0.68097 | val_accuracy: 0.52779 |  0:51:02s\n",
            "epoch 2573| loss: 0.65916 | train_accuracy: 0.68262 | val_accuracy: 0.52899 |  0:51:03s\n",
            "epoch 2574| loss: 0.65371 | train_accuracy: 0.68377 | val_accuracy: 0.52459 |  0:51:05s\n",
            "epoch 2575| loss: 0.65759 | train_accuracy: 0.68359 | val_accuracy: 0.52139 |  0:51:06s\n",
            "epoch 2576| loss: 0.65582 | train_accuracy: 0.68368 | val_accuracy: 0.52819 |  0:51:07s\n",
            "epoch 2577| loss: 0.65758 | train_accuracy: 0.68359 | val_accuracy: 0.51979 |  0:51:08s\n",
            "epoch 2578| loss: 0.66583 | train_accuracy: 0.68217 | val_accuracy: 0.52499 |  0:51:09s\n",
            "epoch 2579| loss: 0.66024 | train_accuracy: 0.68119 | val_accuracy: 0.51939 |  0:51:11s\n",
            "epoch 2580| loss: 0.6816  | train_accuracy: 0.68133 | val_accuracy: 0.52819 |  0:51:12s\n",
            "epoch 2581| loss: 0.70407 | train_accuracy: 0.67835 | val_accuracy: 0.52819 |  0:51:13s\n",
            "epoch 2582| loss: 0.71402 | train_accuracy: 0.66884 | val_accuracy: 0.52019 |  0:51:14s\n",
            "epoch 2583| loss: 0.73487 | train_accuracy: 0.66782 | val_accuracy: 0.52659 |  0:51:15s\n",
            "epoch 2584| loss: 0.75705 | train_accuracy: 0.66898 | val_accuracy: 0.51899 |  0:51:17s\n",
            "epoch 2585| loss: 0.70815 | train_accuracy: 0.672   | val_accuracy: 0.51619 |  0:51:18s\n",
            "epoch 2586| loss: 0.70068 | train_accuracy: 0.6728  | val_accuracy: 0.52259 |  0:51:19s\n",
            "epoch 2587| loss: 0.69375 | train_accuracy: 0.67275 | val_accuracy: 0.52859 |  0:51:20s\n",
            "epoch 2588| loss: 0.6919  | train_accuracy: 0.67582 | val_accuracy: 0.52539 |  0:51:21s\n",
            "epoch 2589| loss: 0.6904  | train_accuracy: 0.67697 | val_accuracy: 0.52859 |  0:51:23s\n",
            "epoch 2590| loss: 0.68496 | train_accuracy: 0.67688 | val_accuracy: 0.52619 |  0:51:24s\n",
            "epoch 2591| loss: 0.68157 | train_accuracy: 0.6788  | val_accuracy: 0.52219 |  0:51:25s\n",
            "epoch 2592| loss: 0.67393 | train_accuracy: 0.68151 | val_accuracy: 0.52219 |  0:51:26s\n",
            "epoch 2593| loss: 0.67573 | train_accuracy: 0.68111 | val_accuracy: 0.52459 |  0:51:27s\n",
            "epoch 2594| loss: 0.67574 | train_accuracy: 0.68142 | val_accuracy: 0.53099 |  0:51:29s\n",
            "epoch 2595| loss: 0.67102 | train_accuracy: 0.68022 | val_accuracy: 0.52659 |  0:51:30s\n",
            "epoch 2596| loss: 0.66618 | train_accuracy: 0.68213 | val_accuracy: 0.52059 |  0:51:31s\n",
            "epoch 2597| loss: 0.67475 | train_accuracy: 0.67995 | val_accuracy: 0.52619 |  0:51:32s\n",
            "epoch 2598| loss: 0.69677 | train_accuracy: 0.67546 | val_accuracy: 0.52579 |  0:51:33s\n",
            "epoch 2599| loss: 0.72575 | train_accuracy: 0.67862 | val_accuracy: 0.53139 |  0:51:34s\n",
            "epoch 2600| loss: 0.70536 | train_accuracy: 0.67746 | val_accuracy: 0.53059 |  0:51:36s\n",
            "epoch 2601| loss: 0.70513 | train_accuracy: 0.67848 | val_accuracy: 0.53539 |  0:51:37s\n",
            "epoch 2602| loss: 0.69663 | train_accuracy: 0.68284 | val_accuracy: 0.52779 |  0:51:38s\n",
            "epoch 2603| loss: 0.68435 | train_accuracy: 0.68377 | val_accuracy: 0.53099 |  0:51:39s\n",
            "epoch 2604| loss: 0.68169 | train_accuracy: 0.68466 | val_accuracy: 0.53059 |  0:51:40s\n",
            "epoch 2605| loss: 0.68351 | train_accuracy: 0.68546 | val_accuracy: 0.52819 |  0:51:42s\n",
            "epoch 2606| loss: 0.67743 | train_accuracy: 0.68324 | val_accuracy: 0.53339 |  0:51:43s\n",
            "epoch 2607| loss: 0.66865 | train_accuracy: 0.68728 | val_accuracy: 0.52099 |  0:51:44s\n",
            "epoch 2608| loss: 0.66939 | train_accuracy: 0.6863  | val_accuracy: 0.52659 |  0:51:45s\n",
            "epoch 2609| loss: 0.67574 | train_accuracy: 0.68821 | val_accuracy: 0.51979 |  0:51:46s\n",
            "epoch 2610| loss: 0.66484 | train_accuracy: 0.68995 | val_accuracy: 0.52459 |  0:51:48s\n",
            "epoch 2611| loss: 0.67135 | train_accuracy: 0.68955 | val_accuracy: 0.52619 |  0:51:49s\n",
            "epoch 2612| loss: 0.66989 | train_accuracy: 0.69106 | val_accuracy: 0.52699 |  0:51:50s\n",
            "epoch 2613| loss: 0.66411 | train_accuracy: 0.68777 | val_accuracy: 0.52979 |  0:51:51s\n",
            "epoch 2614| loss: 0.66618 | train_accuracy: 0.69083 | val_accuracy: 0.53179 |  0:51:52s\n",
            "epoch 2615| loss: 0.66181 | train_accuracy: 0.69252 | val_accuracy: 0.53579 |  0:51:53s\n",
            "epoch 2616| loss: 0.66026 | train_accuracy: 0.69168 | val_accuracy: 0.53259 |  0:51:55s\n",
            "epoch 2617| loss: 0.66592 | train_accuracy: 0.69341 | val_accuracy: 0.53499 |  0:51:56s\n",
            "epoch 2618| loss: 0.66715 | train_accuracy: 0.69488 | val_accuracy: 0.53499 |  0:51:57s\n",
            "epoch 2619| loss: 0.65539 | train_accuracy: 0.69452 | val_accuracy: 0.53259 |  0:51:58s\n",
            "epoch 2620| loss: 0.66418 | train_accuracy: 0.69519 | val_accuracy: 0.52659 |  0:51:59s\n",
            "epoch 2621| loss: 0.66501 | train_accuracy: 0.69283 | val_accuracy: 0.52659 |  0:52:01s\n",
            "epoch 2622| loss: 0.66136 | train_accuracy: 0.69279 | val_accuracy: 0.52899 |  0:52:02s\n",
            "epoch 2623| loss: 0.66642 | train_accuracy: 0.69155 | val_accuracy: 0.53459 |  0:52:03s\n",
            "epoch 2624| loss: 0.66926 | train_accuracy: 0.69163 | val_accuracy: 0.53019 |  0:52:04s\n",
            "epoch 2625| loss: 0.66087 | train_accuracy: 0.69221 | val_accuracy: 0.52819 |  0:52:05s\n",
            "epoch 2626| loss: 0.66229 | train_accuracy: 0.69106 | val_accuracy: 0.53219 |  0:52:06s\n",
            "epoch 2627| loss: 0.66583 | train_accuracy: 0.69123 | val_accuracy: 0.52619 |  0:52:08s\n",
            "epoch 2628| loss: 0.66692 | train_accuracy: 0.69106 | val_accuracy: 0.52339 |  0:52:09s\n",
            "epoch 2629| loss: 0.66403 | train_accuracy: 0.69141 | val_accuracy: 0.52019 |  0:52:10s\n",
            "epoch 2630| loss: 0.65946 | train_accuracy: 0.69461 | val_accuracy: 0.52419 |  0:52:11s\n",
            "epoch 2631| loss: 0.65823 | train_accuracy: 0.69372 | val_accuracy: 0.52379 |  0:52:12s\n",
            "epoch 2632| loss: 0.66178 | train_accuracy: 0.69608 | val_accuracy: 0.52259 |  0:52:14s\n",
            "epoch 2633| loss: 0.65933 | train_accuracy: 0.69341 | val_accuracy: 0.52979 |  0:52:15s\n",
            "epoch 2634| loss: 0.66493 | train_accuracy: 0.6935  | val_accuracy: 0.52499 |  0:52:16s\n",
            "epoch 2635| loss: 0.66154 | train_accuracy: 0.69585 | val_accuracy: 0.52179 |  0:52:17s\n",
            "epoch 2636| loss: 0.65481 | train_accuracy: 0.69652 | val_accuracy: 0.51859 |  0:52:18s\n",
            "epoch 2637| loss: 0.66025 | train_accuracy: 0.69421 | val_accuracy: 0.52339 |  0:52:20s\n",
            "epoch 2638| loss: 0.65237 | train_accuracy: 0.69363 | val_accuracy: 0.52179 |  0:52:21s\n",
            "epoch 2639| loss: 0.65584 | train_accuracy: 0.69439 | val_accuracy: 0.52219 |  0:52:22s\n",
            "epoch 2640| loss: 0.65744 | train_accuracy: 0.69728 | val_accuracy: 0.52219 |  0:52:23s\n",
            "epoch 2641| loss: 0.66055 | train_accuracy: 0.69772 | val_accuracy: 0.52539 |  0:52:24s\n",
            "epoch 2642| loss: 0.66109 | train_accuracy: 0.69808 | val_accuracy: 0.51859 |  0:52:26s\n",
            "epoch 2643| loss: 0.65975 | train_accuracy: 0.69901 | val_accuracy: 0.52299 |  0:52:27s\n",
            "epoch 2644| loss: 0.66317 | train_accuracy: 0.6943  | val_accuracy: 0.52779 |  0:52:28s\n",
            "epoch 2645| loss: 0.65337 | train_accuracy: 0.69554 | val_accuracy: 0.51739 |  0:52:29s\n",
            "epoch 2646| loss: 0.65236 | train_accuracy: 0.69808 | val_accuracy: 0.52019 |  0:52:30s\n",
            "epoch 2647| loss: 0.65187 | train_accuracy: 0.69723 | val_accuracy: 0.52339 |  0:52:32s\n",
            "epoch 2648| loss: 0.65362 | train_accuracy: 0.69674 | val_accuracy: 0.52659 |  0:52:33s\n",
            "epoch 2649| loss: 0.64731 | train_accuracy: 0.69648 | val_accuracy: 0.52379 |  0:52:34s\n",
            "epoch 2650| loss: 0.64919 | train_accuracy: 0.69603 | val_accuracy: 0.52219 |  0:52:35s\n",
            "epoch 2651| loss: 0.64494 | train_accuracy: 0.69625 | val_accuracy: 0.53059 |  0:52:37s\n",
            "epoch 2652| loss: 0.65225 | train_accuracy: 0.6963  | val_accuracy: 0.52619 |  0:52:38s\n",
            "epoch 2653| loss: 0.64634 | train_accuracy: 0.69781 | val_accuracy: 0.52579 |  0:52:39s\n",
            "epoch 2654| loss: 0.64567 | train_accuracy: 0.69945 | val_accuracy: 0.51979 |  0:52:40s\n",
            "epoch 2655| loss: 0.65141 | train_accuracy: 0.70056 | val_accuracy: 0.52259 |  0:52:41s\n",
            "epoch 2656| loss: 0.63894 | train_accuracy: 0.70274 | val_accuracy: 0.52299 |  0:52:43s\n",
            "epoch 2657| loss: 0.64293 | train_accuracy: 0.70145 | val_accuracy: 0.52659 |  0:52:44s\n",
            "epoch 2658| loss: 0.64765 | train_accuracy: 0.69968 | val_accuracy: 0.52499 |  0:52:45s\n",
            "epoch 2659| loss: 0.64495 | train_accuracy: 0.69879 | val_accuracy: 0.52219 |  0:52:46s\n",
            "epoch 2660| loss: 0.64477 | train_accuracy: 0.70092 | val_accuracy: 0.52739 |  0:52:47s\n",
            "epoch 2661| loss: 0.63897 | train_accuracy: 0.69994 | val_accuracy: 0.52379 |  0:52:48s\n",
            "epoch 2662| loss: 0.64254 | train_accuracy: 0.69945 | val_accuracy: 0.52139 |  0:52:50s\n",
            "epoch 2663| loss: 0.64164 | train_accuracy: 0.69861 | val_accuracy: 0.51819 |  0:52:51s\n",
            "epoch 2664| loss: 0.6447  | train_accuracy: 0.69861 | val_accuracy: 0.52099 |  0:52:52s\n",
            "epoch 2665| loss: 0.64428 | train_accuracy: 0.69981 | val_accuracy: 0.51819 |  0:52:53s\n",
            "epoch 2666| loss: 0.64084 | train_accuracy: 0.69892 | val_accuracy: 0.52579 |  0:52:54s\n",
            "epoch 2667| loss: 0.64497 | train_accuracy: 0.69972 | val_accuracy: 0.52899 |  0:52:56s\n",
            "epoch 2668| loss: 0.64501 | train_accuracy: 0.6963  | val_accuracy: 0.52899 |  0:52:57s\n",
            "epoch 2669| loss: 0.64381 | train_accuracy: 0.69737 | val_accuracy: 0.53379 |  0:52:58s\n",
            "epoch 2670| loss: 0.63574 | train_accuracy: 0.69883 | val_accuracy: 0.52619 |  0:52:59s\n",
            "epoch 2671| loss: 0.64069 | train_accuracy: 0.69963 | val_accuracy: 0.53179 |  0:53:00s\n",
            "epoch 2672| loss: 0.64089 | train_accuracy: 0.69923 | val_accuracy: 0.52979 |  0:53:02s\n",
            "epoch 2673| loss: 0.63682 | train_accuracy: 0.69683 | val_accuracy: 0.52779 |  0:53:03s\n",
            "epoch 2674| loss: 0.63859 | train_accuracy: 0.70092 | val_accuracy: 0.53699 |  0:53:04s\n",
            "epoch 2675| loss: 0.6365  | train_accuracy: 0.69954 | val_accuracy: 0.53019 |  0:53:05s\n",
            "epoch 2676| loss: 0.63231 | train_accuracy: 0.69808 | val_accuracy: 0.52499 |  0:53:06s\n",
            "epoch 2677| loss: 0.63938 | train_accuracy: 0.69825 | val_accuracy: 0.52939 |  0:53:08s\n",
            "epoch 2678| loss: 0.64355 | train_accuracy: 0.70003 | val_accuracy: 0.53019 |  0:53:09s\n",
            "epoch 2679| loss: 0.63892 | train_accuracy: 0.70025 | val_accuracy: 0.52739 |  0:53:10s\n",
            "epoch 2680| loss: 0.63781 | train_accuracy: 0.69954 | val_accuracy: 0.52899 |  0:53:11s\n",
            "epoch 2681| loss: 0.6408  | train_accuracy: 0.70194 | val_accuracy: 0.52779 |  0:53:12s\n",
            "epoch 2682| loss: 0.63691 | train_accuracy: 0.70096 | val_accuracy: 0.53219 |  0:53:14s\n",
            "epoch 2683| loss: 0.64301 | train_accuracy: 0.70123 | val_accuracy: 0.52859 |  0:53:15s\n",
            "epoch 2684| loss: 0.64063 | train_accuracy: 0.70012 | val_accuracy: 0.53739 |  0:53:16s\n",
            "epoch 2685| loss: 0.64252 | train_accuracy: 0.70008 | val_accuracy: 0.52699 |  0:53:17s\n",
            "epoch 2686| loss: 0.63957 | train_accuracy: 0.7027  | val_accuracy: 0.52819 |  0:53:18s\n",
            "epoch 2687| loss: 0.64144 | train_accuracy: 0.70061 | val_accuracy: 0.53379 |  0:53:20s\n",
            "epoch 2688| loss: 0.63796 | train_accuracy: 0.69976 | val_accuracy: 0.53219 |  0:53:21s\n",
            "epoch 2689| loss: 0.6373  | train_accuracy: 0.70274 | val_accuracy: 0.52979 |  0:53:22s\n",
            "epoch 2690| loss: 0.63761 | train_accuracy: 0.70061 | val_accuracy: 0.52579 |  0:53:23s\n",
            "epoch 2691| loss: 0.63957 | train_accuracy: 0.70056 | val_accuracy: 0.52419 |  0:53:24s\n",
            "epoch 2692| loss: 0.63553 | train_accuracy: 0.70163 | val_accuracy: 0.52819 |  0:53:26s\n",
            "epoch 2693| loss: 0.63879 | train_accuracy: 0.70096 | val_accuracy: 0.52259 |  0:53:27s\n",
            "epoch 2694| loss: 0.6335  | train_accuracy: 0.70132 | val_accuracy: 0.52939 |  0:53:28s\n",
            "epoch 2695| loss: 0.63552 | train_accuracy: 0.69954 | val_accuracy: 0.53059 |  0:53:29s\n",
            "epoch 2696| loss: 0.63762 | train_accuracy: 0.70034 | val_accuracy: 0.52579 |  0:53:30s\n",
            "epoch 2697| loss: 0.63762 | train_accuracy: 0.69896 | val_accuracy: 0.52219 |  0:53:32s\n",
            "epoch 2698| loss: 0.64708 | train_accuracy: 0.69688 | val_accuracy: 0.52379 |  0:53:33s\n",
            "epoch 2699| loss: 0.64364 | train_accuracy: 0.69554 | val_accuracy: 0.52459 |  0:53:34s\n",
            "epoch 2700| loss: 0.64285 | train_accuracy: 0.69674 | val_accuracy: 0.52739 |  0:53:36s\n",
            "epoch 2701| loss: 0.64714 | train_accuracy: 0.69777 | val_accuracy: 0.52899 |  0:53:38s\n",
            "epoch 2702| loss: 0.64312 | train_accuracy: 0.69741 | val_accuracy: 0.52819 |  0:53:39s\n",
            "epoch 2703| loss: 0.63864 | train_accuracy: 0.69745 | val_accuracy: 0.53259 |  0:53:41s\n",
            "epoch 2704| loss: 0.64529 | train_accuracy: 0.69839 | val_accuracy: 0.52419 |  0:53:42s\n",
            "epoch 2705| loss: 0.63723 | train_accuracy: 0.70034 | val_accuracy: 0.52459 |  0:53:43s\n",
            "epoch 2706| loss: 0.63703 | train_accuracy: 0.69865 | val_accuracy: 0.52379 |  0:53:44s\n",
            "epoch 2707| loss: 0.63582 | train_accuracy: 0.69808 | val_accuracy: 0.53459 |  0:53:45s\n",
            "epoch 2708| loss: 0.63343 | train_accuracy: 0.70065 | val_accuracy: 0.52779 |  0:53:47s\n",
            "epoch 2709| loss: 0.63546 | train_accuracy: 0.70048 | val_accuracy: 0.53019 |  0:53:48s\n",
            "epoch 2710| loss: 0.63543 | train_accuracy: 0.7003  | val_accuracy: 0.52499 |  0:53:49s\n",
            "epoch 2711| loss: 0.64035 | train_accuracy: 0.70088 | val_accuracy: 0.53099 |  0:53:50s\n",
            "epoch 2712| loss: 0.63855 | train_accuracy: 0.69981 | val_accuracy: 0.52579 |  0:53:51s\n",
            "epoch 2713| loss: 0.63292 | train_accuracy: 0.69865 | val_accuracy: 0.53499 |  0:53:52s\n",
            "epoch 2714| loss: 0.63365 | train_accuracy: 0.69781 | val_accuracy: 0.52739 |  0:53:54s\n",
            "epoch 2715| loss: 0.63687 | train_accuracy: 0.6991  | val_accuracy: 0.53259 |  0:53:55s\n",
            "epoch 2716| loss: 0.63714 | train_accuracy: 0.69923 | val_accuracy: 0.53339 |  0:53:56s\n",
            "epoch 2717| loss: 0.62944 | train_accuracy: 0.70092 | val_accuracy: 0.52419 |  0:53:57s\n",
            "epoch 2718| loss: 0.6392  | train_accuracy: 0.70154 | val_accuracy: 0.52819 |  0:53:58s\n",
            "epoch 2719| loss: 0.63145 | train_accuracy: 0.70314 | val_accuracy: 0.53419 |  0:53:59s\n",
            "epoch 2720| loss: 0.63517 | train_accuracy: 0.69928 | val_accuracy: 0.52979 |  0:54:01s\n",
            "epoch 2721| loss: 0.63497 | train_accuracy: 0.69905 | val_accuracy: 0.52939 |  0:54:02s\n",
            "epoch 2722| loss: 0.63774 | train_accuracy: 0.69919 | val_accuracy: 0.52939 |  0:54:03s\n",
            "epoch 2723| loss: 0.641   | train_accuracy: 0.69808 | val_accuracy: 0.52939 |  0:54:04s\n",
            "epoch 2724| loss: 0.63129 | train_accuracy: 0.69941 | val_accuracy: 0.52539 |  0:54:05s\n",
            "epoch 2725| loss: 0.63198 | train_accuracy: 0.69928 | val_accuracy: 0.53419 |  0:54:07s\n",
            "epoch 2726| loss: 0.62607 | train_accuracy: 0.70065 | val_accuracy: 0.52459 |  0:54:08s\n",
            "epoch 2727| loss: 0.63796 | train_accuracy: 0.69932 | val_accuracy: 0.53099 |  0:54:09s\n",
            "epoch 2728| loss: 0.63225 | train_accuracy: 0.70181 | val_accuracy: 0.53139 |  0:54:10s\n",
            "epoch 2729| loss: 0.62809 | train_accuracy: 0.70225 | val_accuracy: 0.53219 |  0:54:11s\n",
            "epoch 2730| loss: 0.63278 | train_accuracy: 0.70092 | val_accuracy: 0.53179 |  0:54:12s\n",
            "epoch 2731| loss: 0.63214 | train_accuracy: 0.70052 | val_accuracy: 0.53379 |  0:54:14s\n",
            "epoch 2732| loss: 0.63497 | train_accuracy: 0.69825 | val_accuracy: 0.53179 |  0:54:15s\n",
            "epoch 2733| loss: 0.63297 | train_accuracy: 0.6995  | val_accuracy: 0.52779 |  0:54:16s\n",
            "epoch 2734| loss: 0.63375 | train_accuracy: 0.70039 | val_accuracy: 0.53019 |  0:54:17s\n",
            "epoch 2735| loss: 0.637   | train_accuracy: 0.70025 | val_accuracy: 0.53339 |  0:54:18s\n",
            "epoch 2736| loss: 0.63607 | train_accuracy: 0.69905 | val_accuracy: 0.52859 |  0:54:20s\n",
            "epoch 2737| loss: 0.6349  | train_accuracy: 0.70052 | val_accuracy: 0.52419 |  0:54:21s\n",
            "epoch 2738| loss: 0.63595 | train_accuracy: 0.70003 | val_accuracy: 0.52459 |  0:54:22s\n",
            "epoch 2739| loss: 0.63787 | train_accuracy: 0.69959 | val_accuracy: 0.52739 |  0:54:23s\n",
            "epoch 2740| loss: 0.63764 | train_accuracy: 0.70056 | val_accuracy: 0.52819 |  0:54:24s\n",
            "epoch 2741| loss: 0.63856 | train_accuracy: 0.6991  | val_accuracy: 0.52739 |  0:54:26s\n",
            "epoch 2742| loss: 0.63925 | train_accuracy: 0.69923 | val_accuracy: 0.52459 |  0:54:27s\n",
            "epoch 2743| loss: 0.63568 | train_accuracy: 0.6999  | val_accuracy: 0.52459 |  0:54:28s\n",
            "epoch 2744| loss: 0.63733 | train_accuracy: 0.69901 | val_accuracy: 0.53059 |  0:54:29s\n",
            "epoch 2745| loss: 0.63658 | train_accuracy: 0.69968 | val_accuracy: 0.52219 |  0:54:30s\n",
            "epoch 2746| loss: 0.63155 | train_accuracy: 0.69865 | val_accuracy: 0.52459 |  0:54:32s\n",
            "epoch 2747| loss: 0.63578 | train_accuracy: 0.69879 | val_accuracy: 0.52419 |  0:54:33s\n",
            "epoch 2748| loss: 0.63319 | train_accuracy: 0.69848 | val_accuracy: 0.52859 |  0:54:34s\n",
            "epoch 2749| loss: 0.64121 | train_accuracy: 0.69697 | val_accuracy: 0.52899 |  0:54:35s\n",
            "epoch 2750| loss: 0.63528 | train_accuracy: 0.70039 | val_accuracy: 0.51779 |  0:54:36s\n",
            "epoch 2751| loss: 0.63183 | train_accuracy: 0.70012 | val_accuracy: 0.52339 |  0:54:38s\n",
            "epoch 2752| loss: 0.6358  | train_accuracy: 0.69857 | val_accuracy: 0.52139 |  0:54:39s\n",
            "epoch 2753| loss: 0.63343 | train_accuracy: 0.69808 | val_accuracy: 0.52339 |  0:54:40s\n",
            "epoch 2754| loss: 0.63383 | train_accuracy: 0.70012 | val_accuracy: 0.52179 |  0:54:42s\n",
            "epoch 2755| loss: 0.63408 | train_accuracy: 0.70105 | val_accuracy: 0.52779 |  0:54:43s\n",
            "epoch 2756| loss: 0.63646 | train_accuracy: 0.69981 | val_accuracy: 0.52139 |  0:54:45s\n",
            "epoch 2757| loss: 0.63654 | train_accuracy: 0.69932 | val_accuracy: 0.52779 |  0:54:46s\n",
            "epoch 2758| loss: 0.64254 | train_accuracy: 0.69803 | val_accuracy: 0.52779 |  0:54:47s\n",
            "epoch 2759| loss: 0.64324 | train_accuracy: 0.69634 | val_accuracy: 0.52339 |  0:54:48s\n",
            "epoch 2760| loss: 0.64169 | train_accuracy: 0.69679 | val_accuracy: 0.52979 |  0:54:50s\n",
            "epoch 2761| loss: 0.63679 | train_accuracy: 0.69697 | val_accuracy: 0.52539 |  0:54:51s\n",
            "epoch 2762| loss: 0.64038 | train_accuracy: 0.6979  | val_accuracy: 0.52299 |  0:54:52s\n",
            "epoch 2763| loss: 0.63547 | train_accuracy: 0.70056 | val_accuracy: 0.51939 |  0:54:53s\n",
            "epoch 2764| loss: 0.63529 | train_accuracy: 0.69905 | val_accuracy: 0.51939 |  0:54:54s\n",
            "epoch 2765| loss: 0.63221 | train_accuracy: 0.7011  | val_accuracy: 0.51619 |  0:54:56s\n",
            "epoch 2766| loss: 0.63848 | train_accuracy: 0.69901 | val_accuracy: 0.51819 |  0:54:57s\n",
            "epoch 2767| loss: 0.64664 | train_accuracy: 0.69941 | val_accuracy: 0.52299 |  0:54:58s\n",
            "epoch 2768| loss: 0.63934 | train_accuracy: 0.70167 | val_accuracy: 0.51659 |  0:54:59s\n",
            "epoch 2769| loss: 0.63706 | train_accuracy: 0.69954 | val_accuracy: 0.52299 |  0:55:00s\n",
            "epoch 2770| loss: 0.64129 | train_accuracy: 0.70145 | val_accuracy: 0.52299 |  0:55:02s\n",
            "epoch 2771| loss: 0.63733 | train_accuracy: 0.70301 | val_accuracy: 0.53339 |  0:55:03s\n",
            "epoch 2772| loss: 0.63412 | train_accuracy: 0.70088 | val_accuracy: 0.52779 |  0:55:04s\n",
            "epoch 2773| loss: 0.63407 | train_accuracy: 0.70132 | val_accuracy: 0.51939 |  0:55:05s\n",
            "epoch 2774| loss: 0.63218 | train_accuracy: 0.70025 | val_accuracy: 0.51979 |  0:55:06s\n",
            "epoch 2775| loss: 0.63024 | train_accuracy: 0.70141 | val_accuracy: 0.52379 |  0:55:07s\n",
            "epoch 2776| loss: 0.62907 | train_accuracy: 0.70163 | val_accuracy: 0.52419 |  0:55:09s\n",
            "epoch 2777| loss: 0.6353  | train_accuracy: 0.70128 | val_accuracy: 0.52659 |  0:55:10s\n",
            "epoch 2778| loss: 0.63111 | train_accuracy: 0.69892 | val_accuracy: 0.52019 |  0:55:11s\n",
            "epoch 2779| loss: 0.62908 | train_accuracy: 0.70172 | val_accuracy: 0.52579 |  0:55:12s\n",
            "epoch 2780| loss: 0.63022 | train_accuracy: 0.7027  | val_accuracy: 0.53139 |  0:55:13s\n",
            "epoch 2781| loss: 0.62733 | train_accuracy: 0.7039  | val_accuracy: 0.53299 |  0:55:15s\n",
            "epoch 2782| loss: 0.62506 | train_accuracy: 0.70363 | val_accuracy: 0.52939 |  0:55:16s\n",
            "epoch 2783| loss: 0.62839 | train_accuracy: 0.70216 | val_accuracy: 0.52619 |  0:55:17s\n",
            "epoch 2784| loss: 0.63245 | train_accuracy: 0.70025 | val_accuracy: 0.53499 |  0:55:18s\n",
            "epoch 2785| loss: 0.6294  | train_accuracy: 0.70181 | val_accuracy: 0.52819 |  0:55:19s\n",
            "epoch 2786| loss: 0.63342 | train_accuracy: 0.70327 | val_accuracy: 0.53099 |  0:55:20s\n",
            "epoch 2787| loss: 0.6333  | train_accuracy: 0.70399 | val_accuracy: 0.53179 |  0:55:22s\n",
            "epoch 2788| loss: 0.62498 | train_accuracy: 0.7015  | val_accuracy: 0.53339 |  0:55:23s\n",
            "epoch 2789| loss: 0.63212 | train_accuracy: 0.70283 | val_accuracy: 0.52939 |  0:55:24s\n",
            "epoch 2790| loss: 0.62635 | train_accuracy: 0.70327 | val_accuracy: 0.53019 |  0:55:25s\n",
            "epoch 2791| loss: 0.62942 | train_accuracy: 0.70221 | val_accuracy: 0.52339 |  0:55:26s\n",
            "epoch 2792| loss: 0.62925 | train_accuracy: 0.70239 | val_accuracy: 0.52539 |  0:55:28s\n",
            "epoch 2793| loss: 0.62754 | train_accuracy: 0.70181 | val_accuracy: 0.52579 |  0:55:29s\n",
            "epoch 2794| loss: 0.6269  | train_accuracy: 0.70176 | val_accuracy: 0.53219 |  0:55:30s\n",
            "epoch 2795| loss: 0.62924 | train_accuracy: 0.7019  | val_accuracy: 0.52939 |  0:55:31s\n",
            "epoch 2796| loss: 0.62479 | train_accuracy: 0.70265 | val_accuracy: 0.52819 |  0:55:32s\n",
            "epoch 2797| loss: 0.63516 | train_accuracy: 0.70172 | val_accuracy: 0.52859 |  0:55:33s\n",
            "epoch 2798| loss: 0.63559 | train_accuracy: 0.70141 | val_accuracy: 0.52259 |  0:55:35s\n",
            "epoch 2799| loss: 0.63453 | train_accuracy: 0.70052 | val_accuracy: 0.52259 |  0:55:36s\n",
            "epoch 2800| loss: 0.63353 | train_accuracy: 0.70194 | val_accuracy: 0.52659 |  0:55:37s\n",
            "epoch 2801| loss: 0.62857 | train_accuracy: 0.70043 | val_accuracy: 0.52459 |  0:55:38s\n",
            "epoch 2802| loss: 0.63098 | train_accuracy: 0.70025 | val_accuracy: 0.52859 |  0:55:39s\n",
            "epoch 2803| loss: 0.62625 | train_accuracy: 0.70141 | val_accuracy: 0.53459 |  0:55:41s\n",
            "epoch 2804| loss: 0.63402 | train_accuracy: 0.7003  | val_accuracy: 0.53699 |  0:55:42s\n",
            "epoch 2805| loss: 0.63068 | train_accuracy: 0.70145 | val_accuracy: 0.53099 |  0:55:43s\n",
            "epoch 2806| loss: 0.63657 | train_accuracy: 0.7023  | val_accuracy: 0.53099 |  0:55:44s\n",
            "epoch 2807| loss: 0.63297 | train_accuracy: 0.70043 | val_accuracy: 0.53139 |  0:55:45s\n",
            "epoch 2808| loss: 0.62923 | train_accuracy: 0.70119 | val_accuracy: 0.52579 |  0:55:47s\n",
            "epoch 2809| loss: 0.62626 | train_accuracy: 0.7015  | val_accuracy: 0.52139 |  0:55:48s\n",
            "epoch 2810| loss: 0.62481 | train_accuracy: 0.70376 | val_accuracy: 0.52579 |  0:55:49s\n",
            "epoch 2811| loss: 0.63214 | train_accuracy: 0.70407 | val_accuracy: 0.52299 |  0:55:50s\n",
            "epoch 2812| loss: 0.6302  | train_accuracy: 0.70243 | val_accuracy: 0.52579 |  0:55:51s\n",
            "epoch 2813| loss: 0.62583 | train_accuracy: 0.70399 | val_accuracy: 0.52899 |  0:55:52s\n",
            "epoch 2814| loss: 0.63095 | train_accuracy: 0.70301 | val_accuracy: 0.52979 |  0:55:54s\n",
            "epoch 2815| loss: 0.63145 | train_accuracy: 0.70372 | val_accuracy: 0.52699 |  0:55:55s\n",
            "epoch 2816| loss: 0.63347 | train_accuracy: 0.7023  | val_accuracy: 0.53739 |  0:55:56s\n",
            "epoch 2817| loss: 0.6527  | train_accuracy: 0.70052 | val_accuracy: 0.53139 |  0:55:57s\n",
            "epoch 2818| loss: 0.64644 | train_accuracy: 0.69812 | val_accuracy: 0.52619 |  0:55:58s\n",
            "epoch 2819| loss: 0.64271 | train_accuracy: 0.7007  | val_accuracy: 0.52419 |  0:56:00s\n",
            "epoch 2820| loss: 0.63962 | train_accuracy: 0.70239 | val_accuracy: 0.53099 |  0:56:01s\n",
            "epoch 2821| loss: 0.63573 | train_accuracy: 0.7011  | val_accuracy: 0.53299 |  0:56:02s\n",
            "epoch 2822| loss: 0.63244 | train_accuracy: 0.70381 | val_accuracy: 0.53499 |  0:56:03s\n",
            "epoch 2823| loss: 0.62859 | train_accuracy: 0.70394 | val_accuracy: 0.53539 |  0:56:04s\n",
            "epoch 2824| loss: 0.63415 | train_accuracy: 0.70252 | val_accuracy: 0.52539 |  0:56:06s\n",
            "epoch 2825| loss: 0.62631 | train_accuracy: 0.70239 | val_accuracy: 0.52859 |  0:56:07s\n",
            "epoch 2826| loss: 0.63175 | train_accuracy: 0.70456 | val_accuracy: 0.53459 |  0:56:08s\n",
            "epoch 2827| loss: 0.62519 | train_accuracy: 0.7035  | val_accuracy: 0.52139 |  0:56:09s\n",
            "epoch 2828| loss: 0.62567 | train_accuracy: 0.70367 | val_accuracy: 0.52139 |  0:56:10s\n",
            "epoch 2829| loss: 0.62675 | train_accuracy: 0.70572 | val_accuracy: 0.51819 |  0:56:12s\n",
            "epoch 2830| loss: 0.62325 | train_accuracy: 0.70492 | val_accuracy: 0.52259 |  0:56:13s\n",
            "epoch 2831| loss: 0.62282 | train_accuracy: 0.70447 | val_accuracy: 0.52099 |  0:56:14s\n",
            "epoch 2832| loss: 0.62742 | train_accuracy: 0.70359 | val_accuracy: 0.52659 |  0:56:15s\n",
            "epoch 2833| loss: 0.62698 | train_accuracy: 0.70336 | val_accuracy: 0.52259 |  0:56:16s\n",
            "epoch 2834| loss: 0.62266 | train_accuracy: 0.70487 | val_accuracy: 0.52499 |  0:56:18s\n",
            "epoch 2835| loss: 0.62679 | train_accuracy: 0.70465 | val_accuracy: 0.52179 |  0:56:19s\n",
            "epoch 2836| loss: 0.62896 | train_accuracy: 0.70416 | val_accuracy: 0.51739 |  0:56:20s\n",
            "epoch 2837| loss: 0.62102 | train_accuracy: 0.70327 | val_accuracy: 0.51859 |  0:56:21s\n",
            "epoch 2838| loss: 0.62615 | train_accuracy: 0.7019  | val_accuracy: 0.52179 |  0:56:22s\n",
            "epoch 2839| loss: 0.62509 | train_accuracy: 0.70465 | val_accuracy: 0.52019 |  0:56:23s\n",
            "epoch 2840| loss: 0.62198 | train_accuracy: 0.70363 | val_accuracy: 0.52939 |  0:56:25s\n",
            "epoch 2841| loss: 0.61788 | train_accuracy: 0.7047  | val_accuracy: 0.52179 |  0:56:26s\n",
            "epoch 2842| loss: 0.62433 | train_accuracy: 0.70496 | val_accuracy: 0.52499 |  0:56:27s\n",
            "epoch 2843| loss: 0.63394 | train_accuracy: 0.70394 | val_accuracy: 0.52659 |  0:56:28s\n",
            "epoch 2844| loss: 0.63474 | train_accuracy: 0.70403 | val_accuracy: 0.53379 |  0:56:29s\n",
            "epoch 2845| loss: 0.62332 | train_accuracy: 0.70554 | val_accuracy: 0.53459 |  0:56:31s\n",
            "epoch 2846| loss: 0.6193  | train_accuracy: 0.70385 | val_accuracy: 0.52979 |  0:56:32s\n",
            "epoch 2847| loss: 0.62151 | train_accuracy: 0.70558 | val_accuracy: 0.52939 |  0:56:34s\n",
            "epoch 2848| loss: 0.62218 | train_accuracy: 0.70438 | val_accuracy: 0.52779 |  0:56:35s\n",
            "epoch 2849| loss: 0.62513 | train_accuracy: 0.70399 | val_accuracy: 0.52979 |  0:56:36s\n",
            "epoch 2850| loss: 0.63306 | train_accuracy: 0.70252 | val_accuracy: 0.52659 |  0:56:37s\n",
            "epoch 2851| loss: 0.63522 | train_accuracy: 0.7027  | val_accuracy: 0.52499 |  0:56:39s\n",
            "epoch 2852| loss: 0.62812 | train_accuracy: 0.70385 | val_accuracy: 0.52579 |  0:56:40s\n",
            "epoch 2853| loss: 0.62093 | train_accuracy: 0.70572 | val_accuracy: 0.52419 |  0:56:42s\n",
            "epoch 2854| loss: 0.62795 | train_accuracy: 0.70443 | val_accuracy: 0.52099 |  0:56:43s\n",
            "epoch 2855| loss: 0.62516 | train_accuracy: 0.70638 | val_accuracy: 0.52499 |  0:56:44s\n",
            "epoch 2856| loss: 0.624   | train_accuracy: 0.70834 | val_accuracy: 0.52939 |  0:56:46s\n",
            "epoch 2857| loss: 0.62007 | train_accuracy: 0.70638 | val_accuracy: 0.52139 |  0:56:47s\n",
            "epoch 2858| loss: 0.62213 | train_accuracy: 0.70674 | val_accuracy: 0.52699 |  0:56:48s\n",
            "epoch 2859| loss: 0.62407 | train_accuracy: 0.70794 | val_accuracy: 0.52579 |  0:56:49s\n",
            "epoch 2860| loss: 0.62253 | train_accuracy: 0.7031  | val_accuracy: 0.52059 |  0:56:50s\n",
            "epoch 2861| loss: 0.62138 | train_accuracy: 0.70172 | val_accuracy: 0.52699 |  0:56:51s\n",
            "epoch 2862| loss: 0.62376 | train_accuracy: 0.70252 | val_accuracy: 0.52379 |  0:56:53s\n",
            "epoch 2863| loss: 0.62337 | train_accuracy: 0.70412 | val_accuracy: 0.52139 |  0:56:54s\n",
            "epoch 2864| loss: 0.61898 | train_accuracy: 0.70461 | val_accuracy: 0.52139 |  0:56:55s\n",
            "epoch 2865| loss: 0.62445 | train_accuracy: 0.70478 | val_accuracy: 0.52299 |  0:56:56s\n",
            "epoch 2866| loss: 0.62537 | train_accuracy: 0.70709 | val_accuracy: 0.52899 |  0:56:57s\n",
            "epoch 2867| loss: 0.62124 | train_accuracy: 0.70687 | val_accuracy: 0.52499 |  0:56:59s\n",
            "epoch 2868| loss: 0.61743 | train_accuracy: 0.70581 | val_accuracy: 0.51939 |  0:57:00s\n",
            "epoch 2869| loss: 0.6165  | train_accuracy: 0.70825 | val_accuracy: 0.52059 |  0:57:01s\n",
            "epoch 2870| loss: 0.61988 | train_accuracy: 0.70847 | val_accuracy: 0.52259 |  0:57:02s\n",
            "epoch 2871| loss: 0.62453 | train_accuracy: 0.70634 | val_accuracy: 0.52619 |  0:57:03s\n",
            "epoch 2872| loss: 0.61626 | train_accuracy: 0.70807 | val_accuracy: 0.52419 |  0:57:05s\n",
            "epoch 2873| loss: 0.619   | train_accuracy: 0.70829 | val_accuracy: 0.52259 |  0:57:06s\n",
            "epoch 2874| loss: 0.61835 | train_accuracy: 0.70723 | val_accuracy: 0.52499 |  0:57:07s\n",
            "epoch 2875| loss: 0.61398 | train_accuracy: 0.70741 | val_accuracy: 0.52779 |  0:57:08s\n",
            "epoch 2876| loss: 0.62053 | train_accuracy: 0.70785 | val_accuracy: 0.52539 |  0:57:09s\n",
            "epoch 2877| loss: 0.61806 | train_accuracy: 0.70843 | val_accuracy: 0.52939 |  0:57:10s\n",
            "epoch 2878| loss: 0.61521 | train_accuracy: 0.70865 | val_accuracy: 0.52179 |  0:57:12s\n",
            "epoch 2879| loss: 0.6158  | train_accuracy: 0.70989 | val_accuracy: 0.52899 |  0:57:13s\n",
            "epoch 2880| loss: 0.62198 | train_accuracy: 0.70434 | val_accuracy: 0.52619 |  0:57:14s\n",
            "epoch 2881| loss: 0.61938 | train_accuracy: 0.70576 | val_accuracy: 0.52459 |  0:57:15s\n",
            "epoch 2882| loss: 0.62286 | train_accuracy: 0.70594 | val_accuracy: 0.52739 |  0:57:16s\n",
            "epoch 2883| loss: 0.6192  | train_accuracy: 0.70621 | val_accuracy: 0.52699 |  0:57:17s\n",
            "epoch 2884| loss: 0.62434 | train_accuracy: 0.70683 | val_accuracy: 0.51939 |  0:57:19s\n",
            "epoch 2885| loss: 0.61859 | train_accuracy: 0.70661 | val_accuracy: 0.51739 |  0:57:20s\n",
            "epoch 2886| loss: 0.61733 | train_accuracy: 0.70732 | val_accuracy: 0.52299 |  0:57:21s\n",
            "epoch 2887| loss: 0.61464 | train_accuracy: 0.70812 | val_accuracy: 0.51899 |  0:57:22s\n",
            "epoch 2888| loss: 0.61553 | train_accuracy: 0.70776 | val_accuracy: 0.52219 |  0:57:24s\n",
            "epoch 2889| loss: 0.61986 | train_accuracy: 0.70852 | val_accuracy: 0.52459 |  0:57:25s\n",
            "epoch 2890| loss: 0.62425 | train_accuracy: 0.70949 | val_accuracy: 0.52379 |  0:57:26s\n",
            "epoch 2891| loss: 0.61541 | train_accuracy: 0.70901 | val_accuracy: 0.52939 |  0:57:27s\n",
            "epoch 2892| loss: 0.61396 | train_accuracy: 0.70798 | val_accuracy: 0.52899 |  0:57:28s\n",
            "epoch 2893| loss: 0.62113 | train_accuracy: 0.70909 | val_accuracy: 0.52339 |  0:57:29s\n",
            "epoch 2894| loss: 0.61605 | train_accuracy: 0.70887 | val_accuracy: 0.52779 |  0:57:31s\n",
            "epoch 2895| loss: 0.61742 | train_accuracy: 0.70607 | val_accuracy: 0.52699 |  0:57:32s\n",
            "epoch 2896| loss: 0.6188  | train_accuracy: 0.70634 | val_accuracy: 0.52499 |  0:57:33s\n",
            "epoch 2897| loss: 0.61912 | train_accuracy: 0.70834 | val_accuracy: 0.52819 |  0:57:34s\n",
            "epoch 2898| loss: 0.62093 | train_accuracy: 0.70914 | val_accuracy: 0.52699 |  0:57:35s\n",
            "epoch 2899| loss: 0.61762 | train_accuracy: 0.70852 | val_accuracy: 0.52459 |  0:57:37s\n",
            "epoch 2900| loss: 0.62305 | train_accuracy: 0.70843 | val_accuracy: 0.52499 |  0:57:38s\n",
            "epoch 2901| loss: 0.61909 | train_accuracy: 0.70923 | val_accuracy: 0.52619 |  0:57:39s\n",
            "epoch 2902| loss: 0.61829 | train_accuracy: 0.70847 | val_accuracy: 0.52539 |  0:57:40s\n",
            "epoch 2903| loss: 0.62452 | train_accuracy: 0.70741 | val_accuracy: 0.51979 |  0:57:41s\n",
            "epoch 2904| loss: 0.62138 | train_accuracy: 0.70661 | val_accuracy: 0.53339 |  0:57:42s\n",
            "epoch 2905| loss: 0.61864 | train_accuracy: 0.70825 | val_accuracy: 0.52019 |  0:57:44s\n",
            "epoch 2906| loss: 0.61865 | train_accuracy: 0.70705 | val_accuracy: 0.52019 |  0:57:45s\n",
            "epoch 2907| loss: 0.61718 | train_accuracy: 0.70794 | val_accuracy: 0.52139 |  0:57:46s\n",
            "epoch 2908| loss: 0.61918 | train_accuracy: 0.70896 | val_accuracy: 0.52099 |  0:57:47s\n",
            "epoch 2909| loss: 0.61896 | train_accuracy: 0.70865 | val_accuracy: 0.52379 |  0:57:48s\n",
            "epoch 2910| loss: 0.62293 | train_accuracy: 0.70905 | val_accuracy: 0.51939 |  0:57:50s\n",
            "epoch 2911| loss: 0.61493 | train_accuracy: 0.70963 | val_accuracy: 0.52979 |  0:57:51s\n",
            "epoch 2912| loss: 0.61816 | train_accuracy: 0.70989 | val_accuracy: 0.52179 |  0:57:52s\n",
            "epoch 2913| loss: 0.61843 | train_accuracy: 0.71038 | val_accuracy: 0.51659 |  0:57:53s\n",
            "epoch 2914| loss: 0.61418 | train_accuracy: 0.71047 | val_accuracy: 0.52059 |  0:57:54s\n",
            "epoch 2915| loss: 0.61545 | train_accuracy: 0.71167 | val_accuracy: 0.52499 |  0:57:56s\n",
            "epoch 2916| loss: 0.61379 | train_accuracy: 0.71092 | val_accuracy: 0.52499 |  0:57:57s\n",
            "epoch 2917| loss: 0.61242 | train_accuracy: 0.70794 | val_accuracy: 0.52659 |  0:57:58s\n",
            "epoch 2918| loss: 0.61526 | train_accuracy: 0.70856 | val_accuracy: 0.52379 |  0:57:59s\n",
            "epoch 2919| loss: 0.61655 | train_accuracy: 0.71056 | val_accuracy: 0.52699 |  0:58:00s\n",
            "epoch 2920| loss: 0.61581 | train_accuracy: 0.71225 | val_accuracy: 0.52099 |  0:58:01s\n",
            "epoch 2921| loss: 0.61167 | train_accuracy: 0.71056 | val_accuracy: 0.52539 |  0:58:03s\n",
            "epoch 2922| loss: 0.61347 | train_accuracy: 0.70989 | val_accuracy: 0.52899 |  0:58:04s\n",
            "epoch 2923| loss: 0.61583 | train_accuracy: 0.71118 | val_accuracy: 0.52979 |  0:58:05s\n",
            "epoch 2924| loss: 0.60914 | train_accuracy: 0.71136 | val_accuracy: 0.52419 |  0:58:06s\n",
            "epoch 2925| loss: 0.60858 | train_accuracy: 0.71274 | val_accuracy: 0.52499 |  0:58:07s\n",
            "epoch 2926| loss: 0.6119  | train_accuracy: 0.70963 | val_accuracy: 0.52859 |  0:58:09s\n",
            "epoch 2927| loss: 0.61602 | train_accuracy: 0.70923 | val_accuracy: 0.52579 |  0:58:10s\n",
            "epoch 2928| loss: 0.61819 | train_accuracy: 0.70816 | val_accuracy: 0.52899 |  0:58:11s\n",
            "epoch 2929| loss: 0.61974 | train_accuracy: 0.70723 | val_accuracy: 0.52459 |  0:58:12s\n",
            "epoch 2930| loss: 0.6179  | train_accuracy: 0.70856 | val_accuracy: 0.53259 |  0:58:13s\n",
            "epoch 2931| loss: 0.62087 | train_accuracy: 0.70701 | val_accuracy: 0.52539 |  0:58:15s\n",
            "epoch 2932| loss: 0.61839 | train_accuracy: 0.70621 | val_accuracy: 0.53579 |  0:58:16s\n",
            "epoch 2933| loss: 0.61977 | train_accuracy: 0.70936 | val_accuracy: 0.53459 |  0:58:17s\n",
            "epoch 2934| loss: 0.61596 | train_accuracy: 0.70949 | val_accuracy: 0.53299 |  0:58:18s\n",
            "epoch 2935| loss: 0.61688 | train_accuracy: 0.70918 | val_accuracy: 0.53259 |  0:58:19s\n",
            "epoch 2936| loss: 0.62229 | train_accuracy: 0.70878 | val_accuracy: 0.52419 |  0:58:21s\n",
            "epoch 2937| loss: 0.62486 | train_accuracy: 0.70829 | val_accuracy: 0.53459 |  0:58:22s\n",
            "epoch 2938| loss: 0.61563 | train_accuracy: 0.70803 | val_accuracy: 0.53019 |  0:58:23s\n",
            "epoch 2939| loss: 0.61394 | train_accuracy: 0.7098  | val_accuracy: 0.53659 |  0:58:24s\n",
            "epoch 2940| loss: 0.61853 | train_accuracy: 0.70896 | val_accuracy: 0.53459 |  0:58:25s\n",
            "epoch 2941| loss: 0.61804 | train_accuracy: 0.70847 | val_accuracy: 0.52979 |  0:58:26s\n",
            "epoch 2942| loss: 0.61477 | train_accuracy: 0.70865 | val_accuracy: 0.53179 |  0:58:28s\n",
            "epoch 2943| loss: 0.6158  | train_accuracy: 0.70723 | val_accuracy: 0.53179 |  0:58:29s\n",
            "epoch 2944| loss: 0.61849 | train_accuracy: 0.70803 | val_accuracy: 0.53219 |  0:58:30s\n",
            "epoch 2945| loss: 0.619   | train_accuracy: 0.71185 | val_accuracy: 0.52899 |  0:58:31s\n",
            "epoch 2946| loss: 0.61552 | train_accuracy: 0.70745 | val_accuracy: 0.52979 |  0:58:32s\n",
            "epoch 2947| loss: 0.61168 | train_accuracy: 0.70932 | val_accuracy: 0.53339 |  0:58:34s\n",
            "epoch 2948| loss: 0.6178  | train_accuracy: 0.70718 | val_accuracy: 0.53019 |  0:58:35s\n",
            "epoch 2949| loss: 0.61278 | train_accuracy: 0.70963 | val_accuracy: 0.53259 |  0:58:36s\n",
            "epoch 2950| loss: 0.61293 | train_accuracy: 0.71123 | val_accuracy: 0.53419 |  0:58:37s\n",
            "epoch 2951| loss: 0.61248 | train_accuracy: 0.71118 | val_accuracy: 0.52899 |  0:58:38s\n",
            "epoch 2952| loss: 0.6189  | train_accuracy: 0.71127 | val_accuracy: 0.53219 |  0:58:39s\n",
            "epoch 2953| loss: 0.61653 | train_accuracy: 0.71305 | val_accuracy: 0.52859 |  0:58:41s\n",
            "epoch 2954| loss: 0.60962 | train_accuracy: 0.71336 | val_accuracy: 0.52979 |  0:58:42s\n",
            "epoch 2955| loss: 0.6151  | train_accuracy: 0.71376 | val_accuracy: 0.53219 |  0:58:44s\n",
            "epoch 2956| loss: 0.6121  | train_accuracy: 0.71283 | val_accuracy: 0.52939 |  0:58:45s\n",
            "epoch 2957| loss: 0.61301 | train_accuracy: 0.71038 | val_accuracy: 0.53219 |  0:58:46s\n",
            "epoch 2958| loss: 0.61498 | train_accuracy: 0.71003 | val_accuracy: 0.53099 |  0:58:47s\n",
            "epoch 2959| loss: 0.61599 | train_accuracy: 0.71074 | val_accuracy: 0.52379 |  0:58:49s\n",
            "epoch 2960| loss: 0.61647 | train_accuracy: 0.71207 | val_accuracy: 0.53059 |  0:58:50s\n",
            "epoch 2961| loss: 0.61709 | train_accuracy: 0.70949 | val_accuracy: 0.52979 |  0:58:51s\n",
            "epoch 2962| loss: 0.6127  | train_accuracy: 0.70998 | val_accuracy: 0.53099 |  0:58:52s\n",
            "epoch 2963| loss: 0.61507 | train_accuracy: 0.70905 | val_accuracy: 0.53179 |  0:58:53s\n",
            "epoch 2964| loss: 0.61271 | train_accuracy: 0.71109 | val_accuracy: 0.53459 |  0:58:54s\n",
            "epoch 2965| loss: 0.61273 | train_accuracy: 0.70909 | val_accuracy: 0.53539 |  0:58:56s\n",
            "epoch 2966| loss: 0.61798 | train_accuracy: 0.711   | val_accuracy: 0.52659 |  0:58:57s\n",
            "epoch 2967| loss: 0.61389 | train_accuracy: 0.71065 | val_accuracy: 0.52699 |  0:58:58s\n",
            "epoch 2968| loss: 0.61475 | train_accuracy: 0.70914 | val_accuracy: 0.53579 |  0:58:59s\n",
            "epoch 2969| loss: 0.61647 | train_accuracy: 0.71078 | val_accuracy: 0.53139 |  0:59:00s\n",
            "epoch 2970| loss: 0.61452 | train_accuracy: 0.71096 | val_accuracy: 0.52979 |  0:59:01s\n",
            "epoch 2971| loss: 0.61146 | train_accuracy: 0.71038 | val_accuracy: 0.53139 |  0:59:03s\n",
            "epoch 2972| loss: 0.61104 | train_accuracy: 0.71043 | val_accuracy: 0.52579 |  0:59:04s\n",
            "epoch 2973| loss: 0.61331 | train_accuracy: 0.7106  | val_accuracy: 0.53219 |  0:59:05s\n",
            "epoch 2974| loss: 0.60975 | train_accuracy: 0.7106  | val_accuracy: 0.53219 |  0:59:06s\n",
            "epoch 2975| loss: 0.613   | train_accuracy: 0.71078 | val_accuracy: 0.53339 |  0:59:07s\n",
            "epoch 2976| loss: 0.61713 | train_accuracy: 0.70998 | val_accuracy: 0.53219 |  0:59:09s\n",
            "epoch 2977| loss: 0.61419 | train_accuracy: 0.71207 | val_accuracy: 0.52699 |  0:59:10s\n",
            "epoch 2978| loss: 0.61317 | train_accuracy: 0.71145 | val_accuracy: 0.53459 |  0:59:11s\n",
            "epoch 2979| loss: 0.61711 | train_accuracy: 0.71189 | val_accuracy: 0.53459 |  0:59:12s\n",
            "epoch 2980| loss: 0.61577 | train_accuracy: 0.71034 | val_accuracy: 0.53059 |  0:59:13s\n",
            "epoch 2981| loss: 0.61268 | train_accuracy: 0.71087 | val_accuracy: 0.53179 |  0:59:15s\n",
            "epoch 2982| loss: 0.61498 | train_accuracy: 0.71029 | val_accuracy: 0.53139 |  0:59:16s\n",
            "epoch 2983| loss: 0.61315 | train_accuracy: 0.71034 | val_accuracy: 0.53099 |  0:59:17s\n",
            "epoch 2984| loss: 0.61037 | train_accuracy: 0.71083 | val_accuracy: 0.52459 |  0:59:18s\n",
            "epoch 2985| loss: 0.61479 | train_accuracy: 0.7114  | val_accuracy: 0.53299 |  0:59:19s\n",
            "epoch 2986| loss: 0.61692 | train_accuracy: 0.70821 | val_accuracy: 0.53379 |  0:59:21s\n",
            "epoch 2987| loss: 0.61385 | train_accuracy: 0.70789 | val_accuracy: 0.52899 |  0:59:22s\n",
            "epoch 2988| loss: 0.62555 | train_accuracy: 0.70985 | val_accuracy: 0.53139 |  0:59:23s\n",
            "epoch 2989| loss: 0.61564 | train_accuracy: 0.71145 | val_accuracy: 0.52859 |  0:59:24s\n",
            "epoch 2990| loss: 0.61188 | train_accuracy: 0.71291 | val_accuracy: 0.52739 |  0:59:25s\n",
            "epoch 2991| loss: 0.61666 | train_accuracy: 0.71123 | val_accuracy: 0.52659 |  0:59:27s\n",
            "epoch 2992| loss: 0.61357 | train_accuracy: 0.711   | val_accuracy: 0.52659 |  0:59:28s\n",
            "epoch 2993| loss: 0.61209 | train_accuracy: 0.7118  | val_accuracy: 0.52419 |  0:59:29s\n",
            "epoch 2994| loss: 0.6117  | train_accuracy: 0.71136 | val_accuracy: 0.52339 |  0:59:30s\n",
            "epoch 2995| loss: 0.61299 | train_accuracy: 0.70954 | val_accuracy: 0.52019 |  0:59:31s\n",
            "epoch 2996| loss: 0.61755 | train_accuracy: 0.71078 | val_accuracy: 0.51819 |  0:59:32s\n",
            "epoch 2997| loss: 0.60988 | train_accuracy: 0.71305 | val_accuracy: 0.52699 |  0:59:34s\n",
            "epoch 2998| loss: 0.61507 | train_accuracy: 0.71029 | val_accuracy: 0.52779 |  0:59:35s\n",
            "epoch 2999| loss: 0.61222 | train_accuracy: 0.71127 | val_accuracy: 0.53059 |  0:59:36s\n",
            "Stop training because you reached max_epochs = 3000 with best_epoch = 1511 and best_val_accuracy = 0.54778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/callbacks.py:155: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot mse\n",
        "plt.plot(clf.history['train_accuracy'])\n",
        "plt.plot(clf.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "lDz9KlVTrH2s",
        "outputId": "a490c276-582b-4f88-aa86-76e20870f644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4101fead50>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##N_a nhỏ"
      ],
      "metadata": {
        "id": "ZGTZCbuOyMsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = TabNetClassifier(\n",
        "    n_d=8, n_a=2, n_steps=5,\n",
        "    cat_idxs=cat_idxs,\n",
        "    cat_dims=cat_dims,\n",
        "    cat_emb_dim=[3,12,3,12,3,12,3,12,3,12],\n",
        "    gamma=1.5, n_ind=2, n_shared=2,\n",
        "    lambda_sparse=1e-6, momentum=0.05, clip_value=2.,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=0.01),\n",
        "    scheduler_params = {\"gamma\": 0.95,\n",
        "                     \"step_size\": 80},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Toj3gW6VEWP",
        "outputId": "a54f2020-7c3d-4260-83a3-80cd37b957ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/abstract_model.py:74: UserWarning: Device used : cuda\n",
            "  warnings.warn(f\"Device used : {self.device}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
        "    eval_name = ['train', 'val'],\n",
        "    max_epochs=3000, patience=3000,\n",
        "    batch_size=4096, vbs=1024 #, augmentations=aug\n",
        ") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfRBKoz6VHYO",
        "outputId": "070d8450-ebe0-40c3-81aa-f6d2917213ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0  | loss: 3.60827 | train_accuracy: 0.11418 | val_accuracy: 0.10756 |  0:00:00s\n",
            "epoch 1  | loss: 2.5191  | train_accuracy: 0.30135 | val_accuracy: 0.29588 |  0:00:01s\n",
            "epoch 2  | loss: 1.91982 | train_accuracy: 0.41219 | val_accuracy: 0.41783 |  0:00:01s\n",
            "epoch 3  | loss: 1.52854 | train_accuracy: 0.45018 | val_accuracy: 0.45062 |  0:00:02s\n",
            "epoch 4  | loss: 1.31343 | train_accuracy: 0.47061 | val_accuracy: 0.48341 |  0:00:02s\n",
            "epoch 5  | loss: 1.18224 | train_accuracy: 0.46288 | val_accuracy: 0.46022 |  0:00:03s\n",
            "epoch 6  | loss: 1.12462 | train_accuracy: 0.47057 | val_accuracy: 0.45662 |  0:00:03s\n",
            "epoch 7  | loss: 1.07573 | train_accuracy: 0.47501 | val_accuracy: 0.47221 |  0:00:04s\n",
            "epoch 8  | loss: 1.05044 | train_accuracy: 0.4743  | val_accuracy: 0.46341 |  0:00:05s\n",
            "epoch 9  | loss: 1.0332  | train_accuracy: 0.47559 | val_accuracy: 0.5018  |  0:00:05s\n",
            "epoch 10 | loss: 1.02076 | train_accuracy: 0.48216 | val_accuracy: 0.48181 |  0:00:06s\n",
            "epoch 11 | loss: 1.01889 | train_accuracy: 0.48634 | val_accuracy: 0.48261 |  0:00:06s\n",
            "epoch 12 | loss: 1.00872 | train_accuracy: 0.48736 | val_accuracy: 0.47221 |  0:00:07s\n",
            "epoch 13 | loss: 1.00601 | train_accuracy: 0.48452 | val_accuracy: 0.48221 |  0:00:07s\n",
            "epoch 14 | loss: 1.00466 | train_accuracy: 0.48554 | val_accuracy: 0.4886  |  0:00:08s\n",
            "epoch 15 | loss: 0.99909 | train_accuracy: 0.49296 | val_accuracy: 0.48021 |  0:00:08s\n",
            "epoch 16 | loss: 0.9931  | train_accuracy: 0.48452 | val_accuracy: 0.48181 |  0:00:09s\n",
            "epoch 17 | loss: 0.99435 | train_accuracy: 0.4942  | val_accuracy: 0.4946  |  0:00:09s\n",
            "epoch 18 | loss: 0.99149 | train_accuracy: 0.48932 | val_accuracy: 0.4902  |  0:00:10s\n",
            "epoch 19 | loss: 0.98745 | train_accuracy: 0.50016 | val_accuracy: 0.505   |  0:00:10s\n",
            "epoch 20 | loss: 0.98943 | train_accuracy: 0.49118 | val_accuracy: 0.48261 |  0:00:11s\n",
            "epoch 21 | loss: 0.98562 | train_accuracy: 0.49922 | val_accuracy: 0.48701 |  0:00:11s\n",
            "epoch 22 | loss: 0.98361 | train_accuracy: 0.49758 | val_accuracy: 0.48581 |  0:00:12s\n",
            "epoch 23 | loss: 0.98586 | train_accuracy: 0.49962 | val_accuracy: 0.4998  |  0:00:12s\n",
            "epoch 24 | loss: 0.98448 | train_accuracy: 0.49745 | val_accuracy: 0.48341 |  0:00:13s\n",
            "epoch 25 | loss: 0.98535 | train_accuracy: 0.49789 | val_accuracy: 0.4886  |  0:00:13s\n",
            "epoch 26 | loss: 0.98495 | train_accuracy: 0.49984 | val_accuracy: 0.4886  |  0:00:14s\n",
            "epoch 27 | loss: 0.98187 | train_accuracy: 0.49936 | val_accuracy: 0.4926  |  0:00:14s\n",
            "epoch 28 | loss: 0.98462 | train_accuracy: 0.50051 | val_accuracy: 0.4902  |  0:00:15s\n",
            "epoch 29 | loss: 0.98626 | train_accuracy: 0.49864 | val_accuracy: 0.497   |  0:00:15s\n",
            "epoch 30 | loss: 0.98363 | train_accuracy: 0.49931 | val_accuracy: 0.5042  |  0:00:16s\n",
            "epoch 31 | loss: 0.98528 | train_accuracy: 0.49793 | val_accuracy: 0.5022  |  0:00:16s\n",
            "epoch 32 | loss: 0.9824  | train_accuracy: 0.49887 | val_accuracy: 0.4918  |  0:00:17s\n",
            "epoch 33 | loss: 0.98214 | train_accuracy: 0.49949 | val_accuracy: 0.4978  |  0:00:17s\n",
            "epoch 34 | loss: 0.9808  | train_accuracy: 0.49856 | val_accuracy: 0.4974  |  0:00:18s\n",
            "epoch 35 | loss: 0.98355 | train_accuracy: 0.50024 | val_accuracy: 0.4966  |  0:00:18s\n",
            "epoch 36 | loss: 0.98275 | train_accuracy: 0.50118 | val_accuracy: 0.4986  |  0:00:19s\n",
            "epoch 37 | loss: 0.97985 | train_accuracy: 0.50189 | val_accuracy: 0.493   |  0:00:20s\n",
            "epoch 38 | loss: 0.98208 | train_accuracy: 0.50371 | val_accuracy: 0.501   |  0:00:21s\n",
            "epoch 39 | loss: 0.97942 | train_accuracy: 0.50242 | val_accuracy: 0.5022  |  0:00:22s\n",
            "epoch 40 | loss: 0.97976 | train_accuracy: 0.50473 | val_accuracy: 0.5066  |  0:00:23s\n",
            "epoch 41 | loss: 0.97673 | train_accuracy: 0.50611 | val_accuracy: 0.4986  |  0:00:23s\n",
            "epoch 42 | loss: 0.97787 | train_accuracy: 0.50304 | val_accuracy: 0.5006  |  0:00:24s\n",
            "epoch 43 | loss: 0.97985 | train_accuracy: 0.50229 | val_accuracy: 0.4942  |  0:00:24s\n",
            "epoch 44 | loss: 0.97838 | train_accuracy: 0.50522 | val_accuracy: 0.4922  |  0:00:25s\n",
            "epoch 45 | loss: 0.97972 | train_accuracy: 0.50482 | val_accuracy: 0.4966  |  0:00:25s\n",
            "epoch 46 | loss: 0.97601 | train_accuracy: 0.50535 | val_accuracy: 0.5014  |  0:00:26s\n",
            "epoch 47 | loss: 0.9772  | train_accuracy: 0.50473 | val_accuracy: 0.4922  |  0:00:26s\n",
            "epoch 48 | loss: 0.97981 | train_accuracy: 0.50544 | val_accuracy: 0.4994  |  0:00:27s\n",
            "epoch 49 | loss: 0.97691 | train_accuracy: 0.50433 | val_accuracy: 0.4974  |  0:00:27s\n",
            "epoch 50 | loss: 0.97825 | train_accuracy: 0.50584 | val_accuracy: 0.4878  |  0:00:28s\n",
            "epoch 51 | loss: 0.97845 | train_accuracy: 0.50335 | val_accuracy: 0.48581 |  0:00:28s\n",
            "epoch 52 | loss: 0.97869 | train_accuracy: 0.50446 | val_accuracy: 0.4918  |  0:00:29s\n",
            "epoch 53 | loss: 0.97555 | train_accuracy: 0.50313 | val_accuracy: 0.5002  |  0:00:29s\n",
            "epoch 54 | loss: 0.97675 | train_accuracy: 0.50993 | val_accuracy: 0.4922  |  0:00:30s\n",
            "epoch 55 | loss: 0.97861 | train_accuracy: 0.5046  | val_accuracy: 0.4918  |  0:00:31s\n",
            "epoch 56 | loss: 0.97446 | train_accuracy: 0.50855 | val_accuracy: 0.4962  |  0:00:31s\n",
            "epoch 57 | loss: 0.98074 | train_accuracy: 0.50891 | val_accuracy: 0.4946  |  0:00:32s\n",
            "epoch 58 | loss: 0.97311 | train_accuracy: 0.50997 | val_accuracy: 0.501   |  0:00:32s\n",
            "epoch 59 | loss: 0.97354 | train_accuracy: 0.5106  | val_accuracy: 0.501   |  0:00:33s\n",
            "epoch 60 | loss: 0.97612 | train_accuracy: 0.51362 | val_accuracy: 0.5026  |  0:00:33s\n",
            "epoch 61 | loss: 0.97283 | train_accuracy: 0.51193 | val_accuracy: 0.5062  |  0:00:34s\n",
            "epoch 62 | loss: 0.97671 | train_accuracy: 0.50953 | val_accuracy: 0.5046  |  0:00:34s\n",
            "epoch 63 | loss: 0.97533 | train_accuracy: 0.51206 | val_accuracy: 0.501   |  0:00:35s\n",
            "epoch 64 | loss: 0.97614 | train_accuracy: 0.51228 | val_accuracy: 0.501   |  0:00:35s\n",
            "epoch 65 | loss: 0.97634 | train_accuracy: 0.50993 | val_accuracy: 0.5034  |  0:00:36s\n",
            "epoch 66 | loss: 0.97332 | train_accuracy: 0.5122  | val_accuracy: 0.5086  |  0:00:36s\n",
            "epoch 67 | loss: 0.97305 | train_accuracy: 0.51211 | val_accuracy: 0.5026  |  0:00:37s\n",
            "epoch 68 | loss: 0.97398 | train_accuracy: 0.50886 | val_accuracy: 0.5034  |  0:00:37s\n",
            "epoch 69 | loss: 0.97561 | train_accuracy: 0.5094  | val_accuracy: 0.4982  |  0:00:38s\n",
            "epoch 70 | loss: 0.97713 | train_accuracy: 0.50895 | val_accuracy: 0.5006  |  0:00:38s\n",
            "epoch 71 | loss: 0.9745  | train_accuracy: 0.5106  | val_accuracy: 0.5006  |  0:00:39s\n",
            "epoch 72 | loss: 0.97507 | train_accuracy: 0.51193 | val_accuracy: 0.5098  |  0:00:40s\n",
            "epoch 73 | loss: 0.97428 | train_accuracy: 0.50984 | val_accuracy: 0.51539 |  0:00:40s\n",
            "epoch 74 | loss: 0.97352 | train_accuracy: 0.51282 | val_accuracy: 0.51539 |  0:00:41s\n",
            "epoch 75 | loss: 0.97419 | train_accuracy: 0.51015 | val_accuracy: 0.5014  |  0:00:41s\n",
            "epoch 76 | loss: 0.97248 | train_accuracy: 0.51291 | val_accuracy: 0.5078  |  0:00:42s\n",
            "epoch 77 | loss: 0.97344 | train_accuracy: 0.51068 | val_accuracy: 0.5038  |  0:00:42s\n",
            "epoch 78 | loss: 0.97737 | train_accuracy: 0.51188 | val_accuracy: 0.5062  |  0:00:43s\n",
            "epoch 79 | loss: 0.96813 | train_accuracy: 0.51228 | val_accuracy: 0.5002  |  0:00:43s\n",
            "epoch 80 | loss: 0.97441 | train_accuracy: 0.51246 | val_accuracy: 0.5058  |  0:00:44s\n",
            "epoch 81 | loss: 0.97459 | train_accuracy: 0.5153  | val_accuracy: 0.5022  |  0:00:44s\n",
            "epoch 82 | loss: 0.97163 | train_accuracy: 0.51344 | val_accuracy: 0.5082  |  0:00:45s\n",
            "epoch 83 | loss: 0.97264 | train_accuracy: 0.51175 | val_accuracy: 0.4986  |  0:00:45s\n",
            "epoch 84 | loss: 0.97542 | train_accuracy: 0.51157 | val_accuracy: 0.5034  |  0:00:46s\n",
            "epoch 85 | loss: 0.97404 | train_accuracy: 0.50997 | val_accuracy: 0.5066  |  0:00:46s\n",
            "epoch 86 | loss: 0.97072 | train_accuracy: 0.5118  | val_accuracy: 0.5062  |  0:00:47s\n",
            "epoch 87 | loss: 0.97478 | train_accuracy: 0.51153 | val_accuracy: 0.5042  |  0:00:47s\n",
            "epoch 88 | loss: 0.97379 | train_accuracy: 0.51331 | val_accuracy: 0.511   |  0:00:48s\n",
            "epoch 89 | loss: 0.96972 | train_accuracy: 0.51362 | val_accuracy: 0.507   |  0:00:48s\n",
            "epoch 90 | loss: 0.97223 | train_accuracy: 0.51419 | val_accuracy: 0.5114  |  0:00:49s\n",
            "epoch 91 | loss: 0.97161 | train_accuracy: 0.50962 | val_accuracy: 0.5042  |  0:00:49s\n",
            "epoch 92 | loss: 0.97142 | train_accuracy: 0.51162 | val_accuracy: 0.4986  |  0:00:50s\n",
            "epoch 93 | loss: 0.97057 | train_accuracy: 0.51446 | val_accuracy: 0.5002  |  0:00:51s\n",
            "epoch 94 | loss: 0.97353 | train_accuracy: 0.51451 | val_accuracy: 0.4978  |  0:00:52s\n",
            "epoch 95 | loss: 0.97416 | train_accuracy: 0.51428 | val_accuracy: 0.4978  |  0:00:53s\n",
            "epoch 96 | loss: 0.97132 | train_accuracy: 0.51366 | val_accuracy: 0.5066  |  0:00:54s\n",
            "epoch 97 | loss: 0.97506 | train_accuracy: 0.51233 | val_accuracy: 0.501   |  0:00:54s\n",
            "epoch 98 | loss: 0.97461 | train_accuracy: 0.51215 | val_accuracy: 0.5062  |  0:00:55s\n",
            "epoch 99 | loss: 0.97206 | train_accuracy: 0.51171 | val_accuracy: 0.51299 |  0:00:55s\n",
            "epoch 100| loss: 0.97951 | train_accuracy: 0.51437 | val_accuracy: 0.5038  |  0:00:56s\n",
            "epoch 101| loss: 0.97223 | train_accuracy: 0.51579 | val_accuracy: 0.505   |  0:00:56s\n",
            "epoch 102| loss: 0.9719  | train_accuracy: 0.51553 | val_accuracy: 0.51739 |  0:00:57s\n",
            "epoch 103| loss: 0.97195 | train_accuracy: 0.51406 | val_accuracy: 0.51739 |  0:00:57s\n",
            "epoch 104| loss: 0.97437 | train_accuracy: 0.51602 | val_accuracy: 0.51939 |  0:00:58s\n",
            "epoch 105| loss: 0.97085 | train_accuracy: 0.51415 | val_accuracy: 0.51979 |  0:00:59s\n",
            "epoch 106| loss: 0.97352 | train_accuracy: 0.51575 | val_accuracy: 0.51499 |  0:00:59s\n",
            "epoch 107| loss: 0.97186 | train_accuracy: 0.51397 | val_accuracy: 0.5118  |  0:01:00s\n",
            "epoch 108| loss: 0.97133 | train_accuracy: 0.51428 | val_accuracy: 0.5046  |  0:01:00s\n",
            "epoch 109| loss: 0.97332 | train_accuracy: 0.51535 | val_accuracy: 0.51419 |  0:01:01s\n",
            "epoch 110| loss: 0.97106 | train_accuracy: 0.51593 | val_accuracy: 0.5114  |  0:01:01s\n",
            "epoch 111| loss: 0.97262 | train_accuracy: 0.51286 | val_accuracy: 0.51299 |  0:01:02s\n",
            "epoch 112| loss: 0.9729  | train_accuracy: 0.51259 | val_accuracy: 0.5106  |  0:01:02s\n",
            "epoch 113| loss: 0.97385 | train_accuracy: 0.51211 | val_accuracy: 0.5074  |  0:01:03s\n",
            "epoch 114| loss: 0.97529 | train_accuracy: 0.50886 | val_accuracy: 0.5098  |  0:01:03s\n",
            "epoch 115| loss: 0.97695 | train_accuracy: 0.50891 | val_accuracy: 0.51499 |  0:01:04s\n",
            "epoch 116| loss: 0.97542 | train_accuracy: 0.5086  | val_accuracy: 0.5002  |  0:01:04s\n",
            "epoch 117| loss: 0.97223 | train_accuracy: 0.51175 | val_accuracy: 0.52019 |  0:01:05s\n",
            "epoch 118| loss: 0.97681 | train_accuracy: 0.51202 | val_accuracy: 0.51499 |  0:01:05s\n",
            "epoch 119| loss: 0.97433 | train_accuracy: 0.50864 | val_accuracy: 0.51939 |  0:01:06s\n",
            "epoch 120| loss: 0.97441 | train_accuracy: 0.51148 | val_accuracy: 0.5046  |  0:01:06s\n",
            "epoch 121| loss: 0.97409 | train_accuracy: 0.51193 | val_accuracy: 0.5046  |  0:01:07s\n",
            "epoch 122| loss: 0.97844 | train_accuracy: 0.5106  | val_accuracy: 0.5046  |  0:01:07s\n",
            "epoch 123| loss: 0.97335 | train_accuracy: 0.51086 | val_accuracy: 0.511   |  0:01:08s\n",
            "epoch 124| loss: 0.97589 | train_accuracy: 0.51584 | val_accuracy: 0.51419 |  0:01:08s\n",
            "epoch 125| loss: 0.97613 | train_accuracy: 0.51148 | val_accuracy: 0.5006  |  0:01:09s\n",
            "epoch 126| loss: 0.97341 | train_accuracy: 0.51166 | val_accuracy: 0.4982  |  0:01:09s\n",
            "epoch 127| loss: 0.97719 | train_accuracy: 0.5118  | val_accuracy: 0.5062  |  0:01:10s\n",
            "epoch 128| loss: 0.97767 | train_accuracy: 0.50953 | val_accuracy: 0.5026  |  0:01:10s\n",
            "epoch 129| loss: 0.97226 | train_accuracy: 0.51228 | val_accuracy: 0.5002  |  0:01:11s\n",
            "epoch 130| loss: 0.97838 | train_accuracy: 0.51282 | val_accuracy: 0.4978  |  0:01:12s\n",
            "epoch 131| loss: 0.97673 | train_accuracy: 0.5098  | val_accuracy: 0.5058  |  0:01:12s\n",
            "epoch 132| loss: 0.97318 | train_accuracy: 0.51353 | val_accuracy: 0.5014  |  0:01:13s\n",
            "epoch 133| loss: 0.97441 | train_accuracy: 0.51419 | val_accuracy: 0.5034  |  0:01:13s\n",
            "epoch 134| loss: 0.97428 | train_accuracy: 0.51335 | val_accuracy: 0.4966  |  0:01:14s\n",
            "epoch 135| loss: 0.97693 | train_accuracy: 0.51144 | val_accuracy: 0.4886  |  0:01:14s\n",
            "epoch 136| loss: 0.97762 | train_accuracy: 0.51175 | val_accuracy: 0.491   |  0:01:15s\n",
            "epoch 137| loss: 0.97097 | train_accuracy: 0.51077 | val_accuracy: 0.495   |  0:01:15s\n",
            "epoch 138| loss: 0.97503 | train_accuracy: 0.51006 | val_accuracy: 0.4986  |  0:01:16s\n",
            "epoch 139| loss: 0.97285 | train_accuracy: 0.51202 | val_accuracy: 0.4906  |  0:01:16s\n",
            "epoch 140| loss: 0.97525 | train_accuracy: 0.51308 | val_accuracy: 0.48581 |  0:01:17s\n",
            "epoch 141| loss: 0.97315 | train_accuracy: 0.51175 | val_accuracy: 0.4954  |  0:01:17s\n",
            "epoch 142| loss: 0.97405 | train_accuracy: 0.51015 | val_accuracy: 0.4986  |  0:01:18s\n",
            "epoch 143| loss: 0.97323 | train_accuracy: 0.51548 | val_accuracy: 0.4962  |  0:01:18s\n",
            "epoch 144| loss: 0.96945 | train_accuracy: 0.5157  | val_accuracy: 0.5038  |  0:01:19s\n",
            "epoch 145| loss: 0.97249 | train_accuracy: 0.51806 | val_accuracy: 0.4994  |  0:01:19s\n",
            "epoch 146| loss: 0.97147 | train_accuracy: 0.51188 | val_accuracy: 0.5062  |  0:01:20s\n",
            "epoch 147| loss: 0.97454 | train_accuracy: 0.51028 | val_accuracy: 0.5006  |  0:01:20s\n",
            "epoch 148| loss: 0.9777  | train_accuracy: 0.51402 | val_accuracy: 0.4978  |  0:01:21s\n",
            "epoch 149| loss: 0.97302 | train_accuracy: 0.51277 | val_accuracy: 0.497   |  0:01:21s\n",
            "epoch 150| loss: 0.97873 | train_accuracy: 0.51286 | val_accuracy: 0.5038  |  0:01:22s\n",
            "epoch 151| loss: 0.97301 | train_accuracy: 0.51517 | val_accuracy: 0.5066  |  0:01:22s\n",
            "epoch 152| loss: 0.97668 | train_accuracy: 0.51442 | val_accuracy: 0.499   |  0:01:23s\n",
            "epoch 153| loss: 0.97496 | train_accuracy: 0.51557 | val_accuracy: 0.507   |  0:01:24s\n",
            "epoch 154| loss: 0.97048 | train_accuracy: 0.51379 | val_accuracy: 0.503   |  0:01:24s\n",
            "epoch 155| loss: 0.97535 | train_accuracy: 0.511   | val_accuracy: 0.505   |  0:01:25s\n",
            "epoch 156| loss: 0.97571 | train_accuracy: 0.51433 | val_accuracy: 0.5014  |  0:01:25s\n",
            "epoch 157| loss: 0.97483 | train_accuracy: 0.51451 | val_accuracy: 0.51339 |  0:01:26s\n",
            "epoch 158| loss: 0.97738 | train_accuracy: 0.51366 | val_accuracy: 0.5122  |  0:01:26s\n",
            "epoch 159| loss: 0.97408 | train_accuracy: 0.51566 | val_accuracy: 0.5118  |  0:01:27s\n",
            "epoch 160| loss: 0.97342 | train_accuracy: 0.51326 | val_accuracy: 0.5046  |  0:01:27s\n",
            "epoch 161| loss: 0.97535 | train_accuracy: 0.51575 | val_accuracy: 0.497   |  0:01:28s\n",
            "epoch 162| loss: 0.97201 | train_accuracy: 0.51397 | val_accuracy: 0.501   |  0:01:28s\n",
            "epoch 163| loss: 0.97062 | train_accuracy: 0.51304 | val_accuracy: 0.497   |  0:01:29s\n",
            "epoch 164| loss: 0.97352 | train_accuracy: 0.51535 | val_accuracy: 0.503   |  0:01:29s\n",
            "epoch 165| loss: 0.97511 | train_accuracy: 0.51655 | val_accuracy: 0.5062  |  0:01:30s\n",
            "epoch 166| loss: 0.97157 | train_accuracy: 0.51642 | val_accuracy: 0.4946  |  0:01:30s\n",
            "epoch 167| loss: 0.96954 | train_accuracy: 0.51339 | val_accuracy: 0.501   |  0:01:31s\n",
            "epoch 168| loss: 0.97263 | train_accuracy: 0.51522 | val_accuracy: 0.5054  |  0:01:31s\n",
            "epoch 169| loss: 0.97246 | train_accuracy: 0.51419 | val_accuracy: 0.5094  |  0:01:32s\n",
            "epoch 170| loss: 0.96729 | train_accuracy: 0.51579 | val_accuracy: 0.5106  |  0:01:32s\n",
            "epoch 171| loss: 0.9709  | train_accuracy: 0.5161  | val_accuracy: 0.51379 |  0:01:33s\n",
            "epoch 172| loss: 0.96969 | train_accuracy: 0.51379 | val_accuracy: 0.5026  |  0:01:33s\n",
            "epoch 173| loss: 0.97147 | train_accuracy: 0.51828 | val_accuracy: 0.5066  |  0:01:34s\n",
            "epoch 174| loss: 0.97002 | train_accuracy: 0.51788 | val_accuracy: 0.51299 |  0:01:34s\n",
            "epoch 175| loss: 0.96491 | train_accuracy: 0.51899 | val_accuracy: 0.51699 |  0:01:35s\n",
            "epoch 176| loss: 0.96655 | train_accuracy: 0.5157  | val_accuracy: 0.5054  |  0:01:35s\n",
            "epoch 177| loss: 0.96597 | train_accuracy: 0.51815 | val_accuracy: 0.5038  |  0:01:36s\n",
            "epoch 178| loss: 0.96852 | train_accuracy: 0.51619 | val_accuracy: 0.5054  |  0:01:36s\n",
            "epoch 179| loss: 0.96715 | train_accuracy: 0.51682 | val_accuracy: 0.5122  |  0:01:37s\n",
            "epoch 180| loss: 0.97025 | train_accuracy: 0.51722 | val_accuracy: 0.51579 |  0:01:37s\n",
            "epoch 181| loss: 0.96804 | train_accuracy: 0.52139 | val_accuracy: 0.51579 |  0:01:38s\n",
            "epoch 182| loss: 0.96591 | train_accuracy: 0.5185  | val_accuracy: 0.51539 |  0:01:38s\n",
            "epoch 183| loss: 0.96733 | train_accuracy: 0.51757 | val_accuracy: 0.51299 |  0:01:39s\n",
            "epoch 184| loss: 0.96885 | train_accuracy: 0.51664 | val_accuracy: 0.51299 |  0:01:39s\n",
            "epoch 185| loss: 0.96615 | train_accuracy: 0.51704 | val_accuracy: 0.51459 |  0:01:40s\n",
            "epoch 186| loss: 0.96912 | train_accuracy: 0.51317 | val_accuracy: 0.51699 |  0:01:40s\n",
            "epoch 187| loss: 0.97032 | train_accuracy: 0.5165  | val_accuracy: 0.51579 |  0:01:41s\n",
            "epoch 188| loss: 0.97105 | train_accuracy: 0.51988 | val_accuracy: 0.5058  |  0:01:41s\n",
            "epoch 189| loss: 0.97137 | train_accuracy: 0.5161  | val_accuracy: 0.511   |  0:01:42s\n",
            "epoch 190| loss: 0.96805 | train_accuracy: 0.51993 | val_accuracy: 0.5086  |  0:01:42s\n",
            "epoch 191| loss: 0.96825 | train_accuracy: 0.51868 | val_accuracy: 0.509   |  0:01:43s\n",
            "epoch 192| loss: 0.96826 | train_accuracy: 0.5173  | val_accuracy: 0.5038  |  0:01:43s\n",
            "epoch 193| loss: 0.96963 | train_accuracy: 0.52201 | val_accuracy: 0.511   |  0:01:44s\n",
            "epoch 194| loss: 0.96638 | train_accuracy: 0.52144 | val_accuracy: 0.5102  |  0:01:44s\n",
            "epoch 195| loss: 0.96632 | train_accuracy: 0.52539 | val_accuracy: 0.51819 |  0:01:45s\n",
            "epoch 196| loss: 0.9653  | train_accuracy: 0.52597 | val_accuracy: 0.51459 |  0:01:46s\n",
            "epoch 197| loss: 0.96755 | train_accuracy: 0.52592 | val_accuracy: 0.51339 |  0:01:46s\n",
            "epoch 198| loss: 0.96387 | train_accuracy: 0.52792 | val_accuracy: 0.51539 |  0:01:46s\n",
            "epoch 199| loss: 0.96613 | train_accuracy: 0.5269  | val_accuracy: 0.5086  |  0:01:47s\n",
            "epoch 200| loss: 0.96301 | train_accuracy: 0.52681 | val_accuracy: 0.5022  |  0:01:48s\n",
            "epoch 201| loss: 0.96387 | train_accuracy: 0.5285  | val_accuracy: 0.5106  |  0:01:48s\n",
            "epoch 202| loss: 0.96183 | train_accuracy: 0.52788 | val_accuracy: 0.5098  |  0:01:49s\n",
            "epoch 203| loss: 0.9615  | train_accuracy: 0.52988 | val_accuracy: 0.51539 |  0:01:49s\n",
            "epoch 204| loss: 0.96398 | train_accuracy: 0.52894 | val_accuracy: 0.5046  |  0:01:50s\n",
            "epoch 205| loss: 0.96378 | train_accuracy: 0.52743 | val_accuracy: 0.51499 |  0:01:50s\n",
            "epoch 206| loss: 0.96404 | train_accuracy: 0.5213  | val_accuracy: 0.5018  |  0:01:51s\n",
            "epoch 207| loss: 0.96232 | train_accuracy: 0.52583 | val_accuracy: 0.5114  |  0:01:51s\n",
            "epoch 208| loss: 0.96462 | train_accuracy: 0.52548 | val_accuracy: 0.52259 |  0:01:52s\n",
            "epoch 209| loss: 0.96442 | train_accuracy: 0.52837 | val_accuracy: 0.51699 |  0:01:52s\n",
            "epoch 210| loss: 0.96089 | train_accuracy: 0.52788 | val_accuracy: 0.52379 |  0:01:53s\n",
            "epoch 211| loss: 0.96434 | train_accuracy: 0.52499 | val_accuracy: 0.52859 |  0:01:53s\n",
            "epoch 212| loss: 0.96305 | train_accuracy: 0.52463 | val_accuracy: 0.51499 |  0:01:54s\n",
            "epoch 213| loss: 0.9617  | train_accuracy: 0.53117 | val_accuracy: 0.52819 |  0:01:54s\n",
            "epoch 214| loss: 0.96305 | train_accuracy: 0.52988 | val_accuracy: 0.52299 |  0:01:55s\n",
            "epoch 215| loss: 0.96094 | train_accuracy: 0.53054 | val_accuracy: 0.52779 |  0:01:55s\n",
            "epoch 216| loss: 0.96039 | train_accuracy: 0.53134 | val_accuracy: 0.52859 |  0:01:56s\n",
            "epoch 217| loss: 0.95801 | train_accuracy: 0.53499 | val_accuracy: 0.52619 |  0:01:56s\n",
            "epoch 218| loss: 0.9627  | train_accuracy: 0.5317  | val_accuracy: 0.52139 |  0:01:57s\n",
            "epoch 219| loss: 0.96019 | train_accuracy: 0.52952 | val_accuracy: 0.52819 |  0:01:57s\n",
            "epoch 220| loss: 0.96003 | train_accuracy: 0.52641 | val_accuracy: 0.51979 |  0:01:58s\n",
            "epoch 221| loss: 0.95952 | train_accuracy: 0.52806 | val_accuracy: 0.51699 |  0:01:58s\n",
            "epoch 222| loss: 0.95983 | train_accuracy: 0.5301  | val_accuracy: 0.51619 |  0:01:59s\n",
            "epoch 223| loss: 0.96191 | train_accuracy: 0.52934 | val_accuracy: 0.52459 |  0:01:59s\n",
            "epoch 224| loss: 0.95588 | train_accuracy: 0.52957 | val_accuracy: 0.52619 |  0:02:00s\n",
            "epoch 225| loss: 0.96124 | train_accuracy: 0.53023 | val_accuracy: 0.52539 |  0:02:00s\n",
            "epoch 226| loss: 0.95903 | train_accuracy: 0.53241 | val_accuracy: 0.52299 |  0:02:01s\n",
            "epoch 227| loss: 0.95723 | train_accuracy: 0.53121 | val_accuracy: 0.52299 |  0:02:01s\n",
            "epoch 228| loss: 0.95804 | train_accuracy: 0.53108 | val_accuracy: 0.52099 |  0:02:02s\n",
            "epoch 229| loss: 0.95978 | train_accuracy: 0.53272 | val_accuracy: 0.52379 |  0:02:02s\n",
            "epoch 230| loss: 0.95969 | train_accuracy: 0.53263 | val_accuracy: 0.51979 |  0:02:03s\n",
            "epoch 231| loss: 0.95684 | train_accuracy: 0.52894 | val_accuracy: 0.51539 |  0:02:04s\n",
            "epoch 232| loss: 0.95862 | train_accuracy: 0.53081 | val_accuracy: 0.52139 |  0:02:04s\n",
            "epoch 233| loss: 0.9586  | train_accuracy: 0.52859 | val_accuracy: 0.52379 |  0:02:05s\n",
            "epoch 234| loss: 0.95964 | train_accuracy: 0.52943 | val_accuracy: 0.53099 |  0:02:05s\n",
            "epoch 235| loss: 0.95851 | train_accuracy: 0.52934 | val_accuracy: 0.52499 |  0:02:06s\n",
            "epoch 236| loss: 0.95543 | train_accuracy: 0.52943 | val_accuracy: 0.51699 |  0:02:06s\n",
            "epoch 237| loss: 0.95951 | train_accuracy: 0.52606 | val_accuracy: 0.52139 |  0:02:07s\n",
            "epoch 238| loss: 0.95711 | train_accuracy: 0.53045 | val_accuracy: 0.51419 |  0:02:07s\n",
            "epoch 239| loss: 0.95898 | train_accuracy: 0.53041 | val_accuracy: 0.51819 |  0:02:08s\n",
            "epoch 240| loss: 0.95944 | train_accuracy: 0.52934 | val_accuracy: 0.51939 |  0:02:08s\n",
            "epoch 241| loss: 0.95916 | train_accuracy: 0.5309  | val_accuracy: 0.52219 |  0:02:09s\n",
            "epoch 242| loss: 0.95695 | train_accuracy: 0.53045 | val_accuracy: 0.51299 |  0:02:09s\n",
            "epoch 243| loss: 0.95628 | train_accuracy: 0.53383 | val_accuracy: 0.51979 |  0:02:10s\n",
            "epoch 244| loss: 0.95319 | train_accuracy: 0.53321 | val_accuracy: 0.52459 |  0:02:10s\n",
            "epoch 245| loss: 0.95513 | train_accuracy: 0.53028 | val_accuracy: 0.52179 |  0:02:11s\n",
            "epoch 246| loss: 0.95363 | train_accuracy: 0.53188 | val_accuracy: 0.52539 |  0:02:11s\n",
            "epoch 247| loss: 0.95653 | train_accuracy: 0.53343 | val_accuracy: 0.51739 |  0:02:12s\n",
            "epoch 248| loss: 0.96053 | train_accuracy: 0.53348 | val_accuracy: 0.52379 |  0:02:12s\n",
            "epoch 249| loss: 0.9576  | train_accuracy: 0.53401 | val_accuracy: 0.51859 |  0:02:13s\n",
            "epoch 250| loss: 0.95748 | train_accuracy: 0.53414 | val_accuracy: 0.51459 |  0:02:13s\n",
            "epoch 251| loss: 0.95941 | train_accuracy: 0.53636 | val_accuracy: 0.51699 |  0:02:14s\n",
            "epoch 252| loss: 0.96114 | train_accuracy: 0.53263 | val_accuracy: 0.52579 |  0:02:15s\n",
            "epoch 253| loss: 0.95755 | train_accuracy: 0.5357  | val_accuracy: 0.54058 |  0:02:15s\n",
            "epoch 254| loss: 0.95579 | train_accuracy: 0.53299 | val_accuracy: 0.52179 |  0:02:16s\n",
            "epoch 255| loss: 0.95552 | train_accuracy: 0.53503 | val_accuracy: 0.52499 |  0:02:16s\n",
            "epoch 256| loss: 0.95643 | train_accuracy: 0.53587 | val_accuracy: 0.52579 |  0:02:17s\n",
            "epoch 257| loss: 0.95735 | train_accuracy: 0.53752 | val_accuracy: 0.52499 |  0:02:17s\n",
            "epoch 258| loss: 0.95654 | train_accuracy: 0.53614 | val_accuracy: 0.52379 |  0:02:18s\n",
            "epoch 259| loss: 0.95358 | train_accuracy: 0.53983 | val_accuracy: 0.52979 |  0:02:18s\n",
            "epoch 260| loss: 0.95375 | train_accuracy: 0.5385  | val_accuracy: 0.52099 |  0:02:19s\n",
            "epoch 261| loss: 0.95267 | train_accuracy: 0.53805 | val_accuracy: 0.52619 |  0:02:19s\n",
            "epoch 262| loss: 0.95265 | train_accuracy: 0.54081 | val_accuracy: 0.52859 |  0:02:20s\n",
            "epoch 263| loss: 0.95656 | train_accuracy: 0.54227 | val_accuracy: 0.52739 |  0:02:20s\n",
            "epoch 264| loss: 0.95297 | train_accuracy: 0.54174 | val_accuracy: 0.52739 |  0:02:21s\n",
            "epoch 265| loss: 0.95251 | train_accuracy: 0.53854 | val_accuracy: 0.51419 |  0:02:21s\n",
            "epoch 266| loss: 0.9561  | train_accuracy: 0.53685 | val_accuracy: 0.51939 |  0:02:22s\n",
            "epoch 267| loss: 0.9633  | train_accuracy: 0.53059 | val_accuracy: 0.51579 |  0:02:23s\n",
            "epoch 268| loss: 0.96326 | train_accuracy: 0.5333  | val_accuracy: 0.51379 |  0:02:23s\n",
            "epoch 269| loss: 0.95952 | train_accuracy: 0.53356 | val_accuracy: 0.52579 |  0:02:24s\n",
            "epoch 270| loss: 0.95858 | train_accuracy: 0.53428 | val_accuracy: 0.5102  |  0:02:24s\n",
            "epoch 271| loss: 0.95515 | train_accuracy: 0.53503 | val_accuracy: 0.5118  |  0:02:25s\n",
            "epoch 272| loss: 0.95607 | train_accuracy: 0.53485 | val_accuracy: 0.51859 |  0:02:25s\n",
            "epoch 273| loss: 0.95709 | train_accuracy: 0.53836 | val_accuracy: 0.51899 |  0:02:26s\n",
            "epoch 274| loss: 0.95235 | train_accuracy: 0.53827 | val_accuracy: 0.52179 |  0:02:26s\n",
            "epoch 275| loss: 0.95323 | train_accuracy: 0.54063 | val_accuracy: 0.51259 |  0:02:27s\n",
            "epoch 276| loss: 0.95429 | train_accuracy: 0.54134 | val_accuracy: 0.52659 |  0:02:27s\n",
            "epoch 277| loss: 0.95395 | train_accuracy: 0.53778 | val_accuracy: 0.52699 |  0:02:28s\n",
            "epoch 278| loss: 0.95494 | train_accuracy: 0.53539 | val_accuracy: 0.52659 |  0:02:28s\n",
            "epoch 279| loss: 0.95202 | train_accuracy: 0.53285 | val_accuracy: 0.52259 |  0:02:29s\n",
            "epoch 280| loss: 0.96079 | train_accuracy: 0.53205 | val_accuracy: 0.52299 |  0:02:29s\n",
            "epoch 281| loss: 0.95966 | train_accuracy: 0.5321  | val_accuracy: 0.51499 |  0:02:30s\n",
            "epoch 282| loss: 0.96177 | train_accuracy: 0.53232 | val_accuracy: 0.51779 |  0:02:30s\n",
            "epoch 283| loss: 0.96148 | train_accuracy: 0.53094 | val_accuracy: 0.51579 |  0:02:31s\n",
            "epoch 284| loss: 0.96024 | train_accuracy: 0.5321  | val_accuracy: 0.52499 |  0:02:31s\n",
            "epoch 285| loss: 0.96339 | train_accuracy: 0.51997 | val_accuracy: 0.511   |  0:02:32s\n",
            "epoch 286| loss: 0.96378 | train_accuracy: 0.53699 | val_accuracy: 0.52139 |  0:02:32s\n",
            "epoch 287| loss: 0.95857 | train_accuracy: 0.53339 | val_accuracy: 0.52619 |  0:02:33s\n",
            "epoch 288| loss: 0.95706 | train_accuracy: 0.53823 | val_accuracy: 0.53499 |  0:02:33s\n",
            "epoch 289| loss: 0.95758 | train_accuracy: 0.53747 | val_accuracy: 0.53059 |  0:02:34s\n",
            "epoch 290| loss: 0.95526 | train_accuracy: 0.53423 | val_accuracy: 0.52139 |  0:02:34s\n",
            "epoch 291| loss: 0.95971 | train_accuracy: 0.53401 | val_accuracy: 0.51619 |  0:02:35s\n",
            "epoch 292| loss: 0.9534  | train_accuracy: 0.53841 | val_accuracy: 0.52219 |  0:02:35s\n",
            "epoch 293| loss: 0.95448 | train_accuracy: 0.53401 | val_accuracy: 0.52179 |  0:02:36s\n",
            "epoch 294| loss: 0.95842 | train_accuracy: 0.53565 | val_accuracy: 0.52219 |  0:02:36s\n",
            "epoch 295| loss: 0.95909 | train_accuracy: 0.53054 | val_accuracy: 0.51739 |  0:02:37s\n",
            "epoch 296| loss: 0.95772 | train_accuracy: 0.53201 | val_accuracy: 0.52259 |  0:02:37s\n",
            "epoch 297| loss: 0.95339 | train_accuracy: 0.53463 | val_accuracy: 0.52179 |  0:02:38s\n",
            "epoch 298| loss: 0.95526 | train_accuracy: 0.53787 | val_accuracy: 0.52939 |  0:02:38s\n",
            "epoch 299| loss: 0.94977 | train_accuracy: 0.53574 | val_accuracy: 0.52899 |  0:02:39s\n",
            "epoch 300| loss: 0.95417 | train_accuracy: 0.53747 | val_accuracy: 0.52379 |  0:02:39s\n",
            "epoch 301| loss: 0.9537  | train_accuracy: 0.53512 | val_accuracy: 0.52899 |  0:02:40s\n",
            "epoch 302| loss: 0.95449 | train_accuracy: 0.53441 | val_accuracy: 0.52739 |  0:02:40s\n",
            "epoch 303| loss: 0.95883 | train_accuracy: 0.53161 | val_accuracy: 0.52259 |  0:02:41s\n",
            "epoch 304| loss: 0.9596  | train_accuracy: 0.53468 | val_accuracy: 0.51619 |  0:02:41s\n",
            "epoch 305| loss: 0.96196 | train_accuracy: 0.53165 | val_accuracy: 0.51819 |  0:02:42s\n",
            "epoch 306| loss: 0.9557  | train_accuracy: 0.52877 | val_accuracy: 0.52899 |  0:02:42s\n",
            "epoch 307| loss: 0.96255 | train_accuracy: 0.52406 | val_accuracy: 0.52099 |  0:02:43s\n",
            "epoch 308| loss: 0.9675  | train_accuracy: 0.5205  | val_accuracy: 0.51419 |  0:02:43s\n",
            "epoch 309| loss: 0.96945 | train_accuracy: 0.52206 | val_accuracy: 0.51419 |  0:02:44s\n",
            "epoch 310| loss: 0.96765 | train_accuracy: 0.52295 | val_accuracy: 0.51299 |  0:02:45s\n",
            "epoch 311| loss: 0.9637  | train_accuracy: 0.52535 | val_accuracy: 0.5118  |  0:02:46s\n",
            "epoch 312| loss: 0.96374 | train_accuracy: 0.52401 | val_accuracy: 0.5066  |  0:02:46s\n",
            "epoch 313| loss: 0.96293 | train_accuracy: 0.52708 | val_accuracy: 0.5062  |  0:02:47s\n",
            "epoch 314| loss: 0.95881 | train_accuracy: 0.52814 | val_accuracy: 0.51419 |  0:02:47s\n",
            "epoch 315| loss: 0.95829 | train_accuracy: 0.52517 | val_accuracy: 0.51619 |  0:02:48s\n",
            "epoch 316| loss: 0.96247 | train_accuracy: 0.53099 | val_accuracy: 0.51539 |  0:02:48s\n",
            "epoch 317| loss: 0.96146 | train_accuracy: 0.52601 | val_accuracy: 0.51499 |  0:02:49s\n",
            "epoch 318| loss: 0.96223 | train_accuracy: 0.52761 | val_accuracy: 0.51459 |  0:02:49s\n",
            "epoch 319| loss: 0.96326 | train_accuracy: 0.53005 | val_accuracy: 0.5118  |  0:02:50s\n",
            "epoch 320| loss: 0.96315 | train_accuracy: 0.53005 | val_accuracy: 0.51779 |  0:02:50s\n",
            "epoch 321| loss: 0.96422 | train_accuracy: 0.52779 | val_accuracy: 0.51979 |  0:02:51s\n",
            "epoch 322| loss: 0.96034 | train_accuracy: 0.52615 | val_accuracy: 0.51859 |  0:02:51s\n",
            "epoch 323| loss: 0.96158 | train_accuracy: 0.52717 | val_accuracy: 0.52539 |  0:02:52s\n",
            "epoch 324| loss: 0.96062 | train_accuracy: 0.52463 | val_accuracy: 0.5082  |  0:02:52s\n",
            "epoch 325| loss: 0.9616  | train_accuracy: 0.53152 | val_accuracy: 0.51699 |  0:02:53s\n",
            "epoch 326| loss: 0.96202 | train_accuracy: 0.53005 | val_accuracy: 0.51259 |  0:02:53s\n",
            "epoch 327| loss: 0.95675 | train_accuracy: 0.53019 | val_accuracy: 0.51619 |  0:02:54s\n",
            "epoch 328| loss: 0.95626 | train_accuracy: 0.53143 | val_accuracy: 0.52379 |  0:02:54s\n",
            "epoch 329| loss: 0.95734 | train_accuracy: 0.5301  | val_accuracy: 0.51659 |  0:02:55s\n",
            "epoch 330| loss: 0.95828 | train_accuracy: 0.53059 | val_accuracy: 0.52979 |  0:02:56s\n",
            "epoch 331| loss: 0.95908 | train_accuracy: 0.53361 | val_accuracy: 0.53139 |  0:02:58s\n",
            "epoch 332| loss: 0.95373 | train_accuracy: 0.53276 | val_accuracy: 0.53459 |  0:02:59s\n",
            "epoch 333| loss: 0.95592 | train_accuracy: 0.53379 | val_accuracy: 0.52339 |  0:03:00s\n",
            "epoch 334| loss: 0.95764 | train_accuracy: 0.53219 | val_accuracy: 0.52859 |  0:03:01s\n",
            "epoch 335| loss: 0.95859 | train_accuracy: 0.53503 | val_accuracy: 0.53099 |  0:03:02s\n",
            "epoch 336| loss: 0.9591  | train_accuracy: 0.53814 | val_accuracy: 0.51819 |  0:03:03s\n",
            "epoch 337| loss: 0.96076 | train_accuracy: 0.53379 | val_accuracy: 0.52499 |  0:03:03s\n",
            "epoch 338| loss: 0.95417 | train_accuracy: 0.5341  | val_accuracy: 0.53219 |  0:03:03s\n",
            "epoch 339| loss: 0.95501 | train_accuracy: 0.53459 | val_accuracy: 0.52539 |  0:03:04s\n",
            "epoch 340| loss: 0.95646 | train_accuracy: 0.53361 | val_accuracy: 0.52379 |  0:03:04s\n",
            "epoch 341| loss: 0.95474 | train_accuracy: 0.53579 | val_accuracy: 0.53099 |  0:03:05s\n",
            "epoch 342| loss: 0.9561  | train_accuracy: 0.52699 | val_accuracy: 0.52699 |  0:03:06s\n",
            "epoch 343| loss: 0.95523 | train_accuracy: 0.53361 | val_accuracy: 0.52859 |  0:03:06s\n",
            "epoch 344| loss: 0.95749 | train_accuracy: 0.5321  | val_accuracy: 0.51859 |  0:03:07s\n",
            "epoch 345| loss: 0.95441 | train_accuracy: 0.53525 | val_accuracy: 0.52379 |  0:03:07s\n",
            "epoch 346| loss: 0.95267 | train_accuracy: 0.53521 | val_accuracy: 0.52419 |  0:03:08s\n",
            "epoch 347| loss: 0.95364 | train_accuracy: 0.53192 | val_accuracy: 0.52179 |  0:03:08s\n",
            "epoch 348| loss: 0.95193 | train_accuracy: 0.53596 | val_accuracy: 0.52499 |  0:03:09s\n",
            "epoch 349| loss: 0.95026 | train_accuracy: 0.53499 | val_accuracy: 0.52579 |  0:03:09s\n",
            "epoch 350| loss: 0.94973 | train_accuracy: 0.53476 | val_accuracy: 0.53259 |  0:03:10s\n",
            "epoch 351| loss: 0.95142 | train_accuracy: 0.53645 | val_accuracy: 0.52299 |  0:03:10s\n",
            "epoch 352| loss: 0.94922 | train_accuracy: 0.5357  | val_accuracy: 0.52219 |  0:03:11s\n",
            "epoch 353| loss: 0.94958 | train_accuracy: 0.53245 | val_accuracy: 0.52219 |  0:03:11s\n",
            "epoch 354| loss: 0.94879 | train_accuracy: 0.5377  | val_accuracy: 0.53059 |  0:03:12s\n",
            "epoch 355| loss: 0.94948 | train_accuracy: 0.53463 | val_accuracy: 0.52379 |  0:03:12s\n",
            "epoch 356| loss: 0.95113 | train_accuracy: 0.53316 | val_accuracy: 0.51539 |  0:03:13s\n",
            "epoch 357| loss: 0.95363 | train_accuracy: 0.54356 | val_accuracy: 0.53459 |  0:03:13s\n",
            "epoch 358| loss: 0.948   | train_accuracy: 0.54121 | val_accuracy: 0.52379 |  0:03:14s\n",
            "epoch 359| loss: 0.9494  | train_accuracy: 0.54352 | val_accuracy: 0.53019 |  0:03:14s\n",
            "epoch 360| loss: 0.9515  | train_accuracy: 0.53494 | val_accuracy: 0.52699 |  0:03:15s\n",
            "epoch 361| loss: 0.94874 | train_accuracy: 0.54409 | val_accuracy: 0.53139 |  0:03:15s\n",
            "epoch 362| loss: 0.94534 | train_accuracy: 0.53632 | val_accuracy: 0.52099 |  0:03:16s\n",
            "epoch 363| loss: 0.94701 | train_accuracy: 0.54294 | val_accuracy: 0.52379 |  0:03:16s\n",
            "epoch 364| loss: 0.94695 | train_accuracy: 0.54192 | val_accuracy: 0.52459 |  0:03:17s\n",
            "epoch 365| loss: 0.94527 | train_accuracy: 0.54067 | val_accuracy: 0.52859 |  0:03:17s\n",
            "epoch 366| loss: 0.94591 | train_accuracy: 0.54329 | val_accuracy: 0.53259 |  0:03:18s\n",
            "epoch 367| loss: 0.94659 | train_accuracy: 0.54436 | val_accuracy: 0.52939 |  0:03:18s\n",
            "epoch 368| loss: 0.94498 | train_accuracy: 0.5432  | val_accuracy: 0.52659 |  0:03:19s\n",
            "epoch 369| loss: 0.94513 | train_accuracy: 0.54254 | val_accuracy: 0.52739 |  0:03:19s\n",
            "epoch 370| loss: 0.94617 | train_accuracy: 0.53774 | val_accuracy: 0.52619 |  0:03:20s\n",
            "epoch 371| loss: 0.94353 | train_accuracy: 0.53872 | val_accuracy: 0.53099 |  0:03:20s\n",
            "epoch 372| loss: 0.94351 | train_accuracy: 0.5381  | val_accuracy: 0.52059 |  0:03:21s\n",
            "epoch 373| loss: 0.94271 | train_accuracy: 0.54591 | val_accuracy: 0.53139 |  0:03:21s\n",
            "epoch 374| loss: 0.94358 | train_accuracy: 0.5456  | val_accuracy: 0.52579 |  0:03:22s\n",
            "epoch 375| loss: 0.94365 | train_accuracy: 0.54578 | val_accuracy: 0.52859 |  0:03:22s\n",
            "epoch 376| loss: 0.94528 | train_accuracy: 0.54574 | val_accuracy: 0.53619 |  0:03:23s\n",
            "epoch 377| loss: 0.94221 | train_accuracy: 0.54516 | val_accuracy: 0.53019 |  0:03:23s\n",
            "epoch 378| loss: 0.94282 | train_accuracy: 0.54427 | val_accuracy: 0.52139 |  0:03:24s\n",
            "epoch 379| loss: 0.94318 | train_accuracy: 0.5436  | val_accuracy: 0.52539 |  0:03:24s\n",
            "epoch 380| loss: 0.93965 | train_accuracy: 0.5448  | val_accuracy: 0.52259 |  0:03:25s\n",
            "epoch 381| loss: 0.94259 | train_accuracy: 0.54543 | val_accuracy: 0.53379 |  0:03:25s\n",
            "epoch 382| loss: 0.94351 | train_accuracy: 0.53805 | val_accuracy: 0.52299 |  0:03:26s\n",
            "epoch 383| loss: 0.94327 | train_accuracy: 0.53841 | val_accuracy: 0.51299 |  0:03:26s\n",
            "epoch 384| loss: 0.94613 | train_accuracy: 0.53854 | val_accuracy: 0.51939 |  0:03:27s\n",
            "epoch 385| loss: 0.9411  | train_accuracy: 0.54214 | val_accuracy: 0.53898 |  0:03:27s\n",
            "epoch 386| loss: 0.9442  | train_accuracy: 0.53987 | val_accuracy: 0.52619 |  0:03:28s\n",
            "epoch 387| loss: 0.94297 | train_accuracy: 0.54503 | val_accuracy: 0.53619 |  0:03:28s\n",
            "epoch 388| loss: 0.94111 | train_accuracy: 0.54743 | val_accuracy: 0.53379 |  0:03:29s\n",
            "epoch 389| loss: 0.94179 | train_accuracy: 0.54236 | val_accuracy: 0.52979 |  0:03:29s\n",
            "epoch 390| loss: 0.94077 | train_accuracy: 0.54316 | val_accuracy: 0.53539 |  0:03:30s\n",
            "epoch 391| loss: 0.94401 | train_accuracy: 0.54445 | val_accuracy: 0.53778 |  0:03:30s\n",
            "epoch 392| loss: 0.94422 | train_accuracy: 0.53743 | val_accuracy: 0.52339 |  0:03:31s\n",
            "epoch 393| loss: 0.93975 | train_accuracy: 0.54241 | val_accuracy: 0.53938 |  0:03:31s\n",
            "epoch 394| loss: 0.94007 | train_accuracy: 0.54747 | val_accuracy: 0.53619 |  0:03:32s\n",
            "epoch 395| loss: 0.93772 | train_accuracy: 0.54383 | val_accuracy: 0.53019 |  0:03:32s\n",
            "epoch 396| loss: 0.93518 | train_accuracy: 0.54649 | val_accuracy: 0.53619 |  0:03:33s\n",
            "epoch 397| loss: 0.93927 | train_accuracy: 0.54427 | val_accuracy: 0.53419 |  0:03:33s\n",
            "epoch 398| loss: 0.93467 | train_accuracy: 0.54889 | val_accuracy: 0.54098 |  0:03:34s\n",
            "epoch 399| loss: 0.93776 | train_accuracy: 0.54738 | val_accuracy: 0.53659 |  0:03:34s\n",
            "epoch 400| loss: 0.93364 | train_accuracy: 0.54805 | val_accuracy: 0.53379 |  0:03:35s\n",
            "epoch 401| loss: 0.93882 | train_accuracy: 0.54516 | val_accuracy: 0.53499 |  0:03:36s\n",
            "epoch 402| loss: 0.93741 | train_accuracy: 0.5456  | val_accuracy: 0.52659 |  0:03:36s\n",
            "epoch 403| loss: 0.93844 | train_accuracy: 0.54569 | val_accuracy: 0.53179 |  0:03:37s\n",
            "epoch 404| loss: 0.93348 | train_accuracy: 0.54831 | val_accuracy: 0.52459 |  0:03:37s\n",
            "epoch 405| loss: 0.9353  | train_accuracy: 0.55213 | val_accuracy: 0.54058 |  0:03:37s\n",
            "epoch 406| loss: 0.93504 | train_accuracy: 0.54978 | val_accuracy: 0.52819 |  0:03:38s\n",
            "epoch 407| loss: 0.93267 | train_accuracy: 0.55142 | val_accuracy: 0.53699 |  0:03:39s\n",
            "epoch 408| loss: 0.93442 | train_accuracy: 0.55173 | val_accuracy: 0.52859 |  0:03:39s\n",
            "epoch 409| loss: 0.93702 | train_accuracy: 0.55511 | val_accuracy: 0.53938 |  0:03:40s\n",
            "epoch 410| loss: 0.93121 | train_accuracy: 0.55045 | val_accuracy: 0.53259 |  0:03:40s\n",
            "epoch 411| loss: 0.935   | train_accuracy: 0.55462 | val_accuracy: 0.53619 |  0:03:41s\n",
            "epoch 412| loss: 0.93267 | train_accuracy: 0.55382 | val_accuracy: 0.53898 |  0:03:41s\n",
            "epoch 413| loss: 0.93521 | train_accuracy: 0.54987 | val_accuracy: 0.54258 |  0:03:42s\n",
            "epoch 414| loss: 0.93486 | train_accuracy: 0.55138 | val_accuracy: 0.54098 |  0:03:42s\n",
            "epoch 415| loss: 0.93369 | train_accuracy: 0.54938 | val_accuracy: 0.53499 |  0:03:43s\n",
            "epoch 416| loss: 0.93418 | train_accuracy: 0.55333 | val_accuracy: 0.54018 |  0:03:43s\n",
            "epoch 417| loss: 0.93437 | train_accuracy: 0.55196 | val_accuracy: 0.53459 |  0:03:44s\n",
            "epoch 418| loss: 0.93064 | train_accuracy: 0.55373 | val_accuracy: 0.53379 |  0:03:44s\n",
            "epoch 419| loss: 0.93552 | train_accuracy: 0.55009 | val_accuracy: 0.53139 |  0:03:45s\n",
            "epoch 420| loss: 0.93534 | train_accuracy: 0.54911 | val_accuracy: 0.53259 |  0:03:45s\n",
            "epoch 421| loss: 0.93527 | train_accuracy: 0.5472  | val_accuracy: 0.53099 |  0:03:46s\n",
            "epoch 422| loss: 0.9366  | train_accuracy: 0.55325 | val_accuracy: 0.52899 |  0:03:46s\n",
            "epoch 423| loss: 0.9337  | train_accuracy: 0.55009 | val_accuracy: 0.52659 |  0:03:47s\n",
            "epoch 424| loss: 0.93325 | train_accuracy: 0.55036 | val_accuracy: 0.53619 |  0:03:47s\n",
            "epoch 425| loss: 0.93189 | train_accuracy: 0.55054 | val_accuracy: 0.53499 |  0:03:48s\n",
            "epoch 426| loss: 0.9344  | train_accuracy: 0.55236 | val_accuracy: 0.53699 |  0:03:48s\n",
            "epoch 427| loss: 0.92881 | train_accuracy: 0.55467 | val_accuracy: 0.53579 |  0:03:49s\n",
            "epoch 428| loss: 0.93144 | train_accuracy: 0.554   | val_accuracy: 0.54458 |  0:03:49s\n",
            "epoch 429| loss: 0.93238 | train_accuracy: 0.55604 | val_accuracy: 0.53699 |  0:03:50s\n",
            "epoch 430| loss: 0.92878 | train_accuracy: 0.55147 | val_accuracy: 0.53539 |  0:03:50s\n",
            "epoch 431| loss: 0.93069 | train_accuracy: 0.55538 | val_accuracy: 0.54218 |  0:03:51s\n",
            "epoch 432| loss: 0.92934 | train_accuracy: 0.55333 | val_accuracy: 0.54178 |  0:03:51s\n",
            "epoch 433| loss: 0.93482 | train_accuracy: 0.53827 | val_accuracy: 0.52459 |  0:03:52s\n",
            "epoch 434| loss: 0.93533 | train_accuracy: 0.54285 | val_accuracy: 0.53219 |  0:03:52s\n",
            "epoch 435| loss: 0.93158 | train_accuracy: 0.53619 | val_accuracy: 0.52859 |  0:03:53s\n",
            "epoch 436| loss: 0.93512 | train_accuracy: 0.54756 | val_accuracy: 0.53179 |  0:03:53s\n",
            "epoch 437| loss: 0.93128 | train_accuracy: 0.552   | val_accuracy: 0.53619 |  0:03:54s\n",
            "epoch 438| loss: 0.94048 | train_accuracy: 0.55054 | val_accuracy: 0.53938 |  0:03:54s\n",
            "epoch 439| loss: 0.93232 | train_accuracy: 0.54849 | val_accuracy: 0.53459 |  0:03:55s\n",
            "epoch 440| loss: 0.93475 | train_accuracy: 0.5528  | val_accuracy: 0.53299 |  0:03:55s\n",
            "epoch 441| loss: 0.93503 | train_accuracy: 0.54827 | val_accuracy: 0.52939 |  0:03:56s\n",
            "epoch 442| loss: 0.93373 | train_accuracy: 0.55405 | val_accuracy: 0.53699 |  0:03:56s\n",
            "epoch 443| loss: 0.93175 | train_accuracy: 0.55325 | val_accuracy: 0.53459 |  0:03:57s\n",
            "epoch 444| loss: 0.93288 | train_accuracy: 0.55489 | val_accuracy: 0.54618 |  0:03:57s\n",
            "epoch 445| loss: 0.92864 | train_accuracy: 0.55396 | val_accuracy: 0.54018 |  0:03:58s\n",
            "epoch 446| loss: 0.92742 | train_accuracy: 0.55813 | val_accuracy: 0.54178 |  0:03:58s\n",
            "epoch 447| loss: 0.92772 | train_accuracy: 0.55533 | val_accuracy: 0.53579 |  0:03:59s\n",
            "epoch 448| loss: 0.92928 | train_accuracy: 0.55613 | val_accuracy: 0.54778 |  0:03:59s\n",
            "epoch 449| loss: 0.93109 | train_accuracy: 0.55333 | val_accuracy: 0.53858 |  0:04:00s\n",
            "epoch 450| loss: 0.92755 | train_accuracy: 0.55636 | val_accuracy: 0.54418 |  0:04:00s\n",
            "epoch 451| loss: 0.92764 | train_accuracy: 0.55547 | val_accuracy: 0.53858 |  0:04:01s\n",
            "epoch 452| loss: 0.93027 | train_accuracy: 0.5564  | val_accuracy: 0.54338 |  0:04:01s\n",
            "epoch 453| loss: 0.92521 | train_accuracy: 0.55427 | val_accuracy: 0.55098 |  0:04:02s\n",
            "epoch 454| loss: 0.92511 | train_accuracy: 0.55378 | val_accuracy: 0.54378 |  0:04:02s\n",
            "epoch 455| loss: 0.92636 | train_accuracy: 0.5576  | val_accuracy: 0.54378 |  0:04:03s\n",
            "epoch 456| loss: 0.92667 | train_accuracy: 0.55569 | val_accuracy: 0.54058 |  0:04:03s\n",
            "epoch 457| loss: 0.93076 | train_accuracy: 0.55591 | val_accuracy: 0.54658 |  0:04:04s\n",
            "epoch 458| loss: 0.92949 | train_accuracy: 0.55653 | val_accuracy: 0.54778 |  0:04:04s\n",
            "epoch 459| loss: 0.92799 | train_accuracy: 0.5564  | val_accuracy: 0.54498 |  0:04:05s\n",
            "epoch 460| loss: 0.92716 | train_accuracy: 0.55213 | val_accuracy: 0.53898 |  0:04:05s\n",
            "epoch 461| loss: 0.92583 | train_accuracy: 0.55707 | val_accuracy: 0.54338 |  0:04:06s\n",
            "epoch 462| loss: 0.92689 | train_accuracy: 0.5568  | val_accuracy: 0.53459 |  0:04:06s\n",
            "epoch 463| loss: 0.92415 | train_accuracy: 0.5608  | val_accuracy: 0.54898 |  0:04:07s\n",
            "epoch 464| loss: 0.94149 | train_accuracy: 0.53481 | val_accuracy: 0.51259 |  0:04:07s\n",
            "epoch 465| loss: 0.95001 | train_accuracy: 0.53223 | val_accuracy: 0.51699 |  0:04:08s\n",
            "epoch 466| loss: 0.94474 | train_accuracy: 0.54014 | val_accuracy: 0.52779 |  0:04:08s\n",
            "epoch 467| loss: 0.94426 | train_accuracy: 0.5464  | val_accuracy: 0.53059 |  0:04:09s\n",
            "epoch 468| loss: 0.93579 | train_accuracy: 0.54241 | val_accuracy: 0.52779 |  0:04:09s\n",
            "epoch 469| loss: 0.93611 | train_accuracy: 0.54885 | val_accuracy: 0.53419 |  0:04:10s\n",
            "epoch 470| loss: 0.93213 | train_accuracy: 0.55187 | val_accuracy: 0.53499 |  0:04:11s\n",
            "epoch 471| loss: 0.92993 | train_accuracy: 0.55556 | val_accuracy: 0.54138 |  0:04:11s\n",
            "epoch 472| loss: 0.93058 | train_accuracy: 0.55351 | val_accuracy: 0.54258 |  0:04:11s\n",
            "epoch 473| loss: 0.93058 | train_accuracy: 0.55298 | val_accuracy: 0.54498 |  0:04:12s\n",
            "epoch 474| loss: 0.93176 | train_accuracy: 0.55449 | val_accuracy: 0.53699 |  0:04:12s\n",
            "epoch 475| loss: 0.93244 | train_accuracy: 0.55533 | val_accuracy: 0.53978 |  0:04:13s\n",
            "epoch 476| loss: 0.93054 | train_accuracy: 0.55564 | val_accuracy: 0.54738 |  0:04:13s\n",
            "epoch 477| loss: 0.93024 | train_accuracy: 0.55045 | val_accuracy: 0.54138 |  0:04:14s\n",
            "epoch 478| loss: 0.9363  | train_accuracy: 0.54312 | val_accuracy: 0.53219 |  0:04:14s\n",
            "epoch 479| loss: 0.9422  | train_accuracy: 0.5456  | val_accuracy: 0.53659 |  0:04:15s\n",
            "epoch 480| loss: 0.94199 | train_accuracy: 0.54854 | val_accuracy: 0.54098 |  0:04:16s\n",
            "epoch 481| loss: 0.94701 | train_accuracy: 0.54129 | val_accuracy: 0.53419 |  0:04:16s\n",
            "epoch 482| loss: 0.93609 | train_accuracy: 0.54543 | val_accuracy: 0.54178 |  0:04:16s\n",
            "epoch 483| loss: 0.9379  | train_accuracy: 0.5496  | val_accuracy: 0.53099 |  0:04:17s\n",
            "epoch 484| loss: 0.93766 | train_accuracy: 0.54951 | val_accuracy: 0.53459 |  0:04:17s\n",
            "epoch 485| loss: 0.93221 | train_accuracy: 0.5504  | val_accuracy: 0.54258 |  0:04:18s\n",
            "epoch 486| loss: 0.93426 | train_accuracy: 0.55036 | val_accuracy: 0.54298 |  0:04:19s\n",
            "epoch 487| loss: 0.9365  | train_accuracy: 0.55116 | val_accuracy: 0.54538 |  0:04:19s\n",
            "epoch 488| loss: 0.93244 | train_accuracy: 0.55213 | val_accuracy: 0.55258 |  0:04:20s\n",
            "epoch 489| loss: 0.93618 | train_accuracy: 0.55382 | val_accuracy: 0.54738 |  0:04:20s\n",
            "epoch 490| loss: 0.93342 | train_accuracy: 0.55462 | val_accuracy: 0.54298 |  0:04:21s\n",
            "epoch 491| loss: 0.93188 | train_accuracy: 0.55347 | val_accuracy: 0.54058 |  0:04:21s\n",
            "epoch 492| loss: 0.92993 | train_accuracy: 0.55698 | val_accuracy: 0.55618 |  0:04:22s\n",
            "epoch 493| loss: 0.93168 | train_accuracy: 0.55369 | val_accuracy: 0.54058 |  0:04:22s\n",
            "epoch 494| loss: 0.93167 | train_accuracy: 0.54974 | val_accuracy: 0.54098 |  0:04:23s\n",
            "epoch 495| loss: 0.93576 | train_accuracy: 0.54907 | val_accuracy: 0.54258 |  0:04:23s\n",
            "epoch 496| loss: 0.93425 | train_accuracy: 0.55262 | val_accuracy: 0.54458 |  0:04:24s\n",
            "epoch 497| loss: 0.9321  | train_accuracy: 0.55005 | val_accuracy: 0.53978 |  0:04:24s\n",
            "epoch 498| loss: 0.93103 | train_accuracy: 0.55489 | val_accuracy: 0.55538 |  0:04:25s\n",
            "epoch 499| loss: 0.92865 | train_accuracy: 0.54996 | val_accuracy: 0.54418 |  0:04:25s\n",
            "epoch 500| loss: 0.9336  | train_accuracy: 0.55178 | val_accuracy: 0.55378 |  0:04:26s\n",
            "epoch 501| loss: 0.93226 | train_accuracy: 0.55427 | val_accuracy: 0.54498 |  0:04:26s\n",
            "epoch 502| loss: 0.93131 | train_accuracy: 0.55351 | val_accuracy: 0.54618 |  0:04:27s\n",
            "epoch 503| loss: 0.93354 | train_accuracy: 0.5496  | val_accuracy: 0.53139 |  0:04:27s\n",
            "epoch 504| loss: 0.93379 | train_accuracy: 0.55213 | val_accuracy: 0.55138 |  0:04:28s\n",
            "epoch 505| loss: 0.92822 | train_accuracy: 0.55049 | val_accuracy: 0.53978 |  0:04:28s\n",
            "epoch 506| loss: 0.9311  | train_accuracy: 0.55453 | val_accuracy: 0.54778 |  0:04:29s\n",
            "epoch 507| loss: 0.93299 | train_accuracy: 0.55462 | val_accuracy: 0.54938 |  0:04:29s\n",
            "epoch 508| loss: 0.93183 | train_accuracy: 0.55458 | val_accuracy: 0.54018 |  0:04:30s\n",
            "epoch 509| loss: 0.92986 | train_accuracy: 0.55493 | val_accuracy: 0.54738 |  0:04:30s\n",
            "epoch 510| loss: 0.92801 | train_accuracy: 0.554   | val_accuracy: 0.54018 |  0:04:31s\n",
            "epoch 511| loss: 0.93041 | train_accuracy: 0.55476 | val_accuracy: 0.54658 |  0:04:31s\n",
            "epoch 512| loss: 0.93021 | train_accuracy: 0.55289 | val_accuracy: 0.54058 |  0:04:32s\n",
            "epoch 513| loss: 0.93051 | train_accuracy: 0.55676 | val_accuracy: 0.54738 |  0:04:32s\n",
            "epoch 514| loss: 0.92612 | train_accuracy: 0.55733 | val_accuracy: 0.53898 |  0:04:33s\n",
            "epoch 515| loss: 0.93108 | train_accuracy: 0.55791 | val_accuracy: 0.54658 |  0:04:33s\n",
            "epoch 516| loss: 0.93049 | train_accuracy: 0.55858 | val_accuracy: 0.55618 |  0:04:34s\n",
            "epoch 517| loss: 0.92839 | train_accuracy: 0.55929 | val_accuracy: 0.55578 |  0:04:34s\n",
            "epoch 518| loss: 0.93259 | train_accuracy: 0.55658 | val_accuracy: 0.54458 |  0:04:35s\n",
            "epoch 519| loss: 0.92873 | train_accuracy: 0.55835 | val_accuracy: 0.54858 |  0:04:35s\n",
            "epoch 520| loss: 0.92751 | train_accuracy: 0.55613 | val_accuracy: 0.55058 |  0:04:36s\n",
            "epoch 521| loss: 0.92502 | train_accuracy: 0.55422 | val_accuracy: 0.54938 |  0:04:36s\n",
            "epoch 522| loss: 0.92395 | train_accuracy: 0.5576  | val_accuracy: 0.55458 |  0:04:37s\n",
            "epoch 523| loss: 0.92537 | train_accuracy: 0.55676 | val_accuracy: 0.54818 |  0:04:37s\n",
            "epoch 524| loss: 0.92469 | train_accuracy: 0.55902 | val_accuracy: 0.55138 |  0:04:38s\n",
            "epoch 525| loss: 0.92473 | train_accuracy: 0.55729 | val_accuracy: 0.55378 |  0:04:38s\n",
            "epoch 526| loss: 0.92043 | train_accuracy: 0.55951 | val_accuracy: 0.55018 |  0:04:39s\n",
            "epoch 527| loss: 0.92376 | train_accuracy: 0.55955 | val_accuracy: 0.54898 |  0:04:39s\n",
            "epoch 528| loss: 0.9185  | train_accuracy: 0.55969 | val_accuracy: 0.54898 |  0:04:40s\n",
            "epoch 529| loss: 0.92073 | train_accuracy: 0.55729 | val_accuracy: 0.55658 |  0:04:40s\n",
            "epoch 530| loss: 0.92021 | train_accuracy: 0.55804 | val_accuracy: 0.55698 |  0:04:41s\n",
            "epoch 531| loss: 0.92324 | train_accuracy: 0.55995 | val_accuracy: 0.55058 |  0:04:41s\n",
            "epoch 532| loss: 0.92136 | train_accuracy: 0.55622 | val_accuracy: 0.54978 |  0:04:42s\n",
            "epoch 533| loss: 0.92291 | train_accuracy: 0.55733 | val_accuracy: 0.55138 |  0:04:43s\n",
            "epoch 534| loss: 0.9221  | train_accuracy: 0.55871 | val_accuracy: 0.55418 |  0:04:44s\n",
            "epoch 535| loss: 0.92085 | train_accuracy: 0.55991 | val_accuracy: 0.55218 |  0:04:45s\n",
            "epoch 536| loss: 0.92368 | train_accuracy: 0.55947 | val_accuracy: 0.55458 |  0:04:46s\n",
            "epoch 537| loss: 0.91989 | train_accuracy: 0.56049 | val_accuracy: 0.54578 |  0:04:47s\n",
            "epoch 538| loss: 0.92476 | train_accuracy: 0.55951 | val_accuracy: 0.55138 |  0:04:48s\n",
            "epoch 539| loss: 0.92231 | train_accuracy: 0.55889 | val_accuracy: 0.55218 |  0:04:49s\n",
            "epoch 540| loss: 0.91891 | train_accuracy: 0.5552  | val_accuracy: 0.53978 |  0:04:49s\n",
            "epoch 541| loss: 0.92852 | train_accuracy: 0.55391 | val_accuracy: 0.55218 |  0:04:50s\n",
            "epoch 542| loss: 0.92857 | train_accuracy: 0.5528  | val_accuracy: 0.54498 |  0:04:50s\n",
            "epoch 543| loss: 0.92733 | train_accuracy: 0.5544  | val_accuracy: 0.55298 |  0:04:51s\n",
            "epoch 544| loss: 0.92631 | train_accuracy: 0.55405 | val_accuracy: 0.55058 |  0:04:51s\n",
            "epoch 545| loss: 0.92617 | train_accuracy: 0.55493 | val_accuracy: 0.55338 |  0:04:52s\n",
            "epoch 546| loss: 0.92566 | train_accuracy: 0.55227 | val_accuracy: 0.55458 |  0:04:52s\n",
            "epoch 547| loss: 0.92329 | train_accuracy: 0.55693 | val_accuracy: 0.55938 |  0:04:53s\n",
            "epoch 548| loss: 0.92228 | train_accuracy: 0.55667 | val_accuracy: 0.55178 |  0:04:53s\n",
            "epoch 549| loss: 0.92765 | train_accuracy: 0.5548  | val_accuracy: 0.56138 |  0:04:54s\n",
            "epoch 550| loss: 0.92558 | train_accuracy: 0.55849 | val_accuracy: 0.55178 |  0:04:54s\n",
            "epoch 551| loss: 0.92069 | train_accuracy: 0.55582 | val_accuracy: 0.54858 |  0:04:55s\n",
            "epoch 552| loss: 0.92448 | train_accuracy: 0.55409 | val_accuracy: 0.55058 |  0:04:55s\n",
            "epoch 553| loss: 0.92287 | train_accuracy: 0.55795 | val_accuracy: 0.55658 |  0:04:56s\n",
            "epoch 554| loss: 0.92205 | train_accuracy: 0.55711 | val_accuracy: 0.55498 |  0:04:56s\n",
            "epoch 555| loss: 0.92104 | train_accuracy: 0.55427 | val_accuracy: 0.54898 |  0:04:57s\n",
            "epoch 556| loss: 0.92066 | train_accuracy: 0.5556  | val_accuracy: 0.55098 |  0:04:57s\n",
            "epoch 557| loss: 0.91816 | train_accuracy: 0.55573 | val_accuracy: 0.53579 |  0:04:58s\n",
            "epoch 558| loss: 0.9197  | train_accuracy: 0.55724 | val_accuracy: 0.54898 |  0:04:58s\n",
            "epoch 559| loss: 0.92219 | train_accuracy: 0.55858 | val_accuracy: 0.55258 |  0:04:59s\n",
            "epoch 560| loss: 0.92029 | train_accuracy: 0.55591 | val_accuracy: 0.55298 |  0:04:59s\n",
            "epoch 561| loss: 0.9227  | train_accuracy: 0.55911 | val_accuracy: 0.55898 |  0:05:00s\n",
            "epoch 562| loss: 0.92371 | train_accuracy: 0.55715 | val_accuracy: 0.56098 |  0:05:00s\n",
            "epoch 563| loss: 0.91864 | train_accuracy: 0.55702 | val_accuracy: 0.55338 |  0:05:01s\n",
            "epoch 564| loss: 0.92039 | train_accuracy: 0.54996 | val_accuracy: 0.54058 |  0:05:01s\n",
            "epoch 565| loss: 0.92013 | train_accuracy: 0.55831 | val_accuracy: 0.54458 |  0:05:02s\n",
            "epoch 566| loss: 0.92067 | train_accuracy: 0.55538 | val_accuracy: 0.55098 |  0:05:02s\n",
            "epoch 567| loss: 0.92165 | train_accuracy: 0.56062 | val_accuracy: 0.55338 |  0:05:03s\n",
            "epoch 568| loss: 0.92579 | train_accuracy: 0.55955 | val_accuracy: 0.53938 |  0:05:03s\n",
            "epoch 569| loss: 0.92058 | train_accuracy: 0.56257 | val_accuracy: 0.55098 |  0:05:04s\n",
            "epoch 570| loss: 0.91846 | train_accuracy: 0.55902 | val_accuracy: 0.54978 |  0:05:04s\n",
            "epoch 571| loss: 0.9173  | train_accuracy: 0.55862 | val_accuracy: 0.55058 |  0:05:05s\n",
            "epoch 572| loss: 0.92024 | train_accuracy: 0.5624  | val_accuracy: 0.55458 |  0:05:05s\n",
            "epoch 573| loss: 0.91871 | train_accuracy: 0.56062 | val_accuracy: 0.55898 |  0:05:06s\n",
            "epoch 574| loss: 0.91714 | train_accuracy: 0.56235 | val_accuracy: 0.54818 |  0:05:06s\n",
            "epoch 575| loss: 0.92019 | train_accuracy: 0.56249 | val_accuracy: 0.55778 |  0:05:07s\n",
            "epoch 576| loss: 0.91546 | train_accuracy: 0.56013 | val_accuracy: 0.55418 |  0:05:07s\n",
            "epoch 577| loss: 0.91459 | train_accuracy: 0.5608  | val_accuracy: 0.55058 |  0:05:08s\n",
            "epoch 578| loss: 0.91735 | train_accuracy: 0.56062 | val_accuracy: 0.55418 |  0:05:08s\n",
            "epoch 579| loss: 0.91866 | train_accuracy: 0.56231 | val_accuracy: 0.55458 |  0:05:09s\n",
            "epoch 580| loss: 0.91591 | train_accuracy: 0.56111 | val_accuracy: 0.55178 |  0:05:09s\n",
            "epoch 581| loss: 0.92139 | train_accuracy: 0.56    | val_accuracy: 0.55098 |  0:05:10s\n",
            "epoch 582| loss: 0.91749 | train_accuracy: 0.55653 | val_accuracy: 0.55218 |  0:05:10s\n",
            "epoch 583| loss: 0.92087 | train_accuracy: 0.55822 | val_accuracy: 0.54538 |  0:05:11s\n",
            "epoch 584| loss: 0.92024 | train_accuracy: 0.5576  | val_accuracy: 0.54898 |  0:05:11s\n",
            "epoch 585| loss: 0.92143 | train_accuracy: 0.55938 | val_accuracy: 0.54498 |  0:05:12s\n",
            "epoch 586| loss: 0.92163 | train_accuracy: 0.56031 | val_accuracy: 0.55298 |  0:05:12s\n",
            "epoch 587| loss: 0.92055 | train_accuracy: 0.55969 | val_accuracy: 0.55338 |  0:05:13s\n",
            "epoch 588| loss: 0.92145 | train_accuracy: 0.56031 | val_accuracy: 0.55178 |  0:05:13s\n",
            "epoch 589| loss: 0.92082 | train_accuracy: 0.56084 | val_accuracy: 0.56377 |  0:05:14s\n",
            "epoch 590| loss: 0.91917 | train_accuracy: 0.55938 | val_accuracy: 0.54938 |  0:05:14s\n",
            "epoch 591| loss: 0.91734 | train_accuracy: 0.55778 | val_accuracy: 0.54858 |  0:05:15s\n",
            "epoch 592| loss: 0.92171 | train_accuracy: 0.55871 | val_accuracy: 0.55418 |  0:05:15s\n",
            "epoch 593| loss: 0.92464 | train_accuracy: 0.55889 | val_accuracy: 0.54898 |  0:05:16s\n",
            "epoch 594| loss: 0.92036 | train_accuracy: 0.55947 | val_accuracy: 0.56098 |  0:05:16s\n",
            "epoch 595| loss: 0.92095 | train_accuracy: 0.56253 | val_accuracy: 0.55738 |  0:05:17s\n",
            "epoch 596| loss: 0.91807 | train_accuracy: 0.56178 | val_accuracy: 0.55698 |  0:05:17s\n",
            "epoch 597| loss: 0.9189  | train_accuracy: 0.55849 | val_accuracy: 0.55578 |  0:05:18s\n",
            "epoch 598| loss: 0.92229 | train_accuracy: 0.56013 | val_accuracy: 0.55378 |  0:05:18s\n",
            "epoch 599| loss: 0.91824 | train_accuracy: 0.56058 | val_accuracy: 0.54818 |  0:05:19s\n",
            "epoch 600| loss: 0.92212 | train_accuracy: 0.55804 | val_accuracy: 0.55098 |  0:05:19s\n",
            "epoch 601| loss: 0.91823 | train_accuracy: 0.55564 | val_accuracy: 0.55978 |  0:05:20s\n",
            "epoch 602| loss: 0.91982 | train_accuracy: 0.5628  | val_accuracy: 0.55418 |  0:05:20s\n",
            "epoch 603| loss: 0.92134 | train_accuracy: 0.55542 | val_accuracy: 0.55458 |  0:05:21s\n",
            "epoch 604| loss: 0.92146 | train_accuracy: 0.5544  | val_accuracy: 0.55218 |  0:05:21s\n",
            "epoch 605| loss: 0.92919 | train_accuracy: 0.55507 | val_accuracy: 0.53659 |  0:05:22s\n",
            "epoch 606| loss: 0.92706 | train_accuracy: 0.5556  | val_accuracy: 0.54658 |  0:05:22s\n",
            "epoch 607| loss: 0.94598 | train_accuracy: 0.54885 | val_accuracy: 0.54738 |  0:05:23s\n",
            "epoch 608| loss: 0.94555 | train_accuracy: 0.53801 | val_accuracy: 0.52579 |  0:05:23s\n",
            "epoch 609| loss: 0.95829 | train_accuracy: 0.53907 | val_accuracy: 0.53219 |  0:05:24s\n",
            "epoch 610| loss: 0.96317 | train_accuracy: 0.52894 | val_accuracy: 0.52259 |  0:05:24s\n",
            "epoch 611| loss: 0.95453 | train_accuracy: 0.52801 | val_accuracy: 0.51699 |  0:05:25s\n",
            "epoch 612| loss: 0.95544 | train_accuracy: 0.53348 | val_accuracy: 0.53179 |  0:05:25s\n",
            "epoch 613| loss: 0.95043 | train_accuracy: 0.53841 | val_accuracy: 0.52819 |  0:05:26s\n",
            "epoch 614| loss: 0.94358 | train_accuracy: 0.54076 | val_accuracy: 0.53099 |  0:05:26s\n",
            "epoch 615| loss: 0.94632 | train_accuracy: 0.54307 | val_accuracy: 0.53499 |  0:05:27s\n",
            "epoch 616| loss: 0.94896 | train_accuracy: 0.54494 | val_accuracy: 0.53459 |  0:05:27s\n",
            "epoch 617| loss: 0.94566 | train_accuracy: 0.54085 | val_accuracy: 0.54018 |  0:05:28s\n",
            "epoch 618| loss: 0.94681 | train_accuracy: 0.53921 | val_accuracy: 0.54378 |  0:05:29s\n",
            "epoch 619| loss: 0.94378 | train_accuracy: 0.5393  | val_accuracy: 0.53339 |  0:05:29s\n",
            "epoch 620| loss: 0.94647 | train_accuracy: 0.54094 | val_accuracy: 0.53579 |  0:05:30s\n",
            "epoch 621| loss: 0.94426 | train_accuracy: 0.54218 | val_accuracy: 0.53739 |  0:05:30s\n",
            "epoch 622| loss: 0.93961 | train_accuracy: 0.54529 | val_accuracy: 0.54138 |  0:05:30s\n",
            "epoch 623| loss: 0.93782 | train_accuracy: 0.54609 | val_accuracy: 0.53818 |  0:05:31s\n",
            "epoch 624| loss: 0.93527 | train_accuracy: 0.54223 | val_accuracy: 0.54018 |  0:05:32s\n",
            "epoch 625| loss: 0.93859 | train_accuracy: 0.54685 | val_accuracy: 0.54178 |  0:05:32s\n",
            "epoch 626| loss: 0.94272 | train_accuracy: 0.54169 | val_accuracy: 0.54858 |  0:05:33s\n",
            "epoch 627| loss: 0.94157 | train_accuracy: 0.5456  | val_accuracy: 0.54218 |  0:05:33s\n",
            "epoch 628| loss: 0.9472  | train_accuracy: 0.54156 | val_accuracy: 0.54058 |  0:05:34s\n",
            "epoch 629| loss: 0.94739 | train_accuracy: 0.54209 | val_accuracy: 0.53339 |  0:05:34s\n",
            "epoch 630| loss: 0.94693 | train_accuracy: 0.54463 | val_accuracy: 0.54338 |  0:05:35s\n",
            "epoch 631| loss: 0.95182 | train_accuracy: 0.54432 | val_accuracy: 0.54498 |  0:05:35s\n",
            "epoch 632| loss: 0.94832 | train_accuracy: 0.54196 | val_accuracy: 0.54418 |  0:05:36s\n",
            "epoch 633| loss: 0.94456 | train_accuracy: 0.54685 | val_accuracy: 0.53978 |  0:05:36s\n",
            "epoch 634| loss: 0.94155 | train_accuracy: 0.54671 | val_accuracy: 0.53978 |  0:05:37s\n",
            "epoch 635| loss: 0.94062 | train_accuracy: 0.54636 | val_accuracy: 0.54018 |  0:05:37s\n",
            "epoch 636| loss: 0.93966 | train_accuracy: 0.54014 | val_accuracy: 0.53778 |  0:05:38s\n",
            "epoch 637| loss: 0.9415  | train_accuracy: 0.54894 | val_accuracy: 0.54018 |  0:05:38s\n",
            "epoch 638| loss: 0.93958 | train_accuracy: 0.54569 | val_accuracy: 0.53818 |  0:05:39s\n",
            "epoch 639| loss: 0.93803 | train_accuracy: 0.54987 | val_accuracy: 0.54338 |  0:05:39s\n",
            "epoch 640| loss: 0.93327 | train_accuracy: 0.55138 | val_accuracy: 0.54378 |  0:05:40s\n",
            "epoch 641| loss: 0.93449 | train_accuracy: 0.5536  | val_accuracy: 0.54338 |  0:05:40s\n",
            "epoch 642| loss: 0.93071 | train_accuracy: 0.55089 | val_accuracy: 0.54578 |  0:05:41s\n",
            "epoch 643| loss: 0.93425 | train_accuracy: 0.55262 | val_accuracy: 0.54458 |  0:05:41s\n",
            "epoch 644| loss: 0.9345  | train_accuracy: 0.54805 | val_accuracy: 0.54338 |  0:05:42s\n",
            "epoch 645| loss: 0.93261 | train_accuracy: 0.55054 | val_accuracy: 0.54378 |  0:05:42s\n",
            "epoch 646| loss: 0.93145 | train_accuracy: 0.55196 | val_accuracy: 0.54658 |  0:05:43s\n",
            "epoch 647| loss: 0.93471 | train_accuracy: 0.55138 | val_accuracy: 0.54818 |  0:05:43s\n",
            "epoch 648| loss: 0.93554 | train_accuracy: 0.54676 | val_accuracy: 0.53898 |  0:05:44s\n",
            "epoch 649| loss: 0.93516 | train_accuracy: 0.55098 | val_accuracy: 0.55098 |  0:05:44s\n",
            "epoch 650| loss: 0.93638 | train_accuracy: 0.55116 | val_accuracy: 0.54378 |  0:05:45s\n",
            "epoch 651| loss: 0.93156 | train_accuracy: 0.55129 | val_accuracy: 0.54218 |  0:05:45s\n",
            "epoch 652| loss: 0.9322  | train_accuracy: 0.55436 | val_accuracy: 0.54098 |  0:05:46s\n",
            "epoch 653| loss: 0.9312  | train_accuracy: 0.5532  | val_accuracy: 0.55058 |  0:05:46s\n",
            "epoch 654| loss: 0.93418 | train_accuracy: 0.55054 | val_accuracy: 0.55378 |  0:05:47s\n",
            "epoch 655| loss: 0.92931 | train_accuracy: 0.55356 | val_accuracy: 0.54338 |  0:05:47s\n",
            "epoch 656| loss: 0.92871 | train_accuracy: 0.55213 | val_accuracy: 0.54938 |  0:05:48s\n",
            "epoch 657| loss: 0.93138 | train_accuracy: 0.55298 | val_accuracy: 0.54738 |  0:05:48s\n",
            "epoch 658| loss: 0.92814 | train_accuracy: 0.54916 | val_accuracy: 0.54658 |  0:05:49s\n",
            "epoch 659| loss: 0.92645 | train_accuracy: 0.55307 | val_accuracy: 0.54338 |  0:05:49s\n",
            "epoch 660| loss: 0.92635 | train_accuracy: 0.55338 | val_accuracy: 0.54578 |  0:05:50s\n",
            "epoch 661| loss: 0.92936 | train_accuracy: 0.55498 | val_accuracy: 0.55058 |  0:05:50s\n",
            "epoch 662| loss: 0.92832 | train_accuracy: 0.5536  | val_accuracy: 0.54658 |  0:05:51s\n",
            "epoch 663| loss: 0.92681 | train_accuracy: 0.55453 | val_accuracy: 0.55138 |  0:05:51s\n",
            "epoch 664| loss: 0.93064 | train_accuracy: 0.554   | val_accuracy: 0.54778 |  0:05:52s\n",
            "epoch 665| loss: 0.92367 | train_accuracy: 0.55245 | val_accuracy: 0.54858 |  0:05:52s\n",
            "epoch 666| loss: 0.93008 | train_accuracy: 0.55209 | val_accuracy: 0.54778 |  0:05:53s\n",
            "epoch 667| loss: 0.92976 | train_accuracy: 0.55271 | val_accuracy: 0.55258 |  0:05:53s\n",
            "epoch 668| loss: 0.92728 | train_accuracy: 0.5572  | val_accuracy: 0.55378 |  0:05:54s\n",
            "epoch 669| loss: 0.92646 | train_accuracy: 0.55667 | val_accuracy: 0.55258 |  0:05:54s\n",
            "epoch 670| loss: 0.92592 | train_accuracy: 0.55427 | val_accuracy: 0.55018 |  0:05:55s\n",
            "epoch 671| loss: 0.92478 | train_accuracy: 0.55493 | val_accuracy: 0.54938 |  0:05:55s\n",
            "epoch 672| loss: 0.92222 | train_accuracy: 0.55409 | val_accuracy: 0.55138 |  0:05:56s\n",
            "epoch 673| loss: 0.92619 | train_accuracy: 0.55405 | val_accuracy: 0.55618 |  0:05:56s\n",
            "epoch 674| loss: 0.92693 | train_accuracy: 0.55222 | val_accuracy: 0.55018 |  0:05:57s\n",
            "epoch 675| loss: 0.92688 | train_accuracy: 0.5556  | val_accuracy: 0.55138 |  0:05:57s\n",
            "epoch 676| loss: 0.92502 | train_accuracy: 0.55373 | val_accuracy: 0.55458 |  0:05:58s\n",
            "epoch 677| loss: 0.92747 | train_accuracy: 0.5528  | val_accuracy: 0.55818 |  0:05:58s\n",
            "epoch 678| loss: 0.92526 | train_accuracy: 0.55125 | val_accuracy: 0.55298 |  0:05:59s\n",
            "epoch 679| loss: 0.92678 | train_accuracy: 0.5584  | val_accuracy: 0.55698 |  0:05:59s\n",
            "epoch 680| loss: 0.92807 | train_accuracy: 0.55858 | val_accuracy: 0.56257 |  0:06:00s\n",
            "epoch 681| loss: 0.92828 | train_accuracy: 0.5584  | val_accuracy: 0.56337 |  0:06:00s\n",
            "epoch 682| loss: 0.92462 | train_accuracy: 0.55693 | val_accuracy: 0.55538 |  0:06:01s\n",
            "epoch 683| loss: 0.92753 | train_accuracy: 0.556   | val_accuracy: 0.55778 |  0:06:01s\n",
            "epoch 684| loss: 0.92443 | train_accuracy: 0.55755 | val_accuracy: 0.56377 |  0:06:02s\n",
            "epoch 685| loss: 0.92483 | train_accuracy: 0.55898 | val_accuracy: 0.56497 |  0:06:02s\n",
            "epoch 686| loss: 0.92418 | train_accuracy: 0.56164 | val_accuracy: 0.56977 |  0:06:03s\n",
            "epoch 687| loss: 0.92525 | train_accuracy: 0.55795 | val_accuracy: 0.56817 |  0:06:03s\n",
            "epoch 688| loss: 0.92604 | train_accuracy: 0.55484 | val_accuracy: 0.55938 |  0:06:04s\n",
            "epoch 689| loss: 0.92635 | train_accuracy: 0.55676 | val_accuracy: 0.56417 |  0:06:04s\n",
            "epoch 690| loss: 0.92402 | train_accuracy: 0.55862 | val_accuracy: 0.55818 |  0:06:05s\n",
            "epoch 691| loss: 0.92166 | train_accuracy: 0.5588  | val_accuracy: 0.56018 |  0:06:05s\n",
            "epoch 692| loss: 0.92156 | train_accuracy: 0.5588  | val_accuracy: 0.55818 |  0:06:06s\n",
            "epoch 693| loss: 0.92456 | train_accuracy: 0.5536  | val_accuracy: 0.56178 |  0:06:06s\n",
            "epoch 694| loss: 0.92359 | train_accuracy: 0.55653 | val_accuracy: 0.56218 |  0:06:07s\n",
            "epoch 695| loss: 0.92343 | train_accuracy: 0.55742 | val_accuracy: 0.56257 |  0:06:07s\n",
            "epoch 696| loss: 0.92611 | train_accuracy: 0.56102 | val_accuracy: 0.56218 |  0:06:08s\n",
            "epoch 697| loss: 0.92582 | train_accuracy: 0.55502 | val_accuracy: 0.55698 |  0:06:08s\n",
            "epoch 698| loss: 0.9333  | train_accuracy: 0.54916 | val_accuracy: 0.54938 |  0:06:09s\n",
            "epoch 699| loss: 0.94318 | train_accuracy: 0.54209 | val_accuracy: 0.53179 |  0:06:09s\n",
            "epoch 700| loss: 0.9367  | train_accuracy: 0.54414 | val_accuracy: 0.53978 |  0:06:10s\n",
            "epoch 701| loss: 0.93734 | train_accuracy: 0.5492  | val_accuracy: 0.55298 |  0:06:10s\n",
            "epoch 702| loss: 0.9383  | train_accuracy: 0.54596 | val_accuracy: 0.54698 |  0:06:11s\n",
            "epoch 703| loss: 0.93728 | train_accuracy: 0.54276 | val_accuracy: 0.54418 |  0:06:11s\n",
            "epoch 704| loss: 0.94255 | train_accuracy: 0.55129 | val_accuracy: 0.54418 |  0:06:12s\n",
            "epoch 705| loss: 0.94104 | train_accuracy: 0.54303 | val_accuracy: 0.54738 |  0:06:12s\n",
            "epoch 706| loss: 0.93823 | train_accuracy: 0.54605 | val_accuracy: 0.54698 |  0:06:13s\n",
            "epoch 707| loss: 0.9394  | train_accuracy: 0.54845 | val_accuracy: 0.54498 |  0:06:13s\n",
            "epoch 708| loss: 0.93472 | train_accuracy: 0.54658 | val_accuracy: 0.54738 |  0:06:14s\n",
            "epoch 709| loss: 0.93994 | train_accuracy: 0.53992 | val_accuracy: 0.53858 |  0:06:14s\n",
            "epoch 710| loss: 0.94155 | train_accuracy: 0.54574 | val_accuracy: 0.54178 |  0:06:15s\n",
            "epoch 711| loss: 0.94304 | train_accuracy: 0.5393  | val_accuracy: 0.53619 |  0:06:15s\n",
            "epoch 712| loss: 0.94707 | train_accuracy: 0.54547 | val_accuracy: 0.53938 |  0:06:16s\n",
            "epoch 713| loss: 0.93854 | train_accuracy: 0.54911 | val_accuracy: 0.53179 |  0:06:16s\n",
            "epoch 714| loss: 0.9403  | train_accuracy: 0.54689 | val_accuracy: 0.53339 |  0:06:17s\n",
            "epoch 715| loss: 0.94176 | train_accuracy: 0.54285 | val_accuracy: 0.52859 |  0:06:17s\n",
            "epoch 716| loss: 0.94122 | train_accuracy: 0.54467 | val_accuracy: 0.53379 |  0:06:18s\n",
            "epoch 717| loss: 0.93954 | train_accuracy: 0.54525 | val_accuracy: 0.53019 |  0:06:18s\n",
            "epoch 718| loss: 0.93739 | train_accuracy: 0.54862 | val_accuracy: 0.53179 |  0:06:19s\n",
            "epoch 719| loss: 0.93992 | train_accuracy: 0.54671 | val_accuracy: 0.53499 |  0:06:19s\n",
            "epoch 720| loss: 0.94126 | train_accuracy: 0.54467 | val_accuracy: 0.54058 |  0:06:20s\n",
            "epoch 721| loss: 0.9377  | train_accuracy: 0.54916 | val_accuracy: 0.54618 |  0:06:20s\n",
            "epoch 722| loss: 0.93667 | train_accuracy: 0.54836 | val_accuracy: 0.53659 |  0:06:21s\n",
            "epoch 723| loss: 0.93362 | train_accuracy: 0.54347 | val_accuracy: 0.53099 |  0:06:21s\n",
            "epoch 724| loss: 0.93679 | train_accuracy: 0.54591 | val_accuracy: 0.53059 |  0:06:22s\n",
            "epoch 725| loss: 0.93777 | train_accuracy: 0.54769 | val_accuracy: 0.53539 |  0:06:22s\n",
            "epoch 726| loss: 0.9349  | train_accuracy: 0.5476  | val_accuracy: 0.54098 |  0:06:23s\n",
            "epoch 727| loss: 0.93349 | train_accuracy: 0.55045 | val_accuracy: 0.54618 |  0:06:23s\n",
            "epoch 728| loss: 0.93624 | train_accuracy: 0.54951 | val_accuracy: 0.54738 |  0:06:24s\n",
            "epoch 729| loss: 0.93796 | train_accuracy: 0.5484  | val_accuracy: 0.53858 |  0:06:24s\n",
            "epoch 730| loss: 0.93736 | train_accuracy: 0.54685 | val_accuracy: 0.53419 |  0:06:25s\n",
            "epoch 731| loss: 0.93517 | train_accuracy: 0.54778 | val_accuracy: 0.53978 |  0:06:25s\n",
            "epoch 732| loss: 0.93212 | train_accuracy: 0.54534 | val_accuracy: 0.54458 |  0:06:26s\n",
            "epoch 733| loss: 0.93637 | train_accuracy: 0.54805 | val_accuracy: 0.54458 |  0:06:26s\n",
            "epoch 734| loss: 0.93094 | train_accuracy: 0.54396 | val_accuracy: 0.53139 |  0:06:27s\n",
            "epoch 735| loss: 0.93849 | train_accuracy: 0.54734 | val_accuracy: 0.52499 |  0:06:27s\n",
            "epoch 736| loss: 0.93694 | train_accuracy: 0.54423 | val_accuracy: 0.53299 |  0:06:28s\n",
            "epoch 737| loss: 0.93706 | train_accuracy: 0.54916 | val_accuracy: 0.53379 |  0:06:28s\n",
            "epoch 738| loss: 0.93654 | train_accuracy: 0.55245 | val_accuracy: 0.53898 |  0:06:29s\n",
            "epoch 739| loss: 0.93401 | train_accuracy: 0.5512  | val_accuracy: 0.53858 |  0:06:29s\n",
            "epoch 740| loss: 0.93613 | train_accuracy: 0.54916 | val_accuracy: 0.53579 |  0:06:30s\n",
            "epoch 741| loss: 0.9365  | train_accuracy: 0.54796 | val_accuracy: 0.53659 |  0:06:30s\n",
            "epoch 742| loss: 0.93897 | train_accuracy: 0.54982 | val_accuracy: 0.53778 |  0:06:31s\n",
            "epoch 743| loss: 0.93764 | train_accuracy: 0.55009 | val_accuracy: 0.53339 |  0:06:31s\n",
            "epoch 744| loss: 0.9347  | train_accuracy: 0.55058 | val_accuracy: 0.53858 |  0:06:32s\n",
            "epoch 745| loss: 0.93265 | train_accuracy: 0.55285 | val_accuracy: 0.54258 |  0:06:32s\n",
            "epoch 746| loss: 0.9315  | train_accuracy: 0.55311 | val_accuracy: 0.53739 |  0:06:33s\n",
            "epoch 747| loss: 0.93402 | train_accuracy: 0.55134 | val_accuracy: 0.53299 |  0:06:34s\n",
            "epoch 748| loss: 0.92996 | train_accuracy: 0.5544  | val_accuracy: 0.53699 |  0:06:34s\n",
            "epoch 749| loss: 0.928   | train_accuracy: 0.55507 | val_accuracy: 0.54338 |  0:06:35s\n",
            "epoch 750| loss: 0.93175 | train_accuracy: 0.55405 | val_accuracy: 0.53898 |  0:06:35s\n",
            "epoch 751| loss: 0.93138 | train_accuracy: 0.55129 | val_accuracy: 0.53818 |  0:06:36s\n",
            "epoch 752| loss: 0.93127 | train_accuracy: 0.55329 | val_accuracy: 0.54258 |  0:06:36s\n",
            "epoch 753| loss: 0.92986 | train_accuracy: 0.54969 | val_accuracy: 0.53898 |  0:06:37s\n",
            "epoch 754| loss: 0.92826 | train_accuracy: 0.54982 | val_accuracy: 0.54098 |  0:06:37s\n",
            "epoch 755| loss: 0.93151 | train_accuracy: 0.5496  | val_accuracy: 0.53898 |  0:06:38s\n",
            "epoch 756| loss: 0.92696 | train_accuracy: 0.55138 | val_accuracy: 0.54378 |  0:06:38s\n",
            "epoch 757| loss: 0.93159 | train_accuracy: 0.55116 | val_accuracy: 0.54458 |  0:06:39s\n",
            "epoch 758| loss: 0.92821 | train_accuracy: 0.55196 | val_accuracy: 0.54498 |  0:06:39s\n",
            "epoch 759| loss: 0.92876 | train_accuracy: 0.54987 | val_accuracy: 0.53938 |  0:06:40s\n",
            "epoch 760| loss: 0.92951 | train_accuracy: 0.55249 | val_accuracy: 0.54098 |  0:06:40s\n",
            "epoch 761| loss: 0.92925 | train_accuracy: 0.55009 | val_accuracy: 0.54618 |  0:06:41s\n",
            "epoch 762| loss: 0.93337 | train_accuracy: 0.55467 | val_accuracy: 0.54018 |  0:06:41s\n",
            "epoch 763| loss: 0.92491 | train_accuracy: 0.55298 | val_accuracy: 0.55218 |  0:06:41s\n",
            "epoch 764| loss: 0.93066 | train_accuracy: 0.55431 | val_accuracy: 0.54018 |  0:06:42s\n",
            "epoch 765| loss: 0.92761 | train_accuracy: 0.55458 | val_accuracy: 0.54018 |  0:06:43s\n",
            "epoch 766| loss: 0.93002 | train_accuracy: 0.55342 | val_accuracy: 0.54938 |  0:06:43s\n",
            "epoch 767| loss: 0.92501 | train_accuracy: 0.55338 | val_accuracy: 0.54658 |  0:06:44s\n",
            "epoch 768| loss: 0.92709 | train_accuracy: 0.554   | val_accuracy: 0.54698 |  0:06:44s\n",
            "epoch 769| loss: 0.92978 | train_accuracy: 0.55267 | val_accuracy: 0.55098 |  0:06:45s\n",
            "epoch 770| loss: 0.92394 | train_accuracy: 0.55422 | val_accuracy: 0.55178 |  0:06:45s\n",
            "epoch 771| loss: 0.92555 | train_accuracy: 0.55453 | val_accuracy: 0.54978 |  0:06:46s\n",
            "epoch 772| loss: 0.93162 | train_accuracy: 0.55453 | val_accuracy: 0.55218 |  0:06:46s\n",
            "epoch 773| loss: 0.92867 | train_accuracy: 0.55245 | val_accuracy: 0.54978 |  0:06:47s\n",
            "epoch 774| loss: 0.92988 | train_accuracy: 0.55591 | val_accuracy: 0.55258 |  0:06:47s\n",
            "epoch 775| loss: 0.92515 | train_accuracy: 0.5548  | val_accuracy: 0.54178 |  0:06:48s\n",
            "epoch 776| loss: 0.9276  | train_accuracy: 0.55627 | val_accuracy: 0.54498 |  0:06:48s\n",
            "epoch 777| loss: 0.92533 | train_accuracy: 0.55671 | val_accuracy: 0.55298 |  0:06:49s\n",
            "epoch 778| loss: 0.92576 | train_accuracy: 0.55684 | val_accuracy: 0.55298 |  0:06:49s\n",
            "epoch 779| loss: 0.92718 | train_accuracy: 0.55524 | val_accuracy: 0.55378 |  0:06:50s\n",
            "epoch 780| loss: 0.92817 | train_accuracy: 0.5536  | val_accuracy: 0.55418 |  0:06:50s\n",
            "epoch 781| loss: 0.92733 | train_accuracy: 0.55591 | val_accuracy: 0.55698 |  0:06:51s\n",
            "epoch 782| loss: 0.92692 | train_accuracy: 0.55715 | val_accuracy: 0.54978 |  0:06:51s\n",
            "epoch 783| loss: 0.92315 | train_accuracy: 0.55693 | val_accuracy: 0.55218 |  0:06:52s\n",
            "epoch 784| loss: 0.92442 | train_accuracy: 0.55964 | val_accuracy: 0.55018 |  0:06:52s\n",
            "epoch 785| loss: 0.92488 | train_accuracy: 0.55755 | val_accuracy: 0.54658 |  0:06:53s\n",
            "epoch 786| loss: 0.92361 | train_accuracy: 0.55898 | val_accuracy: 0.55418 |  0:06:53s\n",
            "epoch 787| loss: 0.92126 | train_accuracy: 0.56289 | val_accuracy: 0.55898 |  0:06:54s\n",
            "epoch 788| loss: 0.92018 | train_accuracy: 0.56329 | val_accuracy: 0.55538 |  0:06:54s\n",
            "epoch 789| loss: 0.91979 | train_accuracy: 0.56151 | val_accuracy: 0.55338 |  0:06:55s\n",
            "epoch 790| loss: 0.92037 | train_accuracy: 0.562   | val_accuracy: 0.55658 |  0:06:55s\n",
            "epoch 791| loss: 0.92077 | train_accuracy: 0.56413 | val_accuracy: 0.55018 |  0:06:56s\n",
            "epoch 792| loss: 0.9234  | train_accuracy: 0.5624  | val_accuracy: 0.56058 |  0:06:56s\n",
            "epoch 793| loss: 0.91751 | train_accuracy: 0.56502 | val_accuracy: 0.54858 |  0:06:57s\n",
            "epoch 794| loss: 0.92173 | train_accuracy: 0.56138 | val_accuracy: 0.55738 |  0:06:57s\n",
            "epoch 795| loss: 0.91927 | train_accuracy: 0.5576  | val_accuracy: 0.53898 |  0:06:58s\n",
            "epoch 796| loss: 0.92066 | train_accuracy: 0.56178 | val_accuracy: 0.54778 |  0:06:58s\n",
            "epoch 797| loss: 0.92309 | train_accuracy: 0.56266 | val_accuracy: 0.53739 |  0:06:59s\n",
            "epoch 798| loss: 0.91758 | train_accuracy: 0.56218 | val_accuracy: 0.54098 |  0:06:59s\n",
            "epoch 799| loss: 0.91939 | train_accuracy: 0.56364 | val_accuracy: 0.54418 |  0:07:00s\n",
            "epoch 800| loss: 0.91741 | train_accuracy: 0.56231 | val_accuracy: 0.54698 |  0:07:00s\n",
            "epoch 801| loss: 0.92123 | train_accuracy: 0.56053 | val_accuracy: 0.55698 |  0:07:01s\n",
            "epoch 802| loss: 0.91849 | train_accuracy: 0.564   | val_accuracy: 0.54898 |  0:07:01s\n",
            "epoch 803| loss: 0.91416 | train_accuracy: 0.56457 | val_accuracy: 0.56257 |  0:07:02s\n",
            "epoch 804| loss: 0.91755 | train_accuracy: 0.56613 | val_accuracy: 0.55378 |  0:07:02s\n",
            "epoch 805| loss: 0.91774 | train_accuracy: 0.56648 | val_accuracy: 0.55458 |  0:07:03s\n",
            "epoch 806| loss: 0.91515 | train_accuracy: 0.56813 | val_accuracy: 0.55778 |  0:07:03s\n",
            "epoch 807| loss: 0.90963 | train_accuracy: 0.56973 | val_accuracy: 0.55618 |  0:07:04s\n",
            "epoch 808| loss: 0.9123  | train_accuracy: 0.56506 | val_accuracy: 0.54698 |  0:07:04s\n",
            "epoch 809| loss: 0.91348 | train_accuracy: 0.56733 | val_accuracy: 0.55538 |  0:07:05s\n",
            "epoch 810| loss: 0.91411 | train_accuracy: 0.56653 | val_accuracy: 0.55698 |  0:07:05s\n",
            "epoch 811| loss: 0.91211 | train_accuracy: 0.56577 | val_accuracy: 0.55538 |  0:07:06s\n",
            "epoch 812| loss: 0.91593 | train_accuracy: 0.56555 | val_accuracy: 0.55738 |  0:07:06s\n",
            "epoch 813| loss: 0.91252 | train_accuracy: 0.56537 | val_accuracy: 0.55218 |  0:07:07s\n",
            "epoch 814| loss: 0.91326 | train_accuracy: 0.56999 | val_accuracy: 0.55818 |  0:07:07s\n",
            "epoch 815| loss: 0.91067 | train_accuracy: 0.56888 | val_accuracy: 0.55178 |  0:07:08s\n",
            "epoch 816| loss: 0.91461 | train_accuracy: 0.56826 | val_accuracy: 0.55658 |  0:07:08s\n",
            "epoch 817| loss: 0.91108 | train_accuracy: 0.56737 | val_accuracy: 0.55258 |  0:07:09s\n",
            "epoch 818| loss: 0.91518 | train_accuracy: 0.56782 | val_accuracy: 0.55018 |  0:07:09s\n",
            "epoch 819| loss: 0.91579 | train_accuracy: 0.57088 | val_accuracy: 0.55338 |  0:07:10s\n",
            "epoch 820| loss: 0.91225 | train_accuracy: 0.57244 | val_accuracy: 0.56297 |  0:07:10s\n",
            "epoch 821| loss: 0.91126 | train_accuracy: 0.56937 | val_accuracy: 0.54978 |  0:07:11s\n",
            "epoch 822| loss: 0.913   | train_accuracy: 0.56871 | val_accuracy: 0.55858 |  0:07:11s\n",
            "epoch 823| loss: 0.9104  | train_accuracy: 0.56844 | val_accuracy: 0.56018 |  0:07:12s\n",
            "epoch 824| loss: 0.91113 | train_accuracy: 0.56777 | val_accuracy: 0.55858 |  0:07:12s\n",
            "epoch 825| loss: 0.91139 | train_accuracy: 0.5652  | val_accuracy: 0.55378 |  0:07:13s\n",
            "epoch 826| loss: 0.91203 | train_accuracy: 0.56782 | val_accuracy: 0.55058 |  0:07:14s\n",
            "epoch 827| loss: 0.90913 | train_accuracy: 0.56826 | val_accuracy: 0.55098 |  0:07:14s\n",
            "epoch 828| loss: 0.91222 | train_accuracy: 0.56839 | val_accuracy: 0.55098 |  0:07:15s\n",
            "epoch 829| loss: 0.91362 | train_accuracy: 0.56644 | val_accuracy: 0.55418 |  0:07:16s\n",
            "epoch 830| loss: 0.91377 | train_accuracy: 0.56706 | val_accuracy: 0.55618 |  0:07:16s\n",
            "epoch 831| loss: 0.91094 | train_accuracy: 0.56218 | val_accuracy: 0.55298 |  0:07:17s\n",
            "epoch 832| loss: 0.91628 | train_accuracy: 0.56253 | val_accuracy: 0.55618 |  0:07:17s\n",
            "epoch 833| loss: 0.91589 | train_accuracy: 0.56711 | val_accuracy: 0.55418 |  0:07:18s\n",
            "epoch 834| loss: 0.91292 | train_accuracy: 0.56711 | val_accuracy: 0.55058 |  0:07:18s\n",
            "epoch 835| loss: 0.9105  | train_accuracy: 0.56773 | val_accuracy: 0.55778 |  0:07:18s\n",
            "epoch 836| loss: 0.91394 | train_accuracy: 0.56604 | val_accuracy: 0.55658 |  0:07:19s\n",
            "epoch 837| loss: 0.91001 | train_accuracy: 0.56693 | val_accuracy: 0.55898 |  0:07:20s\n",
            "epoch 838| loss: 0.91102 | train_accuracy: 0.56817 | val_accuracy: 0.55898 |  0:07:20s\n",
            "epoch 839| loss: 0.9121  | train_accuracy: 0.56857 | val_accuracy: 0.55858 |  0:07:21s\n",
            "epoch 840| loss: 0.90996 | train_accuracy: 0.56449 | val_accuracy: 0.55498 |  0:07:21s\n",
            "epoch 841| loss: 0.90939 | train_accuracy: 0.56622 | val_accuracy: 0.56337 |  0:07:22s\n",
            "epoch 842| loss: 0.91075 | train_accuracy: 0.56586 | val_accuracy: 0.56178 |  0:07:22s\n",
            "epoch 843| loss: 0.90972 | train_accuracy: 0.56733 | val_accuracy: 0.55618 |  0:07:23s\n",
            "epoch 844| loss: 0.90901 | train_accuracy: 0.56693 | val_accuracy: 0.56138 |  0:07:23s\n",
            "epoch 845| loss: 0.9083  | train_accuracy: 0.56684 | val_accuracy: 0.55818 |  0:07:23s\n",
            "epoch 846| loss: 0.91153 | train_accuracy: 0.56835 | val_accuracy: 0.56018 |  0:07:24s\n",
            "epoch 847| loss: 0.91101 | train_accuracy: 0.56937 | val_accuracy: 0.55218 |  0:07:24s\n",
            "epoch 848| loss: 0.91525 | train_accuracy: 0.56919 | val_accuracy: 0.56178 |  0:07:25s\n",
            "epoch 849| loss: 0.90857 | train_accuracy: 0.56746 | val_accuracy: 0.56138 |  0:07:26s\n",
            "epoch 850| loss: 0.90585 | train_accuracy: 0.56764 | val_accuracy: 0.56218 |  0:07:26s\n",
            "epoch 851| loss: 0.90569 | train_accuracy: 0.56751 | val_accuracy: 0.55418 |  0:07:27s\n",
            "epoch 852| loss: 0.90845 | train_accuracy: 0.56764 | val_accuracy: 0.56178 |  0:07:27s\n",
            "epoch 853| loss: 0.90917 | train_accuracy: 0.56768 | val_accuracy: 0.55738 |  0:07:27s\n",
            "epoch 854| loss: 0.90886 | train_accuracy: 0.56755 | val_accuracy: 0.56537 |  0:07:28s\n",
            "epoch 855| loss: 0.90692 | train_accuracy: 0.56813 | val_accuracy: 0.55778 |  0:07:29s\n",
            "epoch 856| loss: 0.90845 | train_accuracy: 0.56684 | val_accuracy: 0.56297 |  0:07:29s\n",
            "epoch 857| loss: 0.90911 | train_accuracy: 0.56973 | val_accuracy: 0.55618 |  0:07:30s\n",
            "epoch 858| loss: 0.90795 | train_accuracy: 0.56804 | val_accuracy: 0.56218 |  0:07:30s\n",
            "epoch 859| loss: 0.90619 | train_accuracy: 0.56866 | val_accuracy: 0.56138 |  0:07:31s\n",
            "epoch 860| loss: 0.90575 | train_accuracy: 0.56808 | val_accuracy: 0.56098 |  0:07:31s\n",
            "epoch 861| loss: 0.90502 | train_accuracy: 0.56733 | val_accuracy: 0.56138 |  0:07:32s\n",
            "epoch 862| loss: 0.90623 | train_accuracy: 0.56622 | val_accuracy: 0.56058 |  0:07:32s\n",
            "epoch 863| loss: 0.90766 | train_accuracy: 0.56813 | val_accuracy: 0.56138 |  0:07:33s\n",
            "epoch 864| loss: 0.9081  | train_accuracy: 0.56915 | val_accuracy: 0.56657 |  0:07:33s\n",
            "epoch 865| loss: 0.90941 | train_accuracy: 0.57133 | val_accuracy: 0.57137 |  0:07:34s\n",
            "epoch 866| loss: 0.90618 | train_accuracy: 0.57168 | val_accuracy: 0.56457 |  0:07:34s\n",
            "epoch 867| loss: 0.90696 | train_accuracy: 0.56973 | val_accuracy: 0.56937 |  0:07:35s\n",
            "epoch 868| loss: 0.90648 | train_accuracy: 0.57071 | val_accuracy: 0.55978 |  0:07:35s\n",
            "epoch 869| loss: 0.90962 | train_accuracy: 0.56924 | val_accuracy: 0.56697 |  0:07:36s\n",
            "epoch 870| loss: 0.90771 | train_accuracy: 0.56742 | val_accuracy: 0.55858 |  0:07:36s\n",
            "epoch 871| loss: 0.90895 | train_accuracy: 0.56817 | val_accuracy: 0.55658 |  0:07:37s\n",
            "epoch 872| loss: 0.90469 | train_accuracy: 0.56955 | val_accuracy: 0.55498 |  0:07:37s\n",
            "epoch 873| loss: 0.91131 | train_accuracy: 0.56862 | val_accuracy: 0.56018 |  0:07:38s\n",
            "epoch 874| loss: 0.90963 | train_accuracy: 0.56897 | val_accuracy: 0.55898 |  0:07:38s\n",
            "epoch 875| loss: 0.90892 | train_accuracy: 0.57057 | val_accuracy: 0.56777 |  0:07:39s\n",
            "epoch 876| loss: 0.90811 | train_accuracy: 0.56853 | val_accuracy: 0.56058 |  0:07:39s\n",
            "epoch 877| loss: 0.90522 | train_accuracy: 0.56959 | val_accuracy: 0.56098 |  0:07:40s\n",
            "epoch 878| loss: 0.90483 | train_accuracy: 0.5676  | val_accuracy: 0.55898 |  0:07:40s\n",
            "epoch 879| loss: 0.90543 | train_accuracy: 0.56631 | val_accuracy: 0.55338 |  0:07:41s\n",
            "epoch 880| loss: 0.90853 | train_accuracy: 0.56608 | val_accuracy: 0.55298 |  0:07:41s\n",
            "epoch 881| loss: 0.90788 | train_accuracy: 0.56742 | val_accuracy: 0.55938 |  0:07:42s\n",
            "epoch 882| loss: 0.90968 | train_accuracy: 0.56528 | val_accuracy: 0.55218 |  0:07:42s\n",
            "epoch 883| loss: 0.91121 | train_accuracy: 0.56422 | val_accuracy: 0.54978 |  0:07:43s\n",
            "epoch 884| loss: 0.91447 | train_accuracy: 0.56457 | val_accuracy: 0.54018 |  0:07:43s\n",
            "epoch 885| loss: 0.90806 | train_accuracy: 0.56675 | val_accuracy: 0.54898 |  0:07:44s\n",
            "epoch 886| loss: 0.91541 | train_accuracy: 0.562   | val_accuracy: 0.54778 |  0:07:44s\n",
            "epoch 887| loss: 0.91814 | train_accuracy: 0.5652  | val_accuracy: 0.55058 |  0:07:45s\n",
            "epoch 888| loss: 0.91486 | train_accuracy: 0.5636  | val_accuracy: 0.55138 |  0:07:45s\n",
            "epoch 889| loss: 0.91447 | train_accuracy: 0.56502 | val_accuracy: 0.56218 |  0:07:46s\n",
            "epoch 890| loss: 0.91712 | train_accuracy: 0.56537 | val_accuracy: 0.55498 |  0:07:46s\n",
            "epoch 891| loss: 0.91175 | train_accuracy: 0.56688 | val_accuracy: 0.55858 |  0:07:47s\n",
            "epoch 892| loss: 0.91377 | train_accuracy: 0.56573 | val_accuracy: 0.55538 |  0:07:47s\n",
            "epoch 893| loss: 0.91199 | train_accuracy: 0.56391 | val_accuracy: 0.55418 |  0:07:48s\n",
            "epoch 894| loss: 0.91    | train_accuracy: 0.56271 | val_accuracy: 0.55378 |  0:07:48s\n",
            "epoch 895| loss: 0.90874 | train_accuracy: 0.56684 | val_accuracy: 0.55738 |  0:07:49s\n",
            "epoch 896| loss: 0.90814 | train_accuracy: 0.56626 | val_accuracy: 0.55618 |  0:07:49s\n",
            "epoch 897| loss: 0.90549 | train_accuracy: 0.56977 | val_accuracy: 0.55698 |  0:07:50s\n",
            "epoch 898| loss: 0.908   | train_accuracy: 0.56577 | val_accuracy: 0.54658 |  0:07:50s\n",
            "epoch 899| loss: 0.9097  | train_accuracy: 0.56169 | val_accuracy: 0.55458 |  0:07:51s\n",
            "epoch 900| loss: 0.90842 | train_accuracy: 0.56377 | val_accuracy: 0.55178 |  0:07:51s\n",
            "epoch 901| loss: 0.91081 | train_accuracy: 0.56475 | val_accuracy: 0.55418 |  0:07:52s\n",
            "epoch 902| loss: 0.91017 | train_accuracy: 0.56422 | val_accuracy: 0.56337 |  0:07:52s\n",
            "epoch 903| loss: 0.90466 | train_accuracy: 0.56777 | val_accuracy: 0.56218 |  0:07:53s\n",
            "epoch 904| loss: 0.91324 | train_accuracy: 0.56417 | val_accuracy: 0.55458 |  0:07:53s\n",
            "epoch 905| loss: 0.90973 | train_accuracy: 0.5668  | val_accuracy: 0.55338 |  0:07:54s\n",
            "epoch 906| loss: 0.91367 | train_accuracy: 0.56688 | val_accuracy: 0.55138 |  0:07:54s\n",
            "epoch 907| loss: 0.9098  | train_accuracy: 0.56675 | val_accuracy: 0.55618 |  0:07:55s\n",
            "epoch 908| loss: 0.90677 | train_accuracy: 0.56804 | val_accuracy: 0.54978 |  0:07:55s\n",
            "epoch 909| loss: 0.90828 | train_accuracy: 0.56817 | val_accuracy: 0.55778 |  0:07:56s\n",
            "epoch 910| loss: 0.91024 | train_accuracy: 0.57066 | val_accuracy: 0.54418 |  0:07:56s\n",
            "epoch 911| loss: 0.90804 | train_accuracy: 0.56888 | val_accuracy: 0.56218 |  0:07:57s\n",
            "epoch 912| loss: 0.90714 | train_accuracy: 0.57031 | val_accuracy: 0.56377 |  0:07:57s\n",
            "epoch 913| loss: 0.90989 | train_accuracy: 0.56866 | val_accuracy: 0.56218 |  0:07:58s\n",
            "epoch 914| loss: 0.90613 | train_accuracy: 0.57026 | val_accuracy: 0.56337 |  0:07:58s\n",
            "epoch 915| loss: 0.90619 | train_accuracy: 0.57057 | val_accuracy: 0.56537 |  0:07:59s\n",
            "epoch 916| loss: 0.90785 | train_accuracy: 0.56871 | val_accuracy: 0.56018 |  0:07:59s\n",
            "epoch 917| loss: 0.90511 | train_accuracy: 0.568   | val_accuracy: 0.56297 |  0:08:00s\n",
            "epoch 918| loss: 0.90541 | train_accuracy: 0.57048 | val_accuracy: 0.55458 |  0:08:00s\n",
            "epoch 919| loss: 0.90363 | train_accuracy: 0.56417 | val_accuracy: 0.55258 |  0:08:01s\n",
            "epoch 920| loss: 0.90945 | train_accuracy: 0.57222 | val_accuracy: 0.55578 |  0:08:01s\n",
            "epoch 921| loss: 0.90759 | train_accuracy: 0.5715  | val_accuracy: 0.56178 |  0:08:02s\n",
            "epoch 922| loss: 0.90416 | train_accuracy: 0.56924 | val_accuracy: 0.55658 |  0:08:02s\n",
            "epoch 923| loss: 0.90362 | train_accuracy: 0.57173 | val_accuracy: 0.56178 |  0:08:03s\n",
            "epoch 924| loss: 0.90639 | train_accuracy: 0.57195 | val_accuracy: 0.55858 |  0:08:03s\n",
            "epoch 925| loss: 0.90616 | train_accuracy: 0.57297 | val_accuracy: 0.56018 |  0:08:04s\n",
            "epoch 926| loss: 0.90412 | train_accuracy: 0.57297 | val_accuracy: 0.56218 |  0:08:04s\n",
            "epoch 927| loss: 0.90715 | train_accuracy: 0.57222 | val_accuracy: 0.55818 |  0:08:05s\n",
            "epoch 928| loss: 0.91021 | train_accuracy: 0.56982 | val_accuracy: 0.56138 |  0:08:05s\n",
            "epoch 929| loss: 0.90578 | train_accuracy: 0.56986 | val_accuracy: 0.56218 |  0:08:06s\n",
            "epoch 930| loss: 0.90385 | train_accuracy: 0.56906 | val_accuracy: 0.56497 |  0:08:06s\n",
            "epoch 931| loss: 0.9073  | train_accuracy: 0.568   | val_accuracy: 0.56138 |  0:08:07s\n",
            "epoch 932| loss: 0.90734 | train_accuracy: 0.57062 | val_accuracy: 0.56018 |  0:08:07s\n",
            "epoch 933| loss: 0.90844 | train_accuracy: 0.55978 | val_accuracy: 0.55498 |  0:08:08s\n",
            "epoch 934| loss: 0.90403 | train_accuracy: 0.56928 | val_accuracy: 0.55818 |  0:08:08s\n",
            "epoch 935| loss: 0.90539 | train_accuracy: 0.57022 | val_accuracy: 0.56218 |  0:08:09s\n",
            "epoch 936| loss: 0.90784 | train_accuracy: 0.57022 | val_accuracy: 0.55498 |  0:08:10s\n",
            "epoch 937| loss: 0.90437 | train_accuracy: 0.57119 | val_accuracy: 0.56138 |  0:08:10s\n",
            "epoch 938| loss: 0.90394 | train_accuracy: 0.56995 | val_accuracy: 0.55698 |  0:08:11s\n",
            "epoch 939| loss: 0.90495 | train_accuracy: 0.56804 | val_accuracy: 0.55338 |  0:08:11s\n",
            "epoch 940| loss: 0.90227 | train_accuracy: 0.57115 | val_accuracy: 0.55378 |  0:08:12s\n",
            "epoch 941| loss: 0.90781 | train_accuracy: 0.57204 | val_accuracy: 0.55458 |  0:08:12s\n",
            "epoch 942| loss: 0.9033  | train_accuracy: 0.57057 | val_accuracy: 0.55498 |  0:08:13s\n",
            "epoch 943| loss: 0.90914 | train_accuracy: 0.57182 | val_accuracy: 0.55898 |  0:08:13s\n",
            "epoch 944| loss: 0.90503 | train_accuracy: 0.57164 | val_accuracy: 0.55978 |  0:08:14s\n",
            "epoch 945| loss: 0.9095  | train_accuracy: 0.56635 | val_accuracy: 0.55858 |  0:08:14s\n",
            "epoch 946| loss: 0.90839 | train_accuracy: 0.568   | val_accuracy: 0.56257 |  0:08:15s\n",
            "epoch 947| loss: 0.91251 | train_accuracy: 0.56577 | val_accuracy: 0.55058 |  0:08:15s\n",
            "epoch 948| loss: 0.90564 | train_accuracy: 0.56844 | val_accuracy: 0.55698 |  0:08:16s\n",
            "epoch 949| loss: 0.91007 | train_accuracy: 0.5676  | val_accuracy: 0.55738 |  0:08:16s\n",
            "epoch 950| loss: 0.90438 | train_accuracy: 0.56848 | val_accuracy: 0.55298 |  0:08:17s\n",
            "epoch 951| loss: 0.91057 | train_accuracy: 0.56377 | val_accuracy: 0.54618 |  0:08:17s\n",
            "epoch 952| loss: 0.91741 | train_accuracy: 0.55902 | val_accuracy: 0.55658 |  0:08:18s\n",
            "epoch 953| loss: 0.91828 | train_accuracy: 0.55627 | val_accuracy: 0.55538 |  0:08:18s\n",
            "epoch 954| loss: 0.91988 | train_accuracy: 0.55875 | val_accuracy: 0.55498 |  0:08:19s\n",
            "epoch 955| loss: 0.92128 | train_accuracy: 0.55289 | val_accuracy: 0.54498 |  0:08:19s\n",
            "epoch 956| loss: 0.91863 | train_accuracy: 0.55729 | val_accuracy: 0.55378 |  0:08:20s\n",
            "epoch 957| loss: 0.92262 | train_accuracy: 0.55662 | val_accuracy: 0.54618 |  0:08:20s\n",
            "epoch 958| loss: 0.92075 | train_accuracy: 0.54974 | val_accuracy: 0.54178 |  0:08:21s\n",
            "epoch 959| loss: 0.92047 | train_accuracy: 0.55542 | val_accuracy: 0.56218 |  0:08:21s\n",
            "epoch 960| loss: 0.91925 | train_accuracy: 0.5536  | val_accuracy: 0.55458 |  0:08:22s\n",
            "epoch 961| loss: 0.92011 | train_accuracy: 0.55884 | val_accuracy: 0.55778 |  0:08:22s\n",
            "epoch 962| loss: 0.91757 | train_accuracy: 0.55587 | val_accuracy: 0.55578 |  0:08:23s\n",
            "epoch 963| loss: 0.91522 | train_accuracy: 0.56218 | val_accuracy: 0.55938 |  0:08:23s\n",
            "epoch 964| loss: 0.9153  | train_accuracy: 0.5592  | val_accuracy: 0.55498 |  0:08:24s\n",
            "epoch 965| loss: 0.91584 | train_accuracy: 0.5588  | val_accuracy: 0.55898 |  0:08:24s\n",
            "epoch 966| loss: 0.9132  | train_accuracy: 0.56026 | val_accuracy: 0.55738 |  0:08:25s\n",
            "epoch 967| loss: 0.91429 | train_accuracy: 0.56138 | val_accuracy: 0.55698 |  0:08:25s\n",
            "epoch 968| loss: 0.91255 | train_accuracy: 0.56102 | val_accuracy: 0.55138 |  0:08:26s\n",
            "epoch 969| loss: 0.91173 | train_accuracy: 0.56218 | val_accuracy: 0.55818 |  0:08:26s\n",
            "epoch 970| loss: 0.90795 | train_accuracy: 0.56369 | val_accuracy: 0.56058 |  0:08:27s\n",
            "epoch 971| loss: 0.91133 | train_accuracy: 0.5628  | val_accuracy: 0.55578 |  0:08:27s\n",
            "epoch 972| loss: 0.9112  | train_accuracy: 0.55955 | val_accuracy: 0.55658 |  0:08:28s\n",
            "epoch 973| loss: 0.9133  | train_accuracy: 0.55951 | val_accuracy: 0.55538 |  0:08:28s\n",
            "epoch 974| loss: 0.90816 | train_accuracy: 0.56146 | val_accuracy: 0.56098 |  0:08:29s\n",
            "epoch 975| loss: 0.90894 | train_accuracy: 0.56102 | val_accuracy: 0.54738 |  0:08:29s\n",
            "epoch 976| loss: 0.91664 | train_accuracy: 0.56324 | val_accuracy: 0.55978 |  0:08:30s\n",
            "epoch 977| loss: 0.91219 | train_accuracy: 0.56528 | val_accuracy: 0.55578 |  0:08:30s\n",
            "epoch 978| loss: 0.91409 | train_accuracy: 0.56631 | val_accuracy: 0.56058 |  0:08:31s\n",
            "epoch 979| loss: 0.91202 | train_accuracy: 0.56551 | val_accuracy: 0.56337 |  0:08:31s\n",
            "epoch 980| loss: 0.91273 | train_accuracy: 0.56075 | val_accuracy: 0.54818 |  0:08:32s\n",
            "epoch 981| loss: 0.91167 | train_accuracy: 0.56297 | val_accuracy: 0.55418 |  0:08:32s\n",
            "epoch 982| loss: 0.9145  | train_accuracy: 0.56013 | val_accuracy: 0.55258 |  0:08:33s\n",
            "epoch 983| loss: 0.91566 | train_accuracy: 0.558   | val_accuracy: 0.55538 |  0:08:33s\n",
            "epoch 984| loss: 0.91519 | train_accuracy: 0.56462 | val_accuracy: 0.55978 |  0:08:34s\n",
            "epoch 985| loss: 0.91613 | train_accuracy: 0.56306 | val_accuracy: 0.55458 |  0:08:34s\n",
            "epoch 986| loss: 0.91405 | train_accuracy: 0.56111 | val_accuracy: 0.55298 |  0:08:35s\n",
            "epoch 987| loss: 0.91752 | train_accuracy: 0.56306 | val_accuracy: 0.56297 |  0:08:35s\n",
            "epoch 988| loss: 0.91343 | train_accuracy: 0.56422 | val_accuracy: 0.56577 |  0:08:36s\n",
            "epoch 989| loss: 0.91387 | train_accuracy: 0.56311 | val_accuracy: 0.55738 |  0:08:36s\n",
            "epoch 990| loss: 0.91329 | train_accuracy: 0.566   | val_accuracy: 0.55978 |  0:08:37s\n",
            "epoch 991| loss: 0.9109  | train_accuracy: 0.56426 | val_accuracy: 0.55698 |  0:08:37s\n",
            "epoch 992| loss: 0.91607 | train_accuracy: 0.56417 | val_accuracy: 0.55698 |  0:08:38s\n",
            "epoch 993| loss: 0.91712 | train_accuracy: 0.56422 | val_accuracy: 0.55458 |  0:08:38s\n",
            "epoch 994| loss: 0.91179 | train_accuracy: 0.56413 | val_accuracy: 0.55978 |  0:08:39s\n",
            "epoch 995| loss: 0.91247 | train_accuracy: 0.56591 | val_accuracy: 0.56098 |  0:08:40s\n",
            "epoch 996| loss: 0.9105  | train_accuracy: 0.56493 | val_accuracy: 0.55898 |  0:08:40s\n",
            "epoch 997| loss: 0.90882 | train_accuracy: 0.5664  | val_accuracy: 0.56138 |  0:08:40s\n",
            "epoch 998| loss: 0.90916 | train_accuracy: 0.56497 | val_accuracy: 0.56337 |  0:08:41s\n",
            "epoch 999| loss: 0.91358 | train_accuracy: 0.56737 | val_accuracy: 0.56138 |  0:08:41s\n",
            "epoch 1000| loss: 0.90533 | train_accuracy: 0.56622 | val_accuracy: 0.56178 |  0:08:42s\n",
            "epoch 1001| loss: 0.90841 | train_accuracy: 0.56951 | val_accuracy: 0.56018 |  0:08:42s\n",
            "epoch 1002| loss: 0.90922 | train_accuracy: 0.56822 | val_accuracy: 0.56257 |  0:08:43s\n",
            "epoch 1003| loss: 0.91011 | train_accuracy: 0.56502 | val_accuracy: 0.55858 |  0:08:43s\n",
            "epoch 1004| loss: 0.91233 | train_accuracy: 0.56684 | val_accuracy: 0.55658 |  0:08:44s\n",
            "epoch 1005| loss: 0.91148 | train_accuracy: 0.56444 | val_accuracy: 0.56098 |  0:08:44s\n",
            "epoch 1006| loss: 0.91314 | train_accuracy: 0.5644  | val_accuracy: 0.55858 |  0:08:45s\n",
            "epoch 1007| loss: 0.9148  | train_accuracy: 0.56449 | val_accuracy: 0.55418 |  0:08:45s\n",
            "epoch 1008| loss: 0.90892 | train_accuracy: 0.56404 | val_accuracy: 0.55418 |  0:08:46s\n",
            "epoch 1009| loss: 0.91005 | train_accuracy: 0.56608 | val_accuracy: 0.55818 |  0:08:46s\n",
            "epoch 1010| loss: 0.91124 | train_accuracy: 0.56502 | val_accuracy: 0.55898 |  0:08:47s\n",
            "epoch 1011| loss: 0.90794 | train_accuracy: 0.56306 | val_accuracy: 0.55298 |  0:08:47s\n",
            "epoch 1012| loss: 0.91014 | train_accuracy: 0.56577 | val_accuracy: 0.55738 |  0:08:48s\n",
            "epoch 1013| loss: 0.91046 | train_accuracy: 0.56817 | val_accuracy: 0.55618 |  0:08:49s\n",
            "epoch 1014| loss: 0.90637 | train_accuracy: 0.56791 | val_accuracy: 0.55618 |  0:08:49s\n",
            "epoch 1015| loss: 0.91347 | train_accuracy: 0.56755 | val_accuracy: 0.56218 |  0:08:49s\n",
            "epoch 1016| loss: 0.91278 | train_accuracy: 0.56591 | val_accuracy: 0.55938 |  0:08:50s\n",
            "epoch 1017| loss: 0.91018 | train_accuracy: 0.56844 | val_accuracy: 0.56178 |  0:08:50s\n",
            "epoch 1018| loss: 0.9114  | train_accuracy: 0.56773 | val_accuracy: 0.55978 |  0:08:51s\n",
            "epoch 1019| loss: 0.91209 | train_accuracy: 0.56751 | val_accuracy: 0.56457 |  0:08:51s\n",
            "epoch 1020| loss: 0.91202 | train_accuracy: 0.56564 | val_accuracy: 0.56178 |  0:08:52s\n",
            "epoch 1021| loss: 0.91088 | train_accuracy: 0.5636  | val_accuracy: 0.56257 |  0:08:52s\n",
            "epoch 1022| loss: 0.91337 | train_accuracy: 0.56631 | val_accuracy: 0.56297 |  0:08:53s\n",
            "epoch 1023| loss: 0.91403 | train_accuracy: 0.56875 | val_accuracy: 0.55938 |  0:08:53s\n",
            "epoch 1024| loss: 0.90872 | train_accuracy: 0.56657 | val_accuracy: 0.56018 |  0:08:54s\n",
            "epoch 1025| loss: 0.90984 | train_accuracy: 0.56795 | val_accuracy: 0.55658 |  0:08:54s\n",
            "epoch 1026| loss: 0.91197 | train_accuracy: 0.56942 | val_accuracy: 0.55858 |  0:08:55s\n",
            "epoch 1027| loss: 0.91189 | train_accuracy: 0.56697 | val_accuracy: 0.55018 |  0:08:55s\n",
            "epoch 1028| loss: 0.9123  | train_accuracy: 0.56933 | val_accuracy: 0.56098 |  0:08:56s\n",
            "epoch 1029| loss: 0.9087  | train_accuracy: 0.56804 | val_accuracy: 0.56098 |  0:08:56s\n",
            "epoch 1030| loss: 0.90997 | train_accuracy: 0.56844 | val_accuracy: 0.56098 |  0:08:57s\n",
            "epoch 1031| loss: 0.90744 | train_accuracy: 0.56884 | val_accuracy: 0.55938 |  0:08:57s\n",
            "epoch 1032| loss: 0.90828 | train_accuracy: 0.56968 | val_accuracy: 0.55778 |  0:08:58s\n",
            "epoch 1033| loss: 0.90533 | train_accuracy: 0.56973 | val_accuracy: 0.55978 |  0:08:58s\n",
            "epoch 1034| loss: 0.90692 | train_accuracy: 0.56986 | val_accuracy: 0.55978 |  0:08:59s\n",
            "epoch 1035| loss: 0.90737 | train_accuracy: 0.57022 | val_accuracy: 0.56098 |  0:08:59s\n",
            "epoch 1036| loss: 0.90896 | train_accuracy: 0.56902 | val_accuracy: 0.56377 |  0:09:00s\n",
            "epoch 1037| loss: 0.90896 | train_accuracy: 0.56902 | val_accuracy: 0.55778 |  0:09:00s\n",
            "epoch 1038| loss: 0.90933 | train_accuracy: 0.56982 | val_accuracy: 0.55938 |  0:09:01s\n",
            "epoch 1039| loss: 0.91141 | train_accuracy: 0.56897 | val_accuracy: 0.56417 |  0:09:01s\n",
            "epoch 1040| loss: 0.91165 | train_accuracy: 0.57079 | val_accuracy: 0.55818 |  0:09:02s\n",
            "epoch 1041| loss: 0.90758 | train_accuracy: 0.56951 | val_accuracy: 0.55898 |  0:09:02s\n",
            "epoch 1042| loss: 0.90547 | train_accuracy: 0.57031 | val_accuracy: 0.56297 |  0:09:03s\n",
            "epoch 1043| loss: 0.90849 | train_accuracy: 0.57159 | val_accuracy: 0.56297 |  0:09:03s\n",
            "epoch 1044| loss: 0.90891 | train_accuracy: 0.56862 | val_accuracy: 0.56058 |  0:09:04s\n",
            "epoch 1045| loss: 0.90797 | train_accuracy: 0.57004 | val_accuracy: 0.55978 |  0:09:04s\n",
            "epoch 1046| loss: 0.90946 | train_accuracy: 0.5652  | val_accuracy: 0.54938 |  0:09:05s\n",
            "epoch 1047| loss: 0.90998 | train_accuracy: 0.56893 | val_accuracy: 0.56257 |  0:09:05s\n",
            "epoch 1048| loss: 0.90799 | train_accuracy: 0.56742 | val_accuracy: 0.56138 |  0:09:06s\n",
            "epoch 1049| loss: 0.90421 | train_accuracy: 0.56951 | val_accuracy: 0.56058 |  0:09:06s\n",
            "epoch 1050| loss: 0.90985 | train_accuracy: 0.57075 | val_accuracy: 0.56417 |  0:09:07s\n",
            "epoch 1051| loss: 0.90704 | train_accuracy: 0.56875 | val_accuracy: 0.56297 |  0:09:07s\n",
            "epoch 1052| loss: 0.90786 | train_accuracy: 0.56915 | val_accuracy: 0.56178 |  0:09:08s\n",
            "epoch 1053| loss: 0.90728 | train_accuracy: 0.56937 | val_accuracy: 0.56777 |  0:09:08s\n",
            "epoch 1054| loss: 0.90724 | train_accuracy: 0.56608 | val_accuracy: 0.56457 |  0:09:09s\n",
            "epoch 1055| loss: 0.90363 | train_accuracy: 0.57062 | val_accuracy: 0.56897 |  0:09:09s\n",
            "epoch 1056| loss: 0.90598 | train_accuracy: 0.57119 | val_accuracy: 0.56218 |  0:09:10s\n",
            "epoch 1057| loss: 0.9077  | train_accuracy: 0.56964 | val_accuracy: 0.56417 |  0:09:10s\n",
            "epoch 1058| loss: 0.90757 | train_accuracy: 0.568   | val_accuracy: 0.56617 |  0:09:11s\n",
            "epoch 1059| loss: 0.90613 | train_accuracy: 0.56831 | val_accuracy: 0.56377 |  0:09:11s\n",
            "epoch 1060| loss: 0.90801 | train_accuracy: 0.56644 | val_accuracy: 0.56058 |  0:09:12s\n",
            "epoch 1061| loss: 0.90889 | train_accuracy: 0.56613 | val_accuracy: 0.55338 |  0:09:12s\n",
            "epoch 1062| loss: 0.90548 | train_accuracy: 0.56933 | val_accuracy: 0.56537 |  0:09:13s\n",
            "epoch 1063| loss: 0.90747 | train_accuracy: 0.56977 | val_accuracy: 0.56138 |  0:09:13s\n",
            "epoch 1064| loss: 0.90735 | train_accuracy: 0.56586 | val_accuracy: 0.55458 |  0:09:14s\n",
            "epoch 1065| loss: 0.91762 | train_accuracy: 0.56231 | val_accuracy: 0.56058 |  0:09:14s\n",
            "epoch 1066| loss: 0.9179  | train_accuracy: 0.56404 | val_accuracy: 0.55818 |  0:09:15s\n",
            "epoch 1067| loss: 0.9083  | train_accuracy: 0.56182 | val_accuracy: 0.55858 |  0:09:15s\n",
            "epoch 1068| loss: 0.9113  | train_accuracy: 0.56404 | val_accuracy: 0.55578 |  0:09:16s\n",
            "epoch 1069| loss: 0.90945 | train_accuracy: 0.56195 | val_accuracy: 0.55298 |  0:09:16s\n",
            "epoch 1070| loss: 0.91162 | train_accuracy: 0.56253 | val_accuracy: 0.55218 |  0:09:17s\n",
            "epoch 1071| loss: 0.91365 | train_accuracy: 0.56146 | val_accuracy: 0.54978 |  0:09:17s\n",
            "epoch 1072| loss: 0.90967 | train_accuracy: 0.56382 | val_accuracy: 0.55698 |  0:09:18s\n",
            "epoch 1073| loss: 0.90884 | train_accuracy: 0.56453 | val_accuracy: 0.55298 |  0:09:18s\n",
            "epoch 1074| loss: 0.90959 | train_accuracy: 0.56391 | val_accuracy: 0.55178 |  0:09:19s\n",
            "epoch 1075| loss: 0.90957 | train_accuracy: 0.56657 | val_accuracy: 0.55258 |  0:09:19s\n",
            "epoch 1076| loss: 0.90962 | train_accuracy: 0.56648 | val_accuracy: 0.55378 |  0:09:20s\n",
            "epoch 1077| loss: 0.90767 | train_accuracy: 0.56413 | val_accuracy: 0.55538 |  0:09:20s\n",
            "epoch 1078| loss: 0.90846 | train_accuracy: 0.56511 | val_accuracy: 0.55378 |  0:09:21s\n",
            "epoch 1079| loss: 0.90729 | train_accuracy: 0.56489 | val_accuracy: 0.55298 |  0:09:21s\n",
            "epoch 1080| loss: 0.90669 | train_accuracy: 0.56551 | val_accuracy: 0.55378 |  0:09:22s\n",
            "epoch 1081| loss: 0.90875 | train_accuracy: 0.56604 | val_accuracy: 0.55378 |  0:09:23s\n",
            "epoch 1082| loss: 0.90871 | train_accuracy: 0.56693 | val_accuracy: 0.55018 |  0:09:23s\n",
            "epoch 1083| loss: 0.90655 | train_accuracy: 0.56751 | val_accuracy: 0.55338 |  0:09:24s\n",
            "epoch 1084| loss: 0.90972 | train_accuracy: 0.56959 | val_accuracy: 0.55298 |  0:09:24s\n",
            "epoch 1085| loss: 0.90644 | train_accuracy: 0.56595 | val_accuracy: 0.55378 |  0:09:25s\n",
            "epoch 1086| loss: 0.91327 | train_accuracy: 0.56919 | val_accuracy: 0.55738 |  0:09:25s\n",
            "epoch 1087| loss: 0.90753 | train_accuracy: 0.56164 | val_accuracy: 0.54698 |  0:09:26s\n",
            "epoch 1088| loss: 0.90576 | train_accuracy: 0.56795 | val_accuracy: 0.55538 |  0:09:26s\n",
            "epoch 1089| loss: 0.90946 | train_accuracy: 0.56791 | val_accuracy: 0.56138 |  0:09:27s\n",
            "epoch 1090| loss: 0.9089  | train_accuracy: 0.56742 | val_accuracy: 0.55858 |  0:09:27s\n",
            "epoch 1091| loss: 0.90784 | train_accuracy: 0.56817 | val_accuracy: 0.56058 |  0:09:28s\n",
            "epoch 1092| loss: 0.90859 | train_accuracy: 0.56942 | val_accuracy: 0.55898 |  0:09:28s\n",
            "epoch 1093| loss: 0.90512 | train_accuracy: 0.56862 | val_accuracy: 0.55338 |  0:09:29s\n",
            "epoch 1094| loss: 0.90972 | train_accuracy: 0.56635 | val_accuracy: 0.55618 |  0:09:29s\n",
            "epoch 1095| loss: 0.90992 | train_accuracy: 0.56791 | val_accuracy: 0.55258 |  0:09:30s\n",
            "epoch 1096| loss: 0.90969 | train_accuracy: 0.56542 | val_accuracy: 0.56098 |  0:09:30s\n",
            "epoch 1097| loss: 0.90833 | train_accuracy: 0.56333 | val_accuracy: 0.54418 |  0:09:31s\n",
            "epoch 1098| loss: 0.90981 | train_accuracy: 0.56053 | val_accuracy: 0.55498 |  0:09:31s\n",
            "epoch 1099| loss: 0.91026 | train_accuracy: 0.56631 | val_accuracy: 0.55338 |  0:09:32s\n",
            "epoch 1100| loss: 0.91407 | train_accuracy: 0.56582 | val_accuracy: 0.55378 |  0:09:32s\n",
            "epoch 1101| loss: 0.91073 | train_accuracy: 0.56551 | val_accuracy: 0.55658 |  0:09:33s\n",
            "epoch 1102| loss: 0.91113 | train_accuracy: 0.56591 | val_accuracy: 0.55818 |  0:09:33s\n",
            "epoch 1103| loss: 0.90967 | train_accuracy: 0.56395 | val_accuracy: 0.55458 |  0:09:34s\n",
            "epoch 1104| loss: 0.90926 | train_accuracy: 0.5632  | val_accuracy: 0.54538 |  0:09:34s\n",
            "epoch 1105| loss: 0.9116  | train_accuracy: 0.56542 | val_accuracy: 0.55178 |  0:09:35s\n",
            "epoch 1106| loss: 0.91172 | train_accuracy: 0.56768 | val_accuracy: 0.55058 |  0:09:36s\n",
            "epoch 1107| loss: 0.9084  | train_accuracy: 0.56484 | val_accuracy: 0.54618 |  0:09:36s\n",
            "epoch 1108| loss: 0.91132 | train_accuracy: 0.56675 | val_accuracy: 0.54778 |  0:09:37s\n",
            "epoch 1109| loss: 0.90561 | train_accuracy: 0.56795 | val_accuracy: 0.55138 |  0:09:37s\n",
            "epoch 1110| loss: 0.90597 | train_accuracy: 0.56662 | val_accuracy: 0.55018 |  0:09:38s\n",
            "epoch 1111| loss: 0.90974 | train_accuracy: 0.56711 | val_accuracy: 0.55338 |  0:09:38s\n",
            "epoch 1112| loss: 0.90939 | train_accuracy: 0.5672  | val_accuracy: 0.55458 |  0:09:39s\n",
            "epoch 1113| loss: 0.90808 | train_accuracy: 0.56737 | val_accuracy: 0.55498 |  0:09:39s\n",
            "epoch 1114| loss: 0.90837 | train_accuracy: 0.56888 | val_accuracy: 0.55498 |  0:09:40s\n",
            "epoch 1115| loss: 0.91024 | train_accuracy: 0.56715 | val_accuracy: 0.55658 |  0:09:40s\n",
            "epoch 1116| loss: 0.9105  | train_accuracy: 0.56711 | val_accuracy: 0.55618 |  0:09:41s\n",
            "epoch 1117| loss: 0.90978 | train_accuracy: 0.56959 | val_accuracy: 0.55898 |  0:09:41s\n",
            "epoch 1118| loss: 0.90294 | train_accuracy: 0.56804 | val_accuracy: 0.55578 |  0:09:42s\n",
            "epoch 1119| loss: 0.90688 | train_accuracy: 0.56848 | val_accuracy: 0.55698 |  0:09:42s\n",
            "epoch 1120| loss: 0.90845 | train_accuracy: 0.56902 | val_accuracy: 0.55618 |  0:09:43s\n",
            "epoch 1121| loss: 0.9075  | train_accuracy: 0.56928 | val_accuracy: 0.55738 |  0:09:43s\n",
            "epoch 1122| loss: 0.90894 | train_accuracy: 0.56808 | val_accuracy: 0.55138 |  0:09:44s\n",
            "epoch 1123| loss: 0.90766 | train_accuracy: 0.5652  | val_accuracy: 0.54498 |  0:09:44s\n",
            "epoch 1124| loss: 0.90878 | train_accuracy: 0.56662 | val_accuracy: 0.55418 |  0:09:45s\n",
            "epoch 1125| loss: 0.91016 | train_accuracy: 0.56688 | val_accuracy: 0.55418 |  0:09:45s\n",
            "epoch 1126| loss: 0.90765 | train_accuracy: 0.56831 | val_accuracy: 0.54778 |  0:09:46s\n",
            "epoch 1127| loss: 0.91009 | train_accuracy: 0.56751 | val_accuracy: 0.55058 |  0:09:46s\n",
            "epoch 1128| loss: 0.90717 | train_accuracy: 0.56751 | val_accuracy: 0.55578 |  0:09:47s\n",
            "epoch 1129| loss: 0.91451 | train_accuracy: 0.56911 | val_accuracy: 0.55978 |  0:09:47s\n",
            "epoch 1130| loss: 0.91013 | train_accuracy: 0.56902 | val_accuracy: 0.56178 |  0:09:48s\n",
            "epoch 1131| loss: 0.90967 | train_accuracy: 0.56942 | val_accuracy: 0.56018 |  0:09:49s\n",
            "epoch 1132| loss: 0.91095 | train_accuracy: 0.57048 | val_accuracy: 0.55818 |  0:09:49s\n",
            "epoch 1133| loss: 0.91338 | train_accuracy: 0.56608 | val_accuracy: 0.55218 |  0:09:50s\n",
            "epoch 1134| loss: 0.90733 | train_accuracy: 0.56933 | val_accuracy: 0.55018 |  0:09:50s\n",
            "epoch 1135| loss: 0.91271 | train_accuracy: 0.56924 | val_accuracy: 0.55778 |  0:09:51s\n",
            "epoch 1136| loss: 0.9102  | train_accuracy: 0.57017 | val_accuracy: 0.55858 |  0:09:51s\n",
            "epoch 1137| loss: 0.91099 | train_accuracy: 0.57048 | val_accuracy: 0.55698 |  0:09:52s\n",
            "epoch 1138| loss: 0.91033 | train_accuracy: 0.56577 | val_accuracy: 0.54698 |  0:09:52s\n",
            "epoch 1139| loss: 0.90872 | train_accuracy: 0.56933 | val_accuracy: 0.55378 |  0:09:53s\n",
            "epoch 1140| loss: 0.90889 | train_accuracy: 0.56782 | val_accuracy: 0.55338 |  0:09:53s\n",
            "epoch 1141| loss: 0.90708 | train_accuracy: 0.57048 | val_accuracy: 0.55618 |  0:09:54s\n",
            "epoch 1142| loss: 0.90897 | train_accuracy: 0.56422 | val_accuracy: 0.55458 |  0:09:54s\n",
            "epoch 1143| loss: 0.91136 | train_accuracy: 0.56888 | val_accuracy: 0.54738 |  0:09:55s\n",
            "epoch 1144| loss: 0.90822 | train_accuracy: 0.56728 | val_accuracy: 0.55418 |  0:09:55s\n",
            "epoch 1145| loss: 0.90972 | train_accuracy: 0.57026 | val_accuracy: 0.55578 |  0:09:56s\n",
            "epoch 1146| loss: 0.90841 | train_accuracy: 0.57053 | val_accuracy: 0.55578 |  0:09:56s\n",
            "epoch 1147| loss: 0.90733 | train_accuracy: 0.56577 | val_accuracy: 0.54978 |  0:09:57s\n",
            "epoch 1148| loss: 0.9086  | train_accuracy: 0.57199 | val_accuracy: 0.55338 |  0:09:57s\n",
            "epoch 1149| loss: 0.90664 | train_accuracy: 0.57248 | val_accuracy: 0.56018 |  0:09:58s\n",
            "epoch 1150| loss: 0.91679 | train_accuracy: 0.57168 | val_accuracy: 0.55938 |  0:09:58s\n",
            "epoch 1151| loss: 0.90587 | train_accuracy: 0.57062 | val_accuracy: 0.55778 |  0:09:59s\n",
            "epoch 1152| loss: 0.90642 | train_accuracy: 0.57226 | val_accuracy: 0.56138 |  0:10:00s\n",
            "epoch 1153| loss: 0.91178 | train_accuracy: 0.56902 | val_accuracy: 0.56657 |  0:10:00s\n",
            "epoch 1154| loss: 0.90472 | train_accuracy: 0.57106 | val_accuracy: 0.55818 |  0:10:01s\n",
            "epoch 1155| loss: 0.90866 | train_accuracy: 0.57142 | val_accuracy: 0.55978 |  0:10:01s\n",
            "epoch 1156| loss: 0.90913 | train_accuracy: 0.57226 | val_accuracy: 0.55818 |  0:10:02s\n",
            "epoch 1157| loss: 0.90589 | train_accuracy: 0.57208 | val_accuracy: 0.55658 |  0:10:02s\n",
            "epoch 1158| loss: 0.90726 | train_accuracy: 0.5715  | val_accuracy: 0.56577 |  0:10:03s\n",
            "epoch 1159| loss: 0.90595 | train_accuracy: 0.57244 | val_accuracy: 0.56297 |  0:10:03s\n",
            "epoch 1160| loss: 0.9055  | train_accuracy: 0.57013 | val_accuracy: 0.56337 |  0:10:04s\n",
            "epoch 1161| loss: 0.90559 | train_accuracy: 0.57328 | val_accuracy: 0.56058 |  0:10:04s\n",
            "epoch 1162| loss: 0.9034  | train_accuracy: 0.57128 | val_accuracy: 0.56138 |  0:10:05s\n",
            "epoch 1163| loss: 0.90479 | train_accuracy: 0.57364 | val_accuracy: 0.55418 |  0:10:05s\n",
            "epoch 1164| loss: 0.9043  | train_accuracy: 0.57319 | val_accuracy: 0.55458 |  0:10:06s\n",
            "epoch 1165| loss: 0.90527 | train_accuracy: 0.57266 | val_accuracy: 0.55738 |  0:10:06s\n",
            "epoch 1166| loss: 0.90796 | train_accuracy: 0.57222 | val_accuracy: 0.55898 |  0:10:07s\n",
            "epoch 1167| loss: 0.90633 | train_accuracy: 0.56995 | val_accuracy: 0.55938 |  0:10:07s\n",
            "epoch 1168| loss: 0.90728 | train_accuracy: 0.57026 | val_accuracy: 0.55898 |  0:10:08s\n",
            "epoch 1169| loss: 0.90258 | train_accuracy: 0.56848 | val_accuracy: 0.55938 |  0:10:08s\n",
            "epoch 1170| loss: 0.90527 | train_accuracy: 0.57102 | val_accuracy: 0.55698 |  0:10:09s\n",
            "epoch 1171| loss: 0.90621 | train_accuracy: 0.57213 | val_accuracy: 0.55578 |  0:10:09s\n",
            "epoch 1172| loss: 0.90299 | train_accuracy: 0.57026 | val_accuracy: 0.55898 |  0:10:10s\n",
            "epoch 1173| loss: 0.90655 | train_accuracy: 0.5723  | val_accuracy: 0.55658 |  0:10:10s\n",
            "epoch 1174| loss: 0.90676 | train_accuracy: 0.57319 | val_accuracy: 0.55498 |  0:10:11s\n",
            "epoch 1175| loss: 0.90721 | train_accuracy: 0.57297 | val_accuracy: 0.55378 |  0:10:11s\n",
            "epoch 1176| loss: 0.90513 | train_accuracy: 0.57079 | val_accuracy: 0.55938 |  0:10:12s\n",
            "epoch 1177| loss: 0.90691 | train_accuracy: 0.57062 | val_accuracy: 0.56058 |  0:10:13s\n",
            "epoch 1178| loss: 0.90434 | train_accuracy: 0.56919 | val_accuracy: 0.56058 |  0:10:13s\n",
            "epoch 1179| loss: 0.90902 | train_accuracy: 0.56937 | val_accuracy: 0.55538 |  0:10:14s\n",
            "epoch 1180| loss: 0.90854 | train_accuracy: 0.57084 | val_accuracy: 0.56218 |  0:10:14s\n",
            "epoch 1181| loss: 0.90748 | train_accuracy: 0.57066 | val_accuracy: 0.56697 |  0:10:15s\n",
            "epoch 1182| loss: 0.90681 | train_accuracy: 0.56782 | val_accuracy: 0.56417 |  0:10:15s\n",
            "epoch 1183| loss: 0.90553 | train_accuracy: 0.56817 | val_accuracy: 0.56337 |  0:10:16s\n",
            "epoch 1184| loss: 0.90953 | train_accuracy: 0.56724 | val_accuracy: 0.56018 |  0:10:16s\n",
            "epoch 1185| loss: 0.90704 | train_accuracy: 0.56826 | val_accuracy: 0.56098 |  0:10:17s\n",
            "epoch 1186| loss: 0.90725 | train_accuracy: 0.56817 | val_accuracy: 0.56218 |  0:10:17s\n",
            "epoch 1187| loss: 0.90698 | train_accuracy: 0.56671 | val_accuracy: 0.55458 |  0:10:18s\n",
            "epoch 1188| loss: 0.90483 | train_accuracy: 0.56711 | val_accuracy: 0.55418 |  0:10:18s\n",
            "epoch 1189| loss: 0.90741 | train_accuracy: 0.56782 | val_accuracy: 0.55698 |  0:10:19s\n",
            "epoch 1190| loss: 0.90662 | train_accuracy: 0.56777 | val_accuracy: 0.56218 |  0:10:19s\n",
            "epoch 1191| loss: 0.90898 | train_accuracy: 0.56924 | val_accuracy: 0.56178 |  0:10:20s\n",
            "epoch 1192| loss: 0.90752 | train_accuracy: 0.56875 | val_accuracy: 0.55978 |  0:10:20s\n",
            "epoch 1193| loss: 0.9082  | train_accuracy: 0.56986 | val_accuracy: 0.56098 |  0:10:21s\n",
            "epoch 1194| loss: 0.90984 | train_accuracy: 0.56902 | val_accuracy: 0.55938 |  0:10:21s\n",
            "epoch 1195| loss: 0.91455 | train_accuracy: 0.5676  | val_accuracy: 0.56457 |  0:10:22s\n",
            "epoch 1196| loss: 0.913   | train_accuracy: 0.56991 | val_accuracy: 0.55498 |  0:10:22s\n",
            "epoch 1197| loss: 0.91148 | train_accuracy: 0.57048 | val_accuracy: 0.56098 |  0:10:23s\n",
            "epoch 1198| loss: 0.91319 | train_accuracy: 0.56324 | val_accuracy: 0.55898 |  0:10:23s\n",
            "epoch 1199| loss: 0.91606 | train_accuracy: 0.56697 | val_accuracy: 0.56018 |  0:10:24s\n",
            "epoch 1200| loss: 0.91397 | train_accuracy: 0.56413 | val_accuracy: 0.56138 |  0:10:24s\n",
            "epoch 1201| loss: 0.91033 | train_accuracy: 0.56604 | val_accuracy: 0.57057 |  0:10:25s\n",
            "epoch 1202| loss: 0.90961 | train_accuracy: 0.56715 | val_accuracy: 0.57217 |  0:10:25s\n",
            "epoch 1203| loss: 0.91353 | train_accuracy: 0.56386 | val_accuracy: 0.56857 |  0:10:26s\n",
            "epoch 1204| loss: 0.91239 | train_accuracy: 0.56648 | val_accuracy: 0.57337 |  0:10:27s\n",
            "epoch 1205| loss: 0.9124  | train_accuracy: 0.5664  | val_accuracy: 0.57537 |  0:10:27s\n",
            "epoch 1206| loss: 0.91003 | train_accuracy: 0.56697 | val_accuracy: 0.56937 |  0:10:28s\n",
            "epoch 1207| loss: 0.9087  | train_accuracy: 0.56968 | val_accuracy: 0.56857 |  0:10:28s\n",
            "epoch 1208| loss: 0.91372 | train_accuracy: 0.56169 | val_accuracy: 0.56417 |  0:10:29s\n",
            "epoch 1209| loss: 0.91208 | train_accuracy: 0.56671 | val_accuracy: 0.55938 |  0:10:29s\n",
            "epoch 1210| loss: 0.91074 | train_accuracy: 0.56755 | val_accuracy: 0.55978 |  0:10:30s\n",
            "epoch 1211| loss: 0.91088 | train_accuracy: 0.56715 | val_accuracy: 0.55898 |  0:10:30s\n",
            "epoch 1212| loss: 0.90989 | train_accuracy: 0.56871 | val_accuracy: 0.56058 |  0:10:31s\n",
            "epoch 1213| loss: 0.90655 | train_accuracy: 0.57026 | val_accuracy: 0.56058 |  0:10:31s\n",
            "epoch 1214| loss: 0.91125 | train_accuracy: 0.56995 | val_accuracy: 0.56058 |  0:10:32s\n",
            "epoch 1215| loss: 0.90992 | train_accuracy: 0.56999 | val_accuracy: 0.56098 |  0:10:32s\n",
            "epoch 1216| loss: 0.90747 | train_accuracy: 0.56857 | val_accuracy: 0.55938 |  0:10:33s\n",
            "epoch 1217| loss: 0.90407 | train_accuracy: 0.56999 | val_accuracy: 0.56337 |  0:10:33s\n",
            "epoch 1218| loss: 0.90932 | train_accuracy: 0.56919 | val_accuracy: 0.56058 |  0:10:34s\n",
            "epoch 1219| loss: 0.91035 | train_accuracy: 0.56777 | val_accuracy: 0.55858 |  0:10:34s\n",
            "epoch 1220| loss: 0.91129 | train_accuracy: 0.564   | val_accuracy: 0.55578 |  0:10:35s\n",
            "epoch 1221| loss: 0.91306 | train_accuracy: 0.56764 | val_accuracy: 0.56337 |  0:10:35s\n",
            "epoch 1222| loss: 0.91267 | train_accuracy: 0.5668  | val_accuracy: 0.56138 |  0:10:36s\n",
            "epoch 1223| loss: 0.91165 | train_accuracy: 0.56351 | val_accuracy: 0.54858 |  0:10:36s\n",
            "epoch 1224| loss: 0.91145 | train_accuracy: 0.56475 | val_accuracy: 0.55338 |  0:10:37s\n",
            "epoch 1225| loss: 0.91467 | train_accuracy: 0.56311 | val_accuracy: 0.55178 |  0:10:37s\n",
            "epoch 1226| loss: 0.91255 | train_accuracy: 0.56466 | val_accuracy: 0.55298 |  0:10:38s\n",
            "epoch 1227| loss: 0.91652 | train_accuracy: 0.56053 | val_accuracy: 0.54938 |  0:10:38s\n",
            "epoch 1228| loss: 0.91659 | train_accuracy: 0.56169 | val_accuracy: 0.55858 |  0:10:39s\n",
            "epoch 1229| loss: 0.9128  | train_accuracy: 0.56493 | val_accuracy: 0.55778 |  0:10:40s\n",
            "epoch 1230| loss: 0.91574 | train_accuracy: 0.56422 | val_accuracy: 0.55418 |  0:10:40s\n",
            "epoch 1231| loss: 0.91082 | train_accuracy: 0.56604 | val_accuracy: 0.55458 |  0:10:41s\n",
            "epoch 1232| loss: 0.91127 | train_accuracy: 0.56675 | val_accuracy: 0.55378 |  0:10:41s\n",
            "epoch 1233| loss: 0.91235 | train_accuracy: 0.566   | val_accuracy: 0.55418 |  0:10:42s\n",
            "epoch 1234| loss: 0.91597 | train_accuracy: 0.5628  | val_accuracy: 0.55538 |  0:10:42s\n",
            "epoch 1235| loss: 0.91359 | train_accuracy: 0.56346 | val_accuracy: 0.54378 |  0:10:43s\n",
            "epoch 1236| loss: 0.91419 | train_accuracy: 0.56293 | val_accuracy: 0.54698 |  0:10:43s\n",
            "epoch 1237| loss: 0.91344 | train_accuracy: 0.56613 | val_accuracy: 0.55578 |  0:10:44s\n",
            "epoch 1238| loss: 0.91325 | train_accuracy: 0.56795 | val_accuracy: 0.55058 |  0:10:44s\n",
            "epoch 1239| loss: 0.90973 | train_accuracy: 0.56524 | val_accuracy: 0.55178 |  0:10:45s\n",
            "epoch 1240| loss: 0.91487 | train_accuracy: 0.56404 | val_accuracy: 0.56058 |  0:10:45s\n",
            "epoch 1241| loss: 0.91072 | train_accuracy: 0.5648  | val_accuracy: 0.55338 |  0:10:46s\n",
            "epoch 1242| loss: 0.91234 | train_accuracy: 0.56568 | val_accuracy: 0.55138 |  0:10:46s\n",
            "epoch 1243| loss: 0.91295 | train_accuracy: 0.56329 | val_accuracy: 0.55258 |  0:10:47s\n",
            "epoch 1244| loss: 0.90886 | train_accuracy: 0.56511 | val_accuracy: 0.55298 |  0:10:47s\n",
            "epoch 1245| loss: 0.9119  | train_accuracy: 0.56604 | val_accuracy: 0.55618 |  0:10:48s\n",
            "epoch 1246| loss: 0.91187 | train_accuracy: 0.56568 | val_accuracy: 0.55698 |  0:10:48s\n",
            "epoch 1247| loss: 0.90911 | train_accuracy: 0.56635 | val_accuracy: 0.56337 |  0:10:49s\n",
            "epoch 1248| loss: 0.91046 | train_accuracy: 0.56839 | val_accuracy: 0.55818 |  0:10:49s\n",
            "epoch 1249| loss: 0.91062 | train_accuracy: 0.56822 | val_accuracy: 0.55898 |  0:10:50s\n",
            "epoch 1250| loss: 0.90688 | train_accuracy: 0.56857 | val_accuracy: 0.56218 |  0:10:50s\n",
            "epoch 1251| loss: 0.90708 | train_accuracy: 0.57039 | val_accuracy: 0.55818 |  0:10:51s\n",
            "epoch 1252| loss: 0.91054 | train_accuracy: 0.5664  | val_accuracy: 0.55498 |  0:10:51s\n",
            "epoch 1253| loss: 0.90976 | train_accuracy: 0.5672  | val_accuracy: 0.56138 |  0:10:52s\n",
            "epoch 1254| loss: 0.90804 | train_accuracy: 0.56924 | val_accuracy: 0.55658 |  0:10:52s\n",
            "epoch 1255| loss: 0.90964 | train_accuracy: 0.56862 | val_accuracy: 0.55938 |  0:10:53s\n",
            "epoch 1256| loss: 0.90735 | train_accuracy: 0.56906 | val_accuracy: 0.56218 |  0:10:53s\n",
            "epoch 1257| loss: 0.90508 | train_accuracy: 0.56986 | val_accuracy: 0.56577 |  0:10:54s\n",
            "epoch 1258| loss: 0.90964 | train_accuracy: 0.57066 | val_accuracy: 0.56977 |  0:10:54s\n",
            "epoch 1259| loss: 0.90358 | train_accuracy: 0.56991 | val_accuracy: 0.57137 |  0:10:55s\n",
            "epoch 1260| loss: 0.90742 | train_accuracy: 0.56973 | val_accuracy: 0.56977 |  0:10:55s\n",
            "epoch 1261| loss: 0.9054  | train_accuracy: 0.57017 | val_accuracy: 0.56218 |  0:10:56s\n",
            "epoch 1262| loss: 0.90563 | train_accuracy: 0.57395 | val_accuracy: 0.56098 |  0:10:56s\n",
            "epoch 1263| loss: 0.90597 | train_accuracy: 0.57186 | val_accuracy: 0.56257 |  0:10:57s\n",
            "epoch 1264| loss: 0.90252 | train_accuracy: 0.57439 | val_accuracy: 0.56218 |  0:10:57s\n",
            "epoch 1265| loss: 0.90387 | train_accuracy: 0.57244 | val_accuracy: 0.56297 |  0:10:58s\n",
            "epoch 1266| loss: 0.90226 | train_accuracy: 0.57199 | val_accuracy: 0.55978 |  0:10:58s\n",
            "epoch 1267| loss: 0.90644 | train_accuracy: 0.57226 | val_accuracy: 0.56457 |  0:10:59s\n",
            "epoch 1268| loss: 0.90192 | train_accuracy: 0.57146 | val_accuracy: 0.56697 |  0:10:59s\n",
            "epoch 1269| loss: 0.9056  | train_accuracy: 0.57119 | val_accuracy: 0.55778 |  0:11:00s\n",
            "epoch 1270| loss: 0.9044  | train_accuracy: 0.57235 | val_accuracy: 0.56018 |  0:11:00s\n",
            "epoch 1271| loss: 0.90544 | train_accuracy: 0.57164 | val_accuracy: 0.55578 |  0:11:01s\n",
            "epoch 1272| loss: 0.90699 | train_accuracy: 0.57266 | val_accuracy: 0.56537 |  0:11:01s\n",
            "epoch 1273| loss: 0.90833 | train_accuracy: 0.57155 | val_accuracy: 0.56737 |  0:11:02s\n",
            "epoch 1274| loss: 0.90439 | train_accuracy: 0.5719  | val_accuracy: 0.56178 |  0:11:02s\n",
            "epoch 1275| loss: 0.90551 | train_accuracy: 0.5735  | val_accuracy: 0.56058 |  0:11:03s\n",
            "epoch 1276| loss: 0.9041  | train_accuracy: 0.57244 | val_accuracy: 0.55778 |  0:11:03s\n",
            "epoch 1277| loss: 0.90497 | train_accuracy: 0.57244 | val_accuracy: 0.55578 |  0:11:04s\n",
            "epoch 1278| loss: 0.90397 | train_accuracy: 0.57213 | val_accuracy: 0.55138 |  0:11:04s\n",
            "epoch 1279| loss: 0.90073 | train_accuracy: 0.57102 | val_accuracy: 0.56138 |  0:11:05s\n",
            "epoch 1280| loss: 0.90268 | train_accuracy: 0.57119 | val_accuracy: 0.56018 |  0:11:05s\n",
            "epoch 1281| loss: 0.90159 | train_accuracy: 0.57248 | val_accuracy: 0.55738 |  0:11:06s\n",
            "epoch 1282| loss: 0.90349 | train_accuracy: 0.57199 | val_accuracy: 0.55938 |  0:11:06s\n",
            "epoch 1283| loss: 0.90557 | train_accuracy: 0.57421 | val_accuracy: 0.56737 |  0:11:07s\n",
            "epoch 1284| loss: 0.90729 | train_accuracy: 0.56959 | val_accuracy: 0.55658 |  0:11:07s\n",
            "epoch 1285| loss: 0.9069  | train_accuracy: 0.57124 | val_accuracy: 0.56018 |  0:11:08s\n",
            "epoch 1286| loss: 0.90681 | train_accuracy: 0.56986 | val_accuracy: 0.55138 |  0:11:08s\n",
            "epoch 1287| loss: 0.90353 | train_accuracy: 0.57448 | val_accuracy: 0.55738 |  0:11:09s\n",
            "epoch 1288| loss: 0.90631 | train_accuracy: 0.57439 | val_accuracy: 0.56497 |  0:11:09s\n",
            "epoch 1289| loss: 0.90329 | train_accuracy: 0.57475 | val_accuracy: 0.56138 |  0:11:10s\n",
            "epoch 1290| loss: 0.90295 | train_accuracy: 0.57031 | val_accuracy: 0.56178 |  0:11:10s\n",
            "epoch 1291| loss: 0.91196 | train_accuracy: 0.56902 | val_accuracy: 0.56178 |  0:11:11s\n",
            "epoch 1292| loss: 0.90692 | train_accuracy: 0.56928 | val_accuracy: 0.56218 |  0:11:11s\n",
            "epoch 1293| loss: 0.90619 | train_accuracy: 0.57155 | val_accuracy: 0.55938 |  0:11:12s\n",
            "epoch 1294| loss: 0.90702 | train_accuracy: 0.57346 | val_accuracy: 0.55578 |  0:11:12s\n",
            "epoch 1295| loss: 0.90861 | train_accuracy: 0.57186 | val_accuracy: 0.55778 |  0:11:13s\n",
            "epoch 1296| loss: 0.9043  | train_accuracy: 0.57435 | val_accuracy: 0.56617 |  0:11:13s\n",
            "epoch 1297| loss: 0.90673 | train_accuracy: 0.57417 | val_accuracy: 0.56577 |  0:11:14s\n",
            "epoch 1298| loss: 0.90389 | train_accuracy: 0.57408 | val_accuracy: 0.56537 |  0:11:14s\n",
            "epoch 1299| loss: 0.90639 | train_accuracy: 0.57159 | val_accuracy: 0.56617 |  0:11:15s\n",
            "epoch 1300| loss: 0.90266 | train_accuracy: 0.56728 | val_accuracy: 0.56617 |  0:11:15s\n",
            "epoch 1301| loss: 0.90631 | train_accuracy: 0.57381 | val_accuracy: 0.56337 |  0:11:16s\n",
            "epoch 1302| loss: 0.90309 | train_accuracy: 0.57257 | val_accuracy: 0.56937 |  0:11:16s\n",
            "epoch 1303| loss: 0.90339 | train_accuracy: 0.5743  | val_accuracy: 0.56337 |  0:11:17s\n",
            "epoch 1304| loss: 0.90275 | train_accuracy: 0.57426 | val_accuracy: 0.56657 |  0:11:17s\n",
            "epoch 1305| loss: 0.89883 | train_accuracy: 0.57421 | val_accuracy: 0.56377 |  0:11:18s\n",
            "epoch 1306| loss: 0.90064 | train_accuracy: 0.5751  | val_accuracy: 0.55938 |  0:11:18s\n",
            "epoch 1307| loss: 0.90068 | train_accuracy: 0.57461 | val_accuracy: 0.55978 |  0:11:19s\n",
            "epoch 1308| loss: 0.90332 | train_accuracy: 0.57595 | val_accuracy: 0.55978 |  0:11:19s\n",
            "epoch 1309| loss: 0.90294 | train_accuracy: 0.57586 | val_accuracy: 0.55658 |  0:11:20s\n",
            "epoch 1310| loss: 0.90306 | train_accuracy: 0.57608 | val_accuracy: 0.55418 |  0:11:20s\n",
            "epoch 1311| loss: 0.9069  | train_accuracy: 0.57457 | val_accuracy: 0.55978 |  0:11:21s\n",
            "epoch 1312| loss: 0.89957 | train_accuracy: 0.57657 | val_accuracy: 0.56218 |  0:11:21s\n",
            "epoch 1313| loss: 0.90416 | train_accuracy: 0.57475 | val_accuracy: 0.55138 |  0:11:22s\n",
            "epoch 1314| loss: 0.90234 | train_accuracy: 0.57568 | val_accuracy: 0.55858 |  0:11:22s\n",
            "epoch 1315| loss: 0.9001  | train_accuracy: 0.57537 | val_accuracy: 0.56058 |  0:11:23s\n",
            "epoch 1316| loss: 0.90082 | train_accuracy: 0.57515 | val_accuracy: 0.56058 |  0:11:23s\n",
            "epoch 1317| loss: 0.90484 | train_accuracy: 0.57644 | val_accuracy: 0.56457 |  0:11:24s\n",
            "epoch 1318| loss: 0.89848 | train_accuracy: 0.57475 | val_accuracy: 0.56377 |  0:11:24s\n",
            "epoch 1319| loss: 0.90319 | train_accuracy: 0.57715 | val_accuracy: 0.56657 |  0:11:25s\n",
            "epoch 1320| loss: 0.89971 | train_accuracy: 0.5735  | val_accuracy: 0.55658 |  0:11:25s\n",
            "epoch 1321| loss: 0.89809 | train_accuracy: 0.57581 | val_accuracy: 0.56178 |  0:11:26s\n",
            "epoch 1322| loss: 0.90094 | train_accuracy: 0.57541 | val_accuracy: 0.56657 |  0:11:26s\n",
            "epoch 1323| loss: 0.90474 | train_accuracy: 0.57768 | val_accuracy: 0.55898 |  0:11:27s\n",
            "epoch 1324| loss: 0.90505 | train_accuracy: 0.5775  | val_accuracy: 0.55858 |  0:11:27s\n",
            "epoch 1325| loss: 0.90083 | train_accuracy: 0.57732 | val_accuracy: 0.56257 |  0:11:28s\n",
            "epoch 1326| loss: 0.8997  | train_accuracy: 0.57555 | val_accuracy: 0.55978 |  0:11:28s\n",
            "epoch 1327| loss: 0.89758 | train_accuracy: 0.57475 | val_accuracy: 0.56257 |  0:11:29s\n",
            "epoch 1328| loss: 0.89849 | train_accuracy: 0.57386 | val_accuracy: 0.56058 |  0:11:29s\n",
            "epoch 1329| loss: 0.90223 | train_accuracy: 0.57519 | val_accuracy: 0.55938 |  0:11:30s\n",
            "epoch 1330| loss: 0.89891 | train_accuracy: 0.57421 | val_accuracy: 0.56058 |  0:11:30s\n",
            "epoch 1331| loss: 0.90273 | train_accuracy: 0.57621 | val_accuracy: 0.55818 |  0:11:31s\n",
            "epoch 1332| loss: 0.90447 | train_accuracy: 0.57466 | val_accuracy: 0.55978 |  0:11:31s\n",
            "epoch 1333| loss: 0.89697 | train_accuracy: 0.57906 | val_accuracy: 0.56218 |  0:11:32s\n",
            "epoch 1334| loss: 0.902   | train_accuracy: 0.57408 | val_accuracy: 0.55258 |  0:11:32s\n",
            "epoch 1335| loss: 0.89955 | train_accuracy: 0.57897 | val_accuracy: 0.55498 |  0:11:33s\n",
            "epoch 1336| loss: 0.90109 | train_accuracy: 0.57692 | val_accuracy: 0.55938 |  0:11:33s\n",
            "epoch 1337| loss: 0.90147 | train_accuracy: 0.57559 | val_accuracy: 0.56497 |  0:11:34s\n",
            "epoch 1338| loss: 0.90031 | train_accuracy: 0.57426 | val_accuracy: 0.55338 |  0:11:34s\n",
            "epoch 1339| loss: 0.90236 | train_accuracy: 0.56951 | val_accuracy: 0.55018 |  0:11:35s\n",
            "epoch 1340| loss: 0.90015 | train_accuracy: 0.5727  | val_accuracy: 0.55978 |  0:11:35s\n",
            "epoch 1341| loss: 0.90189 | train_accuracy: 0.57488 | val_accuracy: 0.56337 |  0:11:36s\n",
            "epoch 1342| loss: 0.89921 | train_accuracy: 0.57102 | val_accuracy: 0.56018 |  0:11:36s\n",
            "epoch 1343| loss: 0.90103 | train_accuracy: 0.57306 | val_accuracy: 0.56537 |  0:11:37s\n",
            "epoch 1344| loss: 0.90044 | train_accuracy: 0.57701 | val_accuracy: 0.56257 |  0:11:37s\n",
            "epoch 1345| loss: 0.89858 | train_accuracy: 0.57524 | val_accuracy: 0.56457 |  0:11:38s\n",
            "epoch 1346| loss: 0.90118 | train_accuracy: 0.57519 | val_accuracy: 0.56098 |  0:11:38s\n",
            "epoch 1347| loss: 0.90345 | train_accuracy: 0.57128 | val_accuracy: 0.55338 |  0:11:39s\n",
            "epoch 1348| loss: 0.90238 | train_accuracy: 0.57333 | val_accuracy: 0.56297 |  0:11:40s\n",
            "epoch 1349| loss: 0.90054 | train_accuracy: 0.57564 | val_accuracy: 0.56297 |  0:11:40s\n",
            "epoch 1350| loss: 0.90748 | train_accuracy: 0.57279 | val_accuracy: 0.55738 |  0:11:41s\n",
            "epoch 1351| loss: 0.90568 | train_accuracy: 0.57639 | val_accuracy: 0.56138 |  0:11:41s\n",
            "epoch 1352| loss: 0.90102 | train_accuracy: 0.5755  | val_accuracy: 0.56018 |  0:11:42s\n",
            "epoch 1353| loss: 0.90386 | train_accuracy: 0.57546 | val_accuracy: 0.55498 |  0:11:42s\n",
            "epoch 1354| loss: 0.91047 | train_accuracy: 0.57568 | val_accuracy: 0.55658 |  0:11:43s\n",
            "epoch 1355| loss: 0.9039  | train_accuracy: 0.57275 | val_accuracy: 0.55338 |  0:11:43s\n",
            "epoch 1356| loss: 0.90194 | train_accuracy: 0.57608 | val_accuracy: 0.55778 |  0:11:44s\n",
            "epoch 1357| loss: 0.90324 | train_accuracy: 0.57617 | val_accuracy: 0.55898 |  0:11:44s\n",
            "epoch 1358| loss: 0.89614 | train_accuracy: 0.57684 | val_accuracy: 0.55938 |  0:11:45s\n",
            "epoch 1359| loss: 0.90186 | train_accuracy: 0.57728 | val_accuracy: 0.56138 |  0:11:45s\n",
            "epoch 1360| loss: 0.89666 | train_accuracy: 0.57715 | val_accuracy: 0.57177 |  0:11:46s\n",
            "epoch 1361| loss: 0.90036 | train_accuracy: 0.57528 | val_accuracy: 0.56218 |  0:11:46s\n",
            "epoch 1362| loss: 0.90013 | train_accuracy: 0.57488 | val_accuracy: 0.55618 |  0:11:47s\n",
            "epoch 1363| loss: 0.89815 | train_accuracy: 0.57701 | val_accuracy: 0.56018 |  0:11:47s\n",
            "epoch 1364| loss: 0.89765 | train_accuracy: 0.57755 | val_accuracy: 0.56138 |  0:11:48s\n",
            "epoch 1365| loss: 0.89957 | train_accuracy: 0.5803  | val_accuracy: 0.56457 |  0:11:48s\n",
            "epoch 1366| loss: 0.89714 | train_accuracy: 0.57892 | val_accuracy: 0.56058 |  0:11:49s\n",
            "epoch 1367| loss: 0.89868 | train_accuracy: 0.57804 | val_accuracy: 0.56297 |  0:11:49s\n",
            "epoch 1368| loss: 0.89732 | train_accuracy: 0.57746 | val_accuracy: 0.55538 |  0:11:50s\n",
            "epoch 1369| loss: 0.89649 | train_accuracy: 0.57741 | val_accuracy: 0.55658 |  0:11:50s\n",
            "epoch 1370| loss: 0.89877 | train_accuracy: 0.57923 | val_accuracy: 0.56058 |  0:11:51s\n",
            "epoch 1371| loss: 0.8982  | train_accuracy: 0.57915 | val_accuracy: 0.55778 |  0:11:51s\n",
            "epoch 1372| loss: 0.89746 | train_accuracy: 0.57955 | val_accuracy: 0.56337 |  0:11:52s\n",
            "epoch 1373| loss: 0.89839 | train_accuracy: 0.57906 | val_accuracy: 0.55978 |  0:11:52s\n",
            "epoch 1374| loss: 0.89744 | train_accuracy: 0.57844 | val_accuracy: 0.55978 |  0:11:53s\n",
            "epoch 1375| loss: 0.9004  | train_accuracy: 0.57728 | val_accuracy: 0.56178 |  0:11:53s\n",
            "epoch 1376| loss: 0.89866 | train_accuracy: 0.57706 | val_accuracy: 0.56337 |  0:11:54s\n",
            "epoch 1377| loss: 0.89602 | train_accuracy: 0.57759 | val_accuracy: 0.56098 |  0:11:54s\n",
            "epoch 1378| loss: 0.89447 | train_accuracy: 0.57697 | val_accuracy: 0.56537 |  0:11:55s\n",
            "epoch 1379| loss: 0.89861 | train_accuracy: 0.57919 | val_accuracy: 0.56977 |  0:11:55s\n",
            "epoch 1380| loss: 0.89697 | train_accuracy: 0.57737 | val_accuracy: 0.56697 |  0:11:56s\n",
            "epoch 1381| loss: 0.89947 | train_accuracy: 0.57799 | val_accuracy: 0.56337 |  0:11:56s\n",
            "epoch 1382| loss: 0.89656 | train_accuracy: 0.57648 | val_accuracy: 0.56377 |  0:11:57s\n",
            "epoch 1383| loss: 0.89245 | train_accuracy: 0.57759 | val_accuracy: 0.56617 |  0:11:57s\n",
            "epoch 1384| loss: 0.89831 | train_accuracy: 0.57919 | val_accuracy: 0.56297 |  0:11:58s\n",
            "epoch 1385| loss: 0.89886 | train_accuracy: 0.5783  | val_accuracy: 0.56138 |  0:11:58s\n",
            "epoch 1386| loss: 0.90074 | train_accuracy: 0.57755 | val_accuracy: 0.56058 |  0:11:59s\n",
            "epoch 1387| loss: 0.89741 | train_accuracy: 0.5791  | val_accuracy: 0.56337 |  0:11:59s\n",
            "epoch 1388| loss: 0.89773 | train_accuracy: 0.57844 | val_accuracy: 0.56058 |  0:12:00s\n",
            "epoch 1389| loss: 0.89809 | train_accuracy: 0.57835 | val_accuracy: 0.56058 |  0:12:00s\n",
            "epoch 1390| loss: 0.89602 | train_accuracy: 0.57986 | val_accuracy: 0.56377 |  0:12:01s\n",
            "epoch 1391| loss: 0.89894 | train_accuracy: 0.57932 | val_accuracy: 0.55978 |  0:12:01s\n",
            "epoch 1392| loss: 0.89744 | train_accuracy: 0.57777 | val_accuracy: 0.56058 |  0:12:02s\n",
            "epoch 1393| loss: 0.89469 | train_accuracy: 0.57879 | val_accuracy: 0.55458 |  0:12:02s\n",
            "epoch 1394| loss: 0.89672 | train_accuracy: 0.57972 | val_accuracy: 0.55818 |  0:12:03s\n",
            "epoch 1395| loss: 0.89481 | train_accuracy: 0.57795 | val_accuracy: 0.55738 |  0:12:03s\n",
            "epoch 1396| loss: 0.89902 | train_accuracy: 0.57852 | val_accuracy: 0.56018 |  0:12:04s\n",
            "epoch 1397| loss: 0.8951  | train_accuracy: 0.57857 | val_accuracy: 0.55418 |  0:12:04s\n",
            "epoch 1398| loss: 0.89407 | train_accuracy: 0.58181 | val_accuracy: 0.56457 |  0:12:05s\n",
            "epoch 1399| loss: 0.89593 | train_accuracy: 0.57972 | val_accuracy: 0.56218 |  0:12:05s\n",
            "epoch 1400| loss: 0.89565 | train_accuracy: 0.58168 | val_accuracy: 0.55818 |  0:12:06s\n",
            "epoch 1401| loss: 0.89776 | train_accuracy: 0.58199 | val_accuracy: 0.55858 |  0:12:06s\n",
            "epoch 1402| loss: 0.89157 | train_accuracy: 0.58075 | val_accuracy: 0.55738 |  0:12:07s\n",
            "epoch 1403| loss: 0.89363 | train_accuracy: 0.57888 | val_accuracy: 0.55778 |  0:12:07s\n",
            "epoch 1404| loss: 0.8966  | train_accuracy: 0.58097 | val_accuracy: 0.56058 |  0:12:08s\n",
            "epoch 1405| loss: 0.89671 | train_accuracy: 0.58052 | val_accuracy: 0.56178 |  0:12:08s\n",
            "epoch 1406| loss: 0.89599 | train_accuracy: 0.58181 | val_accuracy: 0.55498 |  0:12:09s\n",
            "epoch 1407| loss: 0.89787 | train_accuracy: 0.58199 | val_accuracy: 0.55818 |  0:12:09s\n",
            "epoch 1408| loss: 0.89815 | train_accuracy: 0.5811  | val_accuracy: 0.55778 |  0:12:10s\n",
            "epoch 1409| loss: 0.89734 | train_accuracy: 0.58021 | val_accuracy: 0.55778 |  0:12:10s\n",
            "epoch 1410| loss: 0.89779 | train_accuracy: 0.5791  | val_accuracy: 0.55738 |  0:12:11s\n",
            "epoch 1411| loss: 0.90056 | train_accuracy: 0.57817 | val_accuracy: 0.55618 |  0:12:11s\n",
            "epoch 1412| loss: 0.89799 | train_accuracy: 0.57866 | val_accuracy: 0.55658 |  0:12:12s\n",
            "epoch 1413| loss: 0.90018 | train_accuracy: 0.58048 | val_accuracy: 0.55978 |  0:12:12s\n",
            "epoch 1414| loss: 0.89923 | train_accuracy: 0.58106 | val_accuracy: 0.56497 |  0:12:13s\n",
            "epoch 1415| loss: 0.89643 | train_accuracy: 0.58021 | val_accuracy: 0.56218 |  0:12:13s\n",
            "epoch 1416| loss: 0.89593 | train_accuracy: 0.58057 | val_accuracy: 0.55498 |  0:12:14s\n",
            "epoch 1417| loss: 0.89739 | train_accuracy: 0.58226 | val_accuracy: 0.55618 |  0:12:14s\n",
            "epoch 1418| loss: 0.8936  | train_accuracy: 0.57977 | val_accuracy: 0.55978 |  0:12:15s\n",
            "epoch 1419| loss: 0.90182 | train_accuracy: 0.57884 | val_accuracy: 0.56297 |  0:12:15s\n",
            "epoch 1420| loss: 0.89967 | train_accuracy: 0.5803  | val_accuracy: 0.55698 |  0:12:16s\n",
            "epoch 1421| loss: 0.90002 | train_accuracy: 0.57461 | val_accuracy: 0.55378 |  0:12:16s\n",
            "epoch 1422| loss: 0.89481 | train_accuracy: 0.58075 | val_accuracy: 0.56018 |  0:12:17s\n",
            "epoch 1423| loss: 0.89685 | train_accuracy: 0.58168 | val_accuracy: 0.55418 |  0:12:17s\n",
            "epoch 1424| loss: 0.89852 | train_accuracy: 0.58066 | val_accuracy: 0.56257 |  0:12:18s\n",
            "epoch 1425| loss: 0.89678 | train_accuracy: 0.58083 | val_accuracy: 0.55978 |  0:12:18s\n",
            "epoch 1426| loss: 0.89576 | train_accuracy: 0.57977 | val_accuracy: 0.56497 |  0:12:19s\n",
            "epoch 1427| loss: 0.89451 | train_accuracy: 0.58043 | val_accuracy: 0.55938 |  0:12:19s\n",
            "epoch 1428| loss: 0.89463 | train_accuracy: 0.58146 | val_accuracy: 0.56497 |  0:12:20s\n",
            "epoch 1429| loss: 0.89664 | train_accuracy: 0.57963 | val_accuracy: 0.56897 |  0:12:20s\n",
            "epoch 1430| loss: 0.89752 | train_accuracy: 0.58354 | val_accuracy: 0.57017 |  0:12:21s\n",
            "epoch 1431| loss: 0.89306 | train_accuracy: 0.58234 | val_accuracy: 0.56977 |  0:12:21s\n",
            "epoch 1432| loss: 0.89713 | train_accuracy: 0.5831  | val_accuracy: 0.56897 |  0:12:22s\n",
            "epoch 1433| loss: 0.8966  | train_accuracy: 0.57897 | val_accuracy: 0.57137 |  0:12:22s\n",
            "epoch 1434| loss: 0.89535 | train_accuracy: 0.58377 | val_accuracy: 0.56297 |  0:12:23s\n",
            "epoch 1435| loss: 0.89526 | train_accuracy: 0.58279 | val_accuracy: 0.56657 |  0:12:23s\n",
            "epoch 1436| loss: 0.89851 | train_accuracy: 0.5811  | val_accuracy: 0.56098 |  0:12:24s\n",
            "epoch 1437| loss: 0.89722 | train_accuracy: 0.58123 | val_accuracy: 0.56178 |  0:12:24s\n",
            "epoch 1438| loss: 0.89876 | train_accuracy: 0.58186 | val_accuracy: 0.56817 |  0:12:25s\n",
            "epoch 1439| loss: 0.89396 | train_accuracy: 0.58194 | val_accuracy: 0.56497 |  0:12:25s\n",
            "epoch 1440| loss: 0.89836 | train_accuracy: 0.58563 | val_accuracy: 0.57337 |  0:12:26s\n",
            "epoch 1441| loss: 0.89253 | train_accuracy: 0.58528 | val_accuracy: 0.57377 |  0:12:26s\n",
            "epoch 1442| loss: 0.89247 | train_accuracy: 0.58146 | val_accuracy: 0.56697 |  0:12:27s\n",
            "epoch 1443| loss: 0.89854 | train_accuracy: 0.58403 | val_accuracy: 0.56817 |  0:12:27s\n",
            "epoch 1444| loss: 0.89629 | train_accuracy: 0.58341 | val_accuracy: 0.57097 |  0:12:28s\n",
            "epoch 1445| loss: 0.89201 | train_accuracy: 0.58363 | val_accuracy: 0.56817 |  0:12:28s\n",
            "epoch 1446| loss: 0.89401 | train_accuracy: 0.58075 | val_accuracy: 0.56058 |  0:12:29s\n",
            "epoch 1447| loss: 0.89378 | train_accuracy: 0.58119 | val_accuracy: 0.55618 |  0:12:29s\n",
            "epoch 1448| loss: 0.89546 | train_accuracy: 0.58061 | val_accuracy: 0.56617 |  0:12:30s\n",
            "epoch 1449| loss: 0.89505 | train_accuracy: 0.58292 | val_accuracy: 0.55418 |  0:12:30s\n",
            "epoch 1450| loss: 0.89601 | train_accuracy: 0.5819  | val_accuracy: 0.56018 |  0:12:31s\n",
            "epoch 1451| loss: 0.89421 | train_accuracy: 0.58301 | val_accuracy: 0.56098 |  0:12:31s\n",
            "epoch 1452| loss: 0.89086 | train_accuracy: 0.58083 | val_accuracy: 0.55898 |  0:12:32s\n",
            "epoch 1453| loss: 0.88758 | train_accuracy: 0.58163 | val_accuracy: 0.56257 |  0:12:32s\n",
            "epoch 1454| loss: 0.89157 | train_accuracy: 0.58288 | val_accuracy: 0.55858 |  0:12:33s\n",
            "epoch 1455| loss: 0.89187 | train_accuracy: 0.58128 | val_accuracy: 0.56058 |  0:12:33s\n",
            "epoch 1456| loss: 0.89552 | train_accuracy: 0.58212 | val_accuracy: 0.56417 |  0:12:34s\n",
            "epoch 1457| loss: 0.89626 | train_accuracy: 0.57955 | val_accuracy: 0.55818 |  0:12:34s\n",
            "epoch 1458| loss: 0.89607 | train_accuracy: 0.58061 | val_accuracy: 0.55658 |  0:12:35s\n",
            "epoch 1459| loss: 0.89629 | train_accuracy: 0.58257 | val_accuracy: 0.56577 |  0:12:35s\n",
            "epoch 1460| loss: 0.89944 | train_accuracy: 0.58217 | val_accuracy: 0.56218 |  0:12:36s\n",
            "epoch 1461| loss: 0.89443 | train_accuracy: 0.58101 | val_accuracy: 0.56138 |  0:12:36s\n",
            "epoch 1462| loss: 0.89076 | train_accuracy: 0.58097 | val_accuracy: 0.55458 |  0:12:37s\n",
            "epoch 1463| loss: 0.89398 | train_accuracy: 0.58297 | val_accuracy: 0.56018 |  0:12:37s\n",
            "epoch 1464| loss: 0.89286 | train_accuracy: 0.58123 | val_accuracy: 0.55898 |  0:12:38s\n",
            "epoch 1465| loss: 0.89175 | train_accuracy: 0.58146 | val_accuracy: 0.56138 |  0:12:38s\n",
            "epoch 1466| loss: 0.89328 | train_accuracy: 0.58208 | val_accuracy: 0.56377 |  0:12:39s\n",
            "epoch 1467| loss: 0.89115 | train_accuracy: 0.57959 | val_accuracy: 0.56138 |  0:12:39s\n",
            "epoch 1468| loss: 0.89182 | train_accuracy: 0.57963 | val_accuracy: 0.56377 |  0:12:40s\n",
            "epoch 1469| loss: 0.89408 | train_accuracy: 0.58163 | val_accuracy: 0.56257 |  0:12:40s\n",
            "epoch 1470| loss: 0.89171 | train_accuracy: 0.57928 | val_accuracy: 0.55978 |  0:12:41s\n",
            "epoch 1471| loss: 0.89524 | train_accuracy: 0.58012 | val_accuracy: 0.55858 |  0:12:41s\n",
            "epoch 1472| loss: 0.8917  | train_accuracy: 0.58075 | val_accuracy: 0.56098 |  0:12:42s\n",
            "epoch 1473| loss: 0.89133 | train_accuracy: 0.58199 | val_accuracy: 0.56377 |  0:12:42s\n",
            "epoch 1474| loss: 0.89426 | train_accuracy: 0.58043 | val_accuracy: 0.56218 |  0:12:43s\n",
            "epoch 1475| loss: 0.89453 | train_accuracy: 0.58119 | val_accuracy: 0.56337 |  0:12:43s\n",
            "epoch 1476| loss: 0.89353 | train_accuracy: 0.57995 | val_accuracy: 0.56218 |  0:12:44s\n",
            "epoch 1477| loss: 0.89328 | train_accuracy: 0.58199 | val_accuracy: 0.56257 |  0:12:44s\n",
            "epoch 1478| loss: 0.8909  | train_accuracy: 0.58288 | val_accuracy: 0.57217 |  0:12:45s\n",
            "epoch 1479| loss: 0.8879  | train_accuracy: 0.58239 | val_accuracy: 0.56737 |  0:12:45s\n",
            "epoch 1480| loss: 0.89357 | train_accuracy: 0.5827  | val_accuracy: 0.56297 |  0:12:46s\n",
            "epoch 1481| loss: 0.89318 | train_accuracy: 0.57977 | val_accuracy: 0.56178 |  0:12:46s\n",
            "epoch 1482| loss: 0.89127 | train_accuracy: 0.58115 | val_accuracy: 0.56098 |  0:12:47s\n",
            "epoch 1483| loss: 0.89157 | train_accuracy: 0.58332 | val_accuracy: 0.56018 |  0:12:47s\n",
            "epoch 1484| loss: 0.89296 | train_accuracy: 0.57968 | val_accuracy: 0.55178 |  0:12:48s\n",
            "epoch 1485| loss: 0.8929  | train_accuracy: 0.5803  | val_accuracy: 0.56337 |  0:12:48s\n",
            "epoch 1486| loss: 0.89293 | train_accuracy: 0.57244 | val_accuracy: 0.54698 |  0:12:49s\n",
            "epoch 1487| loss: 0.89406 | train_accuracy: 0.58132 | val_accuracy: 0.56218 |  0:12:49s\n",
            "epoch 1488| loss: 0.8958  | train_accuracy: 0.58288 | val_accuracy: 0.55978 |  0:12:50s\n",
            "epoch 1489| loss: 0.88874 | train_accuracy: 0.58399 | val_accuracy: 0.55978 |  0:12:50s\n",
            "epoch 1490| loss: 0.89155 | train_accuracy: 0.58217 | val_accuracy: 0.55618 |  0:12:51s\n",
            "epoch 1491| loss: 0.89465 | train_accuracy: 0.58283 | val_accuracy: 0.56697 |  0:12:51s\n",
            "epoch 1492| loss: 0.89301 | train_accuracy: 0.58035 | val_accuracy: 0.56218 |  0:12:52s\n",
            "epoch 1493| loss: 0.89254 | train_accuracy: 0.58052 | val_accuracy: 0.56178 |  0:12:53s\n",
            "epoch 1494| loss: 0.89371 | train_accuracy: 0.57995 | val_accuracy: 0.55938 |  0:12:53s\n",
            "epoch 1495| loss: 0.89333 | train_accuracy: 0.57981 | val_accuracy: 0.55578 |  0:12:54s\n",
            "epoch 1496| loss: 0.89104 | train_accuracy: 0.58021 | val_accuracy: 0.56337 |  0:12:54s\n",
            "epoch 1497| loss: 0.89317 | train_accuracy: 0.57106 | val_accuracy: 0.55018 |  0:12:55s\n",
            "epoch 1498| loss: 0.89511 | train_accuracy: 0.57488 | val_accuracy: 0.54858 |  0:12:55s\n",
            "epoch 1499| loss: 0.89888 | train_accuracy: 0.58248 | val_accuracy: 0.56297 |  0:12:56s\n",
            "epoch 1500| loss: 0.89482 | train_accuracy: 0.58323 | val_accuracy: 0.55338 |  0:12:56s\n",
            "epoch 1501| loss: 0.89525 | train_accuracy: 0.58199 | val_accuracy: 0.55698 |  0:12:57s\n",
            "epoch 1502| loss: 0.89331 | train_accuracy: 0.58146 | val_accuracy: 0.55058 |  0:12:57s\n",
            "epoch 1503| loss: 0.89386 | train_accuracy: 0.58101 | val_accuracy: 0.56138 |  0:12:58s\n",
            "epoch 1504| loss: 0.89244 | train_accuracy: 0.58168 | val_accuracy: 0.56218 |  0:12:58s\n",
            "epoch 1505| loss: 0.89075 | train_accuracy: 0.57932 | val_accuracy: 0.56697 |  0:12:59s\n",
            "epoch 1506| loss: 0.89599 | train_accuracy: 0.58128 | val_accuracy: 0.56777 |  0:12:59s\n",
            "epoch 1507| loss: 0.89379 | train_accuracy: 0.5783  | val_accuracy: 0.55658 |  0:13:00s\n",
            "epoch 1508| loss: 0.89613 | train_accuracy: 0.57919 | val_accuracy: 0.56417 |  0:13:00s\n",
            "epoch 1509| loss: 0.89768 | train_accuracy: 0.57692 | val_accuracy: 0.56178 |  0:13:01s\n",
            "epoch 1510| loss: 0.89616 | train_accuracy: 0.57915 | val_accuracy: 0.56058 |  0:13:01s\n",
            "epoch 1511| loss: 0.8933  | train_accuracy: 0.58115 | val_accuracy: 0.57097 |  0:13:02s\n",
            "epoch 1512| loss: 0.89477 | train_accuracy: 0.57577 | val_accuracy: 0.56178 |  0:13:02s\n",
            "epoch 1513| loss: 0.8975  | train_accuracy: 0.57772 | val_accuracy: 0.56377 |  0:13:03s\n",
            "epoch 1514| loss: 0.89472 | train_accuracy: 0.57564 | val_accuracy: 0.55978 |  0:13:03s\n",
            "epoch 1515| loss: 0.89874 | train_accuracy: 0.57941 | val_accuracy: 0.56537 |  0:13:04s\n",
            "epoch 1516| loss: 0.89554 | train_accuracy: 0.5799  | val_accuracy: 0.56777 |  0:13:04s\n",
            "epoch 1517| loss: 0.89371 | train_accuracy: 0.57963 | val_accuracy: 0.56697 |  0:13:05s\n",
            "epoch 1518| loss: 0.89471 | train_accuracy: 0.58168 | val_accuracy: 0.56417 |  0:13:05s\n",
            "epoch 1519| loss: 0.89703 | train_accuracy: 0.58075 | val_accuracy: 0.56058 |  0:13:06s\n",
            "epoch 1520| loss: 0.89601 | train_accuracy: 0.5811  | val_accuracy: 0.56138 |  0:13:06s\n",
            "epoch 1521| loss: 0.8931  | train_accuracy: 0.58301 | val_accuracy: 0.56297 |  0:13:07s\n",
            "epoch 1522| loss: 0.89284 | train_accuracy: 0.57928 | val_accuracy: 0.55578 |  0:13:07s\n",
            "epoch 1523| loss: 0.89255 | train_accuracy: 0.58323 | val_accuracy: 0.56937 |  0:13:08s\n",
            "epoch 1524| loss: 0.89175 | train_accuracy: 0.58328 | val_accuracy: 0.56257 |  0:13:08s\n",
            "epoch 1525| loss: 0.89487 | train_accuracy: 0.5819  | val_accuracy: 0.56058 |  0:13:09s\n",
            "epoch 1526| loss: 0.89524 | train_accuracy: 0.58332 | val_accuracy: 0.57057 |  0:13:09s\n",
            "epoch 1527| loss: 0.89493 | train_accuracy: 0.58297 | val_accuracy: 0.57737 |  0:13:10s\n",
            "epoch 1528| loss: 0.89096 | train_accuracy: 0.58083 | val_accuracy: 0.56218 |  0:13:10s\n",
            "epoch 1529| loss: 0.88883 | train_accuracy: 0.58399 | val_accuracy: 0.56297 |  0:13:11s\n",
            "epoch 1530| loss: 0.8936  | train_accuracy: 0.58146 | val_accuracy: 0.56098 |  0:13:11s\n",
            "epoch 1531| loss: 0.89596 | train_accuracy: 0.58234 | val_accuracy: 0.56657 |  0:13:12s\n",
            "epoch 1532| loss: 0.8898  | train_accuracy: 0.58479 | val_accuracy: 0.56337 |  0:13:12s\n",
            "epoch 1533| loss: 0.89517 | train_accuracy: 0.58434 | val_accuracy: 0.56697 |  0:13:13s\n",
            "epoch 1534| loss: 0.89455 | train_accuracy: 0.5815  | val_accuracy: 0.56337 |  0:13:13s\n",
            "epoch 1535| loss: 0.8951  | train_accuracy: 0.58261 | val_accuracy: 0.56657 |  0:13:14s\n",
            "epoch 1536| loss: 0.8925  | train_accuracy: 0.5839  | val_accuracy: 0.57017 |  0:13:14s\n",
            "epoch 1537| loss: 0.89149 | train_accuracy: 0.58239 | val_accuracy: 0.56138 |  0:13:15s\n",
            "epoch 1538| loss: 0.89388 | train_accuracy: 0.58363 | val_accuracy: 0.56537 |  0:13:15s\n",
            "epoch 1539| loss: 0.8891  | train_accuracy: 0.57981 | val_accuracy: 0.55818 |  0:13:16s\n",
            "epoch 1540| loss: 0.89001 | train_accuracy: 0.58328 | val_accuracy: 0.56977 |  0:13:16s\n",
            "epoch 1541| loss: 0.89337 | train_accuracy: 0.58021 | val_accuracy: 0.56138 |  0:13:17s\n",
            "epoch 1542| loss: 0.89534 | train_accuracy: 0.58226 | val_accuracy: 0.56617 |  0:13:17s\n",
            "epoch 1543| loss: 0.8903  | train_accuracy: 0.58186 | val_accuracy: 0.56897 |  0:13:18s\n",
            "epoch 1544| loss: 0.88939 | train_accuracy: 0.58119 | val_accuracy: 0.56697 |  0:13:18s\n",
            "epoch 1545| loss: 0.89196 | train_accuracy: 0.5831  | val_accuracy: 0.57017 |  0:13:19s\n",
            "epoch 1546| loss: 0.89087 | train_accuracy: 0.5827  | val_accuracy: 0.56977 |  0:13:19s\n",
            "epoch 1547| loss: 0.89266 | train_accuracy: 0.58221 | val_accuracy: 0.57097 |  0:13:20s\n",
            "epoch 1548| loss: 0.89095 | train_accuracy: 0.58212 | val_accuracy: 0.56737 |  0:13:20s\n",
            "epoch 1549| loss: 0.89267 | train_accuracy: 0.58248 | val_accuracy: 0.57257 |  0:13:21s\n",
            "epoch 1550| loss: 0.89409 | train_accuracy: 0.58203 | val_accuracy: 0.56897 |  0:13:21s\n",
            "epoch 1551| loss: 0.89212 | train_accuracy: 0.58239 | val_accuracy: 0.56937 |  0:13:22s\n",
            "epoch 1552| loss: 0.89052 | train_accuracy: 0.58257 | val_accuracy: 0.56377 |  0:13:22s\n",
            "epoch 1553| loss: 0.8951  | train_accuracy: 0.58457 | val_accuracy: 0.57337 |  0:13:23s\n",
            "epoch 1554| loss: 0.89234 | train_accuracy: 0.58399 | val_accuracy: 0.56657 |  0:13:23s\n",
            "epoch 1555| loss: 0.89187 | train_accuracy: 0.58252 | val_accuracy: 0.57337 |  0:13:24s\n",
            "epoch 1556| loss: 0.89214 | train_accuracy: 0.58426 | val_accuracy: 0.56897 |  0:13:24s\n",
            "epoch 1557| loss: 0.89034 | train_accuracy: 0.58466 | val_accuracy: 0.57017 |  0:13:25s\n",
            "epoch 1558| loss: 0.89048 | train_accuracy: 0.58346 | val_accuracy: 0.56897 |  0:13:25s\n",
            "epoch 1559| loss: 0.89231 | train_accuracy: 0.5839  | val_accuracy: 0.56737 |  0:13:26s\n",
            "epoch 1560| loss: 0.89174 | train_accuracy: 0.58292 | val_accuracy: 0.56058 |  0:13:26s\n",
            "epoch 1561| loss: 0.89401 | train_accuracy: 0.58439 | val_accuracy: 0.56138 |  0:13:27s\n",
            "epoch 1562| loss: 0.89469 | train_accuracy: 0.58266 | val_accuracy: 0.56937 |  0:13:27s\n",
            "epoch 1563| loss: 0.88515 | train_accuracy: 0.58274 | val_accuracy: 0.56377 |  0:13:28s\n",
            "epoch 1564| loss: 0.89177 | train_accuracy: 0.58332 | val_accuracy: 0.57217 |  0:13:28s\n",
            "epoch 1565| loss: 0.89057 | train_accuracy: 0.58199 | val_accuracy: 0.56857 |  0:13:29s\n",
            "epoch 1566| loss: 0.8945  | train_accuracy: 0.58226 | val_accuracy: 0.56937 |  0:13:29s\n",
            "epoch 1567| loss: 0.8911  | train_accuracy: 0.58283 | val_accuracy: 0.57297 |  0:13:30s\n",
            "epoch 1568| loss: 0.88879 | train_accuracy: 0.58377 | val_accuracy: 0.57257 |  0:13:30s\n",
            "epoch 1569| loss: 0.89582 | train_accuracy: 0.58017 | val_accuracy: 0.56257 |  0:13:31s\n",
            "epoch 1570| loss: 0.89117 | train_accuracy: 0.58319 | val_accuracy: 0.56817 |  0:13:31s\n",
            "epoch 1571| loss: 0.88899 | train_accuracy: 0.58466 | val_accuracy: 0.56337 |  0:13:32s\n",
            "epoch 1572| loss: 0.89089 | train_accuracy: 0.5811  | val_accuracy: 0.56297 |  0:13:32s\n",
            "epoch 1573| loss: 0.89337 | train_accuracy: 0.58083 | val_accuracy: 0.56297 |  0:13:33s\n",
            "epoch 1574| loss: 0.89014 | train_accuracy: 0.58221 | val_accuracy: 0.56657 |  0:13:33s\n",
            "epoch 1575| loss: 0.89292 | train_accuracy: 0.58123 | val_accuracy: 0.55898 |  0:13:34s\n",
            "epoch 1576| loss: 0.89642 | train_accuracy: 0.58434 | val_accuracy: 0.56817 |  0:13:34s\n",
            "epoch 1577| loss: 0.89046 | train_accuracy: 0.58012 | val_accuracy: 0.55738 |  0:13:35s\n",
            "epoch 1578| loss: 0.8909  | train_accuracy: 0.58261 | val_accuracy: 0.56817 |  0:13:35s\n",
            "epoch 1579| loss: 0.89154 | train_accuracy: 0.58283 | val_accuracy: 0.56218 |  0:13:36s\n",
            "epoch 1580| loss: 0.89063 | train_accuracy: 0.5843  | val_accuracy: 0.56497 |  0:13:36s\n",
            "epoch 1581| loss: 0.88867 | train_accuracy: 0.58408 | val_accuracy: 0.57257 |  0:13:37s\n",
            "epoch 1582| loss: 0.88986 | train_accuracy: 0.58408 | val_accuracy: 0.56617 |  0:13:37s\n",
            "epoch 1583| loss: 0.89238 | train_accuracy: 0.58186 | val_accuracy: 0.56457 |  0:13:38s\n",
            "epoch 1584| loss: 0.89376 | train_accuracy: 0.58292 | val_accuracy: 0.56337 |  0:13:38s\n",
            "epoch 1585| loss: 0.89127 | train_accuracy: 0.58443 | val_accuracy: 0.56457 |  0:13:39s\n",
            "epoch 1586| loss: 0.89022 | train_accuracy: 0.58146 | val_accuracy: 0.56657 |  0:13:39s\n",
            "epoch 1587| loss: 0.89281 | train_accuracy: 0.58168 | val_accuracy: 0.56617 |  0:13:40s\n",
            "epoch 1588| loss: 0.89256 | train_accuracy: 0.58306 | val_accuracy: 0.56377 |  0:13:40s\n",
            "epoch 1589| loss: 0.89143 | train_accuracy: 0.58421 | val_accuracy: 0.56257 |  0:13:41s\n",
            "epoch 1590| loss: 0.89115 | train_accuracy: 0.58381 | val_accuracy: 0.56537 |  0:13:41s\n",
            "epoch 1591| loss: 0.89344 | train_accuracy: 0.58532 | val_accuracy: 0.56937 |  0:13:42s\n",
            "epoch 1592| loss: 0.88745 | train_accuracy: 0.58274 | val_accuracy: 0.56138 |  0:13:42s\n",
            "epoch 1593| loss: 0.8883  | train_accuracy: 0.58332 | val_accuracy: 0.56138 |  0:13:43s\n",
            "epoch 1594| loss: 0.88746 | train_accuracy: 0.58399 | val_accuracy: 0.56377 |  0:13:43s\n",
            "epoch 1595| loss: 0.89077 | train_accuracy: 0.58603 | val_accuracy: 0.56577 |  0:13:44s\n",
            "epoch 1596| loss: 0.88893 | train_accuracy: 0.58443 | val_accuracy: 0.56457 |  0:13:44s\n",
            "epoch 1597| loss: 0.89123 | train_accuracy: 0.5855  | val_accuracy: 0.55818 |  0:13:45s\n",
            "epoch 1598| loss: 0.8871  | train_accuracy: 0.58457 | val_accuracy: 0.56577 |  0:13:45s\n",
            "epoch 1599| loss: 0.88821 | train_accuracy: 0.58701 | val_accuracy: 0.56817 |  0:13:46s\n",
            "epoch 1600| loss: 0.89054 | train_accuracy: 0.58234 | val_accuracy: 0.56457 |  0:13:46s\n",
            "epoch 1601| loss: 0.89202 | train_accuracy: 0.58203 | val_accuracy: 0.56537 |  0:13:47s\n",
            "epoch 1602| loss: 0.89138 | train_accuracy: 0.58217 | val_accuracy: 0.56218 |  0:13:47s\n",
            "epoch 1603| loss: 0.89253 | train_accuracy: 0.57941 | val_accuracy: 0.56058 |  0:13:48s\n",
            "epoch 1604| loss: 0.89422 | train_accuracy: 0.57986 | val_accuracy: 0.56657 |  0:13:48s\n",
            "epoch 1605| loss: 0.89942 | train_accuracy: 0.58386 | val_accuracy: 0.55538 |  0:13:49s\n",
            "epoch 1606| loss: 0.89547 | train_accuracy: 0.58363 | val_accuracy: 0.55738 |  0:13:49s\n",
            "epoch 1607| loss: 0.8944  | train_accuracy: 0.58297 | val_accuracy: 0.55378 |  0:13:50s\n",
            "epoch 1608| loss: 0.89202 | train_accuracy: 0.58163 | val_accuracy: 0.55818 |  0:13:50s\n",
            "epoch 1609| loss: 0.89413 | train_accuracy: 0.58399 | val_accuracy: 0.55898 |  0:13:51s\n",
            "epoch 1610| loss: 0.89342 | train_accuracy: 0.58141 | val_accuracy: 0.55978 |  0:13:51s\n",
            "epoch 1611| loss: 0.89354 | train_accuracy: 0.58306 | val_accuracy: 0.55738 |  0:13:52s\n",
            "epoch 1612| loss: 0.89074 | train_accuracy: 0.58377 | val_accuracy: 0.55858 |  0:13:52s\n",
            "epoch 1613| loss: 0.89363 | train_accuracy: 0.58212 | val_accuracy: 0.56218 |  0:13:53s\n",
            "epoch 1614| loss: 0.89384 | train_accuracy: 0.5811  | val_accuracy: 0.56018 |  0:13:53s\n",
            "epoch 1615| loss: 0.89681 | train_accuracy: 0.57848 | val_accuracy: 0.55298 |  0:13:54s\n",
            "epoch 1616| loss: 0.8959  | train_accuracy: 0.57897 | val_accuracy: 0.55938 |  0:13:54s\n",
            "epoch 1617| loss: 0.89692 | train_accuracy: 0.5787  | val_accuracy: 0.55658 |  0:13:55s\n",
            "epoch 1618| loss: 0.89585 | train_accuracy: 0.57506 | val_accuracy: 0.56377 |  0:13:55s\n",
            "epoch 1619| loss: 0.89867 | train_accuracy: 0.57919 | val_accuracy: 0.56697 |  0:13:56s\n",
            "epoch 1620| loss: 0.89238 | train_accuracy: 0.58141 | val_accuracy: 0.56058 |  0:13:56s\n",
            "epoch 1621| loss: 0.89751 | train_accuracy: 0.58359 | val_accuracy: 0.56657 |  0:13:57s\n",
            "epoch 1622| loss: 0.89884 | train_accuracy: 0.58274 | val_accuracy: 0.56098 |  0:13:57s\n",
            "epoch 1623| loss: 0.89449 | train_accuracy: 0.57804 | val_accuracy: 0.55978 |  0:13:58s\n",
            "epoch 1624| loss: 0.89692 | train_accuracy: 0.57955 | val_accuracy: 0.56058 |  0:13:58s\n",
            "epoch 1625| loss: 0.89586 | train_accuracy: 0.57821 | val_accuracy: 0.56018 |  0:13:59s\n",
            "epoch 1626| loss: 0.89677 | train_accuracy: 0.58043 | val_accuracy: 0.56257 |  0:13:59s\n",
            "epoch 1627| loss: 0.89508 | train_accuracy: 0.58212 | val_accuracy: 0.56098 |  0:14:00s\n",
            "epoch 1628| loss: 0.89691 | train_accuracy: 0.57932 | val_accuracy: 0.54658 |  0:14:00s\n",
            "epoch 1629| loss: 0.89728 | train_accuracy: 0.58168 | val_accuracy: 0.55698 |  0:14:01s\n",
            "epoch 1630| loss: 0.89335 | train_accuracy: 0.58141 | val_accuracy: 0.55818 |  0:14:01s\n",
            "epoch 1631| loss: 0.89356 | train_accuracy: 0.58314 | val_accuracy: 0.55458 |  0:14:02s\n",
            "epoch 1632| loss: 0.89657 | train_accuracy: 0.58097 | val_accuracy: 0.55538 |  0:14:02s\n",
            "epoch 1633| loss: 0.89402 | train_accuracy: 0.57981 | val_accuracy: 0.55498 |  0:14:03s\n",
            "epoch 1634| loss: 0.89386 | train_accuracy: 0.58066 | val_accuracy: 0.56178 |  0:14:03s\n",
            "epoch 1635| loss: 0.89405 | train_accuracy: 0.58137 | val_accuracy: 0.56337 |  0:14:04s\n",
            "epoch 1636| loss: 0.8946  | train_accuracy: 0.58226 | val_accuracy: 0.55898 |  0:14:04s\n",
            "epoch 1637| loss: 0.89571 | train_accuracy: 0.58377 | val_accuracy: 0.56098 |  0:14:05s\n",
            "epoch 1638| loss: 0.89172 | train_accuracy: 0.58288 | val_accuracy: 0.56617 |  0:14:05s\n",
            "epoch 1639| loss: 0.89129 | train_accuracy: 0.58234 | val_accuracy: 0.56178 |  0:14:06s\n",
            "epoch 1640| loss: 0.88833 | train_accuracy: 0.57968 | val_accuracy: 0.56657 |  0:14:06s\n",
            "epoch 1641| loss: 0.8943  | train_accuracy: 0.5831  | val_accuracy: 0.56297 |  0:14:07s\n",
            "epoch 1642| loss: 0.89299 | train_accuracy: 0.5815  | val_accuracy: 0.56537 |  0:14:07s\n",
            "epoch 1643| loss: 0.89057 | train_accuracy: 0.58301 | val_accuracy: 0.56297 |  0:14:08s\n",
            "epoch 1644| loss: 0.89465 | train_accuracy: 0.58035 | val_accuracy: 0.56377 |  0:14:08s\n",
            "epoch 1645| loss: 0.89538 | train_accuracy: 0.58119 | val_accuracy: 0.56098 |  0:14:09s\n",
            "epoch 1646| loss: 0.89482 | train_accuracy: 0.58079 | val_accuracy: 0.56377 |  0:14:09s\n",
            "epoch 1647| loss: 0.89428 | train_accuracy: 0.5827  | val_accuracy: 0.56098 |  0:14:10s\n",
            "epoch 1648| loss: 0.89107 | train_accuracy: 0.58292 | val_accuracy: 0.56138 |  0:14:10s\n",
            "epoch 1649| loss: 0.89308 | train_accuracy: 0.58226 | val_accuracy: 0.56098 |  0:14:11s\n",
            "epoch 1650| loss: 0.89131 | train_accuracy: 0.58092 | val_accuracy: 0.56138 |  0:14:11s\n",
            "epoch 1651| loss: 0.89075 | train_accuracy: 0.58163 | val_accuracy: 0.56697 |  0:14:12s\n",
            "epoch 1652| loss: 0.8944  | train_accuracy: 0.58288 | val_accuracy: 0.56257 |  0:14:12s\n",
            "epoch 1653| loss: 0.89282 | train_accuracy: 0.5839  | val_accuracy: 0.56417 |  0:14:13s\n",
            "epoch 1654| loss: 0.89351 | train_accuracy: 0.58314 | val_accuracy: 0.56377 |  0:14:13s\n",
            "epoch 1655| loss: 0.89448 | train_accuracy: 0.58123 | val_accuracy: 0.55858 |  0:14:14s\n",
            "epoch 1656| loss: 0.89055 | train_accuracy: 0.5819  | val_accuracy: 0.56417 |  0:14:14s\n",
            "epoch 1657| loss: 0.88919 | train_accuracy: 0.58146 | val_accuracy: 0.56617 |  0:14:15s\n",
            "epoch 1658| loss: 0.89118 | train_accuracy: 0.58217 | val_accuracy: 0.55778 |  0:14:15s\n",
            "epoch 1659| loss: 0.89384 | train_accuracy: 0.5807  | val_accuracy: 0.56657 |  0:14:16s\n",
            "epoch 1660| loss: 0.89314 | train_accuracy: 0.57892 | val_accuracy: 0.56178 |  0:14:16s\n",
            "epoch 1661| loss: 0.89708 | train_accuracy: 0.57661 | val_accuracy: 0.56337 |  0:14:17s\n",
            "epoch 1662| loss: 0.89813 | train_accuracy: 0.57755 | val_accuracy: 0.56337 |  0:14:17s\n",
            "epoch 1663| loss: 0.89749 | train_accuracy: 0.57786 | val_accuracy: 0.55938 |  0:14:18s\n",
            "epoch 1664| loss: 0.89867 | train_accuracy: 0.58003 | val_accuracy: 0.56537 |  0:14:18s\n",
            "epoch 1665| loss: 0.89701 | train_accuracy: 0.57888 | val_accuracy: 0.55938 |  0:14:19s\n",
            "epoch 1666| loss: 0.89438 | train_accuracy: 0.57941 | val_accuracy: 0.56417 |  0:14:19s\n",
            "epoch 1667| loss: 0.89547 | train_accuracy: 0.57955 | val_accuracy: 0.56257 |  0:14:20s\n",
            "epoch 1668| loss: 0.89453 | train_accuracy: 0.57799 | val_accuracy: 0.56377 |  0:14:20s\n",
            "epoch 1669| loss: 0.89721 | train_accuracy: 0.57995 | val_accuracy: 0.56218 |  0:14:21s\n",
            "epoch 1670| loss: 0.89872 | train_accuracy: 0.5795  | val_accuracy: 0.56058 |  0:14:21s\n",
            "epoch 1671| loss: 0.89192 | train_accuracy: 0.5795  | val_accuracy: 0.56098 |  0:14:22s\n",
            "epoch 1672| loss: 0.89277 | train_accuracy: 0.5807  | val_accuracy: 0.56337 |  0:14:22s\n",
            "epoch 1673| loss: 0.89594 | train_accuracy: 0.58066 | val_accuracy: 0.56337 |  0:14:23s\n",
            "epoch 1674| loss: 0.89625 | train_accuracy: 0.5815  | val_accuracy: 0.56497 |  0:14:23s\n",
            "epoch 1675| loss: 0.89142 | train_accuracy: 0.5815  | val_accuracy: 0.56497 |  0:14:24s\n",
            "epoch 1676| loss: 0.89596 | train_accuracy: 0.57968 | val_accuracy: 0.56537 |  0:14:24s\n",
            "epoch 1677| loss: 0.8935  | train_accuracy: 0.57972 | val_accuracy: 0.56697 |  0:14:25s\n",
            "epoch 1678| loss: 0.89377 | train_accuracy: 0.5823  | val_accuracy: 0.56737 |  0:14:25s\n",
            "epoch 1679| loss: 0.8906  | train_accuracy: 0.58155 | val_accuracy: 0.56497 |  0:14:26s\n",
            "epoch 1680| loss: 0.89448 | train_accuracy: 0.58057 | val_accuracy: 0.56377 |  0:14:27s\n",
            "epoch 1681| loss: 0.89414 | train_accuracy: 0.58101 | val_accuracy: 0.57057 |  0:14:28s\n",
            "epoch 1682| loss: 0.89286 | train_accuracy: 0.57866 | val_accuracy: 0.56218 |  0:14:30s\n",
            "epoch 1683| loss: 0.89194 | train_accuracy: 0.58243 | val_accuracy: 0.56178 |  0:14:31s\n",
            "epoch 1684| loss: 0.89314 | train_accuracy: 0.58101 | val_accuracy: 0.56777 |  0:14:32s\n",
            "epoch 1685| loss: 0.8931  | train_accuracy: 0.58194 | val_accuracy: 0.56337 |  0:14:32s\n",
            "epoch 1686| loss: 0.89039 | train_accuracy: 0.58163 | val_accuracy: 0.56577 |  0:14:32s\n",
            "epoch 1687| loss: 0.89247 | train_accuracy: 0.58319 | val_accuracy: 0.56977 |  0:14:33s\n",
            "epoch 1688| loss: 0.88758 | train_accuracy: 0.58372 | val_accuracy: 0.57257 |  0:14:34s\n",
            "epoch 1689| loss: 0.88932 | train_accuracy: 0.58337 | val_accuracy: 0.56897 |  0:14:34s\n",
            "epoch 1690| loss: 0.88953 | train_accuracy: 0.58314 | val_accuracy: 0.56897 |  0:14:35s\n",
            "epoch 1691| loss: 0.89076 | train_accuracy: 0.58057 | val_accuracy: 0.56417 |  0:14:35s\n",
            "epoch 1692| loss: 0.88975 | train_accuracy: 0.58297 | val_accuracy: 0.56577 |  0:14:36s\n",
            "epoch 1693| loss: 0.8916  | train_accuracy: 0.57781 | val_accuracy: 0.56098 |  0:14:36s\n",
            "epoch 1694| loss: 0.89139 | train_accuracy: 0.58039 | val_accuracy: 0.56857 |  0:14:37s\n",
            "epoch 1695| loss: 0.89051 | train_accuracy: 0.57915 | val_accuracy: 0.57777 |  0:14:37s\n",
            "epoch 1696| loss: 0.88848 | train_accuracy: 0.58052 | val_accuracy: 0.56897 |  0:14:38s\n",
            "epoch 1697| loss: 0.89252 | train_accuracy: 0.58026 | val_accuracy: 0.57057 |  0:14:38s\n",
            "epoch 1698| loss: 0.89052 | train_accuracy: 0.58346 | val_accuracy: 0.56617 |  0:14:39s\n",
            "epoch 1699| loss: 0.89224 | train_accuracy: 0.58381 | val_accuracy: 0.56577 |  0:14:39s\n",
            "epoch 1700| loss: 0.89002 | train_accuracy: 0.58314 | val_accuracy: 0.56337 |  0:14:40s\n",
            "epoch 1701| loss: 0.89565 | train_accuracy: 0.58079 | val_accuracy: 0.56297 |  0:14:40s\n",
            "epoch 1702| loss: 0.89405 | train_accuracy: 0.58106 | val_accuracy: 0.56657 |  0:14:41s\n",
            "epoch 1703| loss: 0.89165 | train_accuracy: 0.58243 | val_accuracy: 0.56657 |  0:14:41s\n",
            "epoch 1704| loss: 0.89197 | train_accuracy: 0.58359 | val_accuracy: 0.56857 |  0:14:42s\n",
            "epoch 1705| loss: 0.89116 | train_accuracy: 0.5827  | val_accuracy: 0.56577 |  0:14:42s\n",
            "epoch 1706| loss: 0.88946 | train_accuracy: 0.58212 | val_accuracy: 0.56657 |  0:14:43s\n",
            "epoch 1707| loss: 0.88829 | train_accuracy: 0.58088 | val_accuracy: 0.56617 |  0:14:43s\n",
            "epoch 1708| loss: 0.89141 | train_accuracy: 0.58319 | val_accuracy: 0.56897 |  0:14:44s\n",
            "epoch 1709| loss: 0.89181 | train_accuracy: 0.58292 | val_accuracy: 0.56857 |  0:14:44s\n",
            "epoch 1710| loss: 0.88714 | train_accuracy: 0.58106 | val_accuracy: 0.56297 |  0:14:45s\n",
            "epoch 1711| loss: 0.89308 | train_accuracy: 0.58306 | val_accuracy: 0.56297 |  0:14:45s\n",
            "epoch 1712| loss: 0.88982 | train_accuracy: 0.58168 | val_accuracy: 0.56697 |  0:14:46s\n",
            "epoch 1713| loss: 0.89023 | train_accuracy: 0.58159 | val_accuracy: 0.56018 |  0:14:46s\n",
            "epoch 1714| loss: 0.89107 | train_accuracy: 0.58079 | val_accuracy: 0.55978 |  0:14:47s\n",
            "epoch 1715| loss: 0.89035 | train_accuracy: 0.58261 | val_accuracy: 0.56297 |  0:14:47s\n",
            "epoch 1716| loss: 0.88946 | train_accuracy: 0.5839  | val_accuracy: 0.56537 |  0:14:48s\n",
            "epoch 1717| loss: 0.89062 | train_accuracy: 0.58239 | val_accuracy: 0.56257 |  0:14:48s\n",
            "epoch 1718| loss: 0.88728 | train_accuracy: 0.58194 | val_accuracy: 0.56297 |  0:14:49s\n",
            "epoch 1719| loss: 0.88901 | train_accuracy: 0.58239 | val_accuracy: 0.56577 |  0:14:49s\n",
            "epoch 1720| loss: 0.89242 | train_accuracy: 0.58194 | val_accuracy: 0.56697 |  0:14:50s\n",
            "epoch 1721| loss: 0.89    | train_accuracy: 0.58159 | val_accuracy: 0.56817 |  0:14:50s\n",
            "epoch 1722| loss: 0.89006 | train_accuracy: 0.58199 | val_accuracy: 0.56937 |  0:14:51s\n",
            "epoch 1723| loss: 0.89032 | train_accuracy: 0.58217 | val_accuracy: 0.56018 |  0:14:51s\n",
            "epoch 1724| loss: 0.88987 | train_accuracy: 0.5819  | val_accuracy: 0.55858 |  0:14:52s\n",
            "epoch 1725| loss: 0.88559 | train_accuracy: 0.58088 | val_accuracy: 0.55738 |  0:14:52s\n",
            "epoch 1726| loss: 0.89165 | train_accuracy: 0.58403 | val_accuracy: 0.56537 |  0:14:53s\n",
            "epoch 1727| loss: 0.88928 | train_accuracy: 0.58132 | val_accuracy: 0.56178 |  0:14:53s\n",
            "epoch 1728| loss: 0.88989 | train_accuracy: 0.58279 | val_accuracy: 0.56497 |  0:14:54s\n",
            "epoch 1729| loss: 0.89152 | train_accuracy: 0.58266 | val_accuracy: 0.56178 |  0:14:54s\n",
            "epoch 1730| loss: 0.88742 | train_accuracy: 0.58408 | val_accuracy: 0.56657 |  0:14:55s\n",
            "epoch 1731| loss: 0.88749 | train_accuracy: 0.5839  | val_accuracy: 0.56537 |  0:14:55s\n",
            "epoch 1732| loss: 0.8896  | train_accuracy: 0.58337 | val_accuracy: 0.56737 |  0:14:56s\n",
            "epoch 1733| loss: 0.88846 | train_accuracy: 0.58274 | val_accuracy: 0.56417 |  0:14:56s\n",
            "epoch 1734| loss: 0.89629 | train_accuracy: 0.58332 | val_accuracy: 0.56817 |  0:14:57s\n",
            "epoch 1735| loss: 0.88906 | train_accuracy: 0.58479 | val_accuracy: 0.56897 |  0:14:57s\n",
            "epoch 1736| loss: 0.88779 | train_accuracy: 0.58377 | val_accuracy: 0.56777 |  0:14:58s\n",
            "epoch 1737| loss: 0.89018 | train_accuracy: 0.58368 | val_accuracy: 0.56737 |  0:14:58s\n",
            "epoch 1738| loss: 0.89049 | train_accuracy: 0.58466 | val_accuracy: 0.56857 |  0:14:59s\n",
            "epoch 1739| loss: 0.88878 | train_accuracy: 0.58417 | val_accuracy: 0.56617 |  0:14:59s\n",
            "epoch 1740| loss: 0.89016 | train_accuracy: 0.58354 | val_accuracy: 0.56337 |  0:15:00s\n",
            "epoch 1741| loss: 0.89024 | train_accuracy: 0.58532 | val_accuracy: 0.57177 |  0:15:00s\n",
            "epoch 1742| loss: 0.88702 | train_accuracy: 0.58337 | val_accuracy: 0.56777 |  0:15:01s\n",
            "epoch 1743| loss: 0.88721 | train_accuracy: 0.58328 | val_accuracy: 0.56697 |  0:15:01s\n",
            "epoch 1744| loss: 0.88472 | train_accuracy: 0.58381 | val_accuracy: 0.56657 |  0:15:02s\n",
            "epoch 1745| loss: 0.88671 | train_accuracy: 0.58585 | val_accuracy: 0.56417 |  0:15:02s\n",
            "epoch 1746| loss: 0.88753 | train_accuracy: 0.58421 | val_accuracy: 0.56737 |  0:15:03s\n",
            "epoch 1747| loss: 0.88743 | train_accuracy: 0.58328 | val_accuracy: 0.57017 |  0:15:03s\n",
            "epoch 1748| loss: 0.89237 | train_accuracy: 0.58421 | val_accuracy: 0.56857 |  0:15:04s\n",
            "epoch 1749| loss: 0.88673 | train_accuracy: 0.58386 | val_accuracy: 0.56577 |  0:15:04s\n",
            "epoch 1750| loss: 0.88737 | train_accuracy: 0.58474 | val_accuracy: 0.56537 |  0:15:05s\n",
            "epoch 1751| loss: 0.88864 | train_accuracy: 0.58381 | val_accuracy: 0.56777 |  0:15:05s\n",
            "epoch 1752| loss: 0.89003 | train_accuracy: 0.58474 | val_accuracy: 0.56138 |  0:15:06s\n",
            "epoch 1753| loss: 0.88848 | train_accuracy: 0.58483 | val_accuracy: 0.56737 |  0:15:06s\n",
            "epoch 1754| loss: 0.88787 | train_accuracy: 0.58528 | val_accuracy: 0.56657 |  0:15:07s\n",
            "epoch 1755| loss: 0.89299 | train_accuracy: 0.58306 | val_accuracy: 0.55898 |  0:15:07s\n",
            "epoch 1756| loss: 0.88909 | train_accuracy: 0.5839  | val_accuracy: 0.56857 |  0:15:08s\n",
            "epoch 1757| loss: 0.89056 | train_accuracy: 0.58394 | val_accuracy: 0.56857 |  0:15:08s\n",
            "epoch 1758| loss: 0.8886  | train_accuracy: 0.58608 | val_accuracy: 0.56897 |  0:15:09s\n",
            "epoch 1759| loss: 0.8905  | train_accuracy: 0.58261 | val_accuracy: 0.55858 |  0:15:09s\n",
            "epoch 1760| loss: 0.88759 | train_accuracy: 0.58292 | val_accuracy: 0.55818 |  0:15:10s\n",
            "epoch 1761| loss: 0.89064 | train_accuracy: 0.58523 | val_accuracy: 0.56377 |  0:15:10s\n",
            "epoch 1762| loss: 0.88639 | train_accuracy: 0.58261 | val_accuracy: 0.55978 |  0:15:11s\n",
            "epoch 1763| loss: 0.89245 | train_accuracy: 0.58252 | val_accuracy: 0.56297 |  0:15:11s\n",
            "epoch 1764| loss: 0.88752 | train_accuracy: 0.58363 | val_accuracy: 0.56138 |  0:15:12s\n",
            "epoch 1765| loss: 0.89103 | train_accuracy: 0.58172 | val_accuracy: 0.55898 |  0:15:12s\n",
            "epoch 1766| loss: 0.88857 | train_accuracy: 0.58386 | val_accuracy: 0.56777 |  0:15:13s\n",
            "epoch 1767| loss: 0.89091 | train_accuracy: 0.58328 | val_accuracy: 0.55818 |  0:15:13s\n",
            "epoch 1768| loss: 0.89035 | train_accuracy: 0.58372 | val_accuracy: 0.56218 |  0:15:14s\n",
            "epoch 1769| loss: 0.89215 | train_accuracy: 0.58457 | val_accuracy: 0.56098 |  0:15:14s\n",
            "epoch 1770| loss: 0.88964 | train_accuracy: 0.58488 | val_accuracy: 0.55378 |  0:15:15s\n",
            "epoch 1771| loss: 0.88707 | train_accuracy: 0.58692 | val_accuracy: 0.56977 |  0:15:15s\n",
            "epoch 1772| loss: 0.88868 | train_accuracy: 0.58697 | val_accuracy: 0.56497 |  0:15:16s\n",
            "epoch 1773| loss: 0.88674 | train_accuracy: 0.58634 | val_accuracy: 0.57057 |  0:15:16s\n",
            "epoch 1774| loss: 0.89085 | train_accuracy: 0.58603 | val_accuracy: 0.56857 |  0:15:17s\n",
            "epoch 1775| loss: 0.88732 | train_accuracy: 0.58399 | val_accuracy: 0.56777 |  0:15:17s\n",
            "epoch 1776| loss: 0.88855 | train_accuracy: 0.58554 | val_accuracy: 0.57177 |  0:15:18s\n",
            "epoch 1777| loss: 0.88834 | train_accuracy: 0.58479 | val_accuracy: 0.55778 |  0:15:18s\n",
            "epoch 1778| loss: 0.88866 | train_accuracy: 0.58674 | val_accuracy: 0.56617 |  0:15:19s\n",
            "epoch 1779| loss: 0.89065 | train_accuracy: 0.58474 | val_accuracy: 0.56857 |  0:15:19s\n",
            "epoch 1780| loss: 0.88782 | train_accuracy: 0.5847  | val_accuracy: 0.56817 |  0:15:20s\n",
            "epoch 1781| loss: 0.89076 | train_accuracy: 0.58261 | val_accuracy: 0.56737 |  0:15:20s\n",
            "epoch 1782| loss: 0.88891 | train_accuracy: 0.58443 | val_accuracy: 0.56817 |  0:15:21s\n",
            "epoch 1783| loss: 0.88729 | train_accuracy: 0.58394 | val_accuracy: 0.56417 |  0:15:21s\n",
            "epoch 1784| loss: 0.88869 | train_accuracy: 0.58439 | val_accuracy: 0.56537 |  0:15:22s\n",
            "epoch 1785| loss: 0.88602 | train_accuracy: 0.58328 | val_accuracy: 0.56657 |  0:15:22s\n",
            "epoch 1786| loss: 0.88957 | train_accuracy: 0.58252 | val_accuracy: 0.56657 |  0:15:23s\n",
            "epoch 1787| loss: 0.88851 | train_accuracy: 0.58372 | val_accuracy: 0.56657 |  0:15:23s\n",
            "epoch 1788| loss: 0.88426 | train_accuracy: 0.58492 | val_accuracy: 0.56457 |  0:15:24s\n",
            "epoch 1789| loss: 0.89048 | train_accuracy: 0.58594 | val_accuracy: 0.56897 |  0:15:24s\n",
            "epoch 1790| loss: 0.88701 | train_accuracy: 0.58346 | val_accuracy: 0.56617 |  0:15:25s\n",
            "epoch 1791| loss: 0.88903 | train_accuracy: 0.58417 | val_accuracy: 0.56577 |  0:15:25s\n",
            "epoch 1792| loss: 0.88727 | train_accuracy: 0.58408 | val_accuracy: 0.56537 |  0:15:26s\n",
            "epoch 1793| loss: 0.88722 | train_accuracy: 0.58306 | val_accuracy: 0.56457 |  0:15:26s\n",
            "epoch 1794| loss: 0.8904  | train_accuracy: 0.58426 | val_accuracy: 0.56777 |  0:15:27s\n",
            "epoch 1795| loss: 0.88713 | train_accuracy: 0.58403 | val_accuracy: 0.56897 |  0:15:27s\n",
            "epoch 1796| loss: 0.88761 | train_accuracy: 0.58403 | val_accuracy: 0.56497 |  0:15:28s\n",
            "epoch 1797| loss: 0.88498 | train_accuracy: 0.58412 | val_accuracy: 0.56897 |  0:15:28s\n",
            "epoch 1798| loss: 0.88693 | train_accuracy: 0.58381 | val_accuracy: 0.57057 |  0:15:29s\n",
            "epoch 1799| loss: 0.88922 | train_accuracy: 0.5847  | val_accuracy: 0.57377 |  0:15:29s\n",
            "epoch 1800| loss: 0.88741 | train_accuracy: 0.58452 | val_accuracy: 0.56937 |  0:15:30s\n",
            "epoch 1801| loss: 0.88755 | train_accuracy: 0.58252 | val_accuracy: 0.57377 |  0:15:30s\n",
            "epoch 1802| loss: 0.89203 | train_accuracy: 0.58181 | val_accuracy: 0.56617 |  0:15:31s\n",
            "epoch 1803| loss: 0.89144 | train_accuracy: 0.58523 | val_accuracy: 0.57017 |  0:15:31s\n",
            "epoch 1804| loss: 0.89101 | train_accuracy: 0.58643 | val_accuracy: 0.56577 |  0:15:32s\n",
            "epoch 1805| loss: 0.88942 | train_accuracy: 0.58274 | val_accuracy: 0.56417 |  0:15:33s\n",
            "epoch 1806| loss: 0.89244 | train_accuracy: 0.58261 | val_accuracy: 0.56577 |  0:15:33s\n",
            "epoch 1807| loss: 0.88687 | train_accuracy: 0.58283 | val_accuracy: 0.56058 |  0:15:33s\n",
            "epoch 1808| loss: 0.89217 | train_accuracy: 0.58203 | val_accuracy: 0.56178 |  0:15:34s\n",
            "epoch 1809| loss: 0.88896 | train_accuracy: 0.57959 | val_accuracy: 0.55298 |  0:15:34s\n",
            "epoch 1810| loss: 0.88891 | train_accuracy: 0.58186 | val_accuracy: 0.56777 |  0:15:35s\n",
            "epoch 1811| loss: 0.89129 | train_accuracy: 0.58288 | val_accuracy: 0.55578 |  0:15:35s\n",
            "epoch 1812| loss: 0.89213 | train_accuracy: 0.58168 | val_accuracy: 0.56537 |  0:15:36s\n",
            "epoch 1813| loss: 0.89157 | train_accuracy: 0.58292 | val_accuracy: 0.56297 |  0:15:37s\n",
            "epoch 1814| loss: 0.88965 | train_accuracy: 0.58052 | val_accuracy: 0.55498 |  0:15:37s\n",
            "epoch 1815| loss: 0.88904 | train_accuracy: 0.58412 | val_accuracy: 0.57097 |  0:15:37s\n",
            "epoch 1816| loss: 0.89046 | train_accuracy: 0.58115 | val_accuracy: 0.55738 |  0:15:38s\n",
            "epoch 1817| loss: 0.89066 | train_accuracy: 0.58221 | val_accuracy: 0.57217 |  0:15:38s\n",
            "epoch 1818| loss: 0.88949 | train_accuracy: 0.58101 | val_accuracy: 0.55938 |  0:15:39s\n",
            "epoch 1819| loss: 0.89262 | train_accuracy: 0.58115 | val_accuracy: 0.56337 |  0:15:40s\n",
            "epoch 1820| loss: 0.88973 | train_accuracy: 0.58341 | val_accuracy: 0.56617 |  0:15:40s\n",
            "epoch 1821| loss: 0.89536 | train_accuracy: 0.58234 | val_accuracy: 0.56018 |  0:15:41s\n",
            "epoch 1822| loss: 0.88764 | train_accuracy: 0.58168 | val_accuracy: 0.55498 |  0:15:41s\n",
            "epoch 1823| loss: 0.89128 | train_accuracy: 0.58479 | val_accuracy: 0.56537 |  0:15:42s\n",
            "epoch 1824| loss: 0.89357 | train_accuracy: 0.58332 | val_accuracy: 0.55858 |  0:15:42s\n",
            "epoch 1825| loss: 0.89114 | train_accuracy: 0.58003 | val_accuracy: 0.56218 |  0:15:43s\n",
            "epoch 1826| loss: 0.89936 | train_accuracy: 0.57875 | val_accuracy: 0.55778 |  0:15:43s\n",
            "epoch 1827| loss: 0.89638 | train_accuracy: 0.58012 | val_accuracy: 0.55338 |  0:15:43s\n",
            "epoch 1828| loss: 0.89316 | train_accuracy: 0.57599 | val_accuracy: 0.56697 |  0:15:44s\n",
            "epoch 1829| loss: 0.89382 | train_accuracy: 0.5783  | val_accuracy: 0.56377 |  0:15:44s\n",
            "epoch 1830| loss: 0.8969  | train_accuracy: 0.57861 | val_accuracy: 0.56417 |  0:15:45s\n",
            "epoch 1831| loss: 0.89618 | train_accuracy: 0.57928 | val_accuracy: 0.56617 |  0:15:46s\n",
            "epoch 1832| loss: 0.89738 | train_accuracy: 0.58043 | val_accuracy: 0.56337 |  0:15:46s\n",
            "epoch 1833| loss: 0.88897 | train_accuracy: 0.58021 | val_accuracy: 0.56337 |  0:15:47s\n",
            "epoch 1834| loss: 0.89588 | train_accuracy: 0.57928 | val_accuracy: 0.56737 |  0:15:47s\n",
            "epoch 1835| loss: 0.89095 | train_accuracy: 0.58119 | val_accuracy: 0.56257 |  0:15:48s\n",
            "epoch 1836| loss: 0.8969  | train_accuracy: 0.58137 | val_accuracy: 0.56457 |  0:15:48s\n",
            "epoch 1837| loss: 0.89651 | train_accuracy: 0.58052 | val_accuracy: 0.55858 |  0:15:49s\n",
            "epoch 1838| loss: 0.89143 | train_accuracy: 0.58226 | val_accuracy: 0.56617 |  0:15:49s\n",
            "epoch 1839| loss: 0.89377 | train_accuracy: 0.57706 | val_accuracy: 0.55018 |  0:15:50s\n",
            "epoch 1840| loss: 0.89581 | train_accuracy: 0.5783  | val_accuracy: 0.55938 |  0:15:50s\n",
            "epoch 1841| loss: 0.89426 | train_accuracy: 0.57817 | val_accuracy: 0.56417 |  0:15:51s\n",
            "epoch 1842| loss: 0.89521 | train_accuracy: 0.57772 | val_accuracy: 0.55978 |  0:15:51s\n",
            "epoch 1843| loss: 0.89764 | train_accuracy: 0.57919 | val_accuracy: 0.56697 |  0:15:52s\n",
            "epoch 1844| loss: 0.89779 | train_accuracy: 0.57613 | val_accuracy: 0.55258 |  0:15:52s\n",
            "epoch 1845| loss: 0.90131 | train_accuracy: 0.57635 | val_accuracy: 0.55938 |  0:15:53s\n",
            "epoch 1846| loss: 0.89482 | train_accuracy: 0.57888 | val_accuracy: 0.55658 |  0:15:53s\n",
            "epoch 1847| loss: 0.89953 | train_accuracy: 0.57941 | val_accuracy: 0.56257 |  0:15:54s\n",
            "epoch 1848| loss: 0.89728 | train_accuracy: 0.57608 | val_accuracy: 0.55178 |  0:15:54s\n",
            "epoch 1849| loss: 0.89673 | train_accuracy: 0.57866 | val_accuracy: 0.55378 |  0:15:55s\n",
            "epoch 1850| loss: 0.8967  | train_accuracy: 0.57981 | val_accuracy: 0.55658 |  0:15:55s\n",
            "epoch 1851| loss: 0.89464 | train_accuracy: 0.58106 | val_accuracy: 0.55818 |  0:15:56s\n",
            "epoch 1852| loss: 0.89093 | train_accuracy: 0.58083 | val_accuracy: 0.55978 |  0:15:56s\n",
            "epoch 1853| loss: 0.89193 | train_accuracy: 0.5827  | val_accuracy: 0.55978 |  0:15:57s\n",
            "epoch 1854| loss: 0.89501 | train_accuracy: 0.58048 | val_accuracy: 0.55738 |  0:15:57s\n",
            "epoch 1855| loss: 0.89732 | train_accuracy: 0.58092 | val_accuracy: 0.56058 |  0:15:58s\n",
            "epoch 1856| loss: 0.89398 | train_accuracy: 0.58097 | val_accuracy: 0.56297 |  0:15:59s\n",
            "epoch 1857| loss: 0.89297 | train_accuracy: 0.5803  | val_accuracy: 0.56018 |  0:15:59s\n",
            "epoch 1858| loss: 0.88752 | train_accuracy: 0.58035 | val_accuracy: 0.56417 |  0:15:59s\n",
            "epoch 1859| loss: 0.89478 | train_accuracy: 0.57857 | val_accuracy: 0.55498 |  0:16:00s\n",
            "epoch 1860| loss: 0.89314 | train_accuracy: 0.57835 | val_accuracy: 0.55538 |  0:16:01s\n",
            "epoch 1861| loss: 0.89176 | train_accuracy: 0.57981 | val_accuracy: 0.56257 |  0:16:01s\n",
            "epoch 1862| loss: 0.89196 | train_accuracy: 0.58177 | val_accuracy: 0.56218 |  0:16:02s\n",
            "epoch 1863| loss: 0.89474 | train_accuracy: 0.57901 | val_accuracy: 0.55898 |  0:16:02s\n",
            "epoch 1864| loss: 0.89495 | train_accuracy: 0.58012 | val_accuracy: 0.55898 |  0:16:02s\n",
            "epoch 1865| loss: 0.89225 | train_accuracy: 0.5795  | val_accuracy: 0.55938 |  0:16:03s\n",
            "epoch 1866| loss: 0.89415 | train_accuracy: 0.57808 | val_accuracy: 0.55418 |  0:16:03s\n",
            "epoch 1867| loss: 0.89541 | train_accuracy: 0.57835 | val_accuracy: 0.55498 |  0:16:04s\n",
            "epoch 1868| loss: 0.89243 | train_accuracy: 0.57928 | val_accuracy: 0.55738 |  0:16:05s\n",
            "epoch 1869| loss: 0.8947  | train_accuracy: 0.57839 | val_accuracy: 0.55618 |  0:16:05s\n",
            "epoch 1870| loss: 0.89312 | train_accuracy: 0.58083 | val_accuracy: 0.56977 |  0:16:06s\n",
            "epoch 1871| loss: 0.89257 | train_accuracy: 0.58061 | val_accuracy: 0.56457 |  0:16:06s\n",
            "epoch 1872| loss: 0.8906  | train_accuracy: 0.58021 | val_accuracy: 0.56417 |  0:16:07s\n",
            "epoch 1873| loss: 0.89291 | train_accuracy: 0.58155 | val_accuracy: 0.56897 |  0:16:07s\n",
            "epoch 1874| loss: 0.89002 | train_accuracy: 0.5795  | val_accuracy: 0.55658 |  0:16:08s\n",
            "epoch 1875| loss: 0.89159 | train_accuracy: 0.57852 | val_accuracy: 0.56377 |  0:16:08s\n",
            "epoch 1876| loss: 0.89238 | train_accuracy: 0.57986 | val_accuracy: 0.56857 |  0:16:09s\n",
            "epoch 1877| loss: 0.88785 | train_accuracy: 0.5807  | val_accuracy: 0.56737 |  0:16:10s\n",
            "epoch 1878| loss: 0.89379 | train_accuracy: 0.58123 | val_accuracy: 0.56737 |  0:16:10s\n",
            "epoch 1879| loss: 0.89372 | train_accuracy: 0.58155 | val_accuracy: 0.56178 |  0:16:11s\n",
            "epoch 1880| loss: 0.89236 | train_accuracy: 0.58026 | val_accuracy: 0.56497 |  0:16:11s\n",
            "epoch 1881| loss: 0.89102 | train_accuracy: 0.57852 | val_accuracy: 0.56218 |  0:16:12s\n",
            "epoch 1882| loss: 0.89257 | train_accuracy: 0.57963 | val_accuracy: 0.56098 |  0:16:12s\n",
            "epoch 1883| loss: 0.88783 | train_accuracy: 0.58266 | val_accuracy: 0.55978 |  0:16:13s\n",
            "epoch 1884| loss: 0.88932 | train_accuracy: 0.58323 | val_accuracy: 0.55698 |  0:16:13s\n",
            "epoch 1885| loss: 0.89318 | train_accuracy: 0.57897 | val_accuracy: 0.56257 |  0:16:14s\n",
            "epoch 1886| loss: 0.89103 | train_accuracy: 0.57852 | val_accuracy: 0.55618 |  0:16:14s\n",
            "epoch 1887| loss: 0.88879 | train_accuracy: 0.57892 | val_accuracy: 0.56138 |  0:16:15s\n",
            "epoch 1888| loss: 0.88957 | train_accuracy: 0.57799 | val_accuracy: 0.55578 |  0:16:15s\n",
            "epoch 1889| loss: 0.89328 | train_accuracy: 0.57839 | val_accuracy: 0.55898 |  0:16:16s\n",
            "epoch 1890| loss: 0.89557 | train_accuracy: 0.57808 | val_accuracy: 0.56377 |  0:16:16s\n",
            "epoch 1891| loss: 0.89636 | train_accuracy: 0.57404 | val_accuracy: 0.56138 |  0:16:17s\n",
            "epoch 1892| loss: 0.89797 | train_accuracy: 0.5759  | val_accuracy: 0.56577 |  0:16:17s\n",
            "epoch 1893| loss: 0.89748 | train_accuracy: 0.57617 | val_accuracy: 0.56457 |  0:16:18s\n",
            "epoch 1894| loss: 0.8944  | train_accuracy: 0.5735  | val_accuracy: 0.55818 |  0:16:18s\n",
            "epoch 1895| loss: 0.89331 | train_accuracy: 0.5767  | val_accuracy: 0.55898 |  0:16:19s\n",
            "epoch 1896| loss: 0.89456 | train_accuracy: 0.5775  | val_accuracy: 0.55258 |  0:16:19s\n",
            "epoch 1897| loss: 0.89443 | train_accuracy: 0.57861 | val_accuracy: 0.56058 |  0:16:20s\n",
            "epoch 1898| loss: 0.89369 | train_accuracy: 0.5791  | val_accuracy: 0.56058 |  0:16:20s\n",
            "epoch 1899| loss: 0.89611 | train_accuracy: 0.57915 | val_accuracy: 0.56218 |  0:16:21s\n",
            "epoch 1900| loss: 0.89228 | train_accuracy: 0.57857 | val_accuracy: 0.56337 |  0:16:21s\n",
            "epoch 1901| loss: 0.89291 | train_accuracy: 0.57968 | val_accuracy: 0.55658 |  0:16:22s\n",
            "epoch 1902| loss: 0.89342 | train_accuracy: 0.57937 | val_accuracy: 0.55658 |  0:16:22s\n",
            "epoch 1903| loss: 0.89147 | train_accuracy: 0.57955 | val_accuracy: 0.55858 |  0:16:23s\n",
            "epoch 1904| loss: 0.89333 | train_accuracy: 0.57928 | val_accuracy: 0.56417 |  0:16:23s\n",
            "epoch 1905| loss: 0.89589 | train_accuracy: 0.57861 | val_accuracy: 0.55098 |  0:16:24s\n",
            "epoch 1906| loss: 0.89696 | train_accuracy: 0.57555 | val_accuracy: 0.54898 |  0:16:24s\n",
            "epoch 1907| loss: 0.89495 | train_accuracy: 0.57488 | val_accuracy: 0.55218 |  0:16:25s\n",
            "epoch 1908| loss: 0.89673 | train_accuracy: 0.57413 | val_accuracy: 0.54818 |  0:16:25s\n",
            "epoch 1909| loss: 0.89446 | train_accuracy: 0.57404 | val_accuracy: 0.55378 |  0:16:26s\n",
            "epoch 1910| loss: 0.89009 | train_accuracy: 0.57421 | val_accuracy: 0.56377 |  0:16:26s\n",
            "epoch 1911| loss: 0.89508 | train_accuracy: 0.57519 | val_accuracy: 0.56058 |  0:16:27s\n",
            "epoch 1912| loss: 0.89518 | train_accuracy: 0.57732 | val_accuracy: 0.56657 |  0:16:27s\n",
            "epoch 1913| loss: 0.89092 | train_accuracy: 0.57466 | val_accuracy: 0.55578 |  0:16:28s\n",
            "epoch 1914| loss: 0.89128 | train_accuracy: 0.57684 | val_accuracy: 0.56297 |  0:16:28s\n",
            "epoch 1915| loss: 0.89314 | train_accuracy: 0.57764 | val_accuracy: 0.56058 |  0:16:29s\n",
            "epoch 1916| loss: 0.89158 | train_accuracy: 0.57715 | val_accuracy: 0.55098 |  0:16:29s\n",
            "epoch 1917| loss: 0.89158 | train_accuracy: 0.57715 | val_accuracy: 0.56018 |  0:16:30s\n",
            "epoch 1918| loss: 0.89495 | train_accuracy: 0.57621 | val_accuracy: 0.55458 |  0:16:30s\n",
            "epoch 1919| loss: 0.89094 | train_accuracy: 0.57879 | val_accuracy: 0.56497 |  0:16:31s\n",
            "epoch 1920| loss: 0.89483 | train_accuracy: 0.57701 | val_accuracy: 0.56018 |  0:16:31s\n",
            "epoch 1921| loss: 0.89295 | train_accuracy: 0.57199 | val_accuracy: 0.55218 |  0:16:32s\n",
            "epoch 1922| loss: 0.89612 | train_accuracy: 0.57861 | val_accuracy: 0.56417 |  0:16:32s\n",
            "epoch 1923| loss: 0.8945  | train_accuracy: 0.57857 | val_accuracy: 0.56417 |  0:16:33s\n",
            "epoch 1924| loss: 0.89304 | train_accuracy: 0.57897 | val_accuracy: 0.56018 |  0:16:33s\n",
            "epoch 1925| loss: 0.89315 | train_accuracy: 0.58012 | val_accuracy: 0.56377 |  0:16:34s\n",
            "epoch 1926| loss: 0.89301 | train_accuracy: 0.57826 | val_accuracy: 0.56617 |  0:16:34s\n",
            "epoch 1927| loss: 0.89321 | train_accuracy: 0.57892 | val_accuracy: 0.56218 |  0:16:35s\n",
            "epoch 1928| loss: 0.89223 | train_accuracy: 0.57897 | val_accuracy: 0.55578 |  0:16:35s\n",
            "epoch 1929| loss: 0.89334 | train_accuracy: 0.57977 | val_accuracy: 0.56098 |  0:16:36s\n",
            "epoch 1930| loss: 0.8908  | train_accuracy: 0.57968 | val_accuracy: 0.56737 |  0:16:36s\n",
            "epoch 1931| loss: 0.89447 | train_accuracy: 0.57533 | val_accuracy: 0.56297 |  0:16:37s\n",
            "epoch 1932| loss: 0.88883 | train_accuracy: 0.57137 | val_accuracy: 0.55258 |  0:16:37s\n",
            "epoch 1933| loss: 0.89781 | train_accuracy: 0.57235 | val_accuracy: 0.55098 |  0:16:38s\n",
            "epoch 1934| loss: 0.8989  | train_accuracy: 0.5771  | val_accuracy: 0.56457 |  0:16:38s\n",
            "epoch 1935| loss: 0.89477 | train_accuracy: 0.57932 | val_accuracy: 0.56337 |  0:16:39s\n",
            "epoch 1936| loss: 0.89255 | train_accuracy: 0.57839 | val_accuracy: 0.55538 |  0:16:39s\n",
            "epoch 1937| loss: 0.89645 | train_accuracy: 0.57866 | val_accuracy: 0.55938 |  0:16:40s\n",
            "epoch 1938| loss: 0.89466 | train_accuracy: 0.57852 | val_accuracy: 0.55858 |  0:16:40s\n",
            "epoch 1939| loss: 0.89172 | train_accuracy: 0.57639 | val_accuracy: 0.56018 |  0:16:41s\n",
            "epoch 1940| loss: 0.89173 | train_accuracy: 0.57684 | val_accuracy: 0.56138 |  0:16:41s\n",
            "epoch 1941| loss: 0.89483 | train_accuracy: 0.57955 | val_accuracy: 0.56577 |  0:16:42s\n",
            "epoch 1942| loss: 0.88907 | train_accuracy: 0.57866 | val_accuracy: 0.56577 |  0:16:42s\n",
            "epoch 1943| loss: 0.89071 | train_accuracy: 0.58132 | val_accuracy: 0.56657 |  0:16:43s\n",
            "epoch 1944| loss: 0.89237 | train_accuracy: 0.57981 | val_accuracy: 0.56058 |  0:16:43s\n",
            "epoch 1945| loss: 0.89503 | train_accuracy: 0.57897 | val_accuracy: 0.57097 |  0:16:44s\n",
            "epoch 1946| loss: 0.89679 | train_accuracy: 0.57968 | val_accuracy: 0.57257 |  0:16:44s\n",
            "epoch 1947| loss: 0.89588 | train_accuracy: 0.57875 | val_accuracy: 0.56218 |  0:16:45s\n",
            "epoch 1948| loss: 0.8908  | train_accuracy: 0.5815  | val_accuracy: 0.56417 |  0:16:45s\n",
            "epoch 1949| loss: 0.89363 | train_accuracy: 0.57684 | val_accuracy: 0.55858 |  0:16:46s\n",
            "epoch 1950| loss: 0.89529 | train_accuracy: 0.58048 | val_accuracy: 0.56457 |  0:16:46s\n",
            "epoch 1951| loss: 0.89406 | train_accuracy: 0.57955 | val_accuracy: 0.56257 |  0:16:47s\n",
            "epoch 1952| loss: 0.89541 | train_accuracy: 0.57897 | val_accuracy: 0.56178 |  0:16:47s\n",
            "epoch 1953| loss: 0.88981 | train_accuracy: 0.58163 | val_accuracy: 0.56537 |  0:16:48s\n",
            "epoch 1954| loss: 0.88947 | train_accuracy: 0.58083 | val_accuracy: 0.56337 |  0:16:48s\n",
            "epoch 1955| loss: 0.8902  | train_accuracy: 0.5795  | val_accuracy: 0.56737 |  0:16:49s\n",
            "epoch 1956| loss: 0.88525 | train_accuracy: 0.57879 | val_accuracy: 0.56657 |  0:16:49s\n",
            "epoch 1957| loss: 0.88757 | train_accuracy: 0.57959 | val_accuracy: 0.56297 |  0:16:50s\n",
            "epoch 1958| loss: 0.88915 | train_accuracy: 0.58279 | val_accuracy: 0.57137 |  0:16:50s\n",
            "epoch 1959| loss: 0.89381 | train_accuracy: 0.5823  | val_accuracy: 0.56257 |  0:16:51s\n",
            "epoch 1960| loss: 0.89161 | train_accuracy: 0.5791  | val_accuracy: 0.55978 |  0:16:51s\n",
            "epoch 1961| loss: 0.88897 | train_accuracy: 0.58177 | val_accuracy: 0.56337 |  0:16:52s\n",
            "epoch 1962| loss: 0.8946  | train_accuracy: 0.57937 | val_accuracy: 0.55258 |  0:16:52s\n",
            "epoch 1963| loss: 0.89591 | train_accuracy: 0.5791  | val_accuracy: 0.55538 |  0:16:53s\n",
            "epoch 1964| loss: 0.8933  | train_accuracy: 0.58199 | val_accuracy: 0.56617 |  0:16:53s\n",
            "epoch 1965| loss: 0.89245 | train_accuracy: 0.57963 | val_accuracy: 0.56377 |  0:16:54s\n",
            "epoch 1966| loss: 0.89284 | train_accuracy: 0.57981 | val_accuracy: 0.55258 |  0:16:54s\n",
            "epoch 1967| loss: 0.88833 | train_accuracy: 0.57977 | val_accuracy: 0.56218 |  0:16:55s\n",
            "epoch 1968| loss: 0.89444 | train_accuracy: 0.57764 | val_accuracy: 0.56257 |  0:16:55s\n",
            "epoch 1969| loss: 0.88971 | train_accuracy: 0.58039 | val_accuracy: 0.56457 |  0:16:56s\n",
            "epoch 1970| loss: 0.89423 | train_accuracy: 0.57706 | val_accuracy: 0.55818 |  0:16:56s\n",
            "epoch 1971| loss: 0.8931  | train_accuracy: 0.5803  | val_accuracy: 0.56138 |  0:16:57s\n",
            "epoch 1972| loss: 0.89142 | train_accuracy: 0.57852 | val_accuracy: 0.56138 |  0:16:57s\n",
            "epoch 1973| loss: 0.8908  | train_accuracy: 0.57959 | val_accuracy: 0.56417 |  0:16:58s\n",
            "epoch 1974| loss: 0.89045 | train_accuracy: 0.58075 | val_accuracy: 0.56577 |  0:16:58s\n",
            "epoch 1975| loss: 0.89388 | train_accuracy: 0.58079 | val_accuracy: 0.55778 |  0:16:59s\n",
            "epoch 1976| loss: 0.88768 | train_accuracy: 0.57977 | val_accuracy: 0.56257 |  0:16:59s\n",
            "epoch 1977| loss: 0.88911 | train_accuracy: 0.57968 | val_accuracy: 0.56018 |  0:17:00s\n",
            "epoch 1978| loss: 0.88906 | train_accuracy: 0.58003 | val_accuracy: 0.55578 |  0:17:00s\n",
            "epoch 1979| loss: 0.89191 | train_accuracy: 0.58212 | val_accuracy: 0.55978 |  0:17:01s\n",
            "epoch 1980| loss: 0.88773 | train_accuracy: 0.58066 | val_accuracy: 0.55738 |  0:17:01s\n",
            "epoch 1981| loss: 0.88561 | train_accuracy: 0.58243 | val_accuracy: 0.56297 |  0:17:02s\n",
            "epoch 1982| loss: 0.89183 | train_accuracy: 0.58163 | val_accuracy: 0.55898 |  0:17:02s\n",
            "epoch 1983| loss: 0.88761 | train_accuracy: 0.58155 | val_accuracy: 0.55778 |  0:17:03s\n",
            "epoch 1984| loss: 0.88566 | train_accuracy: 0.58306 | val_accuracy: 0.55538 |  0:17:03s\n",
            "epoch 1985| loss: 0.8898  | train_accuracy: 0.5803  | val_accuracy: 0.55818 |  0:17:04s\n",
            "epoch 1986| loss: 0.89026 | train_accuracy: 0.58181 | val_accuracy: 0.56537 |  0:17:04s\n",
            "epoch 1987| loss: 0.89313 | train_accuracy: 0.58115 | val_accuracy: 0.55938 |  0:17:05s\n",
            "epoch 1988| loss: 0.88842 | train_accuracy: 0.58132 | val_accuracy: 0.56138 |  0:17:05s\n",
            "epoch 1989| loss: 0.89117 | train_accuracy: 0.58288 | val_accuracy: 0.55858 |  0:17:06s\n",
            "epoch 1990| loss: 0.89084 | train_accuracy: 0.58208 | val_accuracy: 0.55858 |  0:17:06s\n",
            "epoch 1991| loss: 0.89167 | train_accuracy: 0.57839 | val_accuracy: 0.55818 |  0:17:07s\n",
            "epoch 1992| loss: 0.89454 | train_accuracy: 0.57906 | val_accuracy: 0.55058 |  0:17:07s\n",
            "epoch 1993| loss: 0.89079 | train_accuracy: 0.58101 | val_accuracy: 0.55978 |  0:17:08s\n",
            "epoch 1994| loss: 0.89119 | train_accuracy: 0.58377 | val_accuracy: 0.55778 |  0:17:08s\n",
            "epoch 1995| loss: 0.89047 | train_accuracy: 0.58043 | val_accuracy: 0.55738 |  0:17:09s\n",
            "epoch 1996| loss: 0.89087 | train_accuracy: 0.58372 | val_accuracy: 0.56178 |  0:17:09s\n",
            "epoch 1997| loss: 0.89525 | train_accuracy: 0.58328 | val_accuracy: 0.56457 |  0:17:10s\n",
            "epoch 1998| loss: 0.89024 | train_accuracy: 0.58159 | val_accuracy: 0.55698 |  0:17:10s\n",
            "epoch 1999| loss: 0.89022 | train_accuracy: 0.58421 | val_accuracy: 0.56337 |  0:17:11s\n",
            "epoch 2000| loss: 0.88978 | train_accuracy: 0.58101 | val_accuracy: 0.55978 |  0:17:11s\n",
            "epoch 2001| loss: 0.89076 | train_accuracy: 0.58003 | val_accuracy: 0.56178 |  0:17:12s\n",
            "epoch 2002| loss: 0.89033 | train_accuracy: 0.58199 | val_accuracy: 0.55738 |  0:17:12s\n",
            "epoch 2003| loss: 0.89133 | train_accuracy: 0.58083 | val_accuracy: 0.55778 |  0:17:13s\n",
            "epoch 2004| loss: 0.88927 | train_accuracy: 0.58221 | val_accuracy: 0.55858 |  0:17:13s\n",
            "epoch 2005| loss: 0.88905 | train_accuracy: 0.58177 | val_accuracy: 0.56058 |  0:17:14s\n",
            "epoch 2006| loss: 0.89032 | train_accuracy: 0.58426 | val_accuracy: 0.55458 |  0:17:14s\n",
            "epoch 2007| loss: 0.89017 | train_accuracy: 0.58172 | val_accuracy: 0.55618 |  0:17:15s\n",
            "epoch 2008| loss: 0.88563 | train_accuracy: 0.58323 | val_accuracy: 0.56417 |  0:17:15s\n",
            "epoch 2009| loss: 0.89025 | train_accuracy: 0.58088 | val_accuracy: 0.55738 |  0:17:16s\n",
            "epoch 2010| loss: 0.88932 | train_accuracy: 0.58194 | val_accuracy: 0.56178 |  0:17:16s\n",
            "epoch 2011| loss: 0.88695 | train_accuracy: 0.58337 | val_accuracy: 0.55458 |  0:17:17s\n",
            "epoch 2012| loss: 0.88695 | train_accuracy: 0.58319 | val_accuracy: 0.55698 |  0:17:17s\n",
            "epoch 2013| loss: 0.88883 | train_accuracy: 0.58497 | val_accuracy: 0.55858 |  0:17:18s\n",
            "epoch 2014| loss: 0.88992 | train_accuracy: 0.58043 | val_accuracy: 0.55618 |  0:17:18s\n",
            "epoch 2015| loss: 0.89137 | train_accuracy: 0.58403 | val_accuracy: 0.56657 |  0:17:19s\n",
            "epoch 2016| loss: 0.88617 | train_accuracy: 0.5831  | val_accuracy: 0.56218 |  0:17:19s\n",
            "epoch 2017| loss: 0.88644 | train_accuracy: 0.58199 | val_accuracy: 0.55698 |  0:17:20s\n",
            "epoch 2018| loss: 0.88835 | train_accuracy: 0.58279 | val_accuracy: 0.56457 |  0:17:20s\n",
            "epoch 2019| loss: 0.8855  | train_accuracy: 0.58341 | val_accuracy: 0.55698 |  0:17:21s\n",
            "epoch 2020| loss: 0.88814 | train_accuracy: 0.58266 | val_accuracy: 0.56098 |  0:17:21s\n",
            "epoch 2021| loss: 0.89004 | train_accuracy: 0.58141 | val_accuracy: 0.56218 |  0:17:22s\n",
            "epoch 2022| loss: 0.8874  | train_accuracy: 0.58297 | val_accuracy: 0.56657 |  0:17:22s\n",
            "epoch 2023| loss: 0.88817 | train_accuracy: 0.58443 | val_accuracy: 0.56457 |  0:17:23s\n",
            "epoch 2024| loss: 0.88833 | train_accuracy: 0.58243 | val_accuracy: 0.56218 |  0:17:23s\n",
            "epoch 2025| loss: 0.88728 | train_accuracy: 0.58377 | val_accuracy: 0.56697 |  0:17:24s\n",
            "epoch 2026| loss: 0.88983 | train_accuracy: 0.58146 | val_accuracy: 0.56617 |  0:17:24s\n",
            "epoch 2027| loss: 0.89016 | train_accuracy: 0.58346 | val_accuracy: 0.56417 |  0:17:25s\n",
            "epoch 2028| loss: 0.88843 | train_accuracy: 0.58212 | val_accuracy: 0.56657 |  0:17:25s\n",
            "epoch 2029| loss: 0.89048 | train_accuracy: 0.58292 | val_accuracy: 0.56657 |  0:17:26s\n",
            "epoch 2030| loss: 0.8863  | train_accuracy: 0.58248 | val_accuracy: 0.56377 |  0:17:26s\n",
            "epoch 2031| loss: 0.88695 | train_accuracy: 0.57995 | val_accuracy: 0.55978 |  0:17:27s\n",
            "epoch 2032| loss: 0.89024 | train_accuracy: 0.5787  | val_accuracy: 0.56218 |  0:17:27s\n",
            "epoch 2033| loss: 0.88676 | train_accuracy: 0.58163 | val_accuracy: 0.56497 |  0:17:28s\n",
            "epoch 2034| loss: 0.89006 | train_accuracy: 0.58226 | val_accuracy: 0.56098 |  0:17:28s\n",
            "epoch 2035| loss: 0.88868 | train_accuracy: 0.58181 | val_accuracy: 0.56178 |  0:17:29s\n",
            "epoch 2036| loss: 0.88896 | train_accuracy: 0.58319 | val_accuracy: 0.56537 |  0:17:29s\n",
            "epoch 2037| loss: 0.89089 | train_accuracy: 0.58186 | val_accuracy: 0.56018 |  0:17:30s\n",
            "epoch 2038| loss: 0.89428 | train_accuracy: 0.58128 | val_accuracy: 0.55898 |  0:17:30s\n",
            "epoch 2039| loss: 0.88986 | train_accuracy: 0.5819  | val_accuracy: 0.56617 |  0:17:31s\n",
            "epoch 2040| loss: 0.89041 | train_accuracy: 0.5803  | val_accuracy: 0.56697 |  0:17:31s\n",
            "epoch 2041| loss: 0.89041 | train_accuracy: 0.58075 | val_accuracy: 0.56297 |  0:17:32s\n",
            "epoch 2042| loss: 0.8913  | train_accuracy: 0.58261 | val_accuracy: 0.56737 |  0:17:32s\n",
            "epoch 2043| loss: 0.89176 | train_accuracy: 0.5807  | val_accuracy: 0.56697 |  0:17:33s\n",
            "epoch 2044| loss: 0.88884 | train_accuracy: 0.58337 | val_accuracy: 0.56817 |  0:17:33s\n",
            "epoch 2045| loss: 0.89217 | train_accuracy: 0.58101 | val_accuracy: 0.56497 |  0:17:34s\n",
            "epoch 2046| loss: 0.88968 | train_accuracy: 0.58101 | val_accuracy: 0.56257 |  0:17:34s\n",
            "epoch 2047| loss: 0.89095 | train_accuracy: 0.58288 | val_accuracy: 0.56697 |  0:17:35s\n",
            "epoch 2048| loss: 0.89009 | train_accuracy: 0.58194 | val_accuracy: 0.56577 |  0:17:35s\n",
            "epoch 2049| loss: 0.89005 | train_accuracy: 0.58199 | val_accuracy: 0.56257 |  0:17:36s\n",
            "epoch 2050| loss: 0.88662 | train_accuracy: 0.58368 | val_accuracy: 0.56297 |  0:17:36s\n",
            "epoch 2051| loss: 0.88907 | train_accuracy: 0.58332 | val_accuracy: 0.56018 |  0:17:37s\n",
            "epoch 2052| loss: 0.8865  | train_accuracy: 0.58123 | val_accuracy: 0.56497 |  0:17:37s\n",
            "epoch 2053| loss: 0.88739 | train_accuracy: 0.58123 | val_accuracy: 0.56457 |  0:17:38s\n",
            "epoch 2054| loss: 0.89078 | train_accuracy: 0.58075 | val_accuracy: 0.56138 |  0:17:38s\n",
            "epoch 2055| loss: 0.8888  | train_accuracy: 0.58208 | val_accuracy: 0.56497 |  0:17:39s\n",
            "epoch 2056| loss: 0.88898 | train_accuracy: 0.57981 | val_accuracy: 0.56457 |  0:17:39s\n",
            "epoch 2057| loss: 0.88976 | train_accuracy: 0.58172 | val_accuracy: 0.56697 |  0:17:40s\n",
            "epoch 2058| loss: 0.88734 | train_accuracy: 0.58221 | val_accuracy: 0.56018 |  0:17:40s\n",
            "epoch 2059| loss: 0.89165 | train_accuracy: 0.58203 | val_accuracy: 0.55938 |  0:17:41s\n",
            "epoch 2060| loss: 0.88994 | train_accuracy: 0.58092 | val_accuracy: 0.55938 |  0:17:41s\n",
            "epoch 2061| loss: 0.89055 | train_accuracy: 0.58319 | val_accuracy: 0.56018 |  0:17:42s\n",
            "epoch 2062| loss: 0.89346 | train_accuracy: 0.58208 | val_accuracy: 0.55858 |  0:17:42s\n",
            "epoch 2063| loss: 0.88925 | train_accuracy: 0.58408 | val_accuracy: 0.55938 |  0:17:43s\n",
            "epoch 2064| loss: 0.88794 | train_accuracy: 0.5823  | val_accuracy: 0.55578 |  0:17:43s\n",
            "epoch 2065| loss: 0.89165 | train_accuracy: 0.57959 | val_accuracy: 0.55178 |  0:17:44s\n",
            "epoch 2066| loss: 0.8884  | train_accuracy: 0.58314 | val_accuracy: 0.56058 |  0:17:44s\n",
            "epoch 2067| loss: 0.8886  | train_accuracy: 0.58248 | val_accuracy: 0.55258 |  0:17:45s\n",
            "epoch 2068| loss: 0.88658 | train_accuracy: 0.58417 | val_accuracy: 0.55458 |  0:17:45s\n",
            "epoch 2069| loss: 0.88957 | train_accuracy: 0.58306 | val_accuracy: 0.55898 |  0:17:46s\n",
            "epoch 2070| loss: 0.88988 | train_accuracy: 0.5815  | val_accuracy: 0.55538 |  0:17:46s\n",
            "epoch 2071| loss: 0.8903  | train_accuracy: 0.58492 | val_accuracy: 0.56018 |  0:17:47s\n",
            "epoch 2072| loss: 0.88759 | train_accuracy: 0.58297 | val_accuracy: 0.56257 |  0:17:47s\n",
            "epoch 2073| loss: 0.88278 | train_accuracy: 0.58172 | val_accuracy: 0.55618 |  0:17:48s\n",
            "epoch 2074| loss: 0.88914 | train_accuracy: 0.58443 | val_accuracy: 0.55738 |  0:17:48s\n",
            "epoch 2075| loss: 0.88631 | train_accuracy: 0.58328 | val_accuracy: 0.55978 |  0:17:49s\n",
            "epoch 2076| loss: 0.88698 | train_accuracy: 0.58394 | val_accuracy: 0.55818 |  0:17:49s\n",
            "epoch 2077| loss: 0.88725 | train_accuracy: 0.57986 | val_accuracy: 0.55138 |  0:17:50s\n",
            "epoch 2078| loss: 0.8917  | train_accuracy: 0.58266 | val_accuracy: 0.55658 |  0:17:50s\n",
            "epoch 2079| loss: 0.88639 | train_accuracy: 0.58394 | val_accuracy: 0.55778 |  0:17:51s\n",
            "epoch 2080| loss: 0.88597 | train_accuracy: 0.58226 | val_accuracy: 0.55258 |  0:17:51s\n",
            "epoch 2081| loss: 0.88689 | train_accuracy: 0.58354 | val_accuracy: 0.55458 |  0:17:52s\n",
            "epoch 2082| loss: 0.8887  | train_accuracy: 0.58386 | val_accuracy: 0.55818 |  0:17:52s\n",
            "epoch 2083| loss: 0.88546 | train_accuracy: 0.58359 | val_accuracy: 0.55738 |  0:17:53s\n",
            "epoch 2084| loss: 0.88871 | train_accuracy: 0.58354 | val_accuracy: 0.56297 |  0:17:53s\n",
            "epoch 2085| loss: 0.88821 | train_accuracy: 0.58363 | val_accuracy: 0.56297 |  0:17:54s\n",
            "epoch 2086| loss: 0.88652 | train_accuracy: 0.58048 | val_accuracy: 0.55818 |  0:17:54s\n",
            "epoch 2087| loss: 0.88747 | train_accuracy: 0.58048 | val_accuracy: 0.56058 |  0:17:55s\n",
            "epoch 2088| loss: 0.89168 | train_accuracy: 0.58532 | val_accuracy: 0.56977 |  0:17:55s\n",
            "epoch 2089| loss: 0.88998 | train_accuracy: 0.58341 | val_accuracy: 0.57417 |  0:17:56s\n",
            "epoch 2090| loss: 0.88822 | train_accuracy: 0.58306 | val_accuracy: 0.57177 |  0:17:56s\n",
            "epoch 2091| loss: 0.88833 | train_accuracy: 0.57879 | val_accuracy: 0.55618 |  0:17:57s\n",
            "epoch 2092| loss: 0.88849 | train_accuracy: 0.5843  | val_accuracy: 0.56537 |  0:17:57s\n",
            "epoch 2093| loss: 0.89031 | train_accuracy: 0.58466 | val_accuracy: 0.56377 |  0:17:58s\n",
            "epoch 2094| loss: 0.88828 | train_accuracy: 0.5827  | val_accuracy: 0.55698 |  0:17:58s\n",
            "epoch 2095| loss: 0.88764 | train_accuracy: 0.58172 | val_accuracy: 0.56297 |  0:17:59s\n",
            "epoch 2096| loss: 0.88981 | train_accuracy: 0.57919 | val_accuracy: 0.55858 |  0:17:59s\n",
            "epoch 2097| loss: 0.88911 | train_accuracy: 0.58323 | val_accuracy: 0.56138 |  0:18:00s\n",
            "epoch 2098| loss: 0.88871 | train_accuracy: 0.58372 | val_accuracy: 0.56377 |  0:18:00s\n",
            "epoch 2099| loss: 0.88283 | train_accuracy: 0.5827  | val_accuracy: 0.55858 |  0:18:01s\n",
            "epoch 2100| loss: 0.88399 | train_accuracy: 0.58306 | val_accuracy: 0.56577 |  0:18:01s\n",
            "epoch 2101| loss: 0.88628 | train_accuracy: 0.5827  | val_accuracy: 0.56297 |  0:18:02s\n",
            "epoch 2102| loss: 0.88776 | train_accuracy: 0.58026 | val_accuracy: 0.56257 |  0:18:02s\n",
            "epoch 2103| loss: 0.89363 | train_accuracy: 0.57941 | val_accuracy: 0.55978 |  0:18:03s\n",
            "epoch 2104| loss: 0.88798 | train_accuracy: 0.57986 | val_accuracy: 0.56257 |  0:18:03s\n",
            "epoch 2105| loss: 0.88653 | train_accuracy: 0.58288 | val_accuracy: 0.57057 |  0:18:04s\n",
            "epoch 2106| loss: 0.88731 | train_accuracy: 0.58106 | val_accuracy: 0.56817 |  0:18:04s\n",
            "epoch 2107| loss: 0.88592 | train_accuracy: 0.58052 | val_accuracy: 0.56817 |  0:18:05s\n",
            "epoch 2108| loss: 0.88535 | train_accuracy: 0.58159 | val_accuracy: 0.56737 |  0:18:05s\n",
            "epoch 2109| loss: 0.88865 | train_accuracy: 0.5787  | val_accuracy: 0.56178 |  0:18:06s\n",
            "epoch 2110| loss: 0.88986 | train_accuracy: 0.58008 | val_accuracy: 0.55818 |  0:18:06s\n",
            "epoch 2111| loss: 0.88903 | train_accuracy: 0.58039 | val_accuracy: 0.56178 |  0:18:07s\n",
            "epoch 2112| loss: 0.88836 | train_accuracy: 0.57963 | val_accuracy: 0.56337 |  0:18:07s\n",
            "epoch 2113| loss: 0.89163 | train_accuracy: 0.57875 | val_accuracy: 0.56018 |  0:18:08s\n",
            "epoch 2114| loss: 0.88781 | train_accuracy: 0.57719 | val_accuracy: 0.55858 |  0:18:08s\n",
            "epoch 2115| loss: 0.88868 | train_accuracy: 0.5843  | val_accuracy: 0.56977 |  0:18:09s\n",
            "epoch 2116| loss: 0.88795 | train_accuracy: 0.58021 | val_accuracy: 0.56297 |  0:18:09s\n",
            "epoch 2117| loss: 0.89007 | train_accuracy: 0.58332 | val_accuracy: 0.56657 |  0:18:10s\n",
            "epoch 2118| loss: 0.88716 | train_accuracy: 0.58221 | val_accuracy: 0.56098 |  0:18:10s\n",
            "epoch 2119| loss: 0.88507 | train_accuracy: 0.58168 | val_accuracy: 0.56577 |  0:18:11s\n",
            "epoch 2120| loss: 0.88684 | train_accuracy: 0.58083 | val_accuracy: 0.56737 |  0:18:11s\n",
            "epoch 2121| loss: 0.89062 | train_accuracy: 0.58155 | val_accuracy: 0.55578 |  0:18:12s\n",
            "epoch 2122| loss: 0.8864  | train_accuracy: 0.58199 | val_accuracy: 0.56817 |  0:18:12s\n",
            "epoch 2123| loss: 0.88703 | train_accuracy: 0.58048 | val_accuracy: 0.55858 |  0:18:13s\n",
            "epoch 2124| loss: 0.8904  | train_accuracy: 0.5815  | val_accuracy: 0.56657 |  0:18:13s\n",
            "epoch 2125| loss: 0.88896 | train_accuracy: 0.58363 | val_accuracy: 0.56537 |  0:18:14s\n",
            "epoch 2126| loss: 0.89113 | train_accuracy: 0.5823  | val_accuracy: 0.56178 |  0:18:14s\n",
            "epoch 2127| loss: 0.88842 | train_accuracy: 0.58097 | val_accuracy: 0.56018 |  0:18:15s\n",
            "epoch 2128| loss: 0.8871  | train_accuracy: 0.57915 | val_accuracy: 0.55738 |  0:18:15s\n",
            "epoch 2129| loss: 0.88808 | train_accuracy: 0.58123 | val_accuracy: 0.56218 |  0:18:16s\n",
            "epoch 2130| loss: 0.88707 | train_accuracy: 0.58088 | val_accuracy: 0.56178 |  0:18:16s\n",
            "epoch 2131| loss: 0.88738 | train_accuracy: 0.5803  | val_accuracy: 0.56377 |  0:18:17s\n",
            "epoch 2132| loss: 0.8905  | train_accuracy: 0.5779  | val_accuracy: 0.55218 |  0:18:17s\n",
            "epoch 2133| loss: 0.89213 | train_accuracy: 0.58052 | val_accuracy: 0.56497 |  0:18:18s\n",
            "epoch 2134| loss: 0.89277 | train_accuracy: 0.58177 | val_accuracy: 0.56417 |  0:18:18s\n",
            "epoch 2135| loss: 0.8933  | train_accuracy: 0.58123 | val_accuracy: 0.56018 |  0:18:19s\n",
            "epoch 2136| loss: 0.89048 | train_accuracy: 0.58083 | val_accuracy: 0.56577 |  0:18:19s\n",
            "epoch 2137| loss: 0.89135 | train_accuracy: 0.58163 | val_accuracy: 0.56537 |  0:18:20s\n",
            "epoch 2138| loss: 0.89192 | train_accuracy: 0.5831  | val_accuracy: 0.57177 |  0:18:20s\n",
            "epoch 2139| loss: 0.89191 | train_accuracy: 0.58306 | val_accuracy: 0.56817 |  0:18:21s\n",
            "epoch 2140| loss: 0.88946 | train_accuracy: 0.58479 | val_accuracy: 0.56897 |  0:18:21s\n",
            "epoch 2141| loss: 0.88759 | train_accuracy: 0.58381 | val_accuracy: 0.57137 |  0:18:22s\n",
            "epoch 2142| loss: 0.88624 | train_accuracy: 0.58155 | val_accuracy: 0.56657 |  0:18:22s\n",
            "epoch 2143| loss: 0.8877  | train_accuracy: 0.58212 | val_accuracy: 0.56937 |  0:18:23s\n",
            "epoch 2144| loss: 0.88729 | train_accuracy: 0.58359 | val_accuracy: 0.56257 |  0:18:23s\n",
            "epoch 2145| loss: 0.88696 | train_accuracy: 0.58492 | val_accuracy: 0.56537 |  0:18:24s\n",
            "epoch 2146| loss: 0.88864 | train_accuracy: 0.58226 | val_accuracy: 0.56537 |  0:18:24s\n",
            "epoch 2147| loss: 0.88515 | train_accuracy: 0.58279 | val_accuracy: 0.56697 |  0:18:25s\n",
            "epoch 2148| loss: 0.89136 | train_accuracy: 0.58248 | val_accuracy: 0.57177 |  0:18:25s\n",
            "epoch 2149| loss: 0.88969 | train_accuracy: 0.58003 | val_accuracy: 0.56457 |  0:18:26s\n",
            "epoch 2150| loss: 0.887   | train_accuracy: 0.5823  | val_accuracy: 0.56697 |  0:18:26s\n",
            "epoch 2151| loss: 0.88784 | train_accuracy: 0.58194 | val_accuracy: 0.57577 |  0:18:27s\n",
            "epoch 2152| loss: 0.88815 | train_accuracy: 0.58337 | val_accuracy: 0.56857 |  0:18:27s\n",
            "epoch 2153| loss: 0.88708 | train_accuracy: 0.58377 | val_accuracy: 0.56337 |  0:18:28s\n",
            "epoch 2154| loss: 0.88652 | train_accuracy: 0.58203 | val_accuracy: 0.56817 |  0:18:28s\n",
            "epoch 2155| loss: 0.88714 | train_accuracy: 0.58377 | val_accuracy: 0.57377 |  0:18:29s\n",
            "epoch 2156| loss: 0.88726 | train_accuracy: 0.58266 | val_accuracy: 0.57417 |  0:18:29s\n",
            "epoch 2157| loss: 0.8855  | train_accuracy: 0.58266 | val_accuracy: 0.56817 |  0:18:30s\n",
            "epoch 2158| loss: 0.88783 | train_accuracy: 0.58448 | val_accuracy: 0.56577 |  0:18:30s\n",
            "epoch 2159| loss: 0.88637 | train_accuracy: 0.58417 | val_accuracy: 0.57057 |  0:18:30s\n",
            "epoch 2160| loss: 0.88491 | train_accuracy: 0.58434 | val_accuracy: 0.56657 |  0:18:31s\n",
            "epoch 2161| loss: 0.88465 | train_accuracy: 0.58386 | val_accuracy: 0.56777 |  0:18:32s\n",
            "epoch 2162| loss: 0.88597 | train_accuracy: 0.5835  | val_accuracy: 0.56777 |  0:18:32s\n",
            "epoch 2163| loss: 0.88593 | train_accuracy: 0.58403 | val_accuracy: 0.56497 |  0:18:33s\n",
            "epoch 2164| loss: 0.88672 | train_accuracy: 0.58554 | val_accuracy: 0.56417 |  0:18:33s\n",
            "epoch 2165| loss: 0.88523 | train_accuracy: 0.58301 | val_accuracy: 0.56537 |  0:18:34s\n",
            "epoch 2166| loss: 0.88766 | train_accuracy: 0.5847  | val_accuracy: 0.56178 |  0:18:34s\n",
            "epoch 2167| loss: 0.88649 | train_accuracy: 0.58266 | val_accuracy: 0.56297 |  0:18:35s\n",
            "epoch 2168| loss: 0.88752 | train_accuracy: 0.5859  | val_accuracy: 0.56577 |  0:18:36s\n",
            "epoch 2169| loss: 0.88988 | train_accuracy: 0.58466 | val_accuracy: 0.56537 |  0:18:37s\n",
            "epoch 2170| loss: 0.88225 | train_accuracy: 0.58497 | val_accuracy: 0.56457 |  0:18:38s\n",
            "epoch 2171| loss: 0.88527 | train_accuracy: 0.58332 | val_accuracy: 0.56297 |  0:18:39s\n",
            "epoch 2172| loss: 0.88699 | train_accuracy: 0.58559 | val_accuracy: 0.56297 |  0:18:40s\n",
            "epoch 2173| loss: 0.88904 | train_accuracy: 0.58585 | val_accuracy: 0.56337 |  0:18:40s\n",
            "epoch 2174| loss: 0.88707 | train_accuracy: 0.58737 | val_accuracy: 0.56657 |  0:18:41s\n",
            "epoch 2175| loss: 0.887   | train_accuracy: 0.5875  | val_accuracy: 0.56417 |  0:18:41s\n",
            "epoch 2176| loss: 0.88584 | train_accuracy: 0.5867  | val_accuracy: 0.56617 |  0:18:42s\n",
            "epoch 2177| loss: 0.88865 | train_accuracy: 0.58563 | val_accuracy: 0.56138 |  0:18:42s\n",
            "epoch 2178| loss: 0.88303 | train_accuracy: 0.58785 | val_accuracy: 0.56577 |  0:18:43s\n",
            "epoch 2179| loss: 0.88482 | train_accuracy: 0.58719 | val_accuracy: 0.56697 |  0:18:43s\n",
            "epoch 2180| loss: 0.88505 | train_accuracy: 0.58714 | val_accuracy: 0.56138 |  0:18:44s\n",
            "epoch 2181| loss: 0.88291 | train_accuracy: 0.58603 | val_accuracy: 0.56337 |  0:18:44s\n",
            "epoch 2182| loss: 0.88555 | train_accuracy: 0.58554 | val_accuracy: 0.56218 |  0:18:45s\n",
            "epoch 2183| loss: 0.88342 | train_accuracy: 0.58483 | val_accuracy: 0.56337 |  0:18:45s\n",
            "epoch 2184| loss: 0.88685 | train_accuracy: 0.58466 | val_accuracy: 0.56457 |  0:18:46s\n",
            "epoch 2185| loss: 0.88541 | train_accuracy: 0.58479 | val_accuracy: 0.55578 |  0:18:46s\n",
            "epoch 2186| loss: 0.88809 | train_accuracy: 0.58599 | val_accuracy: 0.56018 |  0:18:47s\n",
            "epoch 2187| loss: 0.8865  | train_accuracy: 0.58408 | val_accuracy: 0.56058 |  0:18:47s\n",
            "epoch 2188| loss: 0.88987 | train_accuracy: 0.58132 | val_accuracy: 0.55898 |  0:18:48s\n",
            "epoch 2189| loss: 0.88631 | train_accuracy: 0.58505 | val_accuracy: 0.55658 |  0:18:48s\n",
            "epoch 2190| loss: 0.88732 | train_accuracy: 0.5839  | val_accuracy: 0.55898 |  0:18:49s\n",
            "epoch 2191| loss: 0.88648 | train_accuracy: 0.58474 | val_accuracy: 0.55498 |  0:18:49s\n",
            "epoch 2192| loss: 0.89242 | train_accuracy: 0.58386 | val_accuracy: 0.55938 |  0:18:50s\n",
            "epoch 2193| loss: 0.89021 | train_accuracy: 0.58319 | val_accuracy: 0.56377 |  0:18:50s\n",
            "epoch 2194| loss: 0.89304 | train_accuracy: 0.58283 | val_accuracy: 0.56417 |  0:18:51s\n",
            "epoch 2195| loss: 0.88921 | train_accuracy: 0.58048 | val_accuracy: 0.55218 |  0:18:51s\n",
            "epoch 2196| loss: 0.89248 | train_accuracy: 0.58181 | val_accuracy: 0.55938 |  0:18:52s\n",
            "epoch 2197| loss: 0.89331 | train_accuracy: 0.58354 | val_accuracy: 0.56218 |  0:18:52s\n",
            "epoch 2198| loss: 0.8899  | train_accuracy: 0.58186 | val_accuracy: 0.56457 |  0:18:53s\n",
            "epoch 2199| loss: 0.89099 | train_accuracy: 0.57928 | val_accuracy: 0.55778 |  0:18:53s\n",
            "epoch 2200| loss: 0.89434 | train_accuracy: 0.57955 | val_accuracy: 0.57057 |  0:18:54s\n",
            "epoch 2201| loss: 0.89495 | train_accuracy: 0.57719 | val_accuracy: 0.56457 |  0:18:54s\n",
            "epoch 2202| loss: 0.89456 | train_accuracy: 0.57608 | val_accuracy: 0.55258 |  0:18:55s\n",
            "epoch 2203| loss: 0.89258 | train_accuracy: 0.58199 | val_accuracy: 0.57057 |  0:18:55s\n",
            "epoch 2204| loss: 0.89006 | train_accuracy: 0.5815  | val_accuracy: 0.55738 |  0:18:56s\n",
            "epoch 2205| loss: 0.88864 | train_accuracy: 0.58119 | val_accuracy: 0.56737 |  0:18:56s\n",
            "epoch 2206| loss: 0.89039 | train_accuracy: 0.58283 | val_accuracy: 0.56337 |  0:18:57s\n",
            "epoch 2207| loss: 0.89142 | train_accuracy: 0.58288 | val_accuracy: 0.55658 |  0:18:57s\n",
            "epoch 2208| loss: 0.88587 | train_accuracy: 0.58341 | val_accuracy: 0.56697 |  0:18:58s\n",
            "epoch 2209| loss: 0.88975 | train_accuracy: 0.58488 | val_accuracy: 0.56537 |  0:18:58s\n",
            "epoch 2210| loss: 0.89103 | train_accuracy: 0.58306 | val_accuracy: 0.56058 |  0:18:59s\n",
            "epoch 2211| loss: 0.88609 | train_accuracy: 0.5823  | val_accuracy: 0.55938 |  0:18:59s\n",
            "epoch 2212| loss: 0.89168 | train_accuracy: 0.58372 | val_accuracy: 0.55978 |  0:19:00s\n",
            "epoch 2213| loss: 0.8909  | train_accuracy: 0.58421 | val_accuracy: 0.56058 |  0:19:00s\n",
            "epoch 2214| loss: 0.8918  | train_accuracy: 0.58354 | val_accuracy: 0.56178 |  0:19:01s\n",
            "epoch 2215| loss: 0.88652 | train_accuracy: 0.58403 | val_accuracy: 0.56178 |  0:19:01s\n",
            "epoch 2216| loss: 0.8879  | train_accuracy: 0.57897 | val_accuracy: 0.55778 |  0:19:02s\n",
            "epoch 2217| loss: 0.89383 | train_accuracy: 0.58372 | val_accuracy: 0.56537 |  0:19:02s\n",
            "epoch 2218| loss: 0.88941 | train_accuracy: 0.58408 | val_accuracy: 0.56697 |  0:19:03s\n",
            "epoch 2219| loss: 0.88915 | train_accuracy: 0.58243 | val_accuracy: 0.56257 |  0:19:03s\n",
            "epoch 2220| loss: 0.88796 | train_accuracy: 0.58279 | val_accuracy: 0.55858 |  0:19:04s\n",
            "epoch 2221| loss: 0.89021 | train_accuracy: 0.57941 | val_accuracy: 0.55098 |  0:19:04s\n",
            "epoch 2222| loss: 0.89067 | train_accuracy: 0.58132 | val_accuracy: 0.55538 |  0:19:05s\n",
            "epoch 2223| loss: 0.89081 | train_accuracy: 0.57959 | val_accuracy: 0.55578 |  0:19:05s\n",
            "epoch 2224| loss: 0.89401 | train_accuracy: 0.5775  | val_accuracy: 0.55298 |  0:19:06s\n",
            "epoch 2225| loss: 0.89564 | train_accuracy: 0.57746 | val_accuracy: 0.55378 |  0:19:06s\n",
            "epoch 2226| loss: 0.8959  | train_accuracy: 0.57519 | val_accuracy: 0.55778 |  0:19:07s\n",
            "epoch 2227| loss: 0.89826 | train_accuracy: 0.57559 | val_accuracy: 0.55098 |  0:19:07s\n",
            "epoch 2228| loss: 0.90051 | train_accuracy: 0.57648 | val_accuracy: 0.55458 |  0:19:08s\n",
            "epoch 2229| loss: 0.8965  | train_accuracy: 0.57759 | val_accuracy: 0.55778 |  0:19:08s\n",
            "epoch 2230| loss: 0.89717 | train_accuracy: 0.57946 | val_accuracy: 0.56257 |  0:19:09s\n",
            "epoch 2231| loss: 0.89523 | train_accuracy: 0.57906 | val_accuracy: 0.56018 |  0:19:09s\n",
            "epoch 2232| loss: 0.89369 | train_accuracy: 0.57679 | val_accuracy: 0.55378 |  0:19:10s\n",
            "epoch 2233| loss: 0.89769 | train_accuracy: 0.57755 | val_accuracy: 0.55458 |  0:19:10s\n",
            "epoch 2234| loss: 0.89381 | train_accuracy: 0.57821 | val_accuracy: 0.55498 |  0:19:11s\n",
            "epoch 2235| loss: 0.89424 | train_accuracy: 0.57604 | val_accuracy: 0.55818 |  0:19:11s\n",
            "epoch 2236| loss: 0.89306 | train_accuracy: 0.5771  | val_accuracy: 0.55538 |  0:19:12s\n",
            "epoch 2237| loss: 0.89642 | train_accuracy: 0.57923 | val_accuracy: 0.55818 |  0:19:12s\n",
            "epoch 2238| loss: 0.89363 | train_accuracy: 0.57821 | val_accuracy: 0.55778 |  0:19:13s\n",
            "epoch 2239| loss: 0.89294 | train_accuracy: 0.57755 | val_accuracy: 0.55658 |  0:19:13s\n",
            "epoch 2240| loss: 0.89922 | train_accuracy: 0.57573 | val_accuracy: 0.55018 |  0:19:14s\n",
            "epoch 2241| loss: 0.89114 | train_accuracy: 0.57613 | val_accuracy: 0.55458 |  0:19:14s\n",
            "epoch 2242| loss: 0.89633 | train_accuracy: 0.57279 | val_accuracy: 0.54978 |  0:19:15s\n",
            "epoch 2243| loss: 0.89767 | train_accuracy: 0.57013 | val_accuracy: 0.55178 |  0:19:15s\n",
            "epoch 2244| loss: 0.90158 | train_accuracy: 0.57133 | val_accuracy: 0.55578 |  0:19:16s\n",
            "epoch 2245| loss: 0.89789 | train_accuracy: 0.57457 | val_accuracy: 0.55978 |  0:19:16s\n",
            "epoch 2246| loss: 0.89852 | train_accuracy: 0.57208 | val_accuracy: 0.55338 |  0:19:17s\n",
            "epoch 2247| loss: 0.89796 | train_accuracy: 0.57559 | val_accuracy: 0.55658 |  0:19:17s\n",
            "epoch 2248| loss: 0.89325 | train_accuracy: 0.57759 | val_accuracy: 0.55858 |  0:19:18s\n",
            "epoch 2249| loss: 0.89172 | train_accuracy: 0.58048 | val_accuracy: 0.55898 |  0:19:18s\n",
            "epoch 2250| loss: 0.89072 | train_accuracy: 0.57977 | val_accuracy: 0.56257 |  0:19:19s\n",
            "epoch 2251| loss: 0.89137 | train_accuracy: 0.57621 | val_accuracy: 0.55978 |  0:19:19s\n",
            "epoch 2252| loss: 0.89002 | train_accuracy: 0.5787  | val_accuracy: 0.56058 |  0:19:20s\n",
            "epoch 2253| loss: 0.89569 | train_accuracy: 0.5787  | val_accuracy: 0.56337 |  0:19:20s\n",
            "epoch 2254| loss: 0.89214 | train_accuracy: 0.57715 | val_accuracy: 0.56337 |  0:19:21s\n",
            "epoch 2255| loss: 0.89445 | train_accuracy: 0.57675 | val_accuracy: 0.56377 |  0:19:21s\n",
            "epoch 2256| loss: 0.89374 | train_accuracy: 0.5779  | val_accuracy: 0.56737 |  0:19:22s\n",
            "epoch 2257| loss: 0.89195 | train_accuracy: 0.57955 | val_accuracy: 0.56218 |  0:19:22s\n",
            "epoch 2258| loss: 0.8899  | train_accuracy: 0.57884 | val_accuracy: 0.56138 |  0:19:23s\n",
            "epoch 2259| loss: 0.88964 | train_accuracy: 0.58017 | val_accuracy: 0.56337 |  0:19:23s\n",
            "epoch 2260| loss: 0.89255 | train_accuracy: 0.57884 | val_accuracy: 0.56218 |  0:19:24s\n",
            "epoch 2261| loss: 0.89188 | train_accuracy: 0.57852 | val_accuracy: 0.56857 |  0:19:24s\n",
            "epoch 2262| loss: 0.89547 | train_accuracy: 0.58003 | val_accuracy: 0.56537 |  0:19:25s\n",
            "epoch 2263| loss: 0.89186 | train_accuracy: 0.58012 | val_accuracy: 0.56377 |  0:19:25s\n",
            "epoch 2264| loss: 0.88884 | train_accuracy: 0.58079 | val_accuracy: 0.56657 |  0:19:26s\n",
            "epoch 2265| loss: 0.88753 | train_accuracy: 0.58203 | val_accuracy: 0.56377 |  0:19:26s\n",
            "epoch 2266| loss: 0.89117 | train_accuracy: 0.57999 | val_accuracy: 0.56937 |  0:19:27s\n",
            "epoch 2267| loss: 0.88896 | train_accuracy: 0.5819  | val_accuracy: 0.57097 |  0:19:27s\n",
            "epoch 2268| loss: 0.89108 | train_accuracy: 0.58186 | val_accuracy: 0.56577 |  0:19:28s\n",
            "epoch 2269| loss: 0.89006 | train_accuracy: 0.58137 | val_accuracy: 0.56497 |  0:19:28s\n",
            "epoch 2270| loss: 0.89362 | train_accuracy: 0.58008 | val_accuracy: 0.56657 |  0:19:29s\n",
            "epoch 2271| loss: 0.88992 | train_accuracy: 0.58243 | val_accuracy: 0.56537 |  0:19:29s\n",
            "epoch 2272| loss: 0.88829 | train_accuracy: 0.58066 | val_accuracy: 0.57097 |  0:19:30s\n",
            "epoch 2273| loss: 0.88843 | train_accuracy: 0.58252 | val_accuracy: 0.56377 |  0:19:30s\n",
            "epoch 2274| loss: 0.88899 | train_accuracy: 0.58177 | val_accuracy: 0.56817 |  0:19:31s\n",
            "epoch 2275| loss: 0.89107 | train_accuracy: 0.58088 | val_accuracy: 0.56817 |  0:19:31s\n",
            "epoch 2276| loss: 0.88777 | train_accuracy: 0.58137 | val_accuracy: 0.56178 |  0:19:32s\n",
            "epoch 2277| loss: 0.88712 | train_accuracy: 0.58292 | val_accuracy: 0.56697 |  0:19:33s\n",
            "epoch 2278| loss: 0.88697 | train_accuracy: 0.58199 | val_accuracy: 0.56257 |  0:19:33s\n",
            "epoch 2279| loss: 0.88546 | train_accuracy: 0.58092 | val_accuracy: 0.56138 |  0:19:34s\n",
            "epoch 2280| loss: 0.8877  | train_accuracy: 0.58363 | val_accuracy: 0.56417 |  0:19:35s\n",
            "epoch 2281| loss: 0.88767 | train_accuracy: 0.58403 | val_accuracy: 0.56657 |  0:19:37s\n",
            "epoch 2282| loss: 0.88807 | train_accuracy: 0.58306 | val_accuracy: 0.56817 |  0:19:37s\n",
            "epoch 2283| loss: 0.88496 | train_accuracy: 0.58421 | val_accuracy: 0.56537 |  0:19:37s\n",
            "epoch 2284| loss: 0.88673 | train_accuracy: 0.58292 | val_accuracy: 0.57177 |  0:19:38s\n",
            "epoch 2285| loss: 0.88845 | train_accuracy: 0.58474 | val_accuracy: 0.56817 |  0:19:39s\n",
            "epoch 2286| loss: 0.89066 | train_accuracy: 0.5843  | val_accuracy: 0.57337 |  0:19:40s\n",
            "epoch 2287| loss: 0.88884 | train_accuracy: 0.58452 | val_accuracy: 0.56977 |  0:19:41s\n",
            "epoch 2288| loss: 0.88579 | train_accuracy: 0.58261 | val_accuracy: 0.56817 |  0:19:41s\n",
            "epoch 2289| loss: 0.88778 | train_accuracy: 0.58261 | val_accuracy: 0.56977 |  0:19:42s\n",
            "epoch 2290| loss: 0.88508 | train_accuracy: 0.58292 | val_accuracy: 0.56737 |  0:19:43s\n",
            "epoch 2291| loss: 0.88978 | train_accuracy: 0.58501 | val_accuracy: 0.57017 |  0:19:44s\n",
            "epoch 2292| loss: 0.88643 | train_accuracy: 0.5839  | val_accuracy: 0.56577 |  0:19:45s\n",
            "epoch 2293| loss: 0.88424 | train_accuracy: 0.58386 | val_accuracy: 0.56377 |  0:19:46s\n",
            "epoch 2294| loss: 0.88284 | train_accuracy: 0.58452 | val_accuracy: 0.56377 |  0:19:47s\n",
            "epoch 2295| loss: 0.88563 | train_accuracy: 0.58372 | val_accuracy: 0.56257 |  0:19:48s\n",
            "epoch 2296| loss: 0.88393 | train_accuracy: 0.58443 | val_accuracy: 0.56138 |  0:19:49s\n",
            "epoch 2297| loss: 0.88358 | train_accuracy: 0.58523 | val_accuracy: 0.56257 |  0:19:49s\n",
            "epoch 2298| loss: 0.882   | train_accuracy: 0.58341 | val_accuracy: 0.56058 |  0:19:50s\n",
            "epoch 2299| loss: 0.88565 | train_accuracy: 0.5839  | val_accuracy: 0.56337 |  0:19:50s\n",
            "epoch 2300| loss: 0.88684 | train_accuracy: 0.58439 | val_accuracy: 0.56737 |  0:19:51s\n",
            "epoch 2301| loss: 0.89062 | train_accuracy: 0.58488 | val_accuracy: 0.56577 |  0:19:51s\n",
            "epoch 2302| loss: 0.88485 | train_accuracy: 0.58519 | val_accuracy: 0.57137 |  0:19:52s\n",
            "epoch 2303| loss: 0.8833  | train_accuracy: 0.58297 | val_accuracy: 0.57097 |  0:19:52s\n",
            "epoch 2304| loss: 0.88555 | train_accuracy: 0.58412 | val_accuracy: 0.56337 |  0:19:53s\n",
            "epoch 2305| loss: 0.88816 | train_accuracy: 0.58386 | val_accuracy: 0.57217 |  0:19:54s\n",
            "epoch 2306| loss: 0.88365 | train_accuracy: 0.5843  | val_accuracy: 0.57217 |  0:19:55s\n",
            "epoch 2307| loss: 0.8901  | train_accuracy: 0.58003 | val_accuracy: 0.56337 |  0:19:56s\n",
            "epoch 2308| loss: 0.88505 | train_accuracy: 0.58377 | val_accuracy: 0.57177 |  0:19:56s\n",
            "epoch 2309| loss: 0.88621 | train_accuracy: 0.58261 | val_accuracy: 0.56857 |  0:19:57s\n",
            "epoch 2310| loss: 0.88819 | train_accuracy: 0.58372 | val_accuracy: 0.57417 |  0:19:57s\n",
            "epoch 2311| loss: 0.88538 | train_accuracy: 0.58408 | val_accuracy: 0.57177 |  0:19:58s\n",
            "epoch 2312| loss: 0.88545 | train_accuracy: 0.58363 | val_accuracy: 0.56737 |  0:19:58s\n",
            "epoch 2313| loss: 0.89092 | train_accuracy: 0.58461 | val_accuracy: 0.57057 |  0:19:59s\n",
            "epoch 2314| loss: 0.88807 | train_accuracy: 0.58319 | val_accuracy: 0.56337 |  0:20:01s\n",
            "epoch 2315| loss: 0.88565 | train_accuracy: 0.5855  | val_accuracy: 0.57017 |  0:20:02s\n",
            "epoch 2316| loss: 0.88596 | train_accuracy: 0.58563 | val_accuracy: 0.57177 |  0:20:03s\n",
            "epoch 2317| loss: 0.88412 | train_accuracy: 0.58541 | val_accuracy: 0.56697 |  0:20:03s\n",
            "epoch 2318| loss: 0.88414 | train_accuracy: 0.58528 | val_accuracy: 0.56777 |  0:20:04s\n",
            "epoch 2319| loss: 0.88887 | train_accuracy: 0.58594 | val_accuracy: 0.57177 |  0:20:04s\n",
            "epoch 2320| loss: 0.88646 | train_accuracy: 0.58359 | val_accuracy: 0.57057 |  0:20:05s\n",
            "epoch 2321| loss: 0.88733 | train_accuracy: 0.58394 | val_accuracy: 0.56657 |  0:20:05s\n",
            "epoch 2322| loss: 0.88302 | train_accuracy: 0.58408 | val_accuracy: 0.56577 |  0:20:06s\n",
            "epoch 2323| loss: 0.88534 | train_accuracy: 0.5803  | val_accuracy: 0.55978 |  0:20:06s\n",
            "epoch 2324| loss: 0.88745 | train_accuracy: 0.58683 | val_accuracy: 0.56457 |  0:20:07s\n",
            "epoch 2325| loss: 0.88671 | train_accuracy: 0.58403 | val_accuracy: 0.56617 |  0:20:07s\n",
            "epoch 2326| loss: 0.88315 | train_accuracy: 0.5859  | val_accuracy: 0.56857 |  0:20:08s\n",
            "epoch 2327| loss: 0.88527 | train_accuracy: 0.5847  | val_accuracy: 0.56377 |  0:20:08s\n",
            "epoch 2328| loss: 0.88186 | train_accuracy: 0.58439 | val_accuracy: 0.57057 |  0:20:09s\n",
            "epoch 2329| loss: 0.88378 | train_accuracy: 0.58559 | val_accuracy: 0.56817 |  0:20:09s\n",
            "epoch 2330| loss: 0.88427 | train_accuracy: 0.58421 | val_accuracy: 0.57017 |  0:20:10s\n",
            "epoch 2331| loss: 0.88577 | train_accuracy: 0.58292 | val_accuracy: 0.56657 |  0:20:10s\n",
            "epoch 2332| loss: 0.88115 | train_accuracy: 0.58443 | val_accuracy: 0.56817 |  0:20:11s\n",
            "epoch 2333| loss: 0.88489 | train_accuracy: 0.58212 | val_accuracy: 0.56817 |  0:20:11s\n",
            "epoch 2334| loss: 0.887   | train_accuracy: 0.58377 | val_accuracy: 0.56937 |  0:20:12s\n",
            "epoch 2335| loss: 0.88479 | train_accuracy: 0.5839  | val_accuracy: 0.56857 |  0:20:12s\n",
            "epoch 2336| loss: 0.88314 | train_accuracy: 0.58394 | val_accuracy: 0.56857 |  0:20:13s\n",
            "epoch 2337| loss: 0.88298 | train_accuracy: 0.5839  | val_accuracy: 0.56417 |  0:20:13s\n",
            "epoch 2338| loss: 0.88324 | train_accuracy: 0.58217 | val_accuracy: 0.56817 |  0:20:14s\n",
            "epoch 2339| loss: 0.88009 | train_accuracy: 0.58443 | val_accuracy: 0.57697 |  0:20:15s\n",
            "epoch 2340| loss: 0.88409 | train_accuracy: 0.58408 | val_accuracy: 0.57137 |  0:20:15s\n",
            "epoch 2341| loss: 0.88347 | train_accuracy: 0.58346 | val_accuracy: 0.57017 |  0:20:16s\n",
            "epoch 2342| loss: 0.88409 | train_accuracy: 0.58426 | val_accuracy: 0.56777 |  0:20:16s\n",
            "epoch 2343| loss: 0.8805  | train_accuracy: 0.58559 | val_accuracy: 0.56497 |  0:20:16s\n",
            "epoch 2344| loss: 0.88271 | train_accuracy: 0.5843  | val_accuracy: 0.56257 |  0:20:17s\n",
            "epoch 2345| loss: 0.88041 | train_accuracy: 0.58528 | val_accuracy: 0.56297 |  0:20:18s\n",
            "epoch 2346| loss: 0.88492 | train_accuracy: 0.5819  | val_accuracy: 0.56417 |  0:20:18s\n",
            "epoch 2347| loss: 0.88525 | train_accuracy: 0.58448 | val_accuracy: 0.56937 |  0:20:19s\n",
            "epoch 2348| loss: 0.88218 | train_accuracy: 0.58421 | val_accuracy: 0.56937 |  0:20:19s\n",
            "epoch 2349| loss: 0.87989 | train_accuracy: 0.58519 | val_accuracy: 0.56497 |  0:20:20s\n",
            "epoch 2350| loss: 0.88333 | train_accuracy: 0.5887  | val_accuracy: 0.56537 |  0:20:20s\n",
            "epoch 2351| loss: 0.88532 | train_accuracy: 0.5867  | val_accuracy: 0.56417 |  0:20:21s\n",
            "epoch 2352| loss: 0.88033 | train_accuracy: 0.58643 | val_accuracy: 0.56417 |  0:20:21s\n",
            "epoch 2353| loss: 0.88196 | train_accuracy: 0.58634 | val_accuracy: 0.56377 |  0:20:22s\n",
            "epoch 2354| loss: 0.88164 | train_accuracy: 0.58697 | val_accuracy: 0.56737 |  0:20:22s\n",
            "epoch 2355| loss: 0.88079 | train_accuracy: 0.58723 | val_accuracy: 0.56537 |  0:20:23s\n",
            "epoch 2356| loss: 0.88307 | train_accuracy: 0.5843  | val_accuracy: 0.56537 |  0:20:23s\n",
            "epoch 2357| loss: 0.88227 | train_accuracy: 0.58603 | val_accuracy: 0.56537 |  0:20:24s\n",
            "epoch 2358| loss: 0.88267 | train_accuracy: 0.58612 | val_accuracy: 0.57337 |  0:20:24s\n",
            "epoch 2359| loss: 0.8841  | train_accuracy: 0.5839  | val_accuracy: 0.56897 |  0:20:25s\n",
            "epoch 2360| loss: 0.88082 | train_accuracy: 0.58372 | val_accuracy: 0.56377 |  0:20:25s\n",
            "epoch 2361| loss: 0.87916 | train_accuracy: 0.58692 | val_accuracy: 0.57017 |  0:20:26s\n",
            "epoch 2362| loss: 0.88126 | train_accuracy: 0.58657 | val_accuracy: 0.56577 |  0:20:26s\n",
            "epoch 2363| loss: 0.88285 | train_accuracy: 0.58261 | val_accuracy: 0.56737 |  0:20:27s\n",
            "epoch 2364| loss: 0.88304 | train_accuracy: 0.58674 | val_accuracy: 0.56457 |  0:20:27s\n",
            "epoch 2365| loss: 0.88468 | train_accuracy: 0.58434 | val_accuracy: 0.56377 |  0:20:28s\n",
            "epoch 2366| loss: 0.88028 | train_accuracy: 0.58501 | val_accuracy: 0.56577 |  0:20:28s\n",
            "epoch 2367| loss: 0.87981 | train_accuracy: 0.58434 | val_accuracy: 0.56737 |  0:20:29s\n",
            "epoch 2368| loss: 0.88103 | train_accuracy: 0.58466 | val_accuracy: 0.56377 |  0:20:29s\n",
            "epoch 2369| loss: 0.88051 | train_accuracy: 0.58528 | val_accuracy: 0.56977 |  0:20:30s\n",
            "epoch 2370| loss: 0.88396 | train_accuracy: 0.58541 | val_accuracy: 0.56657 |  0:20:30s\n",
            "epoch 2371| loss: 0.88144 | train_accuracy: 0.58705 | val_accuracy: 0.56777 |  0:20:31s\n",
            "epoch 2372| loss: 0.88334 | train_accuracy: 0.58648 | val_accuracy: 0.57137 |  0:20:31s\n",
            "epoch 2373| loss: 0.88297 | train_accuracy: 0.58474 | val_accuracy: 0.57017 |  0:20:32s\n",
            "epoch 2374| loss: 0.88031 | train_accuracy: 0.58466 | val_accuracy: 0.56657 |  0:20:32s\n",
            "epoch 2375| loss: 0.87941 | train_accuracy: 0.58674 | val_accuracy: 0.56497 |  0:20:33s\n",
            "epoch 2376| loss: 0.88203 | train_accuracy: 0.58545 | val_accuracy: 0.55898 |  0:20:33s\n",
            "epoch 2377| loss: 0.87927 | train_accuracy: 0.58679 | val_accuracy: 0.56657 |  0:20:34s\n",
            "epoch 2378| loss: 0.88379 | train_accuracy: 0.58688 | val_accuracy: 0.56257 |  0:20:34s\n",
            "epoch 2379| loss: 0.87937 | train_accuracy: 0.58808 | val_accuracy: 0.57057 |  0:20:35s\n",
            "epoch 2380| loss: 0.87989 | train_accuracy: 0.58763 | val_accuracy: 0.57377 |  0:20:35s\n",
            "epoch 2381| loss: 0.88029 | train_accuracy: 0.58794 | val_accuracy: 0.56777 |  0:20:36s\n",
            "epoch 2382| loss: 0.88225 | train_accuracy: 0.5879  | val_accuracy: 0.56977 |  0:20:36s\n",
            "epoch 2383| loss: 0.88463 | train_accuracy: 0.58701 | val_accuracy: 0.56777 |  0:20:37s\n",
            "epoch 2384| loss: 0.88245 | train_accuracy: 0.58705 | val_accuracy: 0.56737 |  0:20:37s\n",
            "epoch 2385| loss: 0.88365 | train_accuracy: 0.58759 | val_accuracy: 0.56657 |  0:20:38s\n",
            "epoch 2386| loss: 0.8791  | train_accuracy: 0.58928 | val_accuracy: 0.56697 |  0:20:38s\n",
            "epoch 2387| loss: 0.88422 | train_accuracy: 0.58856 | val_accuracy: 0.57017 |  0:20:39s\n",
            "epoch 2388| loss: 0.88309 | train_accuracy: 0.58843 | val_accuracy: 0.56977 |  0:20:40s\n",
            "epoch 2389| loss: 0.88035 | train_accuracy: 0.58603 | val_accuracy: 0.56937 |  0:20:40s\n",
            "epoch 2390| loss: 0.8808  | train_accuracy: 0.58808 | val_accuracy: 0.57137 |  0:20:41s\n",
            "epoch 2391| loss: 0.8816  | train_accuracy: 0.58732 | val_accuracy: 0.56537 |  0:20:41s\n",
            "epoch 2392| loss: 0.88011 | train_accuracy: 0.58852 | val_accuracy: 0.56937 |  0:20:42s\n",
            "epoch 2393| loss: 0.88261 | train_accuracy: 0.58896 | val_accuracy: 0.57217 |  0:20:42s\n",
            "epoch 2394| loss: 0.88023 | train_accuracy: 0.58745 | val_accuracy: 0.57137 |  0:20:43s\n",
            "epoch 2395| loss: 0.88039 | train_accuracy: 0.5895  | val_accuracy: 0.56497 |  0:20:43s\n",
            "epoch 2396| loss: 0.87695 | train_accuracy: 0.58901 | val_accuracy: 0.56577 |  0:20:44s\n",
            "epoch 2397| loss: 0.88459 | train_accuracy: 0.58719 | val_accuracy: 0.56417 |  0:20:44s\n",
            "epoch 2398| loss: 0.87873 | train_accuracy: 0.58776 | val_accuracy: 0.56817 |  0:20:45s\n",
            "epoch 2399| loss: 0.88108 | train_accuracy: 0.58701 | val_accuracy: 0.56337 |  0:20:45s\n",
            "epoch 2400| loss: 0.88329 | train_accuracy: 0.58617 | val_accuracy: 0.56777 |  0:20:46s\n",
            "epoch 2401| loss: 0.87965 | train_accuracy: 0.5875  | val_accuracy: 0.57257 |  0:20:46s\n",
            "epoch 2402| loss: 0.88411 | train_accuracy: 0.58568 | val_accuracy: 0.57057 |  0:20:47s\n",
            "epoch 2403| loss: 0.8792  | train_accuracy: 0.58545 | val_accuracy: 0.56897 |  0:20:47s\n",
            "epoch 2404| loss: 0.87938 | train_accuracy: 0.58661 | val_accuracy: 0.56537 |  0:20:48s\n",
            "epoch 2405| loss: 0.88155 | train_accuracy: 0.58768 | val_accuracy: 0.56497 |  0:20:48s\n",
            "epoch 2406| loss: 0.87695 | train_accuracy: 0.58674 | val_accuracy: 0.57257 |  0:20:49s\n",
            "epoch 2407| loss: 0.8776  | train_accuracy: 0.58768 | val_accuracy: 0.57017 |  0:20:49s\n",
            "epoch 2408| loss: 0.87798 | train_accuracy: 0.5855  | val_accuracy: 0.56577 |  0:20:50s\n",
            "epoch 2409| loss: 0.87947 | train_accuracy: 0.58692 | val_accuracy: 0.56617 |  0:20:50s\n",
            "epoch 2410| loss: 0.87693 | train_accuracy: 0.58785 | val_accuracy: 0.56218 |  0:20:51s\n",
            "epoch 2411| loss: 0.87927 | train_accuracy: 0.5883  | val_accuracy: 0.57057 |  0:20:51s\n",
            "epoch 2412| loss: 0.8827  | train_accuracy: 0.58865 | val_accuracy: 0.56617 |  0:20:52s\n",
            "epoch 2413| loss: 0.87752 | train_accuracy: 0.58692 | val_accuracy: 0.56737 |  0:20:52s\n",
            "epoch 2414| loss: 0.87718 | train_accuracy: 0.58959 | val_accuracy: 0.57257 |  0:20:53s\n",
            "epoch 2415| loss: 0.8814  | train_accuracy: 0.58808 | val_accuracy: 0.56857 |  0:20:53s\n",
            "epoch 2416| loss: 0.88    | train_accuracy: 0.58808 | val_accuracy: 0.56777 |  0:20:54s\n",
            "epoch 2417| loss: 0.87782 | train_accuracy: 0.58936 | val_accuracy: 0.56937 |  0:20:54s\n",
            "epoch 2418| loss: 0.8791  | train_accuracy: 0.5875  | val_accuracy: 0.57057 |  0:20:55s\n",
            "epoch 2419| loss: 0.88152 | train_accuracy: 0.58861 | val_accuracy: 0.57377 |  0:20:55s\n",
            "epoch 2420| loss: 0.87885 | train_accuracy: 0.58848 | val_accuracy: 0.57257 |  0:20:56s\n",
            "epoch 2421| loss: 0.8794  | train_accuracy: 0.59003 | val_accuracy: 0.56897 |  0:20:56s\n",
            "epoch 2422| loss: 0.88013 | train_accuracy: 0.59087 | val_accuracy: 0.56737 |  0:20:57s\n",
            "epoch 2423| loss: 0.8796  | train_accuracy: 0.58923 | val_accuracy: 0.56697 |  0:20:57s\n",
            "epoch 2424| loss: 0.87942 | train_accuracy: 0.58839 | val_accuracy: 0.57177 |  0:20:58s\n",
            "epoch 2425| loss: 0.87498 | train_accuracy: 0.58848 | val_accuracy: 0.56737 |  0:20:58s\n",
            "epoch 2426| loss: 0.87962 | train_accuracy: 0.58852 | val_accuracy: 0.56737 |  0:20:59s\n",
            "epoch 2427| loss: 0.87465 | train_accuracy: 0.59132 | val_accuracy: 0.56617 |  0:20:59s\n",
            "epoch 2428| loss: 0.87406 | train_accuracy: 0.59119 | val_accuracy: 0.56977 |  0:21:00s\n",
            "epoch 2429| loss: 0.88043 | train_accuracy: 0.5891  | val_accuracy: 0.56537 |  0:21:00s\n",
            "epoch 2430| loss: 0.88022 | train_accuracy: 0.58781 | val_accuracy: 0.57137 |  0:21:01s\n",
            "epoch 2431| loss: 0.87585 | train_accuracy: 0.58781 | val_accuracy: 0.56617 |  0:21:01s\n",
            "epoch 2432| loss: 0.88121 | train_accuracy: 0.58768 | val_accuracy: 0.56737 |  0:21:02s\n",
            "epoch 2433| loss: 0.87379 | train_accuracy: 0.58812 | val_accuracy: 0.56977 |  0:21:02s\n",
            "epoch 2434| loss: 0.87875 | train_accuracy: 0.59008 | val_accuracy: 0.56857 |  0:21:03s\n",
            "epoch 2435| loss: 0.87761 | train_accuracy: 0.58932 | val_accuracy: 0.57017 |  0:21:03s\n",
            "epoch 2436| loss: 0.88147 | train_accuracy: 0.58936 | val_accuracy: 0.57257 |  0:21:03s\n",
            "epoch 2437| loss: 0.87958 | train_accuracy: 0.58839 | val_accuracy: 0.57377 |  0:21:04s\n",
            "epoch 2438| loss: 0.87765 | train_accuracy: 0.58923 | val_accuracy: 0.56937 |  0:21:05s\n",
            "epoch 2439| loss: 0.88013 | train_accuracy: 0.58816 | val_accuracy: 0.57177 |  0:21:05s\n",
            "epoch 2440| loss: 0.87761 | train_accuracy: 0.58968 | val_accuracy: 0.57657 |  0:21:06s\n",
            "epoch 2441| loss: 0.87999 | train_accuracy: 0.58812 | val_accuracy: 0.57097 |  0:21:06s\n",
            "epoch 2442| loss: 0.8744  | train_accuracy: 0.58919 | val_accuracy: 0.57097 |  0:21:07s\n",
            "epoch 2443| loss: 0.8753  | train_accuracy: 0.5895  | val_accuracy: 0.56897 |  0:21:07s\n",
            "epoch 2444| loss: 0.87883 | train_accuracy: 0.58803 | val_accuracy: 0.56857 |  0:21:07s\n",
            "epoch 2445| loss: 0.88039 | train_accuracy: 0.58928 | val_accuracy: 0.56697 |  0:21:08s\n",
            "epoch 2446| loss: 0.87978 | train_accuracy: 0.59016 | val_accuracy: 0.56577 |  0:21:08s\n",
            "epoch 2447| loss: 0.87711 | train_accuracy: 0.58856 | val_accuracy: 0.56178 |  0:21:09s\n",
            "epoch 2448| loss: 0.88008 | train_accuracy: 0.58834 | val_accuracy: 0.56257 |  0:21:09s\n",
            "epoch 2449| loss: 0.87965 | train_accuracy: 0.58803 | val_accuracy: 0.56697 |  0:21:10s\n",
            "epoch 2450| loss: 0.8829  | train_accuracy: 0.58888 | val_accuracy: 0.56297 |  0:21:10s\n",
            "epoch 2451| loss: 0.87919 | train_accuracy: 0.58883 | val_accuracy: 0.56537 |  0:21:11s\n",
            "epoch 2452| loss: 0.87842 | train_accuracy: 0.59119 | val_accuracy: 0.56697 |  0:21:11s\n",
            "epoch 2453| loss: 0.87892 | train_accuracy: 0.59074 | val_accuracy: 0.56657 |  0:21:12s\n",
            "epoch 2454| loss: 0.88136 | train_accuracy: 0.58888 | val_accuracy: 0.57017 |  0:21:12s\n",
            "epoch 2455| loss: 0.87926 | train_accuracy: 0.59043 | val_accuracy: 0.56457 |  0:21:13s\n",
            "epoch 2456| loss: 0.87774 | train_accuracy: 0.59012 | val_accuracy: 0.57017 |  0:21:13s\n",
            "epoch 2457| loss: 0.87723 | train_accuracy: 0.59194 | val_accuracy: 0.57497 |  0:21:14s\n",
            "epoch 2458| loss: 0.87794 | train_accuracy: 0.59163 | val_accuracy: 0.57097 |  0:21:14s\n",
            "epoch 2459| loss: 0.88042 | train_accuracy: 0.58972 | val_accuracy: 0.56817 |  0:21:15s\n",
            "epoch 2460| loss: 0.87586 | train_accuracy: 0.58994 | val_accuracy: 0.57057 |  0:21:15s\n",
            "epoch 2461| loss: 0.87679 | train_accuracy: 0.59199 | val_accuracy: 0.57137 |  0:21:16s\n",
            "epoch 2462| loss: 0.87674 | train_accuracy: 0.58985 | val_accuracy: 0.57057 |  0:21:16s\n",
            "epoch 2463| loss: 0.88118 | train_accuracy: 0.58665 | val_accuracy: 0.56337 |  0:21:17s\n",
            "epoch 2464| loss: 0.87982 | train_accuracy: 0.5899  | val_accuracy: 0.57457 |  0:21:17s\n",
            "epoch 2465| loss: 0.87812 | train_accuracy: 0.58728 | val_accuracy: 0.56537 |  0:21:18s\n",
            "epoch 2466| loss: 0.87599 | train_accuracy: 0.59119 | val_accuracy: 0.57617 |  0:21:18s\n",
            "epoch 2467| loss: 0.88067 | train_accuracy: 0.58945 | val_accuracy: 0.57057 |  0:21:19s\n",
            "epoch 2468| loss: 0.87958 | train_accuracy: 0.59043 | val_accuracy: 0.57177 |  0:21:19s\n",
            "epoch 2469| loss: 0.87634 | train_accuracy: 0.59043 | val_accuracy: 0.56977 |  0:21:20s\n",
            "epoch 2470| loss: 0.87626 | train_accuracy: 0.59043 | val_accuracy: 0.56897 |  0:21:20s\n",
            "epoch 2471| loss: 0.87974 | train_accuracy: 0.58976 | val_accuracy: 0.56617 |  0:21:21s\n",
            "epoch 2472| loss: 0.87731 | train_accuracy: 0.58852 | val_accuracy: 0.56297 |  0:21:21s\n",
            "epoch 2473| loss: 0.88061 | train_accuracy: 0.58985 | val_accuracy: 0.56697 |  0:21:22s\n",
            "epoch 2474| loss: 0.87939 | train_accuracy: 0.59154 | val_accuracy: 0.56897 |  0:21:22s\n",
            "epoch 2475| loss: 0.87682 | train_accuracy: 0.59274 | val_accuracy: 0.55938 |  0:21:23s\n",
            "epoch 2476| loss: 0.87683 | train_accuracy: 0.59172 | val_accuracy: 0.56257 |  0:21:23s\n",
            "epoch 2477| loss: 0.8769  | train_accuracy: 0.59163 | val_accuracy: 0.56577 |  0:21:24s\n",
            "epoch 2478| loss: 0.87666 | train_accuracy: 0.59123 | val_accuracy: 0.56257 |  0:21:24s\n",
            "epoch 2479| loss: 0.87822 | train_accuracy: 0.59194 | val_accuracy: 0.56337 |  0:21:25s\n",
            "epoch 2480| loss: 0.8781  | train_accuracy: 0.59008 | val_accuracy: 0.56377 |  0:21:26s\n",
            "epoch 2481| loss: 0.87841 | train_accuracy: 0.59065 | val_accuracy: 0.55938 |  0:21:26s\n",
            "epoch 2482| loss: 0.87654 | train_accuracy: 0.5923  | val_accuracy: 0.56018 |  0:21:27s\n",
            "epoch 2483| loss: 0.87781 | train_accuracy: 0.59256 | val_accuracy: 0.55738 |  0:21:27s\n",
            "epoch 2484| loss: 0.87935 | train_accuracy: 0.58999 | val_accuracy: 0.55818 |  0:21:27s\n",
            "epoch 2485| loss: 0.87759 | train_accuracy: 0.59345 | val_accuracy: 0.57417 |  0:21:28s\n",
            "epoch 2486| loss: 0.88027 | train_accuracy: 0.59132 | val_accuracy: 0.56297 |  0:21:28s\n",
            "epoch 2487| loss: 0.87666 | train_accuracy: 0.59252 | val_accuracy: 0.56617 |  0:21:29s\n",
            "epoch 2488| loss: 0.87937 | train_accuracy: 0.59256 | val_accuracy: 0.56937 |  0:21:29s\n",
            "epoch 2489| loss: 0.87504 | train_accuracy: 0.59105 | val_accuracy: 0.56897 |  0:21:30s\n",
            "epoch 2490| loss: 0.87648 | train_accuracy: 0.59096 | val_accuracy: 0.57257 |  0:21:30s\n",
            "epoch 2491| loss: 0.87701 | train_accuracy: 0.59216 | val_accuracy: 0.57017 |  0:21:31s\n",
            "epoch 2492| loss: 0.87661 | train_accuracy: 0.59127 | val_accuracy: 0.56817 |  0:21:31s\n",
            "epoch 2493| loss: 0.87733 | train_accuracy: 0.59123 | val_accuracy: 0.57417 |  0:21:32s\n",
            "epoch 2494| loss: 0.8753  | train_accuracy: 0.59199 | val_accuracy: 0.57217 |  0:21:32s\n",
            "epoch 2495| loss: 0.87752 | train_accuracy: 0.59141 | val_accuracy: 0.56977 |  0:21:33s\n",
            "epoch 2496| loss: 0.87721 | train_accuracy: 0.59256 | val_accuracy: 0.56897 |  0:21:33s\n",
            "epoch 2497| loss: 0.87532 | train_accuracy: 0.59105 | val_accuracy: 0.57097 |  0:21:34s\n",
            "epoch 2498| loss: 0.87697 | train_accuracy: 0.59105 | val_accuracy: 0.56337 |  0:21:34s\n",
            "epoch 2499| loss: 0.87528 | train_accuracy: 0.59119 | val_accuracy: 0.56098 |  0:21:35s\n",
            "epoch 2500| loss: 0.87767 | train_accuracy: 0.5911  | val_accuracy: 0.56297 |  0:21:35s\n",
            "epoch 2501| loss: 0.87747 | train_accuracy: 0.59119 | val_accuracy: 0.56737 |  0:21:36s\n",
            "epoch 2502| loss: 0.8739  | train_accuracy: 0.59225 | val_accuracy: 0.56937 |  0:21:36s\n",
            "epoch 2503| loss: 0.87881 | train_accuracy: 0.59039 | val_accuracy: 0.56617 |  0:21:37s\n",
            "epoch 2504| loss: 0.87623 | train_accuracy: 0.59061 | val_accuracy: 0.56897 |  0:21:37s\n",
            "epoch 2505| loss: 0.87562 | train_accuracy: 0.59012 | val_accuracy: 0.56257 |  0:21:38s\n",
            "epoch 2506| loss: 0.87582 | train_accuracy: 0.59216 | val_accuracy: 0.56817 |  0:21:38s\n",
            "epoch 2507| loss: 0.87612 | train_accuracy: 0.59172 | val_accuracy: 0.56937 |  0:21:39s\n",
            "epoch 2508| loss: 0.87523 | train_accuracy: 0.59083 | val_accuracy: 0.56857 |  0:21:39s\n",
            "epoch 2509| loss: 0.87977 | train_accuracy: 0.58994 | val_accuracy: 0.56657 |  0:21:40s\n",
            "epoch 2510| loss: 0.88092 | train_accuracy: 0.59096 | val_accuracy: 0.56617 |  0:21:40s\n",
            "epoch 2511| loss: 0.87583 | train_accuracy: 0.59283 | val_accuracy: 0.56657 |  0:21:41s\n",
            "epoch 2512| loss: 0.87627 | train_accuracy: 0.5915  | val_accuracy: 0.57097 |  0:21:41s\n",
            "epoch 2513| loss: 0.87458 | train_accuracy: 0.59083 | val_accuracy: 0.56777 |  0:21:42s\n",
            "epoch 2514| loss: 0.87729 | train_accuracy: 0.59052 | val_accuracy: 0.56737 |  0:21:42s\n",
            "epoch 2515| loss: 0.87747 | train_accuracy: 0.59047 | val_accuracy: 0.57017 |  0:21:43s\n",
            "epoch 2516| loss: 0.87984 | train_accuracy: 0.59181 | val_accuracy: 0.57297 |  0:21:43s\n",
            "epoch 2517| loss: 0.87581 | train_accuracy: 0.58905 | val_accuracy: 0.56697 |  0:21:44s\n",
            "epoch 2518| loss: 0.87607 | train_accuracy: 0.59092 | val_accuracy: 0.56657 |  0:21:44s\n",
            "epoch 2519| loss: 0.87772 | train_accuracy: 0.5915  | val_accuracy: 0.57097 |  0:21:45s\n",
            "epoch 2520| loss: 0.87614 | train_accuracy: 0.58981 | val_accuracy: 0.56178 |  0:21:45s\n",
            "epoch 2521| loss: 0.87899 | train_accuracy: 0.59127 | val_accuracy: 0.56377 |  0:21:46s\n",
            "epoch 2522| loss: 0.88072 | train_accuracy: 0.59079 | val_accuracy: 0.56977 |  0:21:46s\n",
            "epoch 2523| loss: 0.87759 | train_accuracy: 0.58985 | val_accuracy: 0.55538 |  0:21:47s\n",
            "epoch 2524| loss: 0.88137 | train_accuracy: 0.59265 | val_accuracy: 0.57137 |  0:21:47s\n",
            "epoch 2525| loss: 0.87863 | train_accuracy: 0.58883 | val_accuracy: 0.56218 |  0:21:48s\n",
            "epoch 2526| loss: 0.88094 | train_accuracy: 0.59265 | val_accuracy: 0.56297 |  0:21:48s\n",
            "epoch 2527| loss: 0.87796 | train_accuracy: 0.59159 | val_accuracy: 0.56977 |  0:21:49s\n",
            "epoch 2528| loss: 0.88155 | train_accuracy: 0.59039 | val_accuracy: 0.55978 |  0:21:49s\n",
            "epoch 2529| loss: 0.87709 | train_accuracy: 0.58976 | val_accuracy: 0.55818 |  0:21:50s\n",
            "epoch 2530| loss: 0.87706 | train_accuracy: 0.59132 | val_accuracy: 0.56257 |  0:21:50s\n",
            "epoch 2531| loss: 0.87708 | train_accuracy: 0.59105 | val_accuracy: 0.55738 |  0:21:51s\n",
            "epoch 2532| loss: 0.87627 | train_accuracy: 0.5923  | val_accuracy: 0.56457 |  0:21:51s\n",
            "epoch 2533| loss: 0.8742  | train_accuracy: 0.59154 | val_accuracy: 0.56617 |  0:21:52s\n",
            "epoch 2534| loss: 0.87593 | train_accuracy: 0.58936 | val_accuracy: 0.55978 |  0:21:52s\n",
            "epoch 2535| loss: 0.87402 | train_accuracy: 0.59145 | val_accuracy: 0.56257 |  0:21:53s\n",
            "epoch 2536| loss: 0.8752  | train_accuracy: 0.59079 | val_accuracy: 0.56537 |  0:21:53s\n",
            "epoch 2537| loss: 0.87374 | train_accuracy: 0.59056 | val_accuracy: 0.55898 |  0:21:54s\n",
            "epoch 2538| loss: 0.87877 | train_accuracy: 0.59292 | val_accuracy: 0.56537 |  0:21:54s\n",
            "epoch 2539| loss: 0.87575 | train_accuracy: 0.59261 | val_accuracy: 0.56417 |  0:21:55s\n",
            "epoch 2540| loss: 0.87718 | train_accuracy: 0.59323 | val_accuracy: 0.56377 |  0:21:55s\n",
            "epoch 2541| loss: 0.87334 | train_accuracy: 0.59207 | val_accuracy: 0.56537 |  0:21:56s\n",
            "epoch 2542| loss: 0.87705 | train_accuracy: 0.59092 | val_accuracy: 0.55618 |  0:21:56s\n",
            "epoch 2543| loss: 0.8733  | train_accuracy: 0.59034 | val_accuracy: 0.56018 |  0:21:57s\n",
            "epoch 2544| loss: 0.87549 | train_accuracy: 0.59234 | val_accuracy: 0.56257 |  0:21:57s\n",
            "epoch 2545| loss: 0.87486 | train_accuracy: 0.59105 | val_accuracy: 0.56257 |  0:21:58s\n",
            "epoch 2546| loss: 0.87613 | train_accuracy: 0.59154 | val_accuracy: 0.56218 |  0:21:58s\n",
            "epoch 2547| loss: 0.87335 | train_accuracy: 0.59016 | val_accuracy: 0.56697 |  0:21:59s\n",
            "epoch 2548| loss: 0.8756  | train_accuracy: 0.59039 | val_accuracy: 0.56178 |  0:21:59s\n",
            "epoch 2549| loss: 0.87478 | train_accuracy: 0.59047 | val_accuracy: 0.56138 |  0:22:00s\n",
            "epoch 2550| loss: 0.87603 | train_accuracy: 0.59136 | val_accuracy: 0.56577 |  0:22:00s\n",
            "epoch 2551| loss: 0.87278 | train_accuracy: 0.58954 | val_accuracy: 0.55338 |  0:22:01s\n",
            "epoch 2552| loss: 0.87429 | train_accuracy: 0.5919  | val_accuracy: 0.56417 |  0:22:01s\n",
            "epoch 2553| loss: 0.87795 | train_accuracy: 0.59221 | val_accuracy: 0.55738 |  0:22:02s\n",
            "epoch 2554| loss: 0.87641 | train_accuracy: 0.58941 | val_accuracy: 0.55458 |  0:22:02s\n",
            "epoch 2555| loss: 0.87744 | train_accuracy: 0.5915  | val_accuracy: 0.56537 |  0:22:03s\n",
            "epoch 2556| loss: 0.87336 | train_accuracy: 0.59243 | val_accuracy: 0.56897 |  0:22:03s\n",
            "epoch 2557| loss: 0.87537 | train_accuracy: 0.59096 | val_accuracy: 0.55898 |  0:22:04s\n",
            "epoch 2558| loss: 0.87355 | train_accuracy: 0.59345 | val_accuracy: 0.56377 |  0:22:04s\n",
            "epoch 2559| loss: 0.87564 | train_accuracy: 0.59305 | val_accuracy: 0.56617 |  0:22:05s\n",
            "epoch 2560| loss: 0.87768 | train_accuracy: 0.5919  | val_accuracy: 0.56577 |  0:22:05s\n",
            "epoch 2561| loss: 0.87455 | train_accuracy: 0.59034 | val_accuracy: 0.56218 |  0:22:06s\n",
            "epoch 2562| loss: 0.8768  | train_accuracy: 0.59203 | val_accuracy: 0.56537 |  0:22:06s\n",
            "epoch 2563| loss: 0.87634 | train_accuracy: 0.59043 | val_accuracy: 0.56497 |  0:22:07s\n",
            "epoch 2564| loss: 0.87726 | train_accuracy: 0.58985 | val_accuracy: 0.56058 |  0:22:07s\n",
            "epoch 2565| loss: 0.88032 | train_accuracy: 0.5907  | val_accuracy: 0.56817 |  0:22:08s\n",
            "epoch 2566| loss: 0.88254 | train_accuracy: 0.58945 | val_accuracy: 0.56297 |  0:22:08s\n",
            "epoch 2567| loss: 0.87845 | train_accuracy: 0.58919 | val_accuracy: 0.55778 |  0:22:09s\n",
            "epoch 2568| loss: 0.87805 | train_accuracy: 0.59172 | val_accuracy: 0.56897 |  0:22:09s\n",
            "epoch 2569| loss: 0.88407 | train_accuracy: 0.58848 | val_accuracy: 0.56457 |  0:22:10s\n",
            "epoch 2570| loss: 0.87915 | train_accuracy: 0.58808 | val_accuracy: 0.56377 |  0:22:10s\n",
            "epoch 2571| loss: 0.87735 | train_accuracy: 0.59083 | val_accuracy: 0.56417 |  0:22:11s\n",
            "epoch 2572| loss: 0.87653 | train_accuracy: 0.5899  | val_accuracy: 0.56178 |  0:22:11s\n",
            "epoch 2573| loss: 0.87821 | train_accuracy: 0.58856 | val_accuracy: 0.56337 |  0:22:12s\n",
            "epoch 2574| loss: 0.87656 | train_accuracy: 0.5903  | val_accuracy: 0.56297 |  0:22:12s\n",
            "epoch 2575| loss: 0.8765  | train_accuracy: 0.59167 | val_accuracy: 0.57337 |  0:22:13s\n",
            "epoch 2576| loss: 0.87983 | train_accuracy: 0.58972 | val_accuracy: 0.57057 |  0:22:13s\n",
            "epoch 2577| loss: 0.87915 | train_accuracy: 0.58759 | val_accuracy: 0.56857 |  0:22:14s\n",
            "epoch 2578| loss: 0.87773 | train_accuracy: 0.58808 | val_accuracy: 0.56657 |  0:22:14s\n",
            "epoch 2579| loss: 0.87949 | train_accuracy: 0.58794 | val_accuracy: 0.55778 |  0:22:14s\n",
            "epoch 2580| loss: 0.87851 | train_accuracy: 0.59181 | val_accuracy: 0.56617 |  0:22:15s\n",
            "epoch 2581| loss: 0.87828 | train_accuracy: 0.5911  | val_accuracy: 0.56857 |  0:22:16s\n",
            "epoch 2582| loss: 0.87617 | train_accuracy: 0.58928 | val_accuracy: 0.56937 |  0:22:16s\n",
            "epoch 2583| loss: 0.87671 | train_accuracy: 0.59127 | val_accuracy: 0.56617 |  0:22:17s\n",
            "epoch 2584| loss: 0.87282 | train_accuracy: 0.59159 | val_accuracy: 0.56617 |  0:22:17s\n",
            "epoch 2585| loss: 0.87239 | train_accuracy: 0.59136 | val_accuracy: 0.56657 |  0:22:18s\n",
            "epoch 2586| loss: 0.87877 | train_accuracy: 0.59092 | val_accuracy: 0.56737 |  0:22:18s\n",
            "epoch 2587| loss: 0.87439 | train_accuracy: 0.58994 | val_accuracy: 0.56497 |  0:22:19s\n",
            "epoch 2588| loss: 0.87652 | train_accuracy: 0.59127 | val_accuracy: 0.57017 |  0:22:19s\n",
            "epoch 2589| loss: 0.87461 | train_accuracy: 0.59132 | val_accuracy: 0.56977 |  0:22:19s\n",
            "epoch 2590| loss: 0.87254 | train_accuracy: 0.59079 | val_accuracy: 0.56617 |  0:22:20s\n",
            "epoch 2591| loss: 0.87341 | train_accuracy: 0.59185 | val_accuracy: 0.57177 |  0:22:20s\n",
            "epoch 2592| loss: 0.87695 | train_accuracy: 0.59323 | val_accuracy: 0.56657 |  0:22:21s\n",
            "epoch 2593| loss: 0.87422 | train_accuracy: 0.59341 | val_accuracy: 0.57057 |  0:22:21s\n",
            "epoch 2594| loss: 0.87268 | train_accuracy: 0.59212 | val_accuracy: 0.56897 |  0:22:22s\n",
            "epoch 2595| loss: 0.87754 | train_accuracy: 0.59065 | val_accuracy: 0.56337 |  0:22:22s\n",
            "epoch 2596| loss: 0.88006 | train_accuracy: 0.59292 | val_accuracy: 0.57177 |  0:22:23s\n",
            "epoch 2597| loss: 0.87542 | train_accuracy: 0.59025 | val_accuracy: 0.56098 |  0:22:23s\n",
            "epoch 2598| loss: 0.87718 | train_accuracy: 0.59501 | val_accuracy: 0.56417 |  0:22:24s\n",
            "epoch 2599| loss: 0.87326 | train_accuracy: 0.59372 | val_accuracy: 0.56817 |  0:22:24s\n",
            "epoch 2600| loss: 0.87601 | train_accuracy: 0.59279 | val_accuracy: 0.56497 |  0:22:25s\n",
            "epoch 2601| loss: 0.8754  | train_accuracy: 0.59314 | val_accuracy: 0.57257 |  0:22:25s\n",
            "epoch 2602| loss: 0.8785  | train_accuracy: 0.59043 | val_accuracy: 0.56937 |  0:22:26s\n",
            "epoch 2603| loss: 0.86958 | train_accuracy: 0.5931  | val_accuracy: 0.56697 |  0:22:26s\n",
            "epoch 2604| loss: 0.8798  | train_accuracy: 0.59385 | val_accuracy: 0.57217 |  0:22:27s\n",
            "epoch 2605| loss: 0.87391 | train_accuracy: 0.59318 | val_accuracy: 0.56777 |  0:22:27s\n",
            "epoch 2606| loss: 0.87695 | train_accuracy: 0.59256 | val_accuracy: 0.57617 |  0:22:28s\n",
            "epoch 2607| loss: 0.87542 | train_accuracy: 0.5911  | val_accuracy: 0.56457 |  0:22:28s\n",
            "epoch 2608| loss: 0.8785  | train_accuracy: 0.59212 | val_accuracy: 0.56257 |  0:22:29s\n",
            "epoch 2609| loss: 0.87546 | train_accuracy: 0.59239 | val_accuracy: 0.56937 |  0:22:29s\n",
            "epoch 2610| loss: 0.87568 | train_accuracy: 0.59376 | val_accuracy: 0.56537 |  0:22:30s\n",
            "epoch 2611| loss: 0.87604 | train_accuracy: 0.59438 | val_accuracy: 0.56697 |  0:22:30s\n",
            "epoch 2612| loss: 0.87987 | train_accuracy: 0.59376 | val_accuracy: 0.56737 |  0:22:31s\n",
            "epoch 2613| loss: 0.87943 | train_accuracy: 0.59323 | val_accuracy: 0.56577 |  0:22:31s\n",
            "epoch 2614| loss: 0.87775 | train_accuracy: 0.5935  | val_accuracy: 0.56697 |  0:22:32s\n",
            "epoch 2615| loss: 0.87569 | train_accuracy: 0.59292 | val_accuracy: 0.56937 |  0:22:32s\n",
            "epoch 2616| loss: 0.87931 | train_accuracy: 0.59252 | val_accuracy: 0.56577 |  0:22:33s\n",
            "epoch 2617| loss: 0.87434 | train_accuracy: 0.59434 | val_accuracy: 0.56897 |  0:22:33s\n",
            "epoch 2618| loss: 0.87463 | train_accuracy: 0.59296 | val_accuracy: 0.56857 |  0:22:34s\n",
            "epoch 2619| loss: 0.87587 | train_accuracy: 0.59274 | val_accuracy: 0.56577 |  0:22:34s\n",
            "epoch 2620| loss: 0.87876 | train_accuracy: 0.59123 | val_accuracy: 0.56657 |  0:22:35s\n",
            "epoch 2621| loss: 0.87714 | train_accuracy: 0.5903  | val_accuracy: 0.56537 |  0:22:35s\n",
            "epoch 2622| loss: 0.87398 | train_accuracy: 0.59216 | val_accuracy: 0.56657 |  0:22:36s\n",
            "epoch 2623| loss: 0.87338 | train_accuracy: 0.5899  | val_accuracy: 0.56178 |  0:22:36s\n",
            "epoch 2624| loss: 0.87648 | train_accuracy: 0.59159 | val_accuracy: 0.56257 |  0:22:37s\n",
            "epoch 2625| loss: 0.87615 | train_accuracy: 0.59327 | val_accuracy: 0.56497 |  0:22:37s\n",
            "epoch 2626| loss: 0.87612 | train_accuracy: 0.59265 | val_accuracy: 0.55858 |  0:22:38s\n",
            "epoch 2627| loss: 0.87543 | train_accuracy: 0.59274 | val_accuracy: 0.56297 |  0:22:38s\n",
            "epoch 2628| loss: 0.87193 | train_accuracy: 0.59265 | val_accuracy: 0.56657 |  0:22:39s\n",
            "epoch 2629| loss: 0.87565 | train_accuracy: 0.59279 | val_accuracy: 0.56257 |  0:22:39s\n",
            "epoch 2630| loss: 0.87396 | train_accuracy: 0.59221 | val_accuracy: 0.56617 |  0:22:40s\n",
            "epoch 2631| loss: 0.8725  | train_accuracy: 0.59372 | val_accuracy: 0.56857 |  0:22:40s\n",
            "epoch 2632| loss: 0.87767 | train_accuracy: 0.59292 | val_accuracy: 0.56617 |  0:22:41s\n",
            "epoch 2633| loss: 0.87563 | train_accuracy: 0.59265 | val_accuracy: 0.56657 |  0:22:41s\n",
            "epoch 2634| loss: 0.87367 | train_accuracy: 0.59314 | val_accuracy: 0.57017 |  0:22:42s\n",
            "epoch 2635| loss: 0.87839 | train_accuracy: 0.5895  | val_accuracy: 0.55738 |  0:22:42s\n",
            "epoch 2636| loss: 0.87722 | train_accuracy: 0.59225 | val_accuracy: 0.56497 |  0:22:43s\n",
            "epoch 2637| loss: 0.87582 | train_accuracy: 0.59252 | val_accuracy: 0.56697 |  0:22:43s\n",
            "epoch 2638| loss: 0.87824 | train_accuracy: 0.59323 | val_accuracy: 0.56018 |  0:22:44s\n",
            "epoch 2639| loss: 0.8757  | train_accuracy: 0.59163 | val_accuracy: 0.56897 |  0:22:44s\n",
            "epoch 2640| loss: 0.87854 | train_accuracy: 0.59261 | val_accuracy: 0.57137 |  0:22:45s\n",
            "epoch 2641| loss: 0.87303 | train_accuracy: 0.59385 | val_accuracy: 0.57097 |  0:22:45s\n",
            "epoch 2642| loss: 0.87688 | train_accuracy: 0.59403 | val_accuracy: 0.56937 |  0:22:46s\n",
            "epoch 2643| loss: 0.87641 | train_accuracy: 0.59425 | val_accuracy: 0.56657 |  0:22:46s\n",
            "epoch 2644| loss: 0.87544 | train_accuracy: 0.59265 | val_accuracy: 0.56737 |  0:22:47s\n",
            "epoch 2645| loss: 0.87669 | train_accuracy: 0.59194 | val_accuracy: 0.56897 |  0:22:47s\n",
            "epoch 2646| loss: 0.87417 | train_accuracy: 0.59221 | val_accuracy: 0.57177 |  0:22:48s\n",
            "epoch 2647| loss: 0.87447 | train_accuracy: 0.59221 | val_accuracy: 0.57017 |  0:22:48s\n",
            "epoch 2648| loss: 0.87462 | train_accuracy: 0.59305 | val_accuracy: 0.56657 |  0:22:49s\n",
            "epoch 2649| loss: 0.8751  | train_accuracy: 0.5935  | val_accuracy: 0.56337 |  0:22:49s\n",
            "epoch 2650| loss: 0.87539 | train_accuracy: 0.59252 | val_accuracy: 0.56178 |  0:22:50s\n",
            "epoch 2651| loss: 0.87636 | train_accuracy: 0.59127 | val_accuracy: 0.56337 |  0:22:50s\n",
            "epoch 2652| loss: 0.87474 | train_accuracy: 0.59332 | val_accuracy: 0.56257 |  0:22:51s\n",
            "epoch 2653| loss: 0.87366 | train_accuracy: 0.59225 | val_accuracy: 0.56178 |  0:22:51s\n",
            "epoch 2654| loss: 0.87707 | train_accuracy: 0.59167 | val_accuracy: 0.56138 |  0:22:52s\n",
            "epoch 2655| loss: 0.87614 | train_accuracy: 0.5919  | val_accuracy: 0.56897 |  0:22:52s\n",
            "epoch 2656| loss: 0.87565 | train_accuracy: 0.59154 | val_accuracy: 0.56897 |  0:22:53s\n",
            "epoch 2657| loss: 0.87677 | train_accuracy: 0.59074 | val_accuracy: 0.56138 |  0:22:53s\n",
            "epoch 2658| loss: 0.87768 | train_accuracy: 0.59265 | val_accuracy: 0.56577 |  0:22:54s\n",
            "epoch 2659| loss: 0.87598 | train_accuracy: 0.59199 | val_accuracy: 0.57497 |  0:22:54s\n",
            "epoch 2660| loss: 0.8769  | train_accuracy: 0.59181 | val_accuracy: 0.57017 |  0:22:55s\n",
            "epoch 2661| loss: 0.8741  | train_accuracy: 0.58892 | val_accuracy: 0.56337 |  0:22:55s\n",
            "epoch 2662| loss: 0.87462 | train_accuracy: 0.59212 | val_accuracy: 0.57217 |  0:22:56s\n",
            "epoch 2663| loss: 0.87553 | train_accuracy: 0.59163 | val_accuracy: 0.57057 |  0:22:56s\n",
            "epoch 2664| loss: 0.87098 | train_accuracy: 0.59074 | val_accuracy: 0.56617 |  0:22:57s\n",
            "epoch 2665| loss: 0.8771  | train_accuracy: 0.59074 | val_accuracy: 0.56577 |  0:22:57s\n",
            "epoch 2666| loss: 0.87484 | train_accuracy: 0.59221 | val_accuracy: 0.56977 |  0:22:58s\n",
            "epoch 2667| loss: 0.87325 | train_accuracy: 0.59159 | val_accuracy: 0.56777 |  0:22:58s\n",
            "epoch 2668| loss: 0.87801 | train_accuracy: 0.59065 | val_accuracy: 0.56297 |  0:22:59s\n",
            "epoch 2669| loss: 0.87518 | train_accuracy: 0.59034 | val_accuracy: 0.56937 |  0:22:59s\n",
            "epoch 2670| loss: 0.87923 | train_accuracy: 0.59092 | val_accuracy: 0.56537 |  0:23:00s\n",
            "epoch 2671| loss: 0.87883 | train_accuracy: 0.59043 | val_accuracy: 0.56497 |  0:23:00s\n",
            "epoch 2672| loss: 0.87648 | train_accuracy: 0.59185 | val_accuracy: 0.56577 |  0:23:01s\n",
            "epoch 2673| loss: 0.87652 | train_accuracy: 0.59141 | val_accuracy: 0.56377 |  0:23:01s\n",
            "epoch 2674| loss: 0.87545 | train_accuracy: 0.58905 | val_accuracy: 0.57137 |  0:23:02s\n",
            "epoch 2675| loss: 0.87982 | train_accuracy: 0.58728 | val_accuracy: 0.56617 |  0:23:02s\n",
            "epoch 2676| loss: 0.881   | train_accuracy: 0.59003 | val_accuracy: 0.56178 |  0:23:02s\n",
            "epoch 2677| loss: 0.88239 | train_accuracy: 0.59008 | val_accuracy: 0.55858 |  0:23:03s\n",
            "epoch 2678| loss: 0.88137 | train_accuracy: 0.5879  | val_accuracy: 0.56777 |  0:23:03s\n",
            "epoch 2679| loss: 0.88079 | train_accuracy: 0.58954 | val_accuracy: 0.56617 |  0:23:04s\n",
            "epoch 2680| loss: 0.88218 | train_accuracy: 0.58825 | val_accuracy: 0.56337 |  0:23:04s\n",
            "epoch 2681| loss: 0.88418 | train_accuracy: 0.58839 | val_accuracy: 0.56897 |  0:23:05s\n",
            "epoch 2682| loss: 0.87638 | train_accuracy: 0.59074 | val_accuracy: 0.57737 |  0:23:05s\n",
            "epoch 2683| loss: 0.87938 | train_accuracy: 0.58781 | val_accuracy: 0.57577 |  0:23:06s\n",
            "epoch 2684| loss: 0.87859 | train_accuracy: 0.58728 | val_accuracy: 0.57057 |  0:23:06s\n",
            "epoch 2685| loss: 0.87771 | train_accuracy: 0.58905 | val_accuracy: 0.57097 |  0:23:07s\n",
            "epoch 2686| loss: 0.88199 | train_accuracy: 0.58985 | val_accuracy: 0.57137 |  0:23:07s\n",
            "epoch 2687| loss: 0.8786  | train_accuracy: 0.59061 | val_accuracy: 0.56977 |  0:23:08s\n",
            "epoch 2688| loss: 0.87838 | train_accuracy: 0.59123 | val_accuracy: 0.57017 |  0:23:08s\n",
            "epoch 2689| loss: 0.87845 | train_accuracy: 0.5911  | val_accuracy: 0.56577 |  0:23:09s\n",
            "epoch 2690| loss: 0.87865 | train_accuracy: 0.59047 | val_accuracy: 0.56537 |  0:23:10s\n",
            "epoch 2691| loss: 0.88168 | train_accuracy: 0.58981 | val_accuracy: 0.55738 |  0:23:10s\n",
            "epoch 2692| loss: 0.87496 | train_accuracy: 0.59105 | val_accuracy: 0.56577 |  0:23:11s\n",
            "epoch 2693| loss: 0.88079 | train_accuracy: 0.5883  | val_accuracy: 0.56138 |  0:23:11s\n",
            "epoch 2694| loss: 0.87925 | train_accuracy: 0.58608 | val_accuracy: 0.55818 |  0:23:11s\n",
            "epoch 2695| loss: 0.88039 | train_accuracy: 0.58861 | val_accuracy: 0.57097 |  0:23:12s\n",
            "epoch 2696| loss: 0.87974 | train_accuracy: 0.58968 | val_accuracy: 0.57057 |  0:23:12s\n",
            "epoch 2697| loss: 0.87733 | train_accuracy: 0.58888 | val_accuracy: 0.56497 |  0:23:13s\n",
            "epoch 2698| loss: 0.87516 | train_accuracy: 0.59065 | val_accuracy: 0.57097 |  0:23:13s\n",
            "epoch 2699| loss: 0.87161 | train_accuracy: 0.58896 | val_accuracy: 0.56058 |  0:23:14s\n",
            "epoch 2700| loss: 0.87678 | train_accuracy: 0.59172 | val_accuracy: 0.56297 |  0:23:14s\n",
            "epoch 2701| loss: 0.87662 | train_accuracy: 0.59047 | val_accuracy: 0.56937 |  0:23:15s\n",
            "epoch 2702| loss: 0.87719 | train_accuracy: 0.59141 | val_accuracy: 0.57097 |  0:23:15s\n",
            "epoch 2703| loss: 0.87449 | train_accuracy: 0.5883  | val_accuracy: 0.56178 |  0:23:16s\n",
            "epoch 2704| loss: 0.87759 | train_accuracy: 0.59136 | val_accuracy: 0.57577 |  0:23:16s\n",
            "epoch 2705| loss: 0.87566 | train_accuracy: 0.59056 | val_accuracy: 0.56937 |  0:23:17s\n",
            "epoch 2706| loss: 0.87698 | train_accuracy: 0.5903  | val_accuracy: 0.56018 |  0:23:17s\n",
            "epoch 2707| loss: 0.87629 | train_accuracy: 0.59341 | val_accuracy: 0.58217 |  0:23:18s\n",
            "epoch 2708| loss: 0.87355 | train_accuracy: 0.59216 | val_accuracy: 0.56577 |  0:23:18s\n",
            "epoch 2709| loss: 0.87632 | train_accuracy: 0.59252 | val_accuracy: 0.56977 |  0:23:19s\n",
            "epoch 2710| loss: 0.87753 | train_accuracy: 0.59261 | val_accuracy: 0.57017 |  0:23:19s\n",
            "epoch 2711| loss: 0.87808 | train_accuracy: 0.59221 | val_accuracy: 0.56977 |  0:23:20s\n",
            "epoch 2712| loss: 0.87796 | train_accuracy: 0.59101 | val_accuracy: 0.56577 |  0:23:20s\n",
            "epoch 2713| loss: 0.87632 | train_accuracy: 0.59083 | val_accuracy: 0.56377 |  0:23:21s\n",
            "epoch 2714| loss: 0.8793  | train_accuracy: 0.59203 | val_accuracy: 0.56218 |  0:23:21s\n",
            "epoch 2715| loss: 0.87543 | train_accuracy: 0.59136 | val_accuracy: 0.56897 |  0:23:22s\n",
            "epoch 2716| loss: 0.87954 | train_accuracy: 0.59261 | val_accuracy: 0.56777 |  0:23:22s\n",
            "epoch 2717| loss: 0.88036 | train_accuracy: 0.58981 | val_accuracy: 0.56657 |  0:23:23s\n",
            "epoch 2718| loss: 0.87634 | train_accuracy: 0.59003 | val_accuracy: 0.56577 |  0:23:23s\n",
            "epoch 2719| loss: 0.87769 | train_accuracy: 0.59234 | val_accuracy: 0.56937 |  0:23:24s\n",
            "epoch 2720| loss: 0.87542 | train_accuracy: 0.59256 | val_accuracy: 0.56377 |  0:23:24s\n",
            "epoch 2721| loss: 0.87703 | train_accuracy: 0.59305 | val_accuracy: 0.56337 |  0:23:25s\n",
            "epoch 2722| loss: 0.878   | train_accuracy: 0.59207 | val_accuracy: 0.56297 |  0:23:25s\n",
            "epoch 2723| loss: 0.87694 | train_accuracy: 0.59239 | val_accuracy: 0.56417 |  0:23:26s\n",
            "epoch 2724| loss: 0.87459 | train_accuracy: 0.59247 | val_accuracy: 0.56737 |  0:23:26s\n",
            "epoch 2725| loss: 0.87501 | train_accuracy: 0.59207 | val_accuracy: 0.57217 |  0:23:27s\n",
            "epoch 2726| loss: 0.87375 | train_accuracy: 0.59123 | val_accuracy: 0.56777 |  0:23:27s\n",
            "epoch 2727| loss: 0.87668 | train_accuracy: 0.59052 | val_accuracy: 0.56337 |  0:23:28s\n",
            "epoch 2728| loss: 0.87472 | train_accuracy: 0.59159 | val_accuracy: 0.56617 |  0:23:28s\n",
            "epoch 2729| loss: 0.87362 | train_accuracy: 0.59207 | val_accuracy: 0.56337 |  0:23:29s\n",
            "epoch 2730| loss: 0.87497 | train_accuracy: 0.59292 | val_accuracy: 0.56417 |  0:23:29s\n",
            "epoch 2731| loss: 0.87608 | train_accuracy: 0.59305 | val_accuracy: 0.56817 |  0:23:30s\n",
            "epoch 2732| loss: 0.87492 | train_accuracy: 0.5927  | val_accuracy: 0.56218 |  0:23:30s\n",
            "epoch 2733| loss: 0.87753 | train_accuracy: 0.59345 | val_accuracy: 0.57097 |  0:23:31s\n",
            "epoch 2734| loss: 0.87638 | train_accuracy: 0.59136 | val_accuracy: 0.56577 |  0:23:31s\n",
            "epoch 2735| loss: 0.87386 | train_accuracy: 0.5931  | val_accuracy: 0.56657 |  0:23:32s\n",
            "epoch 2736| loss: 0.87922 | train_accuracy: 0.59199 | val_accuracy: 0.56617 |  0:23:32s\n",
            "epoch 2737| loss: 0.87825 | train_accuracy: 0.59234 | val_accuracy: 0.56897 |  0:23:33s\n",
            "epoch 2738| loss: 0.87911 | train_accuracy: 0.59247 | val_accuracy: 0.56857 |  0:23:33s\n",
            "epoch 2739| loss: 0.87237 | train_accuracy: 0.59341 | val_accuracy: 0.56737 |  0:23:34s\n",
            "epoch 2740| loss: 0.87392 | train_accuracy: 0.59216 | val_accuracy: 0.56417 |  0:23:34s\n",
            "epoch 2741| loss: 0.8745  | train_accuracy: 0.5931  | val_accuracy: 0.56857 |  0:23:35s\n",
            "epoch 2742| loss: 0.87543 | train_accuracy: 0.59345 | val_accuracy: 0.57417 |  0:23:35s\n",
            "epoch 2743| loss: 0.87409 | train_accuracy: 0.59203 | val_accuracy: 0.57257 |  0:23:36s\n",
            "epoch 2744| loss: 0.8752  | train_accuracy: 0.59114 | val_accuracy: 0.57097 |  0:23:36s\n",
            "epoch 2745| loss: 0.87761 | train_accuracy: 0.59105 | val_accuracy: 0.57217 |  0:23:37s\n",
            "epoch 2746| loss: 0.87606 | train_accuracy: 0.59083 | val_accuracy: 0.56617 |  0:23:37s\n",
            "epoch 2747| loss: 0.87707 | train_accuracy: 0.59256 | val_accuracy: 0.57297 |  0:23:38s\n",
            "epoch 2748| loss: 0.87407 | train_accuracy: 0.59234 | val_accuracy: 0.57137 |  0:23:38s\n",
            "epoch 2749| loss: 0.87381 | train_accuracy: 0.58963 | val_accuracy: 0.56178 |  0:23:39s\n",
            "epoch 2750| loss: 0.87519 | train_accuracy: 0.59159 | val_accuracy: 0.57377 |  0:23:39s\n",
            "epoch 2751| loss: 0.875   | train_accuracy: 0.59136 | val_accuracy: 0.57057 |  0:23:40s\n",
            "epoch 2752| loss: 0.877   | train_accuracy: 0.59279 | val_accuracy: 0.57337 |  0:23:40s\n",
            "epoch 2753| loss: 0.87672 | train_accuracy: 0.59239 | val_accuracy: 0.57297 |  0:23:41s\n",
            "epoch 2754| loss: 0.87885 | train_accuracy: 0.59101 | val_accuracy: 0.56897 |  0:23:41s\n",
            "epoch 2755| loss: 0.87821 | train_accuracy: 0.5911  | val_accuracy: 0.57257 |  0:23:42s\n",
            "epoch 2756| loss: 0.87258 | train_accuracy: 0.59412 | val_accuracy: 0.57177 |  0:23:42s\n",
            "epoch 2757| loss: 0.87471 | train_accuracy: 0.59234 | val_accuracy: 0.56937 |  0:23:43s\n",
            "epoch 2758| loss: 0.87438 | train_accuracy: 0.59207 | val_accuracy: 0.57377 |  0:23:43s\n",
            "epoch 2759| loss: 0.87745 | train_accuracy: 0.5911  | val_accuracy: 0.57097 |  0:23:44s\n",
            "epoch 2760| loss: 0.87409 | train_accuracy: 0.59105 | val_accuracy: 0.56617 |  0:23:44s\n",
            "epoch 2761| loss: 0.87308 | train_accuracy: 0.5919  | val_accuracy: 0.57057 |  0:23:45s\n",
            "epoch 2762| loss: 0.87388 | train_accuracy: 0.59199 | val_accuracy: 0.57177 |  0:23:45s\n",
            "epoch 2763| loss: 0.87233 | train_accuracy: 0.5915  | val_accuracy: 0.56937 |  0:23:46s\n",
            "epoch 2764| loss: 0.87628 | train_accuracy: 0.5915  | val_accuracy: 0.56897 |  0:23:46s\n",
            "epoch 2765| loss: 0.87488 | train_accuracy: 0.59234 | val_accuracy: 0.57137 |  0:23:47s\n",
            "epoch 2766| loss: 0.87544 | train_accuracy: 0.59172 | val_accuracy: 0.56617 |  0:23:47s\n",
            "epoch 2767| loss: 0.87445 | train_accuracy: 0.59163 | val_accuracy: 0.57417 |  0:23:48s\n",
            "epoch 2768| loss: 0.87758 | train_accuracy: 0.59181 | val_accuracy: 0.57337 |  0:23:48s\n",
            "epoch 2769| loss: 0.87466 | train_accuracy: 0.59261 | val_accuracy: 0.57017 |  0:23:49s\n",
            "epoch 2770| loss: 0.87515 | train_accuracy: 0.59234 | val_accuracy: 0.57617 |  0:23:49s\n",
            "epoch 2771| loss: 0.87597 | train_accuracy: 0.59287 | val_accuracy: 0.56577 |  0:23:50s\n",
            "epoch 2772| loss: 0.87252 | train_accuracy: 0.5935  | val_accuracy: 0.57297 |  0:23:50s\n",
            "epoch 2773| loss: 0.87371 | train_accuracy: 0.59239 | val_accuracy: 0.57497 |  0:23:51s\n",
            "epoch 2774| loss: 0.87414 | train_accuracy: 0.59079 | val_accuracy: 0.57217 |  0:23:51s\n",
            "epoch 2775| loss: 0.87767 | train_accuracy: 0.5907  | val_accuracy: 0.57217 |  0:23:52s\n",
            "epoch 2776| loss: 0.87993 | train_accuracy: 0.59225 | val_accuracy: 0.56977 |  0:23:52s\n",
            "epoch 2777| loss: 0.87581 | train_accuracy: 0.59301 | val_accuracy: 0.56977 |  0:23:53s\n",
            "epoch 2778| loss: 0.87699 | train_accuracy: 0.58874 | val_accuracy: 0.57177 |  0:23:53s\n",
            "epoch 2779| loss: 0.87854 | train_accuracy: 0.58559 | val_accuracy: 0.56617 |  0:23:54s\n",
            "epoch 2780| loss: 0.87831 | train_accuracy: 0.59079 | val_accuracy: 0.57337 |  0:23:54s\n",
            "epoch 2781| loss: 0.88115 | train_accuracy: 0.59008 | val_accuracy: 0.57457 |  0:23:55s\n",
            "epoch 2782| loss: 0.88296 | train_accuracy: 0.58936 | val_accuracy: 0.56857 |  0:23:55s\n",
            "epoch 2783| loss: 0.87756 | train_accuracy: 0.59132 | val_accuracy: 0.57017 |  0:23:56s\n",
            "epoch 2784| loss: 0.87969 | train_accuracy: 0.58954 | val_accuracy: 0.57337 |  0:23:56s\n",
            "epoch 2785| loss: 0.8755  | train_accuracy: 0.5903  | val_accuracy: 0.57137 |  0:23:57s\n",
            "epoch 2786| loss: 0.88083 | train_accuracy: 0.5895  | val_accuracy: 0.57297 |  0:23:57s\n",
            "epoch 2787| loss: 0.8752  | train_accuracy: 0.5915  | val_accuracy: 0.57537 |  0:23:58s\n",
            "epoch 2788| loss: 0.87695 | train_accuracy: 0.59047 | val_accuracy: 0.56897 |  0:23:58s\n",
            "epoch 2789| loss: 0.87785 | train_accuracy: 0.58816 | val_accuracy: 0.56218 |  0:23:59s\n",
            "epoch 2790| loss: 0.87944 | train_accuracy: 0.58928 | val_accuracy: 0.57257 |  0:23:59s\n",
            "epoch 2791| loss: 0.87689 | train_accuracy: 0.58985 | val_accuracy: 0.57337 |  0:24:00s\n",
            "epoch 2792| loss: 0.87711 | train_accuracy: 0.58963 | val_accuracy: 0.57577 |  0:24:00s\n",
            "epoch 2793| loss: 0.87969 | train_accuracy: 0.58848 | val_accuracy: 0.56977 |  0:24:00s\n",
            "epoch 2794| loss: 0.87837 | train_accuracy: 0.5867  | val_accuracy: 0.56817 |  0:24:01s\n",
            "epoch 2795| loss: 0.87566 | train_accuracy: 0.58834 | val_accuracy: 0.57057 |  0:24:01s\n",
            "epoch 2796| loss: 0.87925 | train_accuracy: 0.58799 | val_accuracy: 0.56537 |  0:24:02s\n",
            "epoch 2797| loss: 0.87812 | train_accuracy: 0.58861 | val_accuracy: 0.57017 |  0:24:02s\n",
            "epoch 2798| loss: 0.88162 | train_accuracy: 0.58896 | val_accuracy: 0.57337 |  0:24:03s\n",
            "epoch 2799| loss: 0.88449 | train_accuracy: 0.58834 | val_accuracy: 0.57497 |  0:24:03s\n",
            "epoch 2800| loss: 0.8771  | train_accuracy: 0.58848 | val_accuracy: 0.56977 |  0:24:04s\n",
            "epoch 2801| loss: 0.88011 | train_accuracy: 0.58723 | val_accuracy: 0.56817 |  0:24:04s\n",
            "epoch 2802| loss: 0.88184 | train_accuracy: 0.58781 | val_accuracy: 0.57217 |  0:24:05s\n",
            "epoch 2803| loss: 0.88201 | train_accuracy: 0.58928 | val_accuracy: 0.57417 |  0:24:05s\n",
            "epoch 2804| loss: 0.87682 | train_accuracy: 0.5887  | val_accuracy: 0.57057 |  0:24:06s\n",
            "epoch 2805| loss: 0.87856 | train_accuracy: 0.58865 | val_accuracy: 0.56977 |  0:24:06s\n",
            "epoch 2806| loss: 0.8762  | train_accuracy: 0.58825 | val_accuracy: 0.56457 |  0:24:07s\n",
            "epoch 2807| loss: 0.87909 | train_accuracy: 0.58683 | val_accuracy: 0.56337 |  0:24:07s\n",
            "epoch 2808| loss: 0.87638 | train_accuracy: 0.5851  | val_accuracy: 0.56897 |  0:24:08s\n",
            "epoch 2809| loss: 0.88148 | train_accuracy: 0.58581 | val_accuracy: 0.57377 |  0:24:08s\n",
            "epoch 2810| loss: 0.88158 | train_accuracy: 0.5863  | val_accuracy: 0.56977 |  0:24:09s\n",
            "epoch 2811| loss: 0.88004 | train_accuracy: 0.58768 | val_accuracy: 0.56657 |  0:24:09s\n",
            "epoch 2812| loss: 0.87787 | train_accuracy: 0.5871  | val_accuracy: 0.57377 |  0:24:10s\n",
            "epoch 2813| loss: 0.87914 | train_accuracy: 0.58825 | val_accuracy: 0.57777 |  0:24:10s\n",
            "epoch 2814| loss: 0.88309 | train_accuracy: 0.58661 | val_accuracy: 0.56817 |  0:24:11s\n",
            "epoch 2815| loss: 0.87713 | train_accuracy: 0.58999 | val_accuracy: 0.57097 |  0:24:11s\n",
            "epoch 2816| loss: 0.8781  | train_accuracy: 0.59092 | val_accuracy: 0.57057 |  0:24:12s\n",
            "epoch 2817| loss: 0.87618 | train_accuracy: 0.59016 | val_accuracy: 0.56777 |  0:24:12s\n",
            "epoch 2818| loss: 0.87656 | train_accuracy: 0.58994 | val_accuracy: 0.57737 |  0:24:13s\n",
            "epoch 2819| loss: 0.87654 | train_accuracy: 0.59181 | val_accuracy: 0.57097 |  0:24:13s\n",
            "epoch 2820| loss: 0.87368 | train_accuracy: 0.59016 | val_accuracy: 0.56937 |  0:24:14s\n",
            "epoch 2821| loss: 0.87799 | train_accuracy: 0.59203 | val_accuracy: 0.57337 |  0:24:14s\n",
            "epoch 2822| loss: 0.87847 | train_accuracy: 0.58936 | val_accuracy: 0.57137 |  0:24:15s\n",
            "epoch 2823| loss: 0.87466 | train_accuracy: 0.58985 | val_accuracy: 0.57177 |  0:24:15s\n",
            "epoch 2824| loss: 0.87975 | train_accuracy: 0.58963 | val_accuracy: 0.57377 |  0:24:16s\n",
            "epoch 2825| loss: 0.87418 | train_accuracy: 0.58972 | val_accuracy: 0.56857 |  0:24:16s\n",
            "epoch 2826| loss: 0.87337 | train_accuracy: 0.59087 | val_accuracy: 0.57337 |  0:24:17s\n",
            "epoch 2827| loss: 0.87574 | train_accuracy: 0.59092 | val_accuracy: 0.57657 |  0:24:17s\n",
            "epoch 2828| loss: 0.87683 | train_accuracy: 0.5915  | val_accuracy: 0.57457 |  0:24:18s\n",
            "epoch 2829| loss: 0.87726 | train_accuracy: 0.5919  | val_accuracy: 0.57537 |  0:24:18s\n",
            "epoch 2830| loss: 0.87775 | train_accuracy: 0.59212 | val_accuracy: 0.57337 |  0:24:19s\n",
            "epoch 2831| loss: 0.87464 | train_accuracy: 0.59301 | val_accuracy: 0.57617 |  0:24:19s\n",
            "epoch 2832| loss: 0.87907 | train_accuracy: 0.59327 | val_accuracy: 0.57657 |  0:24:20s\n",
            "epoch 2833| loss: 0.87542 | train_accuracy: 0.59167 | val_accuracy: 0.57017 |  0:24:20s\n",
            "epoch 2834| loss: 0.8788  | train_accuracy: 0.59199 | val_accuracy: 0.57857 |  0:24:21s\n",
            "epoch 2835| loss: 0.87951 | train_accuracy: 0.58737 | val_accuracy: 0.57497 |  0:24:21s\n",
            "epoch 2836| loss: 0.87936 | train_accuracy: 0.58737 | val_accuracy: 0.57577 |  0:24:22s\n",
            "epoch 2837| loss: 0.87521 | train_accuracy: 0.59114 | val_accuracy: 0.57937 |  0:24:22s\n",
            "epoch 2838| loss: 0.87642 | train_accuracy: 0.59141 | val_accuracy: 0.57977 |  0:24:23s\n",
            "epoch 2839| loss: 0.87966 | train_accuracy: 0.59012 | val_accuracy: 0.57377 |  0:24:23s\n",
            "epoch 2840| loss: 0.87259 | train_accuracy: 0.59136 | val_accuracy: 0.57417 |  0:24:24s\n",
            "epoch 2841| loss: 0.8782  | train_accuracy: 0.59323 | val_accuracy: 0.57377 |  0:24:24s\n",
            "epoch 2842| loss: 0.87463 | train_accuracy: 0.59385 | val_accuracy: 0.57537 |  0:24:25s\n",
            "epoch 2843| loss: 0.87295 | train_accuracy: 0.59221 | val_accuracy: 0.56657 |  0:24:25s\n",
            "epoch 2844| loss: 0.8764  | train_accuracy: 0.59234 | val_accuracy: 0.57337 |  0:24:26s\n",
            "epoch 2845| loss: 0.87503 | train_accuracy: 0.59127 | val_accuracy: 0.57577 |  0:24:26s\n",
            "epoch 2846| loss: 0.87388 | train_accuracy: 0.59008 | val_accuracy: 0.56537 |  0:24:27s\n",
            "epoch 2847| loss: 0.87785 | train_accuracy: 0.59354 | val_accuracy: 0.56817 |  0:24:27s\n",
            "epoch 2848| loss: 0.87361 | train_accuracy: 0.59332 | val_accuracy: 0.56577 |  0:24:28s\n",
            "epoch 2849| loss: 0.87804 | train_accuracy: 0.59279 | val_accuracy: 0.57217 |  0:24:28s\n",
            "epoch 2850| loss: 0.88    | train_accuracy: 0.59398 | val_accuracy: 0.56737 |  0:24:29s\n",
            "epoch 2851| loss: 0.87397 | train_accuracy: 0.59221 | val_accuracy: 0.57177 |  0:24:29s\n",
            "epoch 2852| loss: 0.87501 | train_accuracy: 0.59185 | val_accuracy: 0.56777 |  0:24:30s\n",
            "epoch 2853| loss: 0.8801  | train_accuracy: 0.59074 | val_accuracy: 0.56497 |  0:24:30s\n",
            "epoch 2854| loss: 0.87559 | train_accuracy: 0.59194 | val_accuracy: 0.56577 |  0:24:31s\n",
            "epoch 2855| loss: 0.87476 | train_accuracy: 0.59114 | val_accuracy: 0.56577 |  0:24:31s\n",
            "epoch 2856| loss: 0.87926 | train_accuracy: 0.58972 | val_accuracy: 0.56657 |  0:24:32s\n",
            "epoch 2857| loss: 0.87886 | train_accuracy: 0.59034 | val_accuracy: 0.56657 |  0:24:32s\n",
            "epoch 2858| loss: 0.87856 | train_accuracy: 0.59141 | val_accuracy: 0.57057 |  0:24:33s\n",
            "epoch 2859| loss: 0.88084 | train_accuracy: 0.59123 | val_accuracy: 0.57457 |  0:24:33s\n",
            "epoch 2860| loss: 0.87682 | train_accuracy: 0.5891  | val_accuracy: 0.56497 |  0:24:34s\n",
            "epoch 2861| loss: 0.87653 | train_accuracy: 0.59243 | val_accuracy: 0.57897 |  0:24:34s\n",
            "epoch 2862| loss: 0.8747  | train_accuracy: 0.59207 | val_accuracy: 0.57697 |  0:24:35s\n",
            "epoch 2863| loss: 0.87813 | train_accuracy: 0.58865 | val_accuracy: 0.57177 |  0:24:35s\n",
            "epoch 2864| loss: 0.87718 | train_accuracy: 0.59087 | val_accuracy: 0.57537 |  0:24:36s\n",
            "epoch 2865| loss: 0.87209 | train_accuracy: 0.5915  | val_accuracy: 0.57857 |  0:24:36s\n",
            "epoch 2866| loss: 0.87827 | train_accuracy: 0.59096 | val_accuracy: 0.57697 |  0:24:37s\n",
            "epoch 2867| loss: 0.87956 | train_accuracy: 0.59056 | val_accuracy: 0.57257 |  0:24:37s\n",
            "epoch 2868| loss: 0.87785 | train_accuracy: 0.5923  | val_accuracy: 0.57377 |  0:24:38s\n",
            "epoch 2869| loss: 0.87826 | train_accuracy: 0.59216 | val_accuracy: 0.57417 |  0:24:38s\n",
            "epoch 2870| loss: 0.87937 | train_accuracy: 0.59243 | val_accuracy: 0.57337 |  0:24:39s\n",
            "epoch 2871| loss: 0.87599 | train_accuracy: 0.59185 | val_accuracy: 0.57097 |  0:24:39s\n",
            "epoch 2872| loss: 0.87631 | train_accuracy: 0.59136 | val_accuracy: 0.57137 |  0:24:40s\n",
            "epoch 2873| loss: 0.87529 | train_accuracy: 0.59176 | val_accuracy: 0.57657 |  0:24:40s\n",
            "epoch 2874| loss: 0.87846 | train_accuracy: 0.59216 | val_accuracy: 0.56897 |  0:24:41s\n",
            "epoch 2875| loss: 0.87522 | train_accuracy: 0.5911  | val_accuracy: 0.56937 |  0:24:41s\n",
            "epoch 2876| loss: 0.87853 | train_accuracy: 0.59345 | val_accuracy: 0.57377 |  0:24:42s\n",
            "epoch 2877| loss: 0.87899 | train_accuracy: 0.59385 | val_accuracy: 0.56977 |  0:24:42s\n",
            "epoch 2878| loss: 0.87652 | train_accuracy: 0.59318 | val_accuracy: 0.57257 |  0:24:43s\n",
            "epoch 2879| loss: 0.87262 | train_accuracy: 0.59381 | val_accuracy: 0.57257 |  0:24:43s\n",
            "epoch 2880| loss: 0.87484 | train_accuracy: 0.59447 | val_accuracy: 0.57697 |  0:24:44s\n",
            "epoch 2881| loss: 0.87707 | train_accuracy: 0.59367 | val_accuracy: 0.57537 |  0:24:44s\n",
            "epoch 2882| loss: 0.86922 | train_accuracy: 0.59452 | val_accuracy: 0.57017 |  0:24:45s\n",
            "epoch 2883| loss: 0.87163 | train_accuracy: 0.59194 | val_accuracy: 0.56817 |  0:24:45s\n",
            "epoch 2884| loss: 0.87487 | train_accuracy: 0.59243 | val_accuracy: 0.56697 |  0:24:46s\n",
            "epoch 2885| loss: 0.87558 | train_accuracy: 0.59265 | val_accuracy: 0.57097 |  0:24:46s\n",
            "epoch 2886| loss: 0.87803 | train_accuracy: 0.59305 | val_accuracy: 0.57137 |  0:24:47s\n",
            "epoch 2887| loss: 0.87642 | train_accuracy: 0.59194 | val_accuracy: 0.56937 |  0:24:47s\n",
            "epoch 2888| loss: 0.87476 | train_accuracy: 0.59176 | val_accuracy: 0.56857 |  0:24:48s\n",
            "epoch 2889| loss: 0.87635 | train_accuracy: 0.59265 | val_accuracy: 0.57257 |  0:24:48s\n",
            "epoch 2890| loss: 0.87642 | train_accuracy: 0.59296 | val_accuracy: 0.57457 |  0:24:49s\n",
            "epoch 2891| loss: 0.87566 | train_accuracy: 0.59199 | val_accuracy: 0.56857 |  0:24:49s\n",
            "epoch 2892| loss: 0.87697 | train_accuracy: 0.59216 | val_accuracy: 0.56897 |  0:24:50s\n",
            "epoch 2893| loss: 0.87741 | train_accuracy: 0.59154 | val_accuracy: 0.56817 |  0:24:50s\n",
            "epoch 2894| loss: 0.87848 | train_accuracy: 0.59003 | val_accuracy: 0.57377 |  0:24:51s\n",
            "epoch 2895| loss: 0.87423 | train_accuracy: 0.58963 | val_accuracy: 0.56897 |  0:24:51s\n",
            "epoch 2896| loss: 0.87512 | train_accuracy: 0.58861 | val_accuracy: 0.56537 |  0:24:52s\n",
            "epoch 2897| loss: 0.8772  | train_accuracy: 0.59145 | val_accuracy: 0.57577 |  0:24:52s\n",
            "epoch 2898| loss: 0.8708  | train_accuracy: 0.59212 | val_accuracy: 0.57217 |  0:24:53s\n",
            "epoch 2899| loss: 0.87244 | train_accuracy: 0.59159 | val_accuracy: 0.56897 |  0:24:53s\n",
            "epoch 2900| loss: 0.8763  | train_accuracy: 0.59199 | val_accuracy: 0.56617 |  0:24:54s\n",
            "epoch 2901| loss: 0.87191 | train_accuracy: 0.59203 | val_accuracy: 0.57097 |  0:24:54s\n",
            "epoch 2902| loss: 0.8766  | train_accuracy: 0.59314 | val_accuracy: 0.56817 |  0:24:55s\n",
            "epoch 2903| loss: 0.87513 | train_accuracy: 0.59327 | val_accuracy: 0.56577 |  0:24:55s\n",
            "epoch 2904| loss: 0.88107 | train_accuracy: 0.59301 | val_accuracy: 0.57137 |  0:24:56s\n",
            "epoch 2905| loss: 0.86995 | train_accuracy: 0.59305 | val_accuracy: 0.56577 |  0:24:56s\n",
            "epoch 2906| loss: 0.87432 | train_accuracy: 0.59354 | val_accuracy: 0.56417 |  0:24:57s\n",
            "epoch 2907| loss: 0.87169 | train_accuracy: 0.59385 | val_accuracy: 0.56297 |  0:24:57s\n",
            "epoch 2908| loss: 0.87383 | train_accuracy: 0.59376 | val_accuracy: 0.56257 |  0:24:58s\n",
            "epoch 2909| loss: 0.87384 | train_accuracy: 0.59385 | val_accuracy: 0.56657 |  0:24:58s\n",
            "epoch 2910| loss: 0.87363 | train_accuracy: 0.59239 | val_accuracy: 0.56697 |  0:24:59s\n",
            "epoch 2911| loss: 0.87584 | train_accuracy: 0.59239 | val_accuracy: 0.56657 |  0:24:59s\n",
            "epoch 2912| loss: 0.8753  | train_accuracy: 0.59221 | val_accuracy: 0.56497 |  0:25:00s\n",
            "epoch 2913| loss: 0.87169 | train_accuracy: 0.59398 | val_accuracy: 0.56617 |  0:25:00s\n",
            "epoch 2914| loss: 0.87277 | train_accuracy: 0.59252 | val_accuracy: 0.56697 |  0:25:01s\n",
            "epoch 2915| loss: 0.8747  | train_accuracy: 0.59434 | val_accuracy: 0.56897 |  0:25:01s\n",
            "epoch 2916| loss: 0.87473 | train_accuracy: 0.59203 | val_accuracy: 0.57137 |  0:25:02s\n",
            "epoch 2917| loss: 0.87823 | train_accuracy: 0.59336 | val_accuracy: 0.57097 |  0:25:02s\n",
            "epoch 2918| loss: 0.87236 | train_accuracy: 0.59376 | val_accuracy: 0.56497 |  0:25:03s\n",
            "epoch 2919| loss: 0.87798 | train_accuracy: 0.59252 | val_accuracy: 0.55978 |  0:25:03s\n",
            "epoch 2920| loss: 0.87447 | train_accuracy: 0.59087 | val_accuracy: 0.56537 |  0:25:04s\n",
            "epoch 2921| loss: 0.87647 | train_accuracy: 0.59096 | val_accuracy: 0.57617 |  0:25:04s\n",
            "epoch 2922| loss: 0.8736  | train_accuracy: 0.59096 | val_accuracy: 0.57177 |  0:25:05s\n",
            "epoch 2923| loss: 0.87834 | train_accuracy: 0.59034 | val_accuracy: 0.56777 |  0:25:05s\n",
            "epoch 2924| loss: 0.87813 | train_accuracy: 0.5899  | val_accuracy: 0.56657 |  0:25:06s\n",
            "epoch 2925| loss: 0.87502 | train_accuracy: 0.59061 | val_accuracy: 0.56897 |  0:25:07s\n",
            "epoch 2926| loss: 0.87437 | train_accuracy: 0.59163 | val_accuracy: 0.56497 |  0:25:07s\n",
            "epoch 2927| loss: 0.87846 | train_accuracy: 0.59083 | val_accuracy: 0.56897 |  0:25:08s\n",
            "epoch 2928| loss: 0.87728 | train_accuracy: 0.59239 | val_accuracy: 0.56577 |  0:25:08s\n",
            "epoch 2929| loss: 0.8788  | train_accuracy: 0.59292 | val_accuracy: 0.56697 |  0:25:09s\n",
            "epoch 2930| loss: 0.87166 | train_accuracy: 0.59167 | val_accuracy: 0.56457 |  0:25:09s\n",
            "epoch 2931| loss: 0.87367 | train_accuracy: 0.59141 | val_accuracy: 0.56617 |  0:25:10s\n",
            "epoch 2932| loss: 0.87651 | train_accuracy: 0.59101 | val_accuracy: 0.56857 |  0:25:10s\n",
            "epoch 2933| loss: 0.87527 | train_accuracy: 0.59212 | val_accuracy: 0.56337 |  0:25:11s\n",
            "epoch 2934| loss: 0.87635 | train_accuracy: 0.59345 | val_accuracy: 0.56257 |  0:25:11s\n",
            "epoch 2935| loss: 0.87318 | train_accuracy: 0.59247 | val_accuracy: 0.56417 |  0:25:12s\n",
            "epoch 2936| loss: 0.87421 | train_accuracy: 0.59438 | val_accuracy: 0.56977 |  0:25:12s\n",
            "epoch 2937| loss: 0.87375 | train_accuracy: 0.59421 | val_accuracy: 0.56937 |  0:25:13s\n",
            "epoch 2938| loss: 0.87429 | train_accuracy: 0.59292 | val_accuracy: 0.56697 |  0:25:13s\n",
            "epoch 2939| loss: 0.87477 | train_accuracy: 0.5939  | val_accuracy: 0.56897 |  0:25:14s\n",
            "epoch 2940| loss: 0.87603 | train_accuracy: 0.59434 | val_accuracy: 0.56777 |  0:25:14s\n",
            "epoch 2941| loss: 0.87696 | train_accuracy: 0.59301 | val_accuracy: 0.56218 |  0:25:15s\n",
            "epoch 2942| loss: 0.87449 | train_accuracy: 0.59345 | val_accuracy: 0.57297 |  0:25:15s\n",
            "epoch 2943| loss: 0.87368 | train_accuracy: 0.59354 | val_accuracy: 0.57177 |  0:25:16s\n",
            "epoch 2944| loss: 0.87371 | train_accuracy: 0.59234 | val_accuracy: 0.56497 |  0:25:16s\n",
            "epoch 2945| loss: 0.87582 | train_accuracy: 0.59265 | val_accuracy: 0.56857 |  0:25:17s\n",
            "epoch 2946| loss: 0.87556 | train_accuracy: 0.5943  | val_accuracy: 0.56897 |  0:25:17s\n",
            "epoch 2947| loss: 0.87605 | train_accuracy: 0.59412 | val_accuracy: 0.56937 |  0:25:18s\n",
            "epoch 2948| loss: 0.87379 | train_accuracy: 0.59398 | val_accuracy: 0.57497 |  0:25:18s\n",
            "epoch 2949| loss: 0.87212 | train_accuracy: 0.59394 | val_accuracy: 0.57457 |  0:25:19s\n",
            "epoch 2950| loss: 0.87051 | train_accuracy: 0.59492 | val_accuracy: 0.57337 |  0:25:19s\n",
            "epoch 2951| loss: 0.87507 | train_accuracy: 0.59532 | val_accuracy: 0.57257 |  0:25:20s\n",
            "epoch 2952| loss: 0.87451 | train_accuracy: 0.5943  | val_accuracy: 0.57057 |  0:25:20s\n",
            "epoch 2953| loss: 0.87432 | train_accuracy: 0.59487 | val_accuracy: 0.57457 |  0:25:21s\n",
            "epoch 2954| loss: 0.8764  | train_accuracy: 0.59518 | val_accuracy: 0.57057 |  0:25:21s\n",
            "epoch 2955| loss: 0.87454 | train_accuracy: 0.59456 | val_accuracy: 0.57337 |  0:25:22s\n",
            "epoch 2956| loss: 0.87661 | train_accuracy: 0.59385 | val_accuracy: 0.57457 |  0:25:22s\n",
            "epoch 2957| loss: 0.87707 | train_accuracy: 0.59447 | val_accuracy: 0.57177 |  0:25:23s\n",
            "epoch 2958| loss: 0.87331 | train_accuracy: 0.59327 | val_accuracy: 0.57177 |  0:25:23s\n",
            "epoch 2959| loss: 0.87319 | train_accuracy: 0.59394 | val_accuracy: 0.56977 |  0:25:23s\n",
            "epoch 2960| loss: 0.87373 | train_accuracy: 0.59305 | val_accuracy: 0.56897 |  0:25:24s\n",
            "epoch 2961| loss: 0.87108 | train_accuracy: 0.59323 | val_accuracy: 0.57217 |  0:25:24s\n",
            "epoch 2962| loss: 0.87416 | train_accuracy: 0.59421 | val_accuracy: 0.56697 |  0:25:25s\n",
            "epoch 2963| loss: 0.87188 | train_accuracy: 0.59443 | val_accuracy: 0.57137 |  0:25:26s\n",
            "epoch 2964| loss: 0.87195 | train_accuracy: 0.59438 | val_accuracy: 0.56657 |  0:25:26s\n",
            "epoch 2965| loss: 0.87412 | train_accuracy: 0.59487 | val_accuracy: 0.56697 |  0:25:27s\n",
            "epoch 2966| loss: 0.87659 | train_accuracy: 0.59545 | val_accuracy: 0.57057 |  0:25:27s\n",
            "epoch 2967| loss: 0.87431 | train_accuracy: 0.59354 | val_accuracy: 0.56977 |  0:25:28s\n",
            "epoch 2968| loss: 0.87159 | train_accuracy: 0.59474 | val_accuracy: 0.57137 |  0:25:28s\n",
            "epoch 2969| loss: 0.86911 | train_accuracy: 0.59567 | val_accuracy: 0.56977 |  0:25:28s\n",
            "epoch 2970| loss: 0.87336 | train_accuracy: 0.59594 | val_accuracy: 0.56897 |  0:25:29s\n",
            "epoch 2971| loss: 0.87327 | train_accuracy: 0.59581 | val_accuracy: 0.57217 |  0:25:29s\n",
            "epoch 2972| loss: 0.87058 | train_accuracy: 0.59616 | val_accuracy: 0.57177 |  0:25:30s\n",
            "epoch 2973| loss: 0.86954 | train_accuracy: 0.59718 | val_accuracy: 0.57017 |  0:25:30s\n",
            "epoch 2974| loss: 0.86976 | train_accuracy: 0.59634 | val_accuracy: 0.56937 |  0:25:31s\n",
            "epoch 2975| loss: 0.87107 | train_accuracy: 0.59652 | val_accuracy: 0.57217 |  0:25:31s\n",
            "epoch 2976| loss: 0.8701  | train_accuracy: 0.59741 | val_accuracy: 0.56657 |  0:25:32s\n",
            "epoch 2977| loss: 0.87204 | train_accuracy: 0.59625 | val_accuracy: 0.56617 |  0:25:32s\n",
            "epoch 2978| loss: 0.87338 | train_accuracy: 0.59589 | val_accuracy: 0.56617 |  0:25:33s\n",
            "epoch 2979| loss: 0.87145 | train_accuracy: 0.59638 | val_accuracy: 0.56857 |  0:25:33s\n",
            "epoch 2980| loss: 0.86927 | train_accuracy: 0.59652 | val_accuracy: 0.57097 |  0:25:34s\n",
            "epoch 2981| loss: 0.87174 | train_accuracy: 0.59625 | val_accuracy: 0.56537 |  0:25:34s\n",
            "epoch 2982| loss: 0.8724  | train_accuracy: 0.59585 | val_accuracy: 0.56617 |  0:25:35s\n",
            "epoch 2983| loss: 0.87113 | train_accuracy: 0.59616 | val_accuracy: 0.56657 |  0:25:35s\n",
            "epoch 2984| loss: 0.87148 | train_accuracy: 0.59465 | val_accuracy: 0.56697 |  0:25:36s\n",
            "epoch 2985| loss: 0.8705  | train_accuracy: 0.59572 | val_accuracy: 0.57297 |  0:25:36s\n",
            "epoch 2986| loss: 0.87188 | train_accuracy: 0.59581 | val_accuracy: 0.57057 |  0:25:37s\n",
            "epoch 2987| loss: 0.8737  | train_accuracy: 0.59483 | val_accuracy: 0.56937 |  0:25:37s\n",
            "epoch 2988| loss: 0.87155 | train_accuracy: 0.59501 | val_accuracy: 0.57297 |  0:25:38s\n",
            "epoch 2989| loss: 0.87292 | train_accuracy: 0.59527 | val_accuracy: 0.56777 |  0:25:38s\n",
            "epoch 2990| loss: 0.87318 | train_accuracy: 0.59567 | val_accuracy: 0.57017 |  0:25:39s\n",
            "epoch 2991| loss: 0.87309 | train_accuracy: 0.59705 | val_accuracy: 0.57257 |  0:25:39s\n",
            "epoch 2992| loss: 0.87334 | train_accuracy: 0.59625 | val_accuracy: 0.56937 |  0:25:40s\n",
            "epoch 2993| loss: 0.86944 | train_accuracy: 0.59554 | val_accuracy: 0.56737 |  0:25:40s\n",
            "epoch 2994| loss: 0.87553 | train_accuracy: 0.59674 | val_accuracy: 0.57097 |  0:25:41s\n",
            "epoch 2995| loss: 0.87166 | train_accuracy: 0.59807 | val_accuracy: 0.57377 |  0:25:42s\n",
            "epoch 2996| loss: 0.87128 | train_accuracy: 0.59607 | val_accuracy: 0.57177 |  0:25:42s\n",
            "epoch 2997| loss: 0.87063 | train_accuracy: 0.59558 | val_accuracy: 0.56537 |  0:25:43s\n",
            "epoch 2998| loss: 0.86734 | train_accuracy: 0.59692 | val_accuracy: 0.56817 |  0:25:43s\n",
            "epoch 2999| loss: 0.87299 | train_accuracy: 0.59492 | val_accuracy: 0.56937 |  0:25:43s\n",
            "Stop training because you reached max_epochs = 3000 with best_epoch = 2707 and best_val_accuracy = 0.58217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/Thesis/Code/callbacks.py:155: UserWarning: Best weights from best epoch are automatically used!\n",
            "  warnings.warn(wrn_msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot mse\n",
        "plt.plot(clf.history['train_accuracy'])\n",
        "plt.plot(clf.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "GwgIrPv5bGHg",
        "outputId": "c54f61a6-53ab-4a5c-d612-171ab9aedb66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f410c1d4550>]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3hUVf7H8fd30uhNglRpUsQGGsG1UQRFdxUVC5a17lr52daCii6irrtY19Vdu1jWtaCrrLKLDcVGCYpIEYyAFCmhhZp+fn/cmWQmuUkmISG54fN6njyZuffMzLmZ5JMz55x7rjnnEBGR4AvVdgVERKR6KNBFROoJBbqISD2hQBcRqScU6CIi9URibb1w69atXZcuXWrr5UVEAmnOnDkbnHOpfvtqLdC7dOlCenp6bb28iEggmdnPZe1Tl4uISD2hQBcRqScU6CIi9YQCXUSknogr0M1suJktNrMMMxtTRpmzzWyhmS0ws1ert5oiIlKRCme5mFkC8AQwDFgFzDazyc65hVFlegC3AUc75zabWZuaqrCIiPiLp4XeH8hwzi11zuUCrwEjSpT5PfCEc24zgHNuffVWU0REKhJPoHcAVkbdXxXeFq0n0NPMvjSzGWY23O+JzOxyM0s3s/TMzMyq1VhEJGB25RbwU+Z2Vm/ZxZTv19TY61TXiUWJQA9gENARmG5mBzvntkQXcs49DTwNkJaWpoXYRaRabdieQ2LIaNEoeY+9pnMOM/Pd97/5a0gMhfjdS7EnUT5zYRrD+uxb7XWJJ9BXA52i7ncMb4u2CpjpnMsDlpnZEryAn10ttRSRvYpzDufgg4XreOTDJdwyvBf7NmsAwHertrBi006SE0LkFTiO6NKS4w/Yl6ydeaTd+1GZz/nuNUfTp30zkhK8jokPFqzlfwvWUljoeGfuLwCkJIY4ev/WLF67jVuG92JE3+LOCOccz3+5nHve84YP//m7AUxdsJaXvvZO3Lx6UHf+/ulPcR1f+vJNNRLoVtEVi8wsEVgCHI8X5LOB85xzC6LKDAfOdc5dZGatgW+Bvs65jWU9b1pamtOp/yJ7t0jr9rMlmVz0/CwePacvs5Zv4tWZK2q7akWW3X8yN7w+tyj0q+qjGweycM1WmqQkcFD75rQJ/4OqLDOb45xL89tXYQvdOZdvZqOBqUAC8LxzboGZjQfSnXOTw/tOMLOFQAFwc3lhLiLFyvvIXhesydrFdyu3MPygdrv1PA9/uITD9mvBwJ6pjH1nPv/0Ce3rX5+7W69RE7reNiXusmNO6s2f//sDAOcP2I8rB3anU6tGRfv3b9Ok2usXrcIWek1RC11q087cfN77bg2n9etAcmLZcwO2ZefRODkRM8gvdITMCBnc9e4CXp7xMy9d2p/jevoufOfLOcenSzJ599vVzFudRbMGScxduYUBXVtxxmEd+OSH9Tx6Tj8KnaNxSvUMca3J2kXbZg1K/dNYvy2b5IQQq7fsok+7ZjH712TtolmDJD5dnMk1r34DwMEdmjN59NFs3JFL6yYpvq9VWOhYumEHc1duoW+n5gx9eDoAL17an4uen1Wl+k+59lj6tG/G/NVZPPv5Ut6Z+wuXHN2FkYd1ZOJXy5k0Z1VR2W/uHEbzhkmEDL5fncXmnXn07diC7bn5TPxyGc98vizmuf86qi99O7Wg8z6N2Zadx5J12zi8cyuOnfAJKzftKrNOU68/jhMfnc4j5xzK6f068skP65j2Qyb3nHYQG7bnkF/gaNu8ai3wipTXQlegy14lv6CQjTtyGfCnj4u23TC0JyP6tueUx79gW3Y+N53Qk98d243TnviSH9Zuq/A5922WwuBebXhttjcZ7Noh+3PjCb1YtXknl06czZJ126tU19l3DKVZw0SWZu7ggHbNyCso5PXZKznniE5F/cDRVm3eiXPQvkVD/vrxjzz28Y++z9usQSJbs/PLfN3zBuwXV5fHN3cOo1Xj4sHHxWu3ceKj0+M4stL2b9OEt646Chw0a5jIik07eWJaBhPOPDSux2/YnkPTBomkJCaUW+6HtVvZsC2Xl75ezhUDu3N455a+5d5MX8nNk+YxYeQh3PLWPAAeP68fx+zfmu05+XRs2cj3cXuCAl32SkvWbSO1SQotGiVxztMzmLVs0x577S77NGL5xp018tz3nX4QZx7ekZTEBJas20bDpASOnTCtRl6rPH07teDfVx/FR4vW8/uXKve3/OKl/RnYM5VI/tRKl9Njh0H2FrhlabnF8goK2bwj1+vzdg7ycyCpZlrf8VCgy17hmxWbOePvX3H3qQfy2yM70+32+Ps+/YQoJIVcduH98Z7RrwNvf+tN8NqncTIbd+RW+Bwp5NLZ1rHEFU8U+/fVR9Fvv5Ys+CWLf85cwZiTerM0cwdNUhIZ+vBncdevbbMGrN2aXcmjqpzbT+7NWYd3YsuuPAY/+Glcj3nmwjTWZu3izneL5k3wf0P2p2PLhpx6aAdy8wtp3iiphmoch+wsaNAcxjX37o/LqvgxmYu9x7x4KmxYDLf+DH89FNIuhaF/rNn6lqBAl2BaMRM6pkHI/2N0YaGjwDn+9vGPPPZJRqWf/oMbjqNRcgJfZmzguS+WleoauTfxOS5I/JiPzlzEkD7tCIWMtVnZmMG+zRowe/kmfvdiOlm78gD48xkHM+SANvS/r7g756GkfzAy4XPcTRlYk4r72ueu3FLpYPdz84m9eGvOKh46+1AO7diCrF153PLWPG47qTeJoRAL12TRrnlDEkLGRc/PIikhFPPPYezJvTmNabQ+8lxIbgzA+q3Z9I/qqirprMM7cv8ZB5OYEMI5x88bd9K+RUNc7nZSJnSC056EvueWX/GPxkGzDtD7N/DV3+C4m6BRq8od/JePQbdB0O6Q4m35OZCfDWu+gxdPgd++Ay+f5u0rGeg7NsKHd8KQsTDrGeh3AfztsNgyx/4BPn+o+P6ZLwAODhrpbe91MqT2hu3roWn1Tk9UoEuZtuzMjeskjM07clm8bhtHdtun2uuwNTuPyXN/4cWvlnPlwO6ccmh7ktekw3PDYPAdMPCWorKzl2/irCe/jvu5kxND5OYX8vrlR3JEl1a89c0qbp40j/t+043ztzwDx98JDb1+1C5j3o957E8p55NgDu5YBx/eBSlNodtA7w+1QQtITObDhev4/UvpPHnB4Qw/qC0Ab8xeSZfWjenftRXu7laYK4DrvoOWXcqv7EsjoGErOOsFrvnnN2zYnsPMZZu4+cReXDWwO6GQlapjxL4JW3nggmPp2LoFS9Zti39GytLP4JN74ZIpfL9mJ/s2S6FFo2SSfp6OvRxe4SMceM45rnh5DucO2I//fb+W19OLTyAf1mdfnrkwDbaugaXT4JBRMPHXcPS10OYArzXbrAMccwMcOgrmvAjt+8K+B0LWKkh/AQ48zQvbaO0O9UK4QXO4KQNWzYIOabFdHs5B+nNw0JmQ1AjuTY2pNwDPD4cVX8PQu+GjP8LhF8OcicXlsrPgz/vF9zMrz3Xfecea3AROuAfeu8Hbfvsv3j+VNy6EtofA8D9V+SUU6HsD57yvUHwrIjvnmLZ4PZdOTOeFS45gcC9vPbVP3n6WT+fM4+yr7+HA9s1wDm57+/uYP16A5X/+dZnPXVDoGPHEF8xfvZUhvdvwt3P7+c7Y2Lg9h6enL+Wp6bF9mMMPbMuDm6+lyab5bOowhCaXvEVyYojtOfncevfdtLYsXiw4sdzjGxz6lvFJE+k4dj6WkFz0cyksdEydv5qT3j7QK9htMFz4jtca/GAsvbInkkMSP41YScLU8MKifS+Aua/EvsCBZ8BZLwCwNHM73VJ9pqN9Pwneusy7/X/fwD7dvdtTboaNP8EFb8HaefDUcTA6HR6P+hs9/i6vFRgRfn+nLlrPFS/P4YahPXnkoyVFu5c3OM+7MeLv0O/8cn82Mf7aFzYvg7MmeuHZsit8/ya8/fviMtHB+NkEOOQccpp2ZFt2ftGJPD/e0Z+kSRfBz1+Wfo3UAyBzUfx1Kkt0CN++BpLDA5Nr5sFTx5YuPy4L5r4K71y1+68dr6RGkBfH2Mmty4saEpWlQN8b3L+f19q59L9xFb910ryYkG7aIJFt2flFwXBU9mOcf+LRPDB1se/jP/nDwJgQG/7odJo1TIoZeDzYlnJ74qv8Nm8MVw7uzePTvG6RqwZ15x8VnFEXqUd6YU/OzB3HtJsGMfjBT4u298qe6H23lbyZPJ7QDfNIatG+qAWb3vQPtM5bAwecAov+A3/cApGBt1nPwJSbil9sXBY8fCBsXcUrA95j+U8LGLvh1op+hLD/UBj1L0gs4xNOpI82otMAKMiFX76t+LnB+2QQaYk+1Bu2rYHRc6D1/oDXBfKfuSv5ae1m/rRwWOzxlGXhZOh8FDRu7d3/Wxps9J8NU+S3/4buQyDjI3hlZMxrdBnzPkYhyxpcEN8xVZekxnDbKnjvOvjmJf8yyU0ht+JZSrXi2Ju8T4dVsFsnFklA5GTBiq/iKpq1K69Ui3tbdj7tKD4X7KsG19JlqresfTO208q2sdE1ZzsNcIQ4/uHPWHD3idz73kI6r/4PS9ceSC6xA13/SRkLwKWF/+XxacW/aiXDvK9lMDH5L1yUOIHBOR9zSuhrZhb2ZkDoB34qbA9QakBucYOLYw/qiTTI28GX13zHup8X0To9GbbghTnA+kWwbx/I2Q67tsQ+dv7bRf3EF8z8Tbk/uxgZHxV/vE+7zPvYH3HMjaXLr5wZ/3MD3Bfue71ttRfmAI8fDme/BC060+aTe7ks48PSj5vxpBfazTt6/c+vX1D8c4joOhAumuz9g6nIy6d734+/q3jbuOZw80/MGTuUpp/cDt9U7tB2W94OGF9BC7cmwvzgs+H7N3b/eRJqZq0ZtdDrqJ25+azbmsN+m75i5+a1rOt6Gvu3aepfOHcH/MkLPu7aVOYgInjdA0Me+oxmbGcXDehrGcx2vTgzYToPJj0VU7ZL9qsMDn3LC8kPFG17JG8kLxUMY2Df3vywdhvXbRzPSQmz2eWSGZTzMDMbjOb1/EGck/hpqecqy+yUq0i1sluV9+RdwHMFJzMw9B0vJv+lzHIVqsstttpwUwY8uH/VHz/i79D3PLi7RfXVqS6LdJtFf/I66QFoezC8ejbkbPV/3NHXeQP8K2cUb7vsQ+jUv0rVUJdLHbFxew7frNjiuyhPQaHj6582ctjWj2mUu5Fb3lvKGwWDi7oY+mQ/z9vXD6N322aln/jfV8J3//Jeo8fZ7HP+M2XWocuY90mzH5iUMr5o21P5v+aKRP/BtvKsdy1oY1sqLogX6BMSn+Kg0HJG5N7D57edSJMv7mVnQYg23/y1wsf/KvtvfN3g/ypdx0Bpfxj8sqeburvpqP/zxh+qonEq7IhaRvu21ZC1Ev5+ZPXUrapu/RkatoA3LoKF73gzbjJ/gP+b4+0vyIN182HXZm8MxgwK8uHjcaV/FgkpcGf48hDZW70+9tzt3vNXkQK9lkVO97510jzWb8th0fjhNEz2WtEFhY7uUfOliwa3gFWuNR1tQ9H9j0bOZ+jB0Qtfhp8/MpMiopw+1JvuuKVUS3xPeL7bI1y61Bvxz2h5HPt37VJ232dd1H0I/PRJ5R7Tqps3mNk41Wu9ZXprfHDGM7GDjuANSF7y3+JPWnXBrcthw4/wxSOwOI45/Re8Da+cAUddC189Bhe/7810ARizAnZs8Fq4b14CC96Gkc/BwWfCylnez6hVV+/n9en90O+3MO91+OQe7/H79IAWnSp+DzoNgDZ94Ngb4dGDY/eV9c/n2rmwZq43+yTjIxhwhbc9Zxss/wJ6nVTxsYNX92n3wfQHvAHt1r2g+2BoUr0XcFOg14KsnXk0TE7gtdkrWLlpZ8waEtcd34NOhSvZmf4vuo24nZn/uo+DQstpzC6OSVhQ5nO+OXgaZw0sng/rnGPcu/O4e+5xsQWjAr2w0LEtO5/mjZK45bn3mLCyEjMg6oth471ph7vj8s+8QeeHesPODTB4LEy7t3S5AVfBzH94t6MHYnds9GZibF0NNywAC8HDBxQ/btBtMGhM6YHU6pR2GbTsDIkN4b83l1+2cSrcHDW3v6J6XTjZm9IZUVjgdf1t/Mmbrrdvn+J929bCx/fArx8q/4zLvOzicYQbf4Bm7eAfx8C678t+THRj5sljYO33XlBf+bm37Z1rimcsdT0OznnFmxJZXZyDJf+DHieU2/W5OxToe5hzrsIV2qJb4vE6r+BuXr3nejZsz+G+9xbS6fvH6RVawa8TSix6FDVvOHrZz2sT3ubGpEmVft1ac8gomPda6e09T4Il8c3mAYrnBpenxwnw4weltw+6HQZFzXjJ3em15jof5R9y47K8edXNOhSHeUR+jjcw2jXqH3DkOe7a7E2t3J1A73cBfPtK2fsjYedc6X7v377jDaJGpk6mHgDXRPX5PtgTtq8r+7kj3RTVLTsL1i2Ezr/y7n/6Z68FP+BKmPmkt23wWEi7BEKJpeuwcpY3Dz4lavypIA9+/ir2H1CAlBfo8U1alkp5Z27J63/Avmzi16EZPqXjN7i9160ycMI0dsx7lxuTJpUOc2D1N/9j4/YcLn5hNu/M/YUQhSxvcF58YX7tXDjrRf99B5xa9uNOr4ZunL7ne10PR14DJ9wHp/wVOpXoTx1yJ5xXIuSPCHdf9Do5dvuvRnsf9Vt2gUPO8Z73rInevoveg+vne7NRTn/av/7jsmLDHLy5z52P8m5fUWIhqubhE1Oadywd5gCJKbFhDnDk1TD8LxWfP3DQSG9Q7vYy1uQ+8X7vI35E7/Bsne5DvK6GP0aNdZSs2xWfe10DrXt47z94LfloNxXPeadV99KvX52t3JLPGwlzgONugZuXwkl/8QYbweteadza/x9Kp/6xYQ6QkBTYMK+Ipi1Ws4JCxw2vf1dq+3spt5NqW/lV/gLG5l9apeduECqAhZNpm7eWp1Meidm3K9SEhoXeqev/eOt/vFJQ3KeeTF7FT95oHzjtH14/Zquu8KZPmbNfgrn/hHevKb3v0FHQZ4TXx/naedCotdc1cfpT8O8rKn79Vt3htL+X3l6y//Goa73vJ9wLH4yFc1+DzkfD5uVw8gPw44dQmFd6HOGMp4tvH3h68e2y1uE44BT/7dHaHQp3boQvH/HOtoy3rzXa8Ptj79+x1mtpJiQVt9Yv+wg6HVFc5nefwLNDvNtN23lTGnsNhxadoXkHb378z1/BD+/B8X/0zsgsaejdsGy6908m+hT5Vl2997mrT+BdPQN+mQs9T4QJXWP37anFtUIhaBw+W3nYeO9LiqjLpZoszdzOM58v41+zSi87ug9ZzGlQw2er3bGuuL8xSpfsVzmtZwqPrhjp/7gjr4FjrvcCPbrPr+RH/7YHw5Vf+O/71Wg48b7i++sWQov9YMbfvRZw5g9ev2JkgMtPWafGr5wNzw31brfqBtdWcFJOzjZv9kGLKpzGHTmupMZe/3FynEukfvmYt/bHUdd6p3tXl21rvfnKJdcyiXSZhBLhrnKuI5Of4wV2TZoz0fsUUJWft1SJTiyqQSVnqUSEKOQ/V6bR7oU0WlnV1sMuYiFwhWXvv2FBmYNLZyZ8xoMryugOOeJ3Fa8p0fZgb2Ap0ef5+1/htXb3K9EtEhkAi6zB0vYgb0Dxl2+9VmO0E++HpIZlr3PS6Qj4/SfwzBBI8ZmyWVJK09IfseN1+adeiFa2pZ12ibca37E+JxPtjqZt/bebxXahlKWmwxy80/GlzlCgl2XLSsa9v5jpaxIZeXhHrh7U3XfN5pe+Xl5q229CX/NQy7dJmbga4v0k2vd8rzujpJHPQYfD4TGfj80RzTuWuavcKYrRa4WU5fLpXuuz/+XF246+Hr581FuLIrp/szxm3kf5qbfDIWfDPvt7U+I6+jY0YqUe4HVvnPxgfK9VVe37Ve1xKU3htCeqty4VqcOXrJPao0Avy6MHMQ6vy+KBqYtZvzWbQb3aMKhXKmZGfkEh363KKroSOUBbNjIjcvLLjkq+Xvt+/oF+8JmwPbP09ojry5nC5ee8N+HVs7zbjeJYOTEUiu1OAW96XUGeN9hWGaEEbzArIp4wB6/ro+QApIiUokCP04tf/8yLX/9M19aNmXbTIB78YAlPfla8JkkKucVhXhWHnO2t4bxzEzx/grftwsne98IyLhc2ZGzl+i4jc3kjyvtI/ofFXl+tn6SGu7X8p4jUDAV62PNfLGP8ewuZfvNgZizbyNlR+w60Zbyfcgdn59zJrA3eySA9vvoD4xMb8mzByUxNvpUZhQf4P3E8rvram54VPfXrkHOKp1Y18Vkg/5ZllVv4P3rWx42LYPPP5Zcvq/9WROosBXrY+PcWAnDZgy+TQi5nRzVejwp5Z28en/ANs/IP4IGpP3Bzgjfj48JEb7W7wQmlpyqWtKDDWRy4Omo+YCjJm2JHiZZwySl3Jeco+818qIxm7b0vEalX9vpALyx0dLt9CuMSJ9LWNjM8YXbM/gsSPsSFRzavSHyf3yTM4Ohpj3FzFa4R27tHT4g+5+i81+Cju70Bwjjt7HEKjc4v42zAyz/z5mGXPCX91uWVrquIBM9eH+h/mrKIlmzl4kSf076Be5NeiLnfwTZyuC3xLVuuQbeRUBB1Qd9IK3z/oZV6mtD+x5e9s31f72v6A96AY+TqMVW8MoqIBMtef+r/mq3ZNCKnUo95K+Xu+AqeGfXP4LhbvBM9IrerqEHvEyoudOd6uGT3rngvIsFT/1vohYXeSTkJsYfqnOPZz5fx/rw1jA73h1erkx+Eg87w5k///KXXDx4J9MjlvyojuYm3jnJCUsVlI37/SXxTE0WkXqjfgf7KSG99Y4CxmWzJ9WbitWyczM2T5jFpzipasZUbE6t5BcKxmcXXmdyne/HFgfPDXS5VufxU5DFWiQ9VHQ6v/OuISGDVv0Dfto7tic1pnJKMRcIc2Jwxk34TvUtEDe6VSpeMl1je4OXqe93oRajKakVHWuhVOSW7QTPYtan8JQBEZK9WbwJ9Z24+ny1YxUnvHspb+cP4S/65LIyaifLMyy8DI2jOdjYsWcoLKdUQ5v2v8E7U+Whc7EyVsk7LztvpfQ9fkLhSfvtvmP+Wd+EBEREf9WZQ9E9TFnHH618DcFHihyxsELtE7S1JrwPwQNJTRVejL+XqGd462RGHjIrdf8uy2Pt9z4OjrvNWIeyYBm0OLL+SzTrEfq+MVt3guJu1hoeIlKnetNBfmbGCQaGfKizX01aVvbNlF+/qJjcuKl6xL/qKOSVP5omsM902fO3Cy6Z6F4Ity7C7Yf/j41/DRESkEgIf6HlbVjP/vSdIZAATkx8ot+zFPXLosrKcy2hFBh6jz6K8+H1o1xdSmlRcmYqWbk1q6F0cQESkBsQV6GY2HPgrkAA865z7c4n9FwMPUHwe5OPOuWersZ6lffYATLuXJKAfcFdixSf7jFt5SfkF/C7q2uWY2Pu9fwOblnpBLyJSh1QY6GaWADwBDANWAbPNbLJzbmGJoq8750bXQB1LWzWn1OntR4ZKVqeGjPJZ4lZEpA6Ip4XeH8hwzi0FMLPXgBHAHkpQH5HrKUbpGSp9YeYK3fiDd83KF072rqUoIhJg8cxy6QCsjLq/KrytpJFmNs/MJplZJ78nMrPLzSzdzNIzM8u5aEN1Ku8alM3aed0sl02F05/cM/UREakh1TVt8T9AF+fcIcCHwIt+hZxzTzvn0pxzaampNTSf+sZF3sJXV8+A6+Z50/3GrKz4cSIiARdPl8tqILrF3ZHYRWBxzkVfevxZYMLuV62KIjNU2kRdcKJB1MWFB46Brsd6V6IXEalH4gn02UAPM+uKF+SjgPOiC5hZO+fcmvDdU4FF1VrLeHUaEF+5LseUnr0iIhJwFXa5OOfygdHAVLygfsM5t8DMxpvZqeFi15rZAjP7DrgWuLimKuwrckX6g0bu0ZcVEalL4upDd85Ncc71dM51d87dF952l3Nucvj2bc65A51zhzrnBjvn9mx/RqRl3qZP2WXO9U79p32/mq+PiEgtCN6ZotklrrfZ+Rg4+Ewv1Fv4Tq7x9BoO188vv4yISIAFb3GuvF2x9y981/seT1ArzEWkHgteoFvx6fmFB55R6kpEIiJ7qwAGenGVQy32q8WKiIjULcELdFzxzcpcX1NEpJ4LXKDvzMktvnPUtbVXERGROiZwgb4rN7/4TvQZoCIie7nABXpCdJeLiIgUCVyg66r3IiL+AhfohYUFtV0FEZE6KXiB7hToIiJ+AhforsDrQy80n+t/iojsxQIX6JEul1mH3ltBSRGRvUvgAt2Fu1ycWugiIjGCF+iF3iwXs8BVXUSkRgUuFYsCPRS4qouI1KjApWJBuA9dLXQRkViBS8VICx210EVEYgQvFdWHLiLiK3CpWOgU6CIifgKXioUF4T50dbmIiMQIXCq6yOJcaqGLiMQIXioWTVvUiUUiItECF+iRxbnU5SIiEitwqagzRUVE/AUuFZ1a6CIivgKXiq7QWz43pBa6iEiMwKWiulxERPwFLhULI9eINqvVeoiI1DWBC3SKzhSt5XqIiNQxwQv0MOW5iEisuALdzIab2WIzyzCzMeWUG2lmzszSqq+KsVzFRURE9koVBrqZJQBPACcBfYBzzayPT7mmwHXAzOqupH/FAvvhQkSkRsSTiv2BDOfcUudcLvAaMMKn3D3AX4DsaqxfKU5NdBERX/EEegdgZdT9VeFtRczsMKCTc+798p7IzC43s3QzS8/MzKx0ZQEs3OmiQVERkVi73W9h3oTwh4E/VFTWOfe0cy7NOZeWmpq6u6+8m48XEalf4gn01UCnqPsdw9simgIHAZ+a2XLgSGByTQ2MOgpr4mlFRAIvnkCfDfQws65mlgyMAiZHdjrnspxzrZ1zXZxzXYAZwKnOufQaqXGE+lxERGJUGOjOuXxgNDAVWAS84ZxbYGbjzezUmq5gKYUaFRUR8ZMYTyHn3BRgSoltd5VRdtDuV6tipha6iEiMwE3mVvtcRMRf4AJdkS4i4i+AgR6hLhcRkWjBC3SdKioi4it4gR6hQVERkRiBC3S1z0VE/AUu0CORrva5iEis4AW6LkEnIuIrcI1NeAUAAAs/SURBVIFevNqiAl1EJFrgAj3CqdNFRCRG4ALdaVhURMRX4AI9kudqn4uIxApcoBe3zxXpIiLRAhfo5nQJOhERP4EL9KIWuhJdRCRG4AJda7mIiPgLXqAXUQtdRCRagANdRESiBTDQNSgqIuIncIHuivrQlegiItECF+giIuIvuIGuPhcRkRiBDXTFuYhIrAAGuuahi4j4CVygR8ZEnbpcRERiBC7Qiy5woU4XEZEYgQv0qGvQ1WotRETqmuAFulZbFBHxFbhA15CoiIi/wAV6hFroIiKxghfoWj5XRMRXXIFuZsPNbLGZZZjZGJ/9V5rZ92Y218y+MLM+1V/Vki8avP9FIiI1qcJUNLME4AngJKAPcK5PYL/qnDvYOdcXmAA8XO01FRGRcsXTzO0PZDjnljrncoHXgBHRBZxzW6PuNqYGxy6Le1zUiS4iEi0xjjIdgJVR91cBA0oWMrNrgBuBZGCI3xOZ2eXA5QD77bdfZeta4rl26+EiIvVOtXVEO+eecM51B24FxpZR5mnnXJpzLi01NbWKr1RY5TqKiNRn8QT6aqBT1P2O4W1leQ04bXcqFQ+d+i8iEiueQJ8N9DCzrmaWDIwCJkcXMLMeUXd/DfxYfVUsQdMWRUR8VdiH7pzLN7PRwFQgAXjeObfAzMYD6c65ycBoMxsK5AGbgYtqstKAOtFFREqIZ1AU59wUYEqJbXdF3b6umuslIiKVFLizc5xWcxER8RW4QC+iM0VFRGIELxU1KCoi4it4gR6mMVERkVjBC3S10EVEfAUv0MNMTXQRkRiBDXQREYkVvEBXl4uIiK/gBXqEpi2KiMQIYCqqhS4i4ieAge7RaosiIrECF+jqQhcR8Re4QI90uWjWoohIrAAGepgSXUQkRvACXX0uIiK+ghfoRQJcdRGRGhC4VFT7XETEX+AC3TQoKiLiK3CBXtyFrkQXEYkWuEBXp4uIiL8ABnqY+lxERGIEMNDVQhcR8RPAQPeogS4iEit4ga4GuoiIr8AFevG0RTXRRUSiBS7QixvoCnQRkWiBC/TIRHTFuYhIrOAFephTl4uISIzABrqIiMQKYKBrLRcRET+BC3QNioqI+AtcoFvRoKgCXUQkWlyBbmbDzWyxmWWY2Rif/Tea2UIzm2dmH5tZ5+qvqqd4sUUFuohItAoD3cwSgCeAk4A+wLlm1qdEsW+BNOfcIcAkYEJ1V7SIpi2KiPiKp4XeH8hwzi11zuUCrwEjogs456Y553aG784AOlZvNX2ohS4iEiOeQO8ArIy6vyq8rSyXAf/122Fml5tZupmlZ2Zmxl9LERGpULUOiprZBUAa8IDffufc0865NOdcWmpqahVfRV0uIiJ+EuMosxroFHW/Y3hbDDMbCtwBDHTO5VRP9XzoEnQiIr7iaaHPBnqYWVczSwZGAZOjC5hZP+Ap4FTn3Prqr2a0cKIrz0VEYlQY6M65fGA0MBVYBLzhnFtgZuPN7NRwsQeAJsCbZjbXzCaX8XS7TdMWRUT8xdPlgnNuCjClxLa7om4PreZ6iYhIJQXvTFFdskhExFfgAl2DoiIi/oIX6FptUUTEVwADPUKJLiISLbCBrjgXEYkVuEB3ToOiIiJ+AhfoERYKbNVFRGpE4FJR0xZFRPwFLtCdpi2KiPgKXKBrtUUREX8BDPQwTUQXEYkR2EBXnouIxApeoGvaooiIr+AFepgFt+oiIjUigKmoFrqIiJ8ABrrHqRNdRCRGYANd8xZFRGIFLtC1louIiL/ABXqEqctFRCRG4AJda7mIiPgLXKBHmDrRRURiBDDQ1UIXEfETvECP5Ln60EVEYgQv0MOU5yIisQIX6E5dLiIivgIX6BEaFBURiRW8QNeJRSIivoIX6GEWUgtdRCRaYANdRERiBS7Qf9WtFQCNkhJruSYiInVL4AK9iOYtiojEiCvQzWy4mS02swwzG+Oz/zgz+8bM8s3szOqvZpR9ekCf08ASavRlRESCpsJ+CzNLAJ4AhgGrgNlmNtk5tzCq2ArgYuCmmqhkjN4ne18iIhIjno7o/kCGc24pgJm9BowAigLdObc8vK+wBuooIiJxiKfLpQOwMur+qvC2SjOzy80s3czSMzMzq/IUIiJShj06KOqce9o5l+acS0tNTd2TLy0iUu/FE+irgU5R9zuGt4mISB0ST6DPBnqYWVczSwZGAZNrtloiIlJZFQa6cy4fGA1MBRYBbzjnFpjZeDM7FcDMjjCzVcBZwFNmtqAmKy0iIqXFdbqlc24KMKXEtruibs/G64oREZFaEtwzRUVEJIa5WlqO1swygZ+r+PDWwIZqrE5t0rHUTfXlWOrLcYCOJaKzc853mmCtBfruMLN051xabdejOuhY6qb6ciz15ThAxxIPdbmIiNQTCnQRkXoiqIH+dG1XoBrpWOqm+nIs9eU4QMdSoUD2oYuISGlBbaGLiEgJCnQRkXoicIFe0dWT6hozW25m35vZXDNLD29rZWYfmtmP4e8tw9vNzB4LH9s8Mzusluv+vJmtN7P5UdsqXXczuyhc/kczu6gOHcs4M1sdfm/mmtnJUftuCx/LYjM7MWp7rf7+mVknM5tmZgvNbIGZXRfeHrj3pZxjCeL70sDMZpnZd+FjuTu8vauZzQzX6/XweliYWUr4fkZ4f5eKjjEuzrnAfAEJwE9ANyAZ+A7oU9v1qqDOy4HWJbZNAMaEb48B/hK+fTLwX8CAI4GZtVz344DDgPlVrTvQClga/t4yfLtlHTmWccBNPmX7hH+3UoCu4d+5hLrw+we0Aw4L324KLAnXN3DvSznHEsT3xYAm4dtJwMzwz/sNYFR4+5PAVeHbVwNPhm+PAl4v7xjjrUfQWuhFV09yzuUCkasnBc0I4MXw7ReB06K2v+Q8M4AWZtauNioI4JybDmwqsbmydT8R+NA5t8k5txn4EBhe87WPVcaxlGUE8JpzLsc5twzIwPvdq/XfP+fcGufcN+Hb2/AWzOtAAN+Xco6lLHX5fXHOue3hu0nhLwcMASaFt5d8XyLv1yTgeDMzyj7GuAQt0Kvt6kl7kAM+MLM5ZnZ5eNu+zrk14dtrgX3Dt4NwfJWte10/ptHhrojnI90UBORYwh/T++G1BgP9vpQ4Fgjg+2JmCWY2F1iP9w/yJ2CL81asLVmvojqH92cB+7CbxxK0QA+iY5xzhwEnAdeY2XHRO533OSuQc0eDXPewfwDdgb7AGuCh2q1O/MysCfAWcL1zbmv0vqC9Lz7HEsj3xTlX4Jzri7fybH+g956uQ9ACPXBXT3LOrQ5/Xw/8G++NXhfpSgl/Xx8uHoTjq2zd6+wxOefWhf8IC4FnKP5oW6ePxcyS8ALwn865t8ObA/m++B1LUN+XCOfcFmAa8Cu8Lq7IMuXR9Sqqc3h/c2Aju3ksQQv0QF09ycwam1nTyG3gBGA+Xp0jswouAt4N354MXBiemXAkkBX1MbquqGzdpwInmFnL8EfnE8Lbal2J8YnT8d4b8I5lVHgmQlegBzCLOvD7F+5nfQ5Y5Jx7OGpX4N6Xso4loO9Lqpm1CN9uCAzDGxOYBpwZLlbyfYm8X2cCn4Q/WZV1jPHZkyPB1fGFN2q/BK9/6o7ark8Fde2GN2L9HbAgUl+8vrKPgR+Bj4BWrnik/InwsX0PpNVy/f+F95E3D68v77Kq1B24FG9wJwO4pA4dy8vhus4L/yG1iyp/R/hYFgMn1ZXfP+AYvO6UecDc8NfJQXxfyjmWIL4vhwDfhus8H7grvL0bXiBnAG8CKeHtDcL3M8L7u1V0jPF86dR/EZF6ImhdLiIiUgYFuohIPaFAFxGpJxToIiL1hAJdRKSeUKCLiNQTCnQRkXri/wE1spOPBir8sAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}